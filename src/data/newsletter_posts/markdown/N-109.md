# 109

#

“ _Which professions are safe from being replaced by AI?_ ” is a common question.

From my perspective, you should either specialize in building on top of AI, or focus on the areas that AI is unlikely to touch.

Creative arts, diplomacy, craft, sports, relationships – embodied forms of intelligence will always be required by others. People with skin in the game. Liability and trust. I can’t imagine such areas being affected by automation in our lifetimes. The importance of nurturing these qualities will only increase as the middle is hollowed out.

Everything else is up for grabs.

If your work can be augmented by AI today, it will be automated soon.

Knowledge workers are effectively providing training data back to AI (while we pay for the privilege) and there is no question about what frontier AI labs consider AGI – autonomous systems that replace human labor.

My own approach has been one of maximizing AI exposure on many dimensions, mainly coding. I have tried automating all possible aspects of work and landed on software development as my highest-leverage activity. From the dozen or so pilots launched in the last two years, two projects have stood out: [Signals](https://newsletter.envisioning.io/p/futures-collapse-105) and Purpose.

_Purpose_ is an AI-infused experience which helps people expand their self-perception and find the intersections between various areas of their life, using the “Ikigai” framework.

_Purpose_ went through half a dozen iterations before settling on its current version: a fully offline iPhones app running on the upcoming iOS 26, using local computation.

Most AI models work through the internet – you upload input data and wait for the response from the nearest cloud server. These servers are beefy computers, with loads of RAM and GPUs which quickly respond to your request through models with billions of parameters. Your phone has much less computational capacity, but we have finally reached the point where you can reliably use LLMs offline on modern hardware. This allows for 100% private conversations or data stores, which is particularly important for sensitive information.

iOS 26’s [Foundation Models](https://developer.apple.com/documentation/foundationmodels) were announced last Monday (and discussed live in our [WhatsApp](https://chat.whatsapp.com/FOirxUglTn6Fx7XD2iUm4L)). On Thursday I decided to try porting my current iOS Purpose app away from Google Gemini online onto using local computation. Replacing Gemini with local inference took ~30 minutes in Cursor to reach a working POC.

###### _ **LLM running offline on iPhone 15 Pro.**_

The rest of my weekend was spent fine-tuning, and generally cleaning up the app (called NavigateWithin). The premise of the app warrants a few other future posts, but in short I am exploring approaches for helping people navigate “inner knowledge” with the help of AI. Relying on online language models means less privacy and significant costs – so you can imagine my relief knowing that current and future phones will be able to run limited but fully private inference locally.

The app will likely launch alongside iOS 26 in a few months. If you are running the iOS beta and open to testing the app, please reach out.

I am not suggesting everyone should learn to code with AI, but you should definitely consider which possibilities are being unlocked that were previously unavailable to you.

Until next week,
MZ

P.S. If you are in São Paulo next week, don’t miss our [AI & Foresight meetup](https://lu.ma/rhz83cuu) on Tuesday )(24).

* * *

* * *

#### AI is helping us sleepwalk into social isolation (12 min).

[Big Think](https://youtu.be/fsaeFYGbK2M).

* * *

#### Interview with Cursor founder Michael Truell on YC (37 min)

[They just landed investment valued at $9B](https://youtu.be/oOylEw3tPQ8).

* * *

#### How the universe thinks without a brain (22 min)

[Shared by Richard Wolf](https://youtu.be/jwr1EOvAxQI).

* * *

#### The Economics of AI (42 min)

Excellent [lecture by economist Tyler Cowen](https://youtu.be/XSy7ry-x5pA) (a self proclaimed AI maximalist) about the likely implications of our new thinking machines.

* * *

Self-adapting Learning Models

* * *

Why Meta missed the boat on large language models and how they're trying to catch up:

* * *

* * *