# 101

#

I was taught that my life trajectory would include learning about the world until a certain age, and then apply those learnings to become a useful member of society throughout the rest of my life.

At no point was there a conversation about how to keep _learning about learning_ and the importance of changing my abilities to keep pace with the world around me.

AI shatters this concept and creates space for unlimited upskilling in areas of my life I never considered possible. In the past year, that has meant becoming a full-time software developer. No longer limited by my impatience for writing software line by line, instead I build complexity by endlessly iterating and improving tools for myself and others.

The most exciting of these apps has been **Signals** , our generative approach for scanning signals of change.

Integrated with Envisioning and our incredible data visualization tools, our platform takes you from a few inputs to a complete overview of signals affecting the future of your organization in minutes.

Data is collected from multiple AI models, including OpenAI, Anthropic, Mistral, Google, DeepSeek and Perplexity, and taken through an enrichment and validation process to help you see everything that is out there and prioritize on where to act.

This Thursday (April 24) I’m hosting a quick Webinar to showcase the platform.

At [10 CET in English](https://lu.ma/493kd6bs) and [14 BRT in Portuguese](https://lu.ma/i83cexys).

Next session is [May 8 at 19 CET](https://lu.ma/ew4k3pt0).

Between Lu.ma and [LinkedIn](https://www.linkedin.com/events/envisioningsignalsdemo7318177501799702538/comments/), we have over 150 registrations this Thursday, and would love to see you there\!

The tool is interesting mainly for futurist and innovation researchers who want to leverage AI in their work. We’re still developing the business model, and are looking for a handful of agencies and consultancies to partner with in testing the platform. LMK if that’s you.

Everyone joining the Webinars will receive access to a customized generative Radar.

We want to get facilitators and practitioners from the community involved early in the design process to make sure this approach serves us all.

Until next week,
MZ

* * *

* * *

#### I wonder if butler is the best metaphor for home robots but here we go (14 min).

[NEO on TED](https://youtu.be/p3uBMqCPSDk).

* * *

#### Mustafa Suleyman, Microsoft's recent AI lead on Jules Terpak (60 min)

[Insightful interview](https://youtu.be/D3rtIZV6wB0).

* * *

#### Community Meetup on April 29 (Lisbon)

Join [Emma G. Möller, Allegra Guinan and myself in Lisbon](https://lu.ma/sqnafh8x) for **Responsible AI Horizons** next weeonk the evening of **April 29**. Emma and Allegra, co-founders of Lumiera, are recognized pioneers in AI responsibility and governance. Together we are hosting an intimate evening for foresight and innovation experts. I will present our new Signals tool and together we’ll go deep into the consequences of AI and AGI for our industry. Join us if you want to be part of this conversation. [Sign up on Luma](https://lu.ma/sqnafh8x). Newsletter readers have a 20% discount code: **EVNL20X**. Hope to see you there\!

* * *

[Very good detailed explanation of OpenAI o3 and o4-mini](https://youtu.be/sq8GBPUb3rk):

* * *

####

* * *

#### Quick links

* [Pretty technical but incredibly useful list of Cursor techniques](https://x.com/ericzakariasson/status/1910354619651518662).

* [Great guide for using Claude Code by Anthropic](https://www.anthropic.com/engineering/claude-code-best-practices).

* HBR: [How People Are Really Using Gen AI in 2025](https://hbr.org/2025/04/how-people-are-really-using-gen-ai-in-2025)

* * *

#### Long read about AGI

* * *

#### AI + XR (16 min)

Presentation by Google's Shahram Izadi [about their efforts in XR+AI](https://youtu.be/gElClXpg4J0). Exciting\! I'm incredibly impressed. Had seen clips from this on X during the week, but this demo is amazing. Helpful AI + Lightweight XR = Augmented Intelligence.

* * *

Google undercutting everyone

* * *

* * *

* * *

* * *