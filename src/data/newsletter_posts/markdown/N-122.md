# 122

#

Welcome to your weekly download of memes and insights.

I am trying to organize observations about how I work with AI into somewhat of a framework. Two weeks ago I wrote about [how I think with AI](https://newsletter.envisioning.io/p/dont-believe-everything-you-think), last week about [how I create with AI](https://newsletter.envisioning.io/p/its-not-x-its-y-121), and this week I’m focusing on how I build.

If creating turns ideas into form, building turns form into function.

The gap between a prototype and a working system is filled with decisions: how data moves, where logic lives, what breaks and why. Building with AI means treating architecture as conversation: describing intent until structure emerges.

What surprised me most about building with models is how much happens before code. When I explain what I want a system to do, the model shows me what I haven’t decided yet: the missing schema, the unclear dependency, the workflow I assumed was simple.

This literalness is the leverage. AI build for you by reflecting your specifications back with enough precision to reveal what you left implicit. The clearer the explanation, the closer the implementation lands to what you meant. Even when what you want isn’t what you need.

These field notes document how I am actually using AI, based on ChatGPT’s interpretation of our many conversations, coupled with a Cursor code repository with all my newsletter writing, both of which are used to document the behaviors I display according to the various AIs I interact with.

How I _build_ with AI:

* **Product design reasoning:** Before touching an interface, I describe how a feature should behave – user intent, friction points, edge cases. AI helps expose assumptions and clarify purpose before design locks in decisions that are expensive to reverse.

* **Interface sketching:** I prototype flows entirely in language: what each screen does, what happens next, where feedback appears. Testing logic through conversation catches problems that wireframes miss and turns vague ideas into verifiable sequences.

* **Architecture discussion:** When deciding what lives where – server, client, local inference – I talk through the tradeoffs with AI. It doesn’t choose for me, but it makes structure tangible enough to evaluate stability, complexity, and constraint.

* **Workflow automation design:** I map full sequences before automating: triggers, data sources, transformations, outputs. The exchange turns scattered logic into a blueprint I can implement in steps, reducing confident mistakes from oversized prompts.

* **Error explanation:** Instead of jumping to fixes, I ask AI to explain what failed and why. This builds debugging intuition over time. I’m solving the current error by learning the pattern behind it.

Building becomes deliberate when you design through explanation. The model holds your intent steady while you refine it into working systems.

As trite as it sounds, AI doesn’t build for us – it builds _with_ us, one augmented thought at a time.

Until next week,
MZ

* * *

#### Navigating Manifolds (50 min)

[Dense conversation about AGI](https://youtu.be/uRuY0ozEm3Q). Are LLMs creating knowledge—or just surfing known manifolds? A deep dive on entropy, chain-of-thought, and why true AGI means inventing new science, not just predicting the next token.

* * *

This essay by Jack Clark is trending:

* * *

#### The 1% Apocalypse: Eliezer Yudkowsky on AI’s Endgame (1h08)

[Ezra Klein interview with Eliezer Yudkowski about AI doom](https://youtu.be/2Nn0-kAE5c0). If you’ve ever wondered whether AI’s “helpfulness” could evolve into something uncontrollable, this is a must-watch.

> _This is not a technology that we craft. It’s something that we grow._

* * *

#### Teaching Humans to Think in the Age of AI (22 min)

[Professor Po-Shen Loh about how to better use our thinking after AI more or less takes over](https://youtu.be/xWYb7tImErI). Loh shares why writing, reasoning, and caring about others may be humanity’s last competitive advantage—and how he’s training a generation of thoughtful leaders to keep us human. _Can we still think for ourselves?_

* * *

#### Andrej Karpathy: Teaching Humans in the AI Era (2h26)

[Karpathy on the future of learning](https://youtu.be/lXUZvyajciY): AI won’t replace teachers—it’ll become the perfect tutor. Education will feel like the gym: fun, personalized, and addictive. His goal? Build _Starfleet Academy_ for the AI age, where learning gives humanity its edge.

> _A great tutor gives you the perfect information at the perfect time. That’s the bar for AI education._

* * *

####

* * *