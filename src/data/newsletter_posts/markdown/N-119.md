# 119

#

When the future whispers, what does it say?

There are as many ways of imagining the future as there are people trying. We inform ourselves, visualize, and backcast from the present to picture possible tomorrows.

LLMs are poor at this work: they excel at interpolation – blending what exists, but falter at extrapolation – the invention of new modes and systems. Some people, more comfortable with ambiguity, are attuned to discontinuity. For them, more futures are possible, and they are more likely to thrive when things get weird.

Solarpunk skyscrapers are practically a trope, an easy shorthand for the future. Media and language models alike default to park cities and green urbanism. Pleasant, yes, but revealingly narrow. Such recurring imagery exposes the limits of our collective imagination, the ways we design futures by recycling what feels safe.

AI itself is an imagined technology, a collective desire so strong it became inevitable. Whether envisioned as a voice in your head or a smooth-skinned android on deck, these futures show less about what’s possible and more about the boundaries of the present. Imagination, however wild, remains tethered to context. And AI rarely helps us cut the cord.

Those who want to reshape the future must step outside convention and open to discontinuity. Art, nature, psychedelics – whatever cracks the frame – remind us the futures worth creating don’t emerge from the center, but from the periphery. They arrive nonlinear, strange, and unexpected.

What does this mean for you?

The real work of imagining futures is about cultivating the capacity to sit with the strange, to invite in the discontinuous, to listen from the edges.

That futures worth living will not be generated by default settings, but by willing to step beyond them.

Until next week,
MZ

P.S. If you’re drawn to exploring futures from the edges, don’t miss our [Artificial Insights WhatsApp](https://chat.whatsapp.com/FOirxUglTn6Fx7XD2iUm4L) community.

* * *

* * *

* * *

#### Reasoning like us

Quantum computing expert [Scott Aaronson](https://scottaaronson.blog/?p=9183) says GPT5-Thinking is remarkably close to human researcher skills.

> I had tried similar problems a year ago, with the then-new GPT reasoning models, but I didn’t get results that were nearly as good. Now, in September 2025, I’m here to tell you that AI has finally come for what my experience tells me is the most quintessentially human of all human intellectual activities: namely, proving oracle separations between quantum complexity classes. Right now, it almost certainly _can’t_ write the whole research paper (at least if you want it to be correct and good), but it _can_ help you get unstuck if you otherwise know what you’re doing, which you might call a sweet spot. Who knows how long this state of affairs will last? I guess I should be grateful that I have tenure.

via [/r/singularity](https://old.reddit.com/r/singularity/comments/1nswhei/oai_researcher_tweets_out_blog_from_quantum/)

tl;dr: _you still need expertise to determine what’s right, but the degree of autonomy that reasoning models display is changing how much we can rely on them (which will only increase)._

* * *

#### Quick Links

* I got to hang out with legendary AI artist Ari Kuschnir the past few days at [THNK](https://www.thnk.org) FSTVL here in Amsterdam, which this week’s newsletter intro was written around. Ari creates unbelievable AI videos in multiple flavors, from surreal political commentary to documentaries about events that were not recorded. If you are not yet familiar with his work, spend a couple of minutes on his [Instagram feed](https://www.instagram.com/arikuschnir/) for glimpses of possible futures.

* [The next AI bubble is about to burst](https://wlockett.medium.com/the-ai-bubble-is-about-to-burst-but-the-next-bubble-is-already-growing-383c0c0c7ede) via Carrie Beehan.

* [Agents of change](https://www.fastcompany.com/91409743/ready-for-the-agents-of-change) via Igor Botelho.

* [Attorney Slapped With Hefty Fine for Citing 21 Fake, AI-Generated Cases](https://www.pcmag.com/news/attorney-slapped-with-hefty-fine-for-citing-21-fake-ai-generated-cases) via Alex Kustov.

* [Mira Murati bridges several concerns and groups simultaneously](https://www.linkedin.com/pulse/how-scholarship-student-from-post-communist-albania-can-adxde) via Moulsari Jain.

* [Why Silicon Valley hasn’t quit LLMs](https://www.linkedin.com/posts/kurtcagle_why-silicon-valley-wont-quit-llms-even-activity-7375387763979968512-X6sK) via Parthasarathi.

* [SheBuilds on Lovable](https://www.linkedin.com/posts/elenaverna_womenintech-activity-7375913241954275328-Nkuf?utm_source=share&utm_medium=member_android&rcm=ACoAABLosTkBVLi8suJBW0mHDQVqbpgKQ91ulG8) via Sander Bogers.

* [Using GPT-5 codex to improve my website in an hour](https://pherkan.com/posts/using-gpt5-codex-to-improve-website-in-an-hour/), not days via

.

* [Why China said ‘no’ to stripped-down Nvidia chips](https://www.scmp.com/opinion/china-opinion/article/3326186/why-china-said-no-stripped-down-nvidia-chips) via Guilherme Kujawski.

* Introducing [Google Mixboard](https://youtu.be/6mTWfthVXJs) via

.

* * *

#### The Bitter Lesson (67 min)

[An hour with Richard Sutton](https://youtu.be/21EYKqUsPfg) about why LLMs are probably a dead end. Via

.

* * *

#### Meta’s vision of entertainment is an infinite slop machine

[Don’t miss the replies](https://x.com/alexandr_wang/status/1971295156411433228).

* * *

* * *

* * *

#### Someone built and trained an LLM using redstone in Minecraft (3 min)

<https://x.com/tokenbender/status/1972381941933674596>

[YouTube version](https://youtu.be/VaeI9YgE1o8).

* * *

* * *