# 080

Happy Monday and welcome to your weekly snapshot from the cutting edge of unexpected repositioning efforts.

These weeks have been about presenting the AI masterclass to all sorts of audiences, with a surprisingly positive response.

I haven’t figured out how best to scale up the ideas of the presentation, as [hour-long lectures](https://youtu.be/kwQ79E0DyZo) don’t exactly resonate on YouTube. It is difficult to focus on _anything_ for a full hour, and maybe something we increasingly leave for live meetings? Or is the conversation around the ideas the valuable bit?

If you have an enthusiastic audience looking to upgrade their AI skills, please reach out. I am happy to present the ideas with an eager public anywhere, and want the framework to scale to benefit as many people as possible.

Until next week,
MZ

* * *

* * *

#### A bit of phenomenology to start the week \(2h30\)

[Nora Belrose on how AI models learn](https://www.youtube.com/watch?v=VgPrjHxIS0I) from simple to complex patterns, the challenges of erasing biases while preserving functionality, and the philosophical connections between meaning, consciousness, and the material world.

> _When models just become really big and complex, they become inscrutable monsters, and all of our efforts get resisted because they always find a way to do what they want to do._

* * *

#### Future artificially intelligent relationships \(25 min\)

[Primer on AI compations by Emily Chang](https://www.youtube.com/watch?v=_eNnUUh6-J8) on Bloomberg.

* * *

#### Pioneering Pathways to AGI and Beyond \(35 min\)

The Lightcone podcast is consistently insightful on where the industry is heading. [This edition is no exception](https://www.youtube.com/watch?v=JiwiqYGw4iU).

Don't miss [Diode](https://diode.computer), the startup enabling AI generated printed circuit boards. Generative circuits might seem uninteresting on the surface but consider when software and hardware starts self-improving. It's remarkable how O1 enables whole new categories of possibility.

[Diana Hu](https://sdianahu.com) runs circles around the others IMO. She's on a whole other level.

> _If the scaling laws hold, far more difficult engineering challenges, such as room-temperature fusion, could become solvable._

* * *

#### Dwarkesh Patel interview with the anonymous Gwern \(90 min\)

[Gwern shares their views on the perks of anonymity](https://www.youtube.com/watch?v=a42key59cZQ), automation, and intelligence as "search."

> _I maximize rabbit holes._

* * *

#### Agentic Reasoning \(25 min\)

[This is an excellent keynote](https://www.youtube.com/watch?v=KrRD7r7y7NY) about [SOTA](https://www.envisioning.io/vocab/sota-state-of-the-art) agentic workflows from the venerable Andrew Ng. So many insights. "AI is like electricity" and his framework for the AI tech stack are spot on.

* * *

#### Figure 02 autonomous robot fleet at BMW factory \(90 sec\)

[Source](https://www.press.bmwgroup.com/deutschland/article/detail/T0444264DE/erfolgreicher-testeinsatz-humanoider-roboter-im-bmw-group-werk-spartanburg) and [Reddit](https://old.reddit.com/r/OpenAI/comments/1gv48sq/figure_02_is_now_an_autonomous_fleet_working_at_a/).

> _4x speed increase, 7x reliability increase._

* * *

#### AI for science \(55 min\)

If you are curious about [how AI is shaping science](https://www.youtube.com/watch?v=nQKmVhLIGcs), don't miss this panel by Google DeepMind.

* * *

#### AI models work together faster when they speak their own language

[Droidspeak on NewScientist](https://www.newscientist.com/article/2455173-ai-models-work-together-faster-when-they-speak-their-own-language/) via [Chubby on Twitter](https://x.com/kimmonismus/status/1860693803494990046).

> _Letting AI models communicate with each other in their internal mathematical language, rather than translating back and forth to English, could accelerate their task-solving abilities_

* * *

#### Facebook never disappoints \(60 sec\)

* * *

* * *