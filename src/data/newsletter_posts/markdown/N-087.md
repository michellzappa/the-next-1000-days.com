# 087

Happy Monday and greetings from sunny São Paulo, where I’m spending a couple of days with family and later today with fellow AI nerds.

There are weeks where writing this newsletter feels like a broken record: AI is changing everything \(\!\), the changes are irreversible \(\!\!\) and the best time to change your own attitude to AI is now \(\!\!\!\). While people like us are mostly on board with believing and even welcoming this change, I suspect most people are not only unprepared but also unaware that something is even happening. Some might experience joblessness they hope is temporary, others might find themselves in slowly shrinking areas of opportunity. Some areas of the economy, like consulting and marketing, feel irreversibly affected already, while the service economy and other real-world sectors like construction and healthcare remain relatively insulated for now.

The ripple effects are inevitable, and these industries will also face profound shifts as AI continues to mature. The question isn’t whether these changes will happen but how quickly and decisively they will transform our sense of purpose and identity. I don’t suppose any of this will decelerate, nor is it clear where long term value will be built.

* _Is it more valuable to build something of your own, or to license others’ tech?_

* _Is it better to learn how to leverage these forms of intelligence to enhance your current work, or should you pivot to something entirely new?_

* _Is it better to teach others, or to maximize your self-knowledge?_

None of these questions have easy answers, and my guess is as good as yours.

While all of this unfolds, the only thing I can comfortably recommend is that you remain close to the conversation. You are already informing yourself by following this very publication and probably many others. Engage your peers, involve your community and get more people into the conversation. A new year is ahead of us, so what better time to start your own _thing_. Whether it’s a newsletter, a TikTok or a meetup group – the opportunity space around AI will undoubtedly grow in 2025, so the safest thing in terms of maintaining our collective relevance is to find your own way of learning/teaching to ensure more people fall on the right side of our transition.

If you are in São Paulo, we are hosting a reader meetup from [18:00-20:00 at Botanikafé Jardins today](https://maps.app.goo.gl/F5jQ5QesqzwE7sFcA). Venham\!

Until next week,
MZ

* * *

* * *

#### Prompting chain-of-thought models

Using O1-like models \(and in my experience Claude Sonnet “3.6”\) favors a different approach than the chat we are used to. [Dan Mac calls it a skill issue](https://www.latent.space/p/o1-skill-issue). Specificity begets quality. [Don’t miss this thread](https://x.com/daniel_mac8/status/1878283032215408886) going through some implications.

1. Don’t Write Prompts; Write Briefs

2. Focus on Goals: describe exactly WHAT you want upfront, and less HOW you want it

3. Know what o1 does and does not do well

* * *

#### Reading List

* Some AI researchers sound like prophets of imminent superintelligence. With his usual insight, [Ethan Mollick](https://www.oneusefulthing.org/p/prophecies-of-the-flood) asks us to measure the hype, how fast organizations can really move, and whether we should take these forecasts more seriously.

* Politics, climate, AI, and collapsing birth rates is affecting everything everywhere. This [opinion piece](https://www.nytimes.com/2025/01/12/opinion/ai-climate-change-low-birth-rates.html) by Ezra Klein connects the dots between global shifts that once seemed separate, offering a bracing look at the road ahead.

* Autonomous AI agents are stepping out of theory and into practice. [Huyen Chip’s quick tour of how foundation models](https://huyenchip.com//2025/01/07/agents.html) can handle tasks from start to finish and potentially reshape your workflow.

* Chat-First Development. If Copilot’s in-your-face suggestions felt off, try a chat-driven approach. Smaller asks and tighter prompts keep control in your hands while still tapping the best of LLM coding help, an excellent post by [Shekhar Gulati](https://shekhargulati.com/2025/01/07/chat-first-development-a-better-way-to-use-llms-for-coding/).

* A year with LLMs for coding, searching, and brainstorming: one developer’s honest diary. The verdict according to [Chris Crawshaw](https://crawshaw.io/blog/programming-with-llms)? They’re not magic, but they do lighten the load and open new doors for everyday programming.

* * *

#### AI Brain Dance

If you are interested in exploring approaches for having AI make sense of large quantities of custom data, you should absolutely not miss Amy Daroukakis and Iolanda Carvalho’s event this week. They lead a yearly initiative of collecting and sharing open-source trend reports, and last year me and a few other AI nerds thought of applying our skills to making sense of these tens of thousands of slides. The results were incredibly insightful and our approaches all over the place. This year they have doubled down on the hackathon and are [hosting two sessions later this week](https://www.linkedin.com/posts/amydaroukakis_save-the-brain-dance-x-date-event-call-in-activity-7282439716921081858-ghhx/) at 12pm and 6pm GMT on Wednesday. Unfortunately I did not have time to implement my own solution this year but will see you there\!

* * *

#### **Algorithmic Evolution \(2h\)**

Fascinating deep dive with [AI professor Jeff Clune](https://youtu.be/mw5WIDGRLnA?si=siAedOpTbHjfD5Lu) into the parallels between evolution, culture, and how we can use those ideas to design algorithms that innovate endlessly. He talks about how open-ended systems could create alien intelligence, why randomness and serendipity are crucial for breakthroughs, and how foundation models are now learning what humans find interesting. Worth the listen.

> _One of the grand challenges of computer science—and biology—is understanding how evolution created this explosion of diversity, like jaguars, the human mind, or three-toed sloths._

* * *

* * *