# 096

Happy Monday, and kudos to you for caring so much about AI and this pivotal moment.

Nearly everyone I talk to is shocked by the pace of accelerating change. We have no frame of reference for such rapid transformation, and to many, it feels like AI is reaching a crucial stage in our development. Every generation experiences unprecedented change to some extent, but as we climb the exponential curve, our sense of certainty erodes faster than ever. The key to thriving in times like these is knowing which outdated beliefs to discard and which to hold onto. If everything is fluid, how do we know what’s true?

You probably already rely on AI to help you decide—I know I do.

But if we trust AI more than ourselves, how do we know when to listen to it? And how many times should we challenge its responses before accepting them? Language models are inherently sycophantic—they mimic us—so they struggle to push back when we need them to.

Maybe you’ll take ethical advice from one model while your partner prefers another. Responses will sometimes converge, sometimes diverge, influenced by factors beyond our perception. Yet, I suspect we’ll increasingly listen to them without much intellectual resistance.

How this plays out depends on how we integrate non-human intelligence into our lives. Workplaces, schools, governments, personal devices—everything we interact with today is getting a fresh coat of AI. And in a few decades, today’s technology will seem as quaint in 2050 as the 1800s feel to us now. The next 25 years will bring more change than the last 225. Nobody knows how, but don’t doubt for a second that it will.

The best way to keep up? Embrace uncertainty, stay informed, and get involved. If nothing is predictable, favoring a single outcome or approach is a mistake. Following the cutting edge helps you see how quickly possibilities emerge. Learning and sharing with others helps us understand where help is needed. That’s really all there is to it.

—

Last week, we hosted the first **Amsterdam Vibe Coding** event—six wildly different presentations of personal coding projects to a packed room of AI enthusiasts and free thinkers at the Embassy of the Free Mind. It was a blast\! I’m constantly surprised by how many non-technical audiences are showing up to these sessions, which means I’m always recalibrating the story to make it accessible. There are countless ways to be technical, and finding common ground that everyone can climb together is crucial. So many insights to apply to our upcoming **Coding Club** online sessions on [April 3](https://lu.ma/2od0hbz0) and [April 10](https://lu.ma/ozk8a84b).

Our **Foresight Exchange** group is also picking up steam. We will soon start onboarding early users of our Envisioning Signal Generator _deep research_ tool. Join us if you are interested in joining the next batch of testers.

Until next week,
MZ

* * *

* * *

### The best links from the community

* **Chris:** _I just watched this.[It’s kind of a part 2 to the AlphaGo documentary, going back to Demis’s youth and forward to AlphaFold](https://www.imdb.com/title/tt32150119/?ref_=ext_shr_lnk). Amazing stuff. It’s completely factual, but IMDB labels it as SciFi. What a time to be alive._

* **Gisele:** _Who else can relate to the[observed negative emotional reactions](https://pmc.ncbi.nlm.nih.gov/articles/PMC11513075/) to the use of AI at work?_

* **Nik:** _Hey all.[We’ve launched GOANUS](https://goanus.com)_ \(Autonomous Network Utility System - [trending on X](https://x.com/nikmcfly69)\).

* **Derek:** _Ethan Mollick on point, again, with a post on “[Vibeworking](https://www.oneusefulthing.org/p/speaking-things-into-existence)”._

* **Reinier:** “Sutskever has told associates he isn’t developing advanced AI using the same methods he and colleagues used at OpenAI. He has said he has [instead identified a “different mountain to climb” that is showing early signs of promise](https://bgr.com/tech/ilya-sutskever-might-have-found-a-secret-new-way-to-make-ai-smarter-than-chatgpt/), according to people close to the company.”

* **Justus:** _[Here’s what I built with Lovable](https://poem-booth-booking-site.lovable.app/book/en)._ _It’s the[Poem Booth](https://poembooth.com) booking system - it includes a full login system behind where we can manage bookings as well_

* **Alvaro:** _[This course is really good](https://huggingface.co/learn/agents-course/en/unit0/introduction), it has all the starting point and the references I would recommend you check as you start._

* [Great directory of EU AI services](https://www.aiatlas.eu/) \(AIAtlas.eu\)

* * *

#### Apple Indecision

I don't usually discuss what companies are or are not doing with regards to AI, but Apple's failed attempts at launching "Apple Intelligence" is actually fascinating.

In short, last year they promised way more than they can deliver, and are now apparently struggling to deliver a quality LLM-enhanced experience on personal devices with personal data.

Anyone who has spent more than a minute building LLM-infused tools knows how incredibly fickle and unpredictable they can be, but apparently Apple doubled down on thinking they could actually pull off what was promised, which they are now backtracking on.

I don't mean to shoot them down, but if you want to dive into the specifics of what seems to be going on, [don't miss John Gruber's excellent piece detailing their issues](https://daringfireball.net/2025/03/something_is_rotten_in_the_state_of_cupertino).

* * *

#### Will MacAskill on intelligence explosions \(4h\)

On [80.000 Hours](https://www.youtube.com/watch?v=SjSl2re_Fm8).

> AI systems are rapidly approaching human-level capability in scientific research and intellectual tasks. Once AI exceeds human abilities in AI research itself, we’ll enter a recursive self-improvement cycle — creating wildly more capable systems. Soon after, by improving algorithms and manufacturing chips, we’ll deploy millions, then billions, then trillions of superhuman AI scientists working 24/7 without human limitations. These systems will collaborate across disciplines, build on each discovery instantly, and conduct experiments at unprecedented scale and speed — compressing a century of scientific progress into mere years.

* * *

#### How to build Lovable products \(1h\)

On [Lenny’s Podcast](https://www.youtube.com/watch?v=DZtGxNs9AVg).

> Anton Osika is the co-founder and CEO of Lovable, which is building what they call “the last piece of software”—an AI-powered tool that turns descriptions into working products without requiring any coding knowledge. Since launching three months ago, Lovable hit $4 million ARR in the first four weeks and $10 million ARR in two months with a team of just 15 people, making it Europe’s fastest-growing startup ever.

* * *

#### Dario Amodei on U.S./AI Leadership \(1h\)

On [Council on Foreign Relations](https://www.youtube.com/watch?v=esCSpbDPJik).

> Anthropic Chief Executive Officer and Cofounder Dario Amodei discusses the future of U.S. AI leadership, the role of innovation in an era of strategic competition, and the outlook for frontier model development.

* * *

#### Building AI-powered tools \(20 min\)

Excellent tech talk on [AI Engineer](https://www.youtube.com/watch?v=bVNNvWq6dKo).

* * *

#### Google Gemini 2.0 Flash image generation

I had no idea Google had [advanced so much on the image generation front](https://developers.googleblog.com/en/experiment-with-gemini-20-flash-native-image-generation/). Some amazing examples of consistency and transformation from X.

I tried using 2.0 Flash to create this week’s newsletter image, but still prefer Flux 1.1 Pro for these.

* * *