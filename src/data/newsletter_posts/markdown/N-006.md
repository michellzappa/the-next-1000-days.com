# 006

Instead of the usual introduction with opinions and insight from me this week, I want to strenghthen the dialogue with you the reader. Now that I am a month and a half into the experience of publishing a weekly newsletter, Iâ€™d love to hear from you what has resonated and what youâ€™d like to see more of. Itâ€™s challenging to navigate uncharted territory, and it feels AI and its adjacent technologies have little in terms of maps. Fellow readers have asked me to include more actionable insight - like prompt guides, for example.

If you are in a position of working with, and helping others think about the implications of AI and the problems caused by generative tools, please reach out with your own insight and questions. I want to help you see further in this field and that begins with asking better questions. [Donâ€™t be a stranger](mailto:mz@envisioning.io?subject=Artificial Insights).

MZ

PS. Iâ€™ll be at House of Beautiful Business in Sintra this weekend - ping me if youâ€™re around.

* * *

* * *

#### AIâ€™s positive contribution to society ðŸ«– \(60 min\)

Sam Altman is on a whirlwind tour of governments, universities and conferences around the world this month. One of my favorite sessions is this [one-hour interview from a couple of days ago at Wisdom 2.0](https://www.youtube.com/watch?v=hn1Y6GVWUV0) featuring a frank conversation about mindfulness, AI and the future of life. Sam addresses concerns around the potential misuse of AI and the need for coordinated governance and international cooperation to ensure that AI aligns with human values. They touch on the development of a global regulatory framework and ethical guidelines to ensure fairness and accessibility in AI development, which is something I wish was taken seriously. Highly recommended.

* * *

#### The culture creating AI is weird ðŸ“ \(60 min\)

Spectacular interview by [Ezra Klein with Erik Davis on Californian ](https://podcasts.apple.com/pt/podcast/the-ezra-klein-show/id1548604447?i=1000611417980)_[weirdness](https://podcasts.apple.com/pt/podcast/the-ezra-klein-show/id1548604447?i=1000611417980)_ and how it profoundly shaped the types of technologies we now take for granted. They address our attraction towards dismissal vs. acceptance, how AI might resonate with us emotionally and spiritually, our interactive relationships with objects and the notion of technological singularity as rapture. Note how Davis alludes to some technologies as _traps_ \- which elude and compell us.

> Where does efficiency stop as a value in your life?

* * *

#### Work after AI ðŸ”§ \(20 min\)

Another insightful interview with Sam Altman, this time at the Technical University of Munich where they [specifically address how AI might change the nature of work](https://youtu.be/uaQZIK9gvNo?t=783), careers and collective growth. I especially liked their discussion about limitations and benefits of open source models and the importance of attention to detail and rigorous testing in creating AI products.

* * *

#### Social robots and the empathy crisis â¤ï¸â€ðŸ©¹ \(2 h 30 min\)

Rana el Kaliouby is a researcher in the field of emotion recognition and human-centric artificial intelligence. [In this interview with Lex Fridman](https://www.youtube.com/watch?v=36_rM7wpN5A), she discusses her work in and her personal journey from Egypt to the United States, and how her work has been influenced by her experiences as a woman in the Middle East. El Kaliouby believes that technology can help to solve some of the world's problems, but that it is also contributing to our collective deficit of understanding and compassion.

* * *

#### Meditations on Moloch ðŸ›¢ï¸ \(1 h 45 min\)

I find myself coming back to this 2014 essay by Scott Alexander every few years as it helps me understand the underlying reality of incentives and how deeply â€œgroovedâ€ reality actually is. If you havenâ€™t [read](https://www.slatestarcodexabridged.com/Meditations-On-Moloch) read or [listened](https://sscpodcast.libsyn.com/meditations-on-moloch) to it, you are in for a dense reflection of the long-term implications of our choices and the technologies that surrounds us.

> The opposite of a trap is a garden. The only way to avoid having all human values gradually ground down by optimization-â€‹competition is to install a Gardener over the entire universe who optimizes for human values.

* * *

####

* * *

##### Emerging Vocabulary

### **Hallucination**

_Situations where the AI model generates output that isn't grounded in the input it received. That is, the AI "imagines" details or facts that were not present or implied in the input, thereby producing inaccurate or misleading responses. This behavior often becomes noticeable in AI models like GPT-3 and GPT-4, which generate text based on patterns they learned during their training phase._

* * *

##### **Project Showcase**

### **[NewsMinimalist.com](https://www.newsminimalist.com)**

Ranked news aggregator. Uses ChatGPT-4 to read the top 1000 news every day and rank them by significance on a scale from 0 to 10, considering the scale, magnitude, potential and credibility of each piece of news.

* * *

##### Prompt Techniques

* * *