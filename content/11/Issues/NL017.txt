If you were an AGI – an unlimited intelligence capable of solving any problem or discovering anything – what would you learn from humanity? If you were capable of complete omniscience, what would you gain from interacting with us? 

We have not directly experienced any such intelligence, though some would argue we are currently developing something like superintelligence or AGI. Myriad definitions of what a “general” intelligence would entail, but most seem to agree that an autonomous agent capable of optimizing for its own growth is unlikely to align with the interests of humanity at large. Especially when considering the interests of private organizations and nation states working to achieve AGI first. 

Such an intelligence might be difficult to imagine, but it’s important we do. Neither of us are individually responsible for developing such technologies – but technology does not exist in a vacum, and our collective actions determine the futures we end up experiencing. 

This week’s edition again tries to capture the spirit of such change, while inviting us to think about the kinds of intelligence we want to interact with. 


#c08
