good morning everybody um it's my very great pleasure to be here moderating this session with one of the world's foremost AI Pioneers Dr Yan laon Chief AI scientist at meta and as a slight spoiler alert to answer the question posed by this session's title uh the answer will be no uh that is what I I anticipate this is what we'll we'll probably be concluding um now interestingly on this stage yesterday the CEO of Nvidia Jensen hang um said that one of if not the most significant moments over the last year in AI was the release of llama 2 the open source model from from meta and also Falcon family developed here in the UAE so can you talk to us Jan about open source AI why is open source the way forward from a security and Innovation perspective so there's going to be a future not very far in the future where all of our interaction with the digital world are going to be mediated by AI systems we already see this with u uh companies putting out basically replacement for search engines uh that are backed by AI systems and so in this in this future if all of our digital diet is mediated by AI systems um it's going to be there's going to be a need for a very wide diversity of AI systems that cater to different languages different cultures different value systems different centers of interest and it it can't be produced by a small number of companies on the west coast of the US um um or any single country U so essentially AI tools assistance will become kind of a repository of all human knowledge and um it's going to be a kind of infrastructure and the history shows that infrastructure software always end ends up being open source because it's more secure it's more customizable uh it enables the creation of an ecosystem on top of it and so the the entire infrastructure of our communication systems the internet um even or cell phones uh software stack for the you know communic communicating with cell phone towers it's all open sourc for very good reasons it's not by Design it's really the the market forces that push it so there's a similar phenomenon which is definitely happening now in the last uh uh few months that latu has uh has been available and more open source U llms have been available that people are using those open source models and and customizing them for vertical applications in businesses but also uh training them for you know particular types of uh uh languages or or cultures and so it's a necessity we we need it we need free and diverse AI platforms for the same reason that we need free and diverse press um so we don't have a single opinion coming to us from from AI yeah and how do you how do you manage the expectation of of stakeholders you know obviously at meta I imagine there was at least one serious conversation that evolved around should we make this open source or should we not and I'm I'm curious you know how do you how do you how did you manage that you know was there resistance well there was a lot of conversations over several months uh of of uh whether to open source and and how to do it best and what happened is that we did it in in sort of so we released the first llama in early 2023 uh and it was not really open source you you had to apply to to get the the model and sort of you know give your email and you know promise that you were a researcher and things like this and and then we got flooded essentially with requests from uh startups and and large companies and U ngos all kinds of people who wanted to use uh Lama for commercial applications or for whatever things that you know were not purely research um so to us it felt like um basically a another internet like you know the kind of frenzy that happened in the early and mid90s around around the internet and and and clearly this was going to be a platform and of course you know there is only a small number of companies in the world today that can train those uh high power uh Frontier models um and and at at meta there's been a long tradition of practicing open research first but also open sourcing uh infrastructure software going back to the beginning of the company and and you know certainly uh when it comes to AI I think uh We've open source on the order of a thousand different projects uh over the last 10 years so that that tells you the volume of of production uh probably the most popular one is called pytorch it's a software platform that's almost universally used for research and development in AI um we just heard from some Alman uh chbt is built with pych and pych was built at meta and is now actually the property of the Linux Foundation So Meta transferred the ownership because it's become too big of a thing for a single company to really manage I mean getting towards the the title will a AI leaders to our endend how specifically does being open source not leaders to our end is there something fundamental that makes it easier to secure yes uh so it's it's certainly been the case historically that uh open source software has been more more secure simply because there's more eyeballs on it right so the entire world today runs on Linux um maybe not your desktop uh but probably more more than half of your phones run on Linux whatever is not an iPhone runs on Linux uh the web servers around the world run on Linux all the cloud services run on Linux your car has several microcontrollers that probably run Linux the helicopter on Mars runs Linux I mean Linux runs the world and the reason is because it's open source so you can Port it to anything you want and you can make it more secure and and so you know there's kind of a similar story uh to be uh to be made for uh for for AI uh Bas models more eyeballs more ways to uh make it safe um Etc now the only reason why you might think that it's not a good idea to open source is if if you have this belief that somehow AI is so powerful that it it's going to take over the world at some point okay and uh and this is this is not happening um so first of all we're still very far despite all the wonderful things that AI can do today uh we're still very far from matching human and animal intelligence and learning capacities with AI systems we're very far it's not just a around the corner it's not going to happen in the next two years um we still some need some scientific breakthroughs to get through the type of learning abilities that we observe in uh not just humans but even your your cat um your cat has a much better understanding of the physical world than uh the most powerful AI systems that we have and You' seen my dog run into the glass door in my house you you I I i' debate that but sure but you know I've run into glass doors um so the the uh here is an interesting statistic um so first of all before we get to human level AI uh we're going to need some breakthroughs that allow machines to understand how the world Works which they can't do at the moment uh can remember facts which they can't really do at the moment they don't really have persistent memory at least llms don't um they can reason and they can plan and those are characteristics that are essential to intelligent Behavior current large language models cannot do any of those things at least not to the level that uh we' like them to to do and the reason is is relatively simple um if you if you look at how much data is used to train those llms it sounds staggering it's uh typically 10 trillion tokens right a token is like a word so it's 10 to the 13 right one with 13 zeros uh words or word equivalent each word or each of those tokens is stored on two bytes so that's 2 10 to the 13 bytes seems staggering if you evaluate how long it would take for humans to read this it would take you know anywhere between 150,000 and 200,000 years for a single person to read this reading eight hours a day uh enormous so the conclusion is those systems are incredibly smart right because they they are capable of digesting this enormous amount of knowledge and then you talk to psychologists and they tell you a 4-year-old child has been awake for 16,000 hours total and you try to put a number on how much information gets into the visual cortex through vision it's about 20 megabytes per second going through the optical nerves so do the math and that's 10 to the 15 bytes in four years a child has seen has seen 50 times more data than our biggest llm that have been trained on the entire public internet so what that tells you is that we're never going to get to human level intelligence or even cat level intelligence by just training or AI systems on text text is a very poor source of information very low bandwidth and only reflects a tiny portion of human knowledge most of human knowledge comes for from our interaction with the the real world and with each other and with you know other entities in the world um but it doesn't come from language and so we keep running into this Paradox that roboticist have known for a long time the marave Paradox or computer scientists that uh things that we take for granted like you know grabbing an object and uh manipulating it and you know planning a sequence of actions to arrive at a result we don't think of this as being an intelligent task it's kind of um too easy and that's finally complicated to do for for for AI or for robot and that's the reason why we don't have sell driving cars yet right um I mean we have llms that can pass the bar exam but we don't have sell driving cars um we don't even have domestic robots that can uh you know clean up the dinner table uh fill up the dishwasher you know clean the house M the lawn all those things uh all tasks that a 10-year-old can learn in one shot so that tells you we we we need some breakthroughs before we reach uh before we make real prog where do you think that breakthrough is going to come from well it's going to it's going to come from science it's not going to come from just you know scaling up the current architectures that we have and training them on more data first because as we increase the amount of data with llms the performance is saturating and we don't have more data we we're already using all the public data on the internet uh so that's not going to work um and so it's going to come from scientific breakthroughs not for not just from more be using more data that's this is not uh sufficient um and you know 16,000 hours of video corresponds to about 30 minutes of YouTube uploads so we have more video than we need to be able to if we had the techniques to to to get a system to learn how the world works by by watching like babies um you know for example it takes it takes about nine months for babies to learn uh about intuitive physics the fact that objects that are not supported fall because of gravity uh before that babies haven't really kind of understood that and uh what type of learning do they use you know that's really kind of a big big puzzle we're we're working on it we're making progress but it's going to take a while you speak to a lot of Business Leaders a lot of government Representatives around the world I'm curious to get your your perspective on how the rhetoric has changed over the last year let's say um particularly as it relates to the security and the safety um concerns associated with um generative AI in particular how is that evolved um and where are the concerns currently coming from yeah so there there is good news and bad news uh in that respect uh the I mean some of us certainly uh have a very positive view of the the potential of Technology we just we just heard from Sam Alman um you know we wouldn't be working on this if we didn't think that was beneficial for for Humanity and in fact uh my opinion is that AI systems will essentially amplify uh intelligence of of humanity as a as a whole you know we'll have ai assistant working for us they're not going to take over the world because they'll be working for us we'll be setting goals for them uh you know AI might be dangerous if it sets its own goals but if we set their goals then they just work for us it's like having a staff of really smart people working for you which I think most of the leaders in this room are familiar with the concept I think of working with people who are smarter than them certainly I am um so uh so we we shouldn't feel threatened by this and and I think more and more people are realizing that um this could bring a new Renaissance to Humanity basically by you know similar to uh what happened in the 15th century with the invention of the printing press which really allowed the dissemination of knowledge uh so it's a bit of the same the same effect so what you what I've observed over the last U six months roughly is there was a lot of noise around existential risk and and a lot of discussions about this and those have some somewhat um been more muted over the last uh two months or so and now people are more interested in like how how do we do it right so um you know I think it's uh very similar to a lot of technologies that have been developed over the the the last century or so where you know the the first models were perhaps uh not very not very reliable and safe uh and eventually because of good engineering and Market forces and everything uh they became reliable you know came here through long flights on twin engine airplanes uh turbojets have become incredibly reliable because of careful engineering over decades uh but that wasn't the case early on it's going to be the same for AI we're going to start with you know not so powerful AI systems but still systems are capable of understanding the world planning remembering uh reasoning you know maybe at the level of a cat and then we're going to progressively turn on you know increase the level of sophistication of those systems all the while kind of implementing guardrails to keep those systems uh uh under control you know basically uh uh fulfilling our objectives and and and uh they working for us and to pick up on the the comparison to the to the Jets there you are right you know the the the jet technology is very safe but every now and again as we've seen recently a door on a plane will blow out mid-flight uh and causes everyone quite a great degree of alarm and I suppose the question is how do we avoid that equivalent happening with with AI you know we we didn't expect that you might expect an engine failure but you don't expect the door to fall off a plane while it's in midair so you know is the confidence that the equivalent of that isn't isn't being posed here well so you know every powerful technology comes with risks uh and that uh I mean despite the fact that commercial flights are unbelievable ably safe uh in terms of statistics uh mishaps happen as with every technology they're incredibly safer than cars and people drive cars right um everywhere um so it's going to be the same for AI there's going to be you know good ways to deploy AI bad ways to deploy AI we're going to learn as we go the way we've learned how to make cars safer you know with seat belts and crumple zones and bumpers and and and you know automatic braking systems and things like that uh so there's going to be this this process but I think what cause people alarm is the idea that comes out of Science Fiction that somehow if you get it wrong once humanity is doomed and that scenario is just Preposterous I mean it's a big year for for elections around the world I mean do you think are we are we prepared have we done enough so sadly no that's a real short shortterm risk uh this is not particularly attached to to sophisticated AI by the way because uh the ability to uh produce you know fake content images or or even video has been around for a while uh and uh you know the ability of of generative AI to do this on a on a big scale is is is scaring a number of people because of uh elections across the world in the coming year now what the industry has has been working on is U standards to authenticate or to essentially label authentic content so this requires the Buy in from camera manufacturers uh image uh manipulation software uh providers uh distribution channels like social networks and so the entire industry basically sort of agreed on a standard called c2p which um would you know propagate uh a sort of marks of authenticity if you want uh simultaneously some uh companies social networks in particular meta in particular uh uh sort of watermarks generated content now the thing is it's better to Watermark and authenticate real content than than generated content uh because journalists uh have an incentive you know people who actually want to disseminate true information have an incentive to preserve that that Mark whereas people who want to just disinform don't have any incentive so it's it's probably a better idea to to Mark authentic authentic content so trust your journalists as a journalist I'm very pleased to hear that that's excellent um we're at the risk of running out of time here but just you know in a final final word if there's sort of one piece of advice you would give people out here who want to take something away um from this to make sure their AI systems are are robust uh and will not lead to the end of us all what would that be well so the short story is uh open source based models are a necessity and will happen regardless of what governments think they should do and so a good recommendation for governments around the world is do not legislate open source AI out of existence Dr Yan Lon thank you so much for taking the time to join us today it's been a pleasure thank you very much