d up. Is that way i fired, it means that. >> Watch that one live, his job is on the line. >> It looks like we got polling. >> Yeah. We have to do our job now. [laughter] >> What, we're not just talking? >> I know. Some of us are trying out our new stand-up routine. We're kicking off our first poll of Build. We should just do it. Who wants to be a millionaire style. First poll. All right. First question. What are you most looking forward to at Microsoft Build? Is it A, gaining skills in your career path? B, connecting with people across the tech world? C, learning more about Microsoft and AI? Or D, starting the Microsoft Learn challenge, Build Edition? >> I'm a gain skilled kind of guy. I already have my ninja skills -- >> Your dad joke skills. >> My dad joke skills. >> We don't -- >> I love learning new stuff. What is everyone else excited about? >> I just like connecting with people. That's why I like conferences. I like getting to run into folks I don't see often. We're all talking about similar stuff that is really cool and interesting. Also connecting with the customers that we've been trying to create cool tools for. Getting their feedback. It's really exciting. For me and . net Aspire, I'm really interested to get people's takes about how that is working for them and what can be improved later down the line. >> If you're online, you can also build community. There's a chat, you can interact with each other, you can reach out to us. I know I share my profile on Microsoft Build, so you could reach out to us. I think I read those too quickly. I'm more excited about Microsoft and AI. >> I was going to say, that seems like you. That's also probably me. We're doing so many great things with AI, this is having a moment. You were into it before it was cool. But it's cool now, and there are so many -- >> I'm cool now! >> There was an announcement yesterday around new hardware and we are going to have a lot of conversations throughout the week, a lot of sessions around how you can leverage this on your device, not just in the cloud and the things you can build. That's exciting to me. >> And like I said, if you didn't -- if you missed out on the hardware announcements there's a ton of amazing AI stuff there at the hardware level, which is exciting. One of the things that makes this more magical, I remember how it works, I remember the first time I wrote a machine learning algorithm, you're like, it's thinking, but I know what it's doing! >> Wow! >> It was actually -- it was -- I was in math lab back then. With this hardware, now it's able to be magical because it's so fast. Right? That's the thing. So that's why I'm really excited about that. >> We're getting feedback from the poll, people are excited about learning about Microsoft and AI. That's leading. >> I knew it. >> That makes a lot of sense. >> And gain new skills they're sayings. >> Absolutely. >> I want to know from Dawn, you're coming in, before you landed, before you got on the plane or whereverou came from, when you wrote it down, what was the number one thing you were coming for? >> I totally serious, it is the Microsoft Learn challenges that I didn't get involved with because we do so many with our pythonistas already, and we have this special Build Edition one, the challenges are assortments of modules and learn skills that we have on Microsoft Learn and we grab them together, we make some sort of curriculum for you, and you get to accomplish it, and you have your skills and there's a leader board, and it's very cool. You get to game I identify your learning. Who doesn't like to gamify your learning? Do I get a badge? >> Yes. >> Achievement unlocked. Now that you're here and you've seen some of the things that we're not talking about just yet, has it changed anything? Are you going to change and find something else you really have to do? >> I have a couple of swag booths I need to reach out to. I can't get them too early, but I will be in line. So if you're here in person, definitely might see me over there. >> And also, we real are excited about this, we have a bunch of amazing featured partners. We're excited for their partnership, a lot of them will show some of their amazing things. You can go to the featured partner page to look at live demos, and really understand how they are enriching the stuff that we do. Without -- we build cool stuff, but partners amplify the coolness of our stuff, you know what I'm saying? >> That's the thing. We call this Build for a reason. This is all about the things you can build on top of the frameworks and the platforms we have. And our featured partners are doing that and the people in our community are doing that. That's amazing. >> Also for the folks out there who wrote in the poll that they're excited to connect with people, good news, it's super easy, whether you're remote or in person. You can go check out the attendee directory. The attendee directory, make new friends, go find that other person who loves to use the same project type that you do. And go create the next best thing. >> I love the idea of -- you know, it's hard for us to reach out, but if an attendee said I want to connect with people, just reach out. You can make that experience that we have here also virtual. I bet some really good people ad people at these conferences. >> Talking about connection, coming up next, have you heard about this thing called the Imagine Cup? >> Huh? >> Tell us more. >> This is an awesome competition that we do the finals of every year at Build, where we get to see some of the top teams, all of whom are students, by the way. Creating the next best thing that can help people in their day-to-day lives. And really leave an impact. >> Look, these -- I say youngsters because I think I'm like at the -- I'm like at the age, look at these kids! They really are inspiring. They build some amazing things, and just the fact that they're doing it to better the world and they're also using technology that I just am inspired by, it's cool to see the stuff that they're doing. >> I agree. They are going to change things. We've seen so many great things happen from past Imagine Cup winners. I'm excited to see what the finalists are doing this year. I get inspired every year. I'm like, wow. Okay, you're way younger than me. Not that much younger. [laughter] >> Let's not go there. >> Look what you're doing. I wish I had that ability, on so many levels when I was in college. >> I just want to throw this out there -- we should talk to some of these Imagine Cup people. >> That's a reason for you at home to keep coming back. >> There is a real cup. >> I think they're bringing it out in the cup. They're putting Dona in the cup. If you haven't seen her, she's with the Imagine Cup people, she's obviously in the cup. Am I hearing this right? >> I believe it was Dona and the Imagine Cup -- >> Not in the Imagine Cup. >> It's one of the most stereo typical looking trophies you have ever seen. It looks like a trophy you've seen in clip art. It's amazing. >> I just found a new saying, that looks like it belongs in clip art! >> Word Art. >> So cool. In addition to the really big trophy that the team can potentially win, they also get money, right? Money is on the line. >> $100,000. >> And they get the mentoring -- I don't know how long it is, but with Satya himself. >> That's pretty sweet. I don't know about you all, but I know I wasn't doing anything like that in college. >> No. >> No. >> I was watching a lot of Netflix. >> I dropped out. >> It's really cool, because I don't get a mentoring spot with Satya. I go to his office -- >> They're like, please, can you step away, sir? >> He's a really good guy. We love the stuff he says and the aspiration we have to make every organization and every person on the planet achieve more. It's literally on our badges. >> You just said the company cede. >> Oh, wow, there you go, the company creed. >> So there's a ton of good stuff, there's a ton of announcements, a ton of sessions. Stay here for that, stay tuned for the Imagine Cup, and then Satya will deliver his keynote with all of the amazing things. But there's also a keynote tomorrow with Scott Guthrie and friends. So I'm excited about that. >> Even more good things tomorrow. >> I'm already excited about tomorrow. >> Are you going to be part of it? >> He just criticized me for doing it, and he is doing it. >> I get to do a demo. >> You paved the way. >> Is that what it is? I started it? >> I'm not going to be bald-faced promoting my session on Thursday either. >> I can't believe -- >> I would never do that. You do that. It's not something I would do. Thursday in the middle of the day, look it up in the session catalog. >> Lots of conversations on this stage. >> I love a live demo. Did I get the subliminal message? >> I have been praying to the demo gods all week that all the awesome demos are going super. But first before we get into all of that, coming up next is the Imagine Cup World Championship p happening life, right now. It's early. Check this out. >> The moment we've all been waiting for. >> Please welcome Dona Sarkar and the Imagine Cup world championship finalists. [applause] >> Hello, Microsoft Build! [cheers] We are so excited to be here to announce who will be crowned the Imagine Cup world champion. For those who don't know who might be new here, anyone new here? A few hands. Imagine Cup has a proud 22-year-old history of empowering students all around the world to solve some of our most difficult challenges using tech. From the tens of thousands of students who applied, and we really do mean tens of thousands, every country in the world, by the way, we're so excited to have the final three start-ups live here with us today. These students are not holograms and they're not AI, they're real and live. Wave. Earlier this month -- [applause] Everyone! Yes! Thank you. Earlier this month, these finalists touched to our esteemed panel of judges. The CEO and founder of Roy B Robot, CEO of Ne, and Annie Pearl, corporate vice-president of Ecosystems at Microsoft. Each of these start-ups presented their solution, demoed their technology and fielded some pretty hard questions, I think. They were judged on their use of AI, their consideration of inclusive practices and design, and third, their overall viability. These students are just so impressive, and you're absolutely going to fall in love with them. Let's get to know them. Tell us about you, your team and your project. >> My name is Leah, this is Everett and that's Clay, we're from the United States. I go to Georgia Tech and they go to Binghamton University. We Provided Something Called Road Trip. It Leverages Motivators and Simplifies Decision Making to Help People Start Their Task. We Used Azure to Personalize the Experience with Learned User Information and the Latest ADC Research. We Want to Help People Work with Their Brains, Not Against Them. >> That Is Fantastic. Can We get a round of applause, please? [applause] Thank you. All right, next up with, Jerry, over to you. >> Absolutely. What if I told you that with a device we can revolutionize the steel manufacturing industry? That's what we do. By using this sensor and our AI model we're able to detect anomalies in the steel making process, helping the industry become safer, greener, more efficient, and more profitable. By doing so, we truly put AI to work for our motto, people, planet, profit. >> People, planet, profit. Can we agree with that? [applause] Yes. So we all know, sustainable manufacturing is the future of manufacturing, yeah? Thank you for your work. Hardware is hard. Good job. All right. Last and definitely not least, from your eyes, let's hear from you. >> We have a company that's actually trained our own custom AI model in order to customize and localize the processing. We also use -- we have free solutions right now, the first one is API, for developers and businesses in order to give them the basic environment to build their own solutions. The second one, in order to make vehicles safe. And the third and last one is the -- is for visually impaired people. >> So impressive, yes? [applause] You know I love a good accessibility project, that's pretty cool. Love it. So all of these start-ups are doing absolutely incredible things with AI and making such an impact in the world. We'd love to see them in action and watch a recap of their pitches and the competition. Let's roll. >> There are over half a billion people estimated with ADHD worldwide. >> In general, someone with ADHD has a higher chance of dropping out of school, getting unemployed. Having depression. All these other ailments >> We want to change that for people. I think there's two big ways Road map could change the world. First, I think it could help people struggling with ADHD unlock their true potential. Second, we can start reducing the stigma against ADHD worldwide. >> Okay, Plan Road Trip, it's time for your pitch. >> It asks small questions to break down into steps. Let's take the test lab report and type it in. As you chat, road trip learns about you and tailors future conversations to strengths and weaknesses. It can suggest tools such as a timer which creates urgency, or a music player if you need novelty. >> Winning the Microsoft Imagine Cup would give us the funding we need to address more of the things people with ADHD struggle with. >> This industry is one of the top -- accounting for almost 7%, and by using a sensor no bigger than the size of a can, we can create huge environmental impact, huge savings in terms of raw material used, and huge added value in terms -- >> JRE, we are ready for your pitch. >> Will at the optimal level ensuring the amount of wasted steel is brought out to almost zero with minimal slack. The commercial benefits are massive too. With an increase in profits by an average of 1.5 million dollars. >> We deploy our system and get about 10% of the global market share, we'll be able to safe over 30 billion liters of water and enough electricity to power the New York City skyline for over two months. So this is the power of small gains. >> Our main purpose is to design this with AI. >> Okay, let's start your pitch. >> From your eyes is an AI vision company, and we have two solutions. The first one is the XYE and second is API. Visually impaired users can design their own AI assistance in order to get descriptions to the photos, videos, or other visual things as well. Thanks to our API -- to the required fields such as developers, and enterprises, by licensing it. For example -- in order to become a car assistance for visually impaired passengers. >> The vehicle is driving on asphalt. A two-way road is framed by the beauty of the surrounding nature. >> If we win the competition, all of the visually impaired people have a chance to see with the technology. >> I was quite blown away by all three of your projects. >> Every team members is working on something truly impactful. >> My words of encouragement are keep pushing. Keep pushing during the peaks of the journey, but more importantly, keep pushing during the valleys of your journey. And just don't ever lose this passion to really change the world. >> Okay. [applause] I still can't get over how amazing your pitches were. We could all use some life coaching on how to pitch like that, right? Okay. So the pitches were amazing, competition was incredible. And I'm thrilled to be joined by Imagine Cup judge, Annie Pearl. Thank you so much for joining us here today. So how fantastic are these start-ups? >> Every single one of these start-ups has shown the grit and resourcefulness it takes to be a successful entrepreneur. And it's been so inspiring to see their creative uses of AI, and it really just goes to show you what can happen when you take students and you give them access to the power of Azure AI and you let them build. >> That's right. And when they're given these awesome tools, like AI Copilot and all of these things, it's amazing how you can just do the thing. Yeah? All right. So -- in fact, all of these teams are winners today. Both runners up will receive $50,000, and our world champion will go home with $100,000, plus a mentoring session with Microsoft Chairman and CEO Satya Nadella. Pretty good mentor, huh? Not so bad. [applause] For all of you in person, you absolutely need to go up to the fifth floor. What I did say? Fifth floor. Demo theater. And see their demos live. They're amazing. Absolutely amazing. All right. >> is everyone ready? Here we go. Let's go. We need a little excitement here. And the 2024 Imagine Cup World Champion is from Your Eyes from turkey! [cheers and applause] [cheers and applause] >> Imagine Cup 2025 is now open. Everyone, please enjoy Microsoft Build. >> I think our industry has to have the common vision. >> It was a time that connected us to incredible things. >> My name for this vision is information at your fingertips. >> And three decades later, we find ourselves in a new era. One where access to information becomes access to expertise. From the farm, to the lab, from the boardroom, to the classroom. This new generation of AI is for everyone. Everywhere. Now anyone can save time with a personal assistant. >> I'm serving about -- saving about 50% of the time, time I can use to do other innovative things. >> Anyone can access a personal tutor to learn new skills. >> I think it has the potential to reimagine the way every student learns in the world. >> This is a new way to analyze with a personal coach. >> We're going to be able to have not only productivity gains, but insights near realtime. >> Generative AI can learn to help improve the farmer's productivity. >> AI is unlocking creativity for us all. >> They're so detailed, in my imagination I can paint the artwork. >> With expertise at your fingertips. You can build what matters. Welcome to the age of AI transformation. [applause] >> Good morning. Good morning. It's fantastic to be back here at Microsoft Build, welcome to everyone here, and joining us on the web. You know, developer conferences are always most exciting, most fun when there's these fundamental changes that you can sense in the air. I mocked all my adult life by coming to PDCs and Builds for the last three decades. I still remember distinctly the first time Win 32 was discussed, I guess it was '91, .NET, Azure. These are moments that I mark my life with. And it just feels like we're yet again at a moment like that. It's just at the scale, the scope is so much deeper, so much broader this time around, right? Every layer of this tech stack is changing. You know, from everything from the power draw and the cooling layer of the data center, to the MPUs of the Edge are being shaped by these new workloads, by these distributed, synchronous data power and workloads are reshaping every layer of the tech stack. But if you think about even going all the way back to the beginning of modern computing, say, 70 years ago, there have been two real dreams we've had. First is can computers understand us, instead of us having to understand computers? And second, in a world where we have these ever-increasing information of people, places and things, as as you digitize more artifacts on people, places, and things, and you have more information, can computers help us reason, plan, and act more effectively on all that information? Those are the two dreams that we had for the last 70-plus years. And here we are. I think we have real breakthroughs on both fronts. The core underlying forks one of the questions I always ask myself -- okay, this is great, this is maybe the golden age of systems, what's really driving it? I always come back to the scaling laws. Just like Moore's Law, helping to drive the -- the scaling laws of DNNs are really, along with the model architecture, the interesting ways to use data, generate data, are really driving this intelligence revolution. You could say Moore's Law was probably more stable in the sense that it is scaling at maybe 15 months, 18 months. We now have these things scaling every six months, or doubling every six months. What we have, though, with the effect of these laws is a natural user interface that's multimodal, that supports tech, speech, has video, input and output, we have memory that retains important context, recalls both our personal knowledge and data across our apps and devices. We have new reasoning and planning capabilities that helps us understand very complex context, and complete complex tasks. While reducing the cognitive load on us. What stands out for me as I look back at this past year is how you all, as developers, have taken all of these capabilities and applied them, quite frankly, to change the world around us. I'll always remember this moment in January 2023, when I met a rural Indian farmer who was able to reason over government farm subsidies he heard about on television using GTP5 and his voice. It just brought home the power of all of this. A frontier model developed in the West Coast of the United States just a few months earlier, was used by a developer in India to directly improve the life of a rural Indian farmer. The rate of diffusion is unlike anything I've seen in my professional career, and it's just increasing. In fact, earlier this month I was in Southeast Asia, where I met a developer and I was having a great round table and he was talking about how he's using 5, 3, and GPT4 to optimize all of the things he was doing with RAG. This is crazy. This is unbelievable. And it had just launched a few weeks earlier, and I was there in Thailand and Bangkok listening to a developer talk ug about this technology as a real expert on it. So it's just great to see the democratization force, that we love to talk about, but to witness it has just been something. And this is quite frankly the impact of why we are in this industry, it's what gives us the deep meaning in our work. So I want to start, though, with a very big thank you to every one of you who is really going about bringing about this impact to the world. Thank you all so very much. [applause] When I think about what progress we've made even, since last time we were here at Build, we've built three platforms. The first is Microsoft Copilot, which is your everyday companion. It puts knowledge and expertise at your fingertips, helps you act on it. And we built the Copilot stack so you can build your AI applications and solutions and experiences. And just yesterday, we introduced a new category of Copilot+ PC, the fastest AI-first PCs ever built. All three of these things are exciting platforms. But I want to start with croapt+ PCs. We're exposing AI as a first class name space for Windows. This week we're introducing the  Windows Copilot Run Time to make it the best platform to build your AI applications. [applause] You know, what Win 32 was to graphical user interface, we believe the Windows Copilot Run Time will be for AI. It starts with the library, a collection of these ready-to-use local APIs that help you integrate into your new experiences all of the AI capabilities that we shared yesterday. Now, this includes no-code integrations for Studio, things like creative filter, teleprompter, and much more. But of course new want to access these models, you can directly call them through APIs. We have 40 plus models available out of the box, including our newest member of our small line family model, which we can specifically -- which we specifically designed to run locally on your MPUs on Copilot+ PCs, bringing that lightning-fast local inference to the device. You know, the other thing is Copilot library makes it easy for you to incorporate RAG inside of your applications on-device data. It gives you the right tools to build a store within your app, it enables you to do that semantic search you saw with Recall, but now you can, in your own application, construct these prompts using local data for RAG applications. Now, I'm so thrilled to announce as well today that we will be natively supporting poi torch and new WebNN framework through Windows DirectML. [applause] Native PyTorch support means thousands of OSS models will just work out of the box on Windows, making it easy for you to get started. In fact, with WebNN, developers finally have a web native machine learning framework that gives them direct access to both guns and NPUs, last night I was playing it, and seeing that the WebNN sample code running, it's so cool to see it now using the NPUs. Both PyTorch and WebNN are available in developer preview today. Let's take a look. Plan [applause] >> These are just one of the many announcements today. We're introducing more than 50 plus new products and partnerships to create new opportunities for you. We have always been a platform company, and our goal is to build the most complete end-to-end stack from infrastructure, to data, to tooling, to the application extensibility. So that you can apply the power of this technology to build your own applications. And so today I want to highlight our top news for this event across every layer of this Copilot stack. Let's dive right in with infrastructure. We have the most complete scalable AI infrastructure that meets your needs in this AI era. We're building Azure as the world's computer, we have the most comprehensive global infrastructure with more than 60 plus data center regions, more than any other cloud provider. Over the past year, we've expanded our data center regions and AI capacity from Japan, to Mexico, from Spain, to Wisconsin. We're making our best in class AI infrastructure available everywhere. We're doing this with a focus on delivering our cloud services sustainability. In fact, we're on track to meet our goal to have our data centers powered by 100% renewable energy by next year. [applause] We're optimizing power and efficiency across every layer of the stack from the data center to the network. Our latest data center designs are purpose built for these workloads so we can effectively and responsibly use every megawatt of power to drive down the cost of AI and the power draw. And we're incorporating advanced data center cooling techniques to fit the profile of the workloads, and match it to the environment and the location where it operates. At the silicon layer, we are dynamically able to map workloads to the best accelerated AI hardware, so that we have the best performance. And our custom I/O hard ware and server designs allow us to provide dramatically faster networking, remote storage, and local storage. This end-to-end approach is really helping us get to the unprecedented scale. In fact, last November we announced the most powerful AI supercomputer in the cloud for training using just a very small fraction of our cloud infrastructure. And over the past six months, we've added 30 times that super computing power to Azure. [applause] It's crazy to see the scale. And of course we're not just scaling training fleets, we're scaling our inference fleet around the world, quadrupling the number of countries where Azure services are available today, and it's great to see that. [applause] At the heart of our AI infrastructure, are the words most -- world's most advanced AI accelerators. We offer the most complete selections, including from Nvidia and AMD as well as Azure, all dynamically optimized for the workloads. That means whether you're using Microsoft Copilot or building your own Copilot apps, we ensure that you get the best accelerator performance at the best cost. For example, you see this in what has happened with GPT4 U. it's Sx faster since it launched. Are that's the type of progress you can continue to see how -- continue to see the progress as we -- it all starts, though, with this very deep, deep partnership with Nvidia, which spans the entirety of the Copilot stack across both all of the hardware innovation as well as the systems software innovation. Together we offer Azure confidential computing on GPUs to be really help you protect sensitive data around the AI models end-to-end. We're bringing in fact the latest H2 hundred to Azure later this year, and will be among the first cloud providers to offer Nvidias Blackwell GPUs as well as configurations. We're continuing to work with them, to train and optimize both Large Language Models like GPT40, as well as the 53 family. Now, beyond the hardware, we are bringing Nvidia's key enterprise platform offerings to our cloud. Like DGX cloud to Azure, with deep integration with even the broader Microsoft cloud. For example, Nvidia announced they -- that means you can train those models using DGX cloud with full access to fabric data. The and the API ls available first on Azure for developers to build their industrial AI solutions. We also are working with Nvidia in developer services and making them fantastic on Azure. So a lot of exciting work with Nvidia. Now, coming to AMD, I am really excited to share that we are the first cloud to deliver general availability of VMs based on MI300XAI accelerator. [applause] It's a big milestone for both AMD and Microsoft, we've been working at it for a while, and it's great to see that today as we speak, it offers the best price performance on GPT4 inference. And we'll continue to move forward with Azure, our first clusters are live and soon if you're using Copilot or one of the Azure OpenAI services, some of your prompts will be served using Maia hardware. Now, beyond AI, our end-to-end systems optimization also makes cloud native apps, the development of cloud native apps better. Simsbury months ago we announced our first general purpose compute processor, Microsoft  Cobalt, and today I'm excited to announce the public preview of cobalt-based 3Ms. You know, Cobalt is being used for video processing and permissions management in Microsoft 365, helping power billions of conversations on services like Microsoft Teams already. And we're delivering that same is performance and efficiencies to many customers. In fact, including Elastic, Mongo, snowflake, and Tera data. The in our most recent benchmark data and tests are cobalt hundred VMs delivered up to 40% better performance than any other generally available arm-based VM. We're very excited about Cobalt getting into the market. Now let's move up the stack to the foundation models. With Azure AI, we offer the broadest selection of frontier and open source models, including LLMs and SLMs, so you can choose the model that makes the most sense of your unique needs and application needs. In fact, more than 50,000 organizations use Azure AI toda- [applause] Yeah. It's great momentum. And it all starts, though, with our most strategic and most important partnership, with OpenAI. Just last week OpenAI announced GPT4.0, their latest multimodal model, which was trained on Azure. It's an absole breakthrough, it has text, audio, image and video as input and output, it can respond and have a humanlike conversation that's fast and fluid. It can even be interrupted mid-sentence. GPT4.0 is also the top performing model on benchmarks across a variety of modalities. It's a little going to get you to the best answer. It has state of the art performance at understanding the information you provide in your prompt, because that's really what matters. What OpenAI demoed last week, that was just pretty magical stuff. And yesterday, we showed how Copilot will leverage GPT4o. In the video I'm going to play, notice that you can share your screen or session as a prompt in Copilot, and have Copilot help you in whatever it is that you're doing. Let's roll the video. >> Hey, Copilot, how's it going? >> Hey. I'm doing great. It looks like you're about to dive into some mine craft. Ready to build, explore, and maybe dodge a few -- >> I'm trying to figure out how to make a sword. My son plays this all the time and I have no idea what I'm doing. >> No worries. I'm here to help you impress your son. I see you've good a crafting table. Which is a great start. To craft a sword, you'll need some materials. Can you open your inventory, just press oh. Your keyboard. >> Yeah. Do I have what I need? >> Let's see. You've got some sticks, perfect for the sword's handle. But it looks like you're missing the material for the blade. You can use wood, stone, iron U. gold, or diamond. Let's start by gathering some wood or stone, shall we head out and find some resources? >> Yeah, that sounds great. Oh, my god, what's that? >> Oh, no! It's a zombie n run! You need to get away from it fast! Sprint away or build a tower of blocks straight up to get out of its reach! If you can find a shelter, or dig into the side of a hill, do it now! Just make sure it can't reach you. >> All right. I think I might be safe now. >> That was a close one. Great job finding shelter. >> It's really cool to see that. [applause] You know, the magic here is that Copilot is your personal assistant that's helping you with any task, helping you stay in the flow, in the moment, whether it's a game or a document, or a line of code. And as OpenAI innovates, our promise is we will bring all that innovation to Azure 2. In fact the same day OpenAI announced GPT4o, we made the model available, and today I'm excited to say that it's generally available on Azure AI. [applause] What this means, though, is that now we can have these groundbreaking apps that all of you can build using this capability. One of the coolest things is that now any app, any website can essentially be turned into a full multimodal, full duplex operational canvas. Let's take a look. >> Let me ask the agent here. Hey, Seth, how's it going? What can I help you with? >> I'm fantastic, I'm sorry, I'm in such a hurry. I'm going to go on an overnight camping hike, it's going to be dark, cold. Should I use these shoes? It's the mountains, probably it's going to be cold. >> No worries. Let me take a look. Those are the trek star hiking sandals. While they're fantastic for summer hikes and keeping your feet cool, they might not be the best choice for cold mountain -- >> Okay, I'm sorry to interrupt. Pick the best thing I can use, and can you add it to my cart? One product. >> No worries. Let's go with the trek ready hiking boots. They're durable, provide great ankle support and most importantly they'll keep your feet warm in the cold mountains. I'll add them to your cart now. >> I see that. Amazing. [ snot speaking English ] >> While Seth was -- [applause] Seth was in a hurry, but there you go. Gpt-4o kept up with him. I want to thank the OpenAI team for their partnership and really their responsible approach to innovation, helping our industry move forward. Sam will be here in fact joining Kevin in a little bit to talk a lot more about what's coming. That's the exciting stuff, how you all sample what comes next. We also brought -- we're bringing lots and lots of other models as well, date background checks, me stral, snowflake, All to Azure AI. We an to Support the Models from Every Country, Every Language, I'm Excited  to in Fact We're bringing models from G42, NTT data, as well as many more, as models as service, because that's what you can easily get to. And we love open source too. Two years ago at Build we were the first to partner with Hugging Face, making it simple for you to access the leading open source library, which state of the art language models via Azure AI, and today I'm excited to announce we're expanding our partnership, bringing more models from Hugging Face with text generation inference, embedding inference, directly into Azure AI Studio. [applause] And we're not stopping there. We are adding not just Large Language Models, but we're also leading the small language revolution. Small language model evolution. Our Phi-3 family are the most capable and cost effective. As well as mapped benchmarks. If you think about it, by performance to parameter count ratio, it's truly best in class. And today we are adding new models to the Phi-3 family to add even more flexibility across that quality cost curve. We're introducing Phi-3 vision, a 4.2 billion parameter multimodal language with language and vision capabilities, it can be used to reason over real world images, generate insights about images, as you can see right here. [applause] And we're also making a 7 billion parameter 53 small and a 14 billion parameter Phi-3 medium models available. With Phi you can build apps that span the web, Android, IOS, Windows and the Edge. They can take advantage of local hardware when available, and fall back on the cloud when not. Simplifying, really, all of what we as developers have to do to support multiple platforms using one AI model. It's just awesome to see how many developers are already using Phi-3 to do incredible things. From solutions -- Amity solutions, the ITC, which has been built a Copilot for Indian farmers to ask questions about their crops. Epic in healthcare, which is using Phi to summarize histories more quickly and efficiently. And another cool use case is in education. Today I'm very thrilled to announce a new partnership with Khan Academy, we'll be working together to use Phi-3 to make map tutor -- math tutoring more accessible and they'll be making ComAmigo free toe all U.S. teachers. Let's roll the video. >> I felt like I was in a place in my teaching career where I felt like I was kind of losing my sparkle. And I would just feel really defeated when I looked out on the classroom and I would see students that just didn't look engaged. >> Teachers have an incredibly hard job. We think we can leverage technology to take some of the stuff off their plate, to really humanize the classroom. >> By some miracle, we became a ComAmigo pilot school. >> With new advances in generative AI, we launched ComAmigo. The point is to be that tutor for every student, and to be a teaching assistant for every teacher. >> I started to build these more robust lessons, and can I started to see my students engage. >> We're working with Microsoft on these Phi models specifically tuned for math tutoring. If we can make a small language model like PHI work in that use case, we would like to shift the traffic to Phi in those particular scenarios. Using a small language model, the cost is lower. >> We're really excited that ComAmigo being able to give these teacher tools for free, to U.S. teachers, it's going to make a dramatic impact in U.S. education. >> I think we're going to make them  I think we're going to make them the inventors, the questioners. That's our future. Our next generation. And to me that's everything. I'm thank Tom teachers for everg they do. Thank you very much. It's about more than just model. It's about the tools you need td these experiences. With Azure AI studio we provideo end tooling solution to develope guard the Copilot apps you buil. We provide tooling and guide tos evaluate your AI models and fors for quality which is one of thet important task as you can imagen all these models. I'm excited to announce that Azi Studio is now generally availab. [applause] . It's an end to end development environment to build, train ande AI models and do so responsibly. It includes built in support whs perhaps the most important feath is in this age of AI which is s. Azure Ai Studio includes the ste art safety tooling to forever dg hallucinations in model out putk and safety monitoring. It helps understand which inputt puts are triggering content fil, prompt shields to detect and blk injection attacks. Today we're adding new capabilis including custom categories so n create unique filters for prompd completions with rapid deploymes which is important as you deploe models into the real world, witg threats appearing. Beyond Azure Ai Studio we recogy are advanced applications whered much more customization of thess for very specific use cases. And today I'm really excited toe Azure AI custom models will comg you the ability to train a custl that is unique to your domain, r data that is perhaps proprietar, scientist working with open AI t the Phi advances to you to be ao build out the custom models. The out put will be domain spec. Multitask and multimodal. Best in class defined by benchmd specific language proficiency wy be required. Now let's stack to data. In order to train, fine tune, gr models, you need your data to bs best shape. And to do so we are building oul data estate. From operational stores to analn Azure. We have also added AI capabilitl of our operational stores wheths SQL or post SQL. The core of the intelligent datm is Microsoft fabric. We have over 11,000 customers ig leaders in every industry using. It's fantastic to see the progr. [applause] . With fabric you get everything d in a single integrated Social Sy platform.  SAAS platform. Your experience is unified, govs unified and more importantly ths models unified. What is also great about fabrict it works with data anywhere. Not just an Azure but it can ber GCP or on your own premise data. Today we're taking the next ste. We're introducing real time inte in fabric. [applause]   customers today have more andf this real time data coming fromt systems, your telemetry systems. Cloud applications are generatif data. With fabric anyone can unlock ae insights across all of your dat. Let's take a look. >> Introducing real time intelln Microsoft fabric, an end to endn empowering you to get instant in streaming data. At its heart lies a central plao discover, manage and consume eva across your entire organizationa rich governed experience. Get started quickly by bringinga from psych soft sources and acrs with a variety of out of the box connectors. Route the really vent data to tt destination and fabric using a e drag and drop experience. Explore insights on bites of stg data with just a few clicks. Elevate your analysis by harnese intelligence of Copilot by usine language. Make efficient decisions in thet with real time actionable insigd respond to changing landscapes proactively. Allow users to monitor the datae about. Detect changing patterns and ses or actions that drive business . All your data, all your teams, e place. This is Microsoft fabric. >> And we're making it even easo design, build and interoperate h fabric with your own applicatio. We're building out a new appellm with fabric workload developmeno people who have integrated their analytics with fabric so customn generate insights from their own data using rich tools and librat on fabric. This is exciting to see. It's the first time where the ac stack is a first class appellats well. Beyond fabric we're integratingf AI across the entirety of the da stack. There is no question that RAG io any AI powered application, AzuI search makes it possible to runt any scale delivering very highle responses using the state of tht retrieval systems. Chat GPT supports for GPTs, ther assistance API are all powered e AI search today and we're builte lake integration, Azure AI searl automatically structure your owo and it's integrated into Azure o bringing your own embedding mod. It's incredible to see search gr the last year into the core devr service. Now let's go up to developer to. Nearly 50 years of our foundinga developer tools company here wee again defined software developm. GitHub it was first hit products generative AI age. It's the most widely adopted AIr tools, 1.8 million subs across 0 organizations are are using it. [applause]   and GitHub Copilot we're empog every developer on the planet ts programming languaged knowledger own native language. Think about. That any person who can start pg whether it's Brazilian, Portugug back the native coding to theire and with Copilot work space stan your flow has never been easier. We're closer to a world where an can go from idea to code in an . You start with an issue, it cree spec based on its deep understaf your code base. It then creates a plan which yon execute to generate the code acs multiple files. At every point in this process e issue to spec to plan to code, n control, you can edit it. And that is really what is fundy a new way of building software. And we're looking forward to mat more broadly available in the cg months and today we're taking oe big leap forward. We are bridging the broader devr tools and Social Securities ecom with Copilot for the first time. We're thrilled to be announcingb Copilot extensions. [applause]   now you can customize GitHub t with capabilities from third pay services, and of course we havew extension for Azure too, GitHubt for Azure. You can instantly deploy to Azut information about Azure resourct using natural language and whatt did for coding, we're now doingr infraand ops to show you all thn action. Here is our team. Take it away. >> Thanks Satya. GitHub Copilot gives you suggesn your favorite editor like here m writing unit tests. Copilot is great at meeting youe you're at regardless of the lane you're most comfortable with. Let's ask for something simple w do I write a prime number test . Let's convert to Spanish using . [Speaking Spanish] >> Look at that. Copilot is great at turning natl language into code and back aga. But what about beyond the code? With the new GitHub Copilot exts you can now bring the context fr connected systems to you. So now I can ask Azure where mys deployed. I could ask on my available Azue resources or diagnosis resourcey environment. And this isn't just for Azure. At Satya announced any developen create extensions for GitHub Cod is this includes any tool in yok including in-house tools keepinn the flow across your entire day. Actually 75 percent of the devey is spent outside of coding. Gathering requirements, writing specifications and creating pla. Let's show how GitHub Copilot cp with that. Live on stage for the first tim. Typically my day starts by lookt GitHub issues. Looks like we want to support at input for a product description. Let's open work space and get hh that. Copilot interprets the intent oe issue to see what is required an looks across the entire code bad proposes what clangs should be . This specification is fully edid the whole process is iterative. Actually this looks pretty good. Copilot can now help us build an how to implement this change. That's a great start but we must forget about our documentation. Let's edit the plan and have Cot update our read me. And then we can even get Copilon starting to implement the code . Now this was just a simple examn a large enterprise code base the tens of thousands of files and f stakeholders involved and that s meetings, so many meetings. Work space helps you focus on wu need to change and by the way, a developer I'm always in control. I can see exactly what changes s proposing and I can even get a e preview. Let's test out the input. This looks great. So I can go back and I can edite or I can submit these changes al request to share with my team. GitHub Copilot, Copilot extensid work space help you stay focusen solving problems and keeping yoe flow. Back to you Satya. >> Thank you so much. GitHub Copilot and everything tt ecosystem is doing is just brink a lot of fun and a lot of joy bo coding. And really the thing about stayn that flow is I think what we ale dreamt about and it's coming ba. That brings us to the top of th. >> MIKE: Copilot. We build Copilot so you have thy to tap into knowledge as well ae knowledge inside of your organid act on it. Now Copilot has had a remarkablt across organizations. It's having a real cascading ef. It reminds me of the beginning C era where work, the work artifad work flow all changing. And it's just really having brod enterprise business process imp. It's lowering both the floor ang the ceiling at the same time fog any one of us can do. Since no two business processese same with Copilot studio you non extend Copilot to be able to cut for your business processes andk flows. Today we're introducing Copilot connectors in Copilot studio son ground Copilot with data from ae graph, from power platform, fabs well as you now have all the thy connectors for Saas applicatione now, Snowflake and many more. This makes the process of groung Copilot in first and third partf business data just a wizard like experience enabling you to quicy incorporate your own organizatil knowledge and data. We're extending Copilot beyond l assistant to become a team assi. I'm thrilled today to announce m Copilot. You'll be able to invoke a teamt wherever you collaborate in tea. It can be in teams, loop, plannd many other places. Think about it, it can be your g facilitator when you are in teae agendas, tracking time, taking r you. Or a collaborator writing chats, surfacing the most important in, tracking action items, addressig unresolved issues. And it can even be your projectr ensuring that every project thae working on as a team is running smoothly. These capabilities will all comu all and be available in previewy are year and they are not stoppg there. With Copilot studio anyone can d Copilots that have agent capabi. And work on your behalf and indy proactively orchestrate tasks f. Simply provide your Copilot a jb description or choose from one r premade templates in the Cupid e necessary knowledge and actionsd Copilot will work in the backgrd act asynchronously for you. That's one of the key things ths going to change in the next yeae your going to have Copilots plus with this assign behavior. You can delegate authorities tot to automate processes. Copilot can ask for help when it encounters situations it doesn'w much about and can't handle. To show you this let's roll the. >> Redefine processes with Copit studio. Simply describe what you want yr Copilot to do. Easily configure your Copilot we details it needs like instructi, triggers, knowledge, and action. Quickly test your Copilot beforu deploy. And seam losely publish across e channels. Watch it use memory for context. Reason over user input. And manage long running tasks. Copilot can learn from feedbacko improve. And you are always in control. Put Copilot to work for you. With Copilot studio. >> You know all around this stas perhaps one of the most importas that we at Microsoft are doing s wrapping it with robust securit. Security underlies our approachh Copilot, Copilot plus PC, Copil. We're committed to our secure fe initiative. You can see us make rapid progrs each of the six pillars of SF I. And the core design principles s secure by design, secure by defd secure operations. You'll hear throughout this cona lot more tomorrow in the keynott under lies everything that we bd everything that we do. So coming to the close, I want e are many announcements that your about at Build. I want to go back to the core oI think why we chose to be in thiy and why we come to work every ds developers which is the mission ultimately of empowering every d every organization. Attend of the day it's not about innovation that is only useful a few. It's about really being able tor everyone. And it comes down to you all as developers and builders of thisw world. For us it's never about celebrah for tech sake. It's about celebrating what we o with technology to create magicl experiences that make a real die in our countries, in our compand communities. Already this new generation of s having an incredible impact. Thanks to all of you, the passid the hard work you put in. I want to leave with you this oe unbelievable example of how youe building a more accessible worlh means a lot to me using our plad tools. Thank you so very much. Enjoy the rest of build. >> The description is somethingt enables me to be able to watch m and film and get as much out ofs everybody else I who is sighted. A white car drives down the roas on a steering wheel. I see art as collective good. Everyone should have access to . Audio descriptions really helpst the full experience. A portrait of a group of 17th cy guardsmen in Amsterdam. >> The challenge there are limid amounts of audio descriptions bg incorporated across media and entertainment. >> Potential to bring a low visn community into the fold. >> So at WPP we really care pasy about opening up access to conto people in a way they want to co. >> It's an application that allu upload videos and on the other h GPT4 with vision, you get your k with spoken descriptions over t. Kitchen seen with cats and mayo. >> This makes audio descriptionr and faster. Our goal is to be able to offers product as as service for advert campaigns. >> There are so many art works e museum there are almost a milli. To describe ourselves it would e hundreds of years. With AI we can do it in a mattef hours. >> The subject is a male with ah beard and mustache, visible brus that add texture and mood. >> First time I heard audio des, it brought me to light. It was this opportunity of oh m, I'm seen through power of AI. We're able to do things only drt until recently. Our access of culture, we struce culture itself connecting our sd humanity. >> Please welcome executive Vice President experiences plus devis Rajesh. >> Good morning. You heard Satya talk about a Cot stack. The AI architecture of the futu. Now I want to talk about bringiI stack to Microsoft products. First I'm going to focus on howe expanding Copilot. Then Jeff will talk more about extensibility and then finally l share more on Copilot plus PCs d windows ecosystem. Diving into how Copilot is evolt was only in the year that we shu the promise of AI and then we me Copilot for Microsoft 365 genery available in November. I want to spend a moment and tat the journey that we've been on. Within 365 we brought Copilot te applications of hundreds of milf people use every day. Given users powerful new AI to t in the flow of their work. We've seen great adoption acrose of industries. Nearly 60 percent of the fortune Copilot. We've seen accelerated adoptions industries and countries. We've added over 150 Copilot cas since just the start of this ye. In addition we continue to intee Copilot across more productivitd services from one note to streas to one drive and more. We also launched a stand alone t application where as Copilot han embedded in office, outlook and. That Copilot app now has all oft 365 embedded in it. And what makes the Copilot app d uniquely powerful is the groundt has. First, our Copilot understands . Copilot is crucially grounded ie users work context, who do theyk with, what do they work on, ther documents and that's the Microst graph. The Microsoft graph represents , their team, their permissions, r organization. It represents their context. It's important to know that a Cp is no different from any of othr commercial services in terms of compliance and data handling. Microsoft has no eyes on accessr data is not used to train the m. To let's dive in and see how als comes together in the Copilot a. In the tab you can get answers e complex questions grounded in lb data all with commercial data protection Now let's go over to the work t. Here Copilot is grounded in Mict graph meaning it has access to r personalized work environment, e you interact with, teams, meetil your communications. By the way, this is not a demo . This is my actual Microsoft acc. Using real data to show you howl this experience really is. Of course you are going to see f the action do I want to keep my. Now learning to ask the right qs key so you can get the most of e Copilot to help you there is a t library to give you suggestion n you need them. Let me start by getting caught e latest my boss, you may have hef him. Copilot organizational structurt knows Satya is my boss. It scans the latest emails and d files and in moments I have a dd breakdown of updates that need y attention. Let's try one more. Here I'm asking Copilot to propa session title based on this keye script. Which is a document in share poo create a list of topics on geneI to discuss in the session. Copilot analyzed the document wy work environment and proposed ae headline. Since Copilot is grounded in wed data it's able to recommend Tonm the web for me to consider. Switching gears, since its incen Copilot has been a uniquely perl assistant as you've just seen. We all work in teams, small and, organizations, intimate and glo. And we want to do more to go beo empower people when they come tr and like Satya said, today we're announcing team Copilot, the exf Copilot beyond a personal assis. This will enable Copilot to sert on behalf of a team, a departmen entire organization, not just an individual user. Copilot will act as a valuable m member improving collaboration,t management. Let's take a look. >> Expands Copilot for Mike 365a personal assist tonight a team t that becomes a valuable member e team. It gets added to a meeting and t like any other participant makit visible for anyone to interact . Here Copilot has been added to g as the meeting facilitate herb,g the team focus on having a prode conversation. Copilot shares the agenda in thg chat and anyone can add topics t interrupting the interactive di. It tracks time providing remindn it's time to move on to the nex. Copilot can take notes anyone cr add to. And task for everyone to see. Let's switch over to teams chat. Here Copilot has been added as a collaborator to streamline communications. As the conversation happens, Cot maintains an up to date view oft information for everyone to see. This includes surfacing unresole for the team. Copilot will also help the teamk together to resolve open issues. Here a team northbound asks Copr recommendations and grounds thet with the relevant document. Copilot instantly responds with suggestions for the team to con. Once the team has agreed on the, Copilot automatically updates te removing the open issue and dete decision made. With team Copilot assisting in s the entire team will be more pre and collaborative. [applause] . >> Team Copilot will be a valuar of any team. These initial capabilities wille available to our customers in pw late they are year. Now in my conversation with cuse of the top questions I get is hI translate productivity gains ino transformation biz results. Simply put the answer is movinga reimagining of business processg your own Copilots and agents and Microsoft Copilot. Jeff is going to walk you throur platform enable you to do just . First, let's take a look at thet architecture that makes all of s possible. Copilot as we spoke can recall n up to date web knowledge. It is grounded in search. All Copilot experiences have thb scale. Now in addition to being grounde web, it is also grounded in your the Microsoft graph. And when the Copilot is in an an like office or teams or edge, io understands the application con. For example in PowerPoint it's o draft a slide deck for from youa document. The Copilot has capabilities bae user context. Now as a developer you can built extensions at that time data lat the experience layer to furtherd and customize the Copilot. And all of this is enterprise gh tools for IT to manage and perse for employees. A leading ISPs are working withs building solutions that can expe Microsoft Copilot. I'd like to share two examples m service now and adobe. Service now helps organizations orchestrate and ought mat tasksd processes across our enterprise. Here we see service now's Copilt extension now assist respondingr prompts inside Copilot and Micr5 with the exact same knowledge functionality and experience ass today in teams. Service now is included ID promo help users get started with thet common tasks without having to w to craft the right text to stare conversation. Over to adope. Working on bring adobe experiend work flow and insights to 365 ad Copilot. With the extension users stay iw of their work. In a word document, adobe expret allows them to create social co, select and edit images and stagr publishing. As we close out this first chapI hope you are excited. Microsoft Copilot is already heg people save time, be more precid creative, team Copilot expands n meaningful ways and then there t developer opportunities for youd Microsoft Copilot. Jeff will join us now to share y you can build Copilot extension. But first, I want to close my sn with a video show casing how Lus using Copilot to enhance sales s and connecting Copilot to theirs using connectors. Let's roll the video. >> LumeN a company going througa tremendous transformation. Revolution to move from tell low communications to technology. Our goal is to help 3,000 Selled professionals shift away from transactional selling and move o customer obsessed. >> 365 helps us move faster. >> It's hard for a seller to len everything about all their cust. One way they can do this is usit for sales. What takes Sellers hour they cao in minutes. Copilot in Salesforce, that intn has been vital. People are coming to the table e prepared. They have more information, thee armed, ready to have customer conversations. Before Copilot with third partya connectors, the seller would hao out to all different systems. Copilot connectors help to solve fragmentation that customers cal which drives customer satisfact. We've seen an increase in outbos by 40 percent. Customer outreach typically takr hours. Now with Microsoft Copilot withf these third party data connectos a 15 minute journey. If we can give our Sellers backr hours a week. It's worth $50 million in annua. And that is math that matters. When you unlock, people, teams d culture, you unlong lock growth. We're at an intersection. It's time for disruption in this industry. [applause] . >> You will be able to easily ad securely use your applications d knowledge to build Copilots thap your employees and organizationr more productive and grow your b. You can now extend the Microsoft with your own Copilot with handd all the Copilot experiences as n Microsoft teams where you can rh hundreds of millions of users tr both the personal and group asse scenarios that Rajesh outlined. We're making building these Cops easier, from a few clicks in sht to more advanced customization e Ai Studio to full control of mo, data, applications, experience l studio code. Let's first look at what this mr end users. Copilot extensions run everywhet Copilot is. Stand alone experience across Mt teams and as we're showing heree Microsoft 365 app. On the right you can easily bror installed Copilot extensions, fw ones or build your own which I'w coming up. And how Microsoft Copilot workst reasons over the user's prompt s it to the right Ebonies tensionu  rightle extensions. You're going to be able to drila focused conversation with extene we're doing in this marketing ee that has suggested prompts for k actions and to show the use tere capability of your Copilot. This allows the Microsoft Copile real time access to knowledge ad applications in your environmen. Here we're using a suggested pro ask about a key feature of a dey drone. The Copilot extension you buildg to come back with a visual adapd bringing in all the informationd an unnecessary multiturn convero the user can just focus on gettr work done. And again these Copilot extensio run in teams and group chats and channelsnd meetings so you can l these users today. All right. This is build so let's get to bg with our first custom Copilot e. You are going to be able to do h Dr. a few clicks in share pointo advance CSU my vagues to Azure o to code. We'll start in share point whicn the authoritative source of knod content processes with advanced collaboration, work flow and sel of which Copilot honors to makee users only get access to informt they have permission to. I'm in this share point see. I'm going to select a few docum. Hit click to Copilot and right t looks good. I'll go ahead and change the naf this. The delivery drone. That looks fine. And just like that, I've createt custom Copilot that you can used to Microsoft Copilot. Let's try this one out. How much does delivery drone see cost? And we can see it comes back wit fee of $5 per order. All of that looks pretty good. Secured, grounded, we're going o ahead and share that with our t. Up comes the sharing dialogue tr the organization. We're going to copy this link. Go into teams, paste it in the . We'll say try this out. We will go ahead and paste that. And just like that in seconds we created a secure grounded custot and shared it with our team in t teams. So we're very excited about letg anybody create these secure cusm Copilots and this support will e available in share point this s. Sign up today for the preview. We're very excited about that. You can see this is all carriedd from SharePoint. Let me test this out by asking e launch event is. It's on June 20. What I really want is that Copio work for me, not just answer qu. And so for this I need to go int studio and start by adding addil data sources in the knowledge t. Here we can add websites and fid connect to over 1,000 Copilot connectors. In this case our account informs in two tables and data verse. I'll select them. We have the information we need. Next we move to the actions tabI need to see if somebody is alrey registered for the event and ifd them a personalized invitation. Our event registration is managn external systems so we created m connector to go get it ever. You can see us configure that. We can tailer the action and pus where we need. The second step is automate that invitation. We built a custom power automat. We'll add that as a Copilot acts well. There you go. Pretty quickly we have a come fx Copilot extension with content m SharePoint, data from data verso disparate actions and we can ten Copilot studio to see if they ae attending the launch event. It says they are not. And the Copilot conversation heu see why what is happening and mt all through. We can ask a followup question s routed to data verse about who e account manager is and we can st the Perry Lang. We can ask Copilot to send the invitation. What happened here is the conven was entirely generated for me, identifying and chaining togethy knowledge from data verse and te appropriate actions we added eah generative AI capability. Last we're ready to publish thit extension back to SharePoint, Mt Copilot and teams. From teams you can search for ie unified marketplace. I can add it to one on one or gs etc. I can see this in the Microsoftt experience. That same cloud Copilot continud experience there. We're very excited. This is a pattern that people ay doing today. Let me show you what one of ours who is a leader in information d software and solutions is doingo enhance their tax and accounting practitionerral work flow with . They are building a Copilot exto enable their accountants to comh step of their work flows interah their back end system just usinl language with no context switch. Copilot takes actions on their f saving time and cutting the pron from minutes to seconds. It's time to communicate back tr client, the extensions help cloe loop, drafts and email, attach e estimates and ensures a seamleso end productive experience. Copilot is available to build ee grade Copilot. The Copilot extensions from yout is in private preview. And as you heard Satya say Copit connectors are now in public prd they make it even easier to conr Copilots to your business data,s and work flows. Last we want to show you how toa Copilot extension as a professil developer with full control of r models, your data, your actionsr experience and visual studio co. Let me go ahead and do that. What we've got here is visual se with the teams AI tool kit inst. We load up a template using it n extension. The first thing you see in the s where icon figure the model. You can use an off the shelf mo. Here we're using one from open e model or build your own tailoret you need. If we scroll down further. This is where rag integration i. You can see in a few lines of ce integrated our data. Azure vector search capabilitien use any other data source. The Azure AI search cape State't a great one to use. We keep scrolling down, see the. Defined and registered. Here is where we go search for t inventory and you can see we'ved a break point so that we can fos along. I want to show how easy it is td to end development here. We'll bring up teams where we id that Copilot extension for the , find information for the produc. Hit return and we're paused. Why? Because we've hit that break po. So we can go back into visual s. You can see it's fired. If I hover over the parameters,n see the product name has been po it. This is incredibly powerful rigm within visual studio to do end d debugging across the Microsoft , Copilot and your Copilot extens. If we keep going down before wen that to the user, I wanted to st the UX looks like. Here is an adaptive card. Comes back, you can see the user experience for that. That all looks good. Let's go ahead and resume execum the debugger. You can see we've now returned o teams. The result and we've gotten atte card that gets the user the infn they need. Does handoff with the Copilot. So right in line the user can ce the work. It's pretty exciting full flexiy with the teams AI library and vl studio code. We're excited just like with Cot studio, this is something you co today targeting hundreds of milf teams users and very soon the ao turn your custom Copilot into an extension will be available. On this -- this is something tht hundreds of ISVs are already dog today. Across all sorts of experiencesn Microsoft 365 teams and now Cop. Just two examples are leading se organizations. Esri is the market leader in gec information systems. They are building a Copilot extn that adds spatial analytical cas directly into teams meetings sot users can ask Copilot Microsofta question about map data and it l seamlessly hand off to a rich ee with visualization and custom Ct with all the associated context. Next is Tom son who is a leadiny transforming the legal professih AI. They are extending the experienn outlook and word and teams for s like risk assessment so based oe content of the outlook email thn update the policy documents in d communicate those policy changeo reduce risks within the teams m. We're super excited to see whato targeting this huge user base ae going to help promote and distrr application through our unified marketplace again reaching hundf millions of users today in Micr5 and in teams. And one of the reasons this mare is trusted is IT has confidencee full governance capabilities for own applications and custom exts they build as well as the ones t from you building them in a vibd party ecosystem. To recap, we have a simple powel platform for AI and Microsoft 3t you can use to be far more prode across the full spectrum from sg everyone can do in SharePoint te customization in Copilot studioe full power of visual studio andl studio code. Wait, there is one e one more t. We are very excited to make teaa fantastic place for developers k together with AI to write bettee faster. And so we've got a whole set of announcements around that this s well. First things first, source codee teams with syntax formatting. And get this. [applause]   with Microsoft loop. Coed did iting within teams. You can see more content on then compact mode. You can be productive with keybd shortcuts and new slash commandr teams and of course developers n the flow of resolving issues ind one of the features we're excito announce is meet now so within u can bring up a ringless call ben members of the team and resolvee in seconds. And last developer teams love tn to break from the stress so youe custom I knowledge joys now in t teams. [applause]   of course this is building ona growing set of partnerships witp tools and of course deeper inten with GitHub. And much more integrated with Mt teams. So we're very excited to make ta great place for developers to wk together to build this next genn AI. The next chapter is how windowse best platform for building thatt generation AI and to show that m excited to invite to the stage. >> Good morning. I'm excited about the Copilot extensionability that was just . It shines on windows the platfos customers choose Microsoft 365 d Copilot. Over the last year we've learneh about how Copilot can best serv. We're working hard to make it ee valuable with the vision for Cot meeting you right in your work . Imagine creating a presentationa document in file explorer or heg customers troubleshoot PCs usink actions and natural language rin settings. We're focused on making Copilote contextual and useful across wi. We took a big step towards thatl yesterday with the announcementf Copilot plus PCs. The fastest and most intelligen. That is inspiring. AI is woven into every layer ofe devices. From the silicone to the operatg system. With the most powerful PCMPUs cf delivering over 40 trillion opes per second. This is up to 20 times as powerd hundred times as efficient for I workloads compared to traditions from just a few years ago. Built together with our silicons AMD, intel and Qualcomm and OEM partners. These will be available June 18g with Qualcomm series of chips. Copilot plus PCs are redefiningu can do on a PC and setting the n for the next decade of windows. To put this new waive of AI innn your hands Qualcomm announced sn dev kit for windows. It's designed to be your dev boI with the power and flexibility . As we define this new path for n the era of AI, one thing that wr change our commitment to openne. We recognize that the real valuf windows comes from the energy ae innovation of the ecosystem. It comes from all of you. As we enter this new era, let'sk about how we're going to serve a billion windows customers toget. As Satya said earlier building l platform takes more than a chipr model. It takes reimagining the entirem from top to bottom. The Copilot long time is a systt extends the Copilot stack to wi. Windows Copilot run time is a nw integral part of windows 11. It has everything you need to bt AI experiences whether you are t getting started or already havef your own. It includes the windows Copilotn a set of APIs powered by on devs that ship with windows. Includes AI frameworks and toolp you with your own device models. And it's built on the foundatioe silicone including NPU in the d. Let's take a look at how the wis Copilot run time enables a new f experiences. OS experiences like recall thatp users find anything they've seer P C. Inbox app experiences in photost which let you bring your ideas e using real time image generatio. And app experiences like resolvf our first partners using it andg us build the window Copilot run. Looking ahead, the "X" box teama vision for using the run time tr players and game developers. Let's take a look. >> That's pretty inspiring. Faster task completion. Let's look at that time recall experience. That data is transformed into vd index in vector store called wis semantic index. Recall user activity AI allows u extend your app into recall. So users can jump back to wheree in your app and increase your ap engagement. In the same way edge and Micros5 apps like outlook, PowerPoint as already have. In fact soon recall will join ct from the Microsoft 365 graph. To build your own store you cane vector embeddings AP I. That makes it possible to use rl augmenting generation or RAG wir applications with your data. Imagine you have wind farms or p that works against a logger corf sensitive data, with vector youe able to create vector stores foe vectors. That's powerful when congress bh RAG to enable search in your aps for your users. Of course that's just one examp. The APIs in windows Copilot libr the spectrum of locoed API to sophisticated pipelines to fully multimodal models. The recently released Phi-3. It does a better job than modele its size on key benchmarks. Today we're thrilled to announcl casement built from models specy built for PCs. It offers lightning fast infered state of the art responsiveness. Windows is the first platform ta state of the art SLM custom buie SNU custom in box. Look at what you can do using frameworks. It starts with direct M L. The lowest framework in windows. We're going to look at open sous or open source models from hugg, direct ML helps you scale the bf your efforts across the windows ecosystem. By giving you access to GPUs. We know a lot of you do developn windows. We're thrilled to announce windl support through direct M L. [applause] . The hugging face models will jun windows and not just that we're collaborating to bring these wos to over 100 million RTX in the s ecosystem. That's incredible. You can download the preview to. We're also going to extend direM throw. Our web developers. Introducing web on windows. It's a machine learning framewo. We've been working with partnero unlock the access to local actie insights set raters so you can n your web execs. You see the auto compos featureh cloud savings by leveraging ORTd web N N. I'm excited to announce that wes available in developer preview . [applause]   that's a glimpse of the windot run time how it lays the foundar anyone.  innovation, making windows then platform for AI. I heard you. That's fantastic. As windows transforms for the e, we're continuing to reach expane platform. Including all the AI experienceu create with the windows Copilotn time. We're delivering windows from td with windows 365 so your apps ch any device anywhere. And we're introducing windows es to new form factors beyond the . For example we're deepening our partnership with Meta to make wa first class experience on quest. And windows can take advantage t unique capabilities to exten wis apps into 3D space. We call these volume met I can . >> Work flows are transforming d reality. Microsoft is partnering with Meo bring windows 365 to quest. Enable developers to extend thes apps into the 3D space. This extension allows users to e spatial understanding without le app that powers their work. As developers you have access te metric AP I. This is one of the ways to broar reach through the windows ecosy. For decades windows has been a r world innovation. The Copilot run time and 365, wg to unlock a new era of innovatin together. Thank you. Back to you. >> Thank you. And thank you Jeff. We've covered a lot of ground oe last 40 minutes from the expansf Copilot beyond a personal assist acting as a valuable team membew you as developers can extend Mit Copilot with your own Copilots d agents. In just a few clicks in SharePoo more advanced customization in i Studio. Full control of your models, dad actions. And of course a phenomenal oppoy for developers with over a billn windows customers. I'm going to close with highligg another customer, pioneering bio technology company to fight thes diseases. We're going to see how they hars Microsoft Copilot in their miss. Kevin Scott, our CTO along withe special guests will round out te of keynotes. Let me finish by saying thank y. Thank you for spending your tims here at build. It means a great deal for all o. And thank you for the trust youe working together building the fs every day. Let's roll the video and thank . >> We're at a once in a generatt where we have the opportunity he power of tech and bio tech to revolutionize drug discovery and development, manufacturing and commercialization. We started with 300 licenses anw 20,000 of our employees have aco Copilot. >> In manufacturing you are mova very fast pace. You have a lot of data coming a. Copilot is one tool that allowso synthesize that information ands that we can focus on what is im, the production of that drug. >> We've taken advantage of extensionabilitiesing ons usingh connectors, identifying opportuo use Copilot for daily efficiencs and multiplying those by 100 or0 times in the life of a moleculen idea to achieving marketing autn gives you a sense for what is p. >> We have capabilities in our h these new tools, in the early df this new platform to absolutelyo amazing things. Where literally the challenge fl is to go do some legendary stuft someone will be in a of you for. >> People are looking for food , it can be a hum bling experienc. >> Childhood hunger and food iny is a problem we can solve. We're using AI to connect those. We know through research peopleo talk to an AI agent, talk to a t because their not talking to a . >> Technology can really help pt what they need with multiple ren one place. It's making it mobile friendly s important. Most people access this informaa smartphone. No kid hung I have ensuring thad childhood hunger. >> Around 2019 Brian started hae issues with his ankle. I was able to get him an appoinh a doctor and he was like I hatel you, but this is AL S. >> How would I live in a world y kids wouldn't be able to hear mI love you. >> The biggest opportunities wht comes to emerging technologies p that it can fill. >> AI has the ability to increae communication, increase indepen. It's a next wave for accessibil. >> Their voice thinking technoly live gives someone back the intn and a little more of their pers. >> We're going to play a newer f your voice. You choose a phrase and I'll pln here as well. >> Hey Beal people I'm so happye with all of you. >> I'm going to tippet out. >> Hey beautiful people I'm so o be with all of you. >> This sounds like me and I'm overwhelmed with joy my family o experience this part of me. In many ways I feel like I'm ba. >> Please welcome chief technoly officer and executive vice presf AI Kevin Scott. [applause] . >> Thank you all so much for beh us here today. I've been fascinated my entire y tools and the power that they gs individuals in teams to really e extraordinary things. In my own personal making my wie sometimes wishes that the ratios to extraordinary things was a le different than they are. But as a person who is dedicater entire career to building systed infrastructure, tools and framer other developers to use to go me things that they need to make fr whatever reason they need to mas just extraordinary gratifying te these new AI tools we have a roo bring into exist. I want to thank you so much fore greatgreat stuff you've made ovr the past year. I want to give a callout to ours that share our strength. The work we showed in the videoe doing. As Satya mentioned we have over0 customers using Azure AI tools d platform. Like this range of customer spas everything imaginable from all t industry categories, all differs of business from small startups. Using AI to do transformative te trying to find product market fo scaling things where you found e product market fit to folks jusg to figure out how to optimize ae the things they've been doing fy long while. My team has had collaborations e of you in the audience. We've been doing cool work withi using generative AI and Azure Am to build features like their net mode. So we have the CTO of et si in e audience with us today. You all should go check out gif. It's an innovative way to help e out how to buy things for people difficult to buy for. It's super stressful trying 20 t what the right gift is for the u care about. This is one of many interestingt si is doing with generative AI e the experience of the product ao bring delight to their customer. Another thing that I'm super exd about is the work that cognition doing. So scoot Scott and the cognitioe also here with us today. We have just recently announceda partnership between Microsoft ad cognition. Their product Devin like an absy amazing tool. So like if you can imagine for f some of the mousteddous things u do as an engineer of software d, Devin a tool designed to help yh those tasks. I can't even tell you all the nf times as an engineering leader r engineer I've had to write coded teams writing code for doing the replatforming and application. And replatforming is one of thef physics of how we build software systems. It's a thing that must be done. But it's rare that an engineer y enjoys doing that. Like the incredible work that ds doing on top of these incredibll tools is just really extraordine excited to be partnering with td bring the power of what they aro Azure and having their systems d infrastructure run on Azure. I really want to talk with you y about just a couple of simple t. What is driving all of this pro? Why is all of this happening ri. We're riding a wave. Something is changing in the unf technology, much in the same wat changed when we were going throC revolution where moors law was n incredible increase in the powed lowering of the cost of personal computing which led to somethinw all take for granted. Similar thing happened with thet revolution where technology cond this together and allowed to uss previously unimaginable. We're going through one of thosr changes right now. Being partly driven by a set ofs we'll talk about in a few minutt the incredible scaling of the cy of AI systems as you apply moree and more data to training them. To figure out the things that he done to deploy in real applicato you can deliver real customers e about what you are doing. We've done a huge amount of wore past year on the Copilot stack. It is optimizing a bunch of syso things are getting  This progress we're making in filline tool kit for you all so that itr for to you build software. But we are riding a fundamentaln the development of this platforf allonge at compute over time. Like how much GPU cycles or accr cycles we're using to train thet models in the world since 2012 t increase and compute when afraig has been increasing. So we're sort of doing two thine at Microsoft. We are optimizing the current fr and while at the same time invet an incredible rate in pushing te frontier forward. One of the super interesting tht just happens avenue happened ase pushing the frontier guard and e really driving forward on effic. Is what our partners open AI lad last week in the form of GPT4. Add Satya mentioned earlier GPTa stunning achievement, multimodal that understands a bunch of dift input types from video to text h that can respond in a rich wayst and speech and eventually video. It can respond to you to the ins for users in the applications il time and in the case of the ChaT demos that folks have seen, youn interrupt the model so that youe fluid interactions with these s. An enormous amount of work has o GPT and the infrastructure arouo ensure it's that safe by design. I wanted to remind folks like ts efficiency point is real. So while we're off building bigr computers to get the next big mt and deliver more and more capabo you. We're grinding away on making tt generation of models much more efficient. Between the launch of GPT4 whict quite a year and a half ago now. It's 12 times cheap tore make ao GPT40 than the original model. And it's six times fastener tere to first open response. It's really extraordinary how mh progress we're making because ol set of optimizations we're doine silicone that we're building, n, data center optimization and an incredible amount of software we doing top of this infrastructuro really tune the performance of e systems. And the great thing is again tho point of diminishing return her. One of the messages that I wantd with you all today is that you t on things getting more robust ar at a pretty aggressive clip ove. It's like a really important tho internal lose like we challenges on at Microsoft all the time. I'm for things that are big. I just want to show a little quo video here. Let's roll the video to show yo. >> Microsoft build conference iw and I've not been sleeping and g stupid mistakes. Can you take a look at this cod. >> I'll be happy to help. Can you tell me more about the h the code. Are you getting an error messags the code not doing what you expo do. >> Let me show this to you. It looks like you are working on function to summarize main poin. Approximate. >> Summarize all of this work. My problem is I wanted to add to the were keynote list. What did I do wrong here? >> Change keynote list dot exteo keynote list apend e pend. This will add Kevin as aa singlt to your list just like Satya. That sounds good. Let me try that. >> Sounds good. Give it a go and let me know hot works. >> I replaced extend with apend. Does that look right? >> Yes, that looks better. >> I made that change. Let me run it and try. >> Sounds good. Let's see how it goes. >> It worked. Satya and Kevin all came out. >> Awesome. I'm glad it worked out. Sometimes the smallest things ck us up, especially when we're slp deprived. >> Thank you. It is extraordinary. I should say Jennifer would neve that mistake writing a python an but Kevin might. This is giving me hope a CTO wie to program again if the need ar. Do I want to make sure we're pag attention to just how much has d over the past year. Like what you just saw would han absolutely inconceivable to thit actually working. And this was not a tortured deme were looking for something to sf GPT4 to you all last night. And Jennifer showed me this andt recorded this demo. Like this is just crazy that its this well. So another set of things that hn really making a huge amount of s is like what is possible with sr models. So we have been working for a wn this series of models called Phe small language models. Satya chatted about this earlie. And the way that we think abouts just imagine an efficient front. Usually when you build these mou are trading a couple of things . So you can trade size off whichs related to performance and costa bunch of other things versus qu. So the small ter model is like e cheaper it is to do inference ae ifth less commuted compute you o run the model, so small models e ameanable to running on devices. But it usually means you have ta hit on quality. And like what we discovering in particular over the past year is this notion of efficient pron t. So we don't show the GPT4.0 on s slide. It would be way off to the righs of size. If you want extreme levels of qd performance. A frontier model is your friend. In some cases you may want to ce another model somewhere else ons efficient frontier where the trf you're making between a cost tor latency or locality is acceptabn the quality that you can get. And the very interesting thing s been happening over the past yee quality that you are able to acn these small models getting pret. So I just wanted to show this an illustration. Remember back ancient history te launch of Chat GPT in November . Chat GPT launched on top of 3.59 everybody was absolutely gob smt what was possible with GPT3.5. Just a stunning revolutionary tt happened. We fast forward a few months toh 2023 and Chat GPT gets an upgra4 which is more extraordinary whas able to do. You are able to ask complicateds and get rich interesting compelg completions. So fast forward to today and lin sort of see a version of Phi 3 d to run on a mobile phone can rea prompt just like Chat GPT coulda year or so ago with responses te sort of equivalent. This is not arguing that Phi 3 g on this device is just as powers GPT4. It is not. But the way you all should be tg about it is in many cases theses can be appropriate to use for bg your applications when you havec constraints you are trying to oe towards. All of this is abstract in a wa. And so I wanted to motivate whys matters with the following exam.  they shall triking to ensure tr on the planet no matter where ts to high quality individualized . One of the things we're explorih Khan academy is the possibilityt goal of ubiquity of personalizes by using something like Phi 3 wn imagine training afire 3 model d at something like math instruct. So this has been fine tuned to y well for math tutoring.You wante answer for themselves. A Tuesday or the is different from an answer agent. It's exciting to think about how many tools Khan academy have to solve important missions they have in the world. With that I'd love to bring can academy on to the stage. >> Thank you so much for being here with us today. We have been chatting about your mission I think for quite a while. And one of the interesting things that happened when Chat GPT burst on to the scene a few years ago was there was a reaction from a bunch of educators. Reasonable reaction where we're like OK we don't understand. This we don't want students  you on the other hand, looked at this and said, this is amazing, and leaned all the way in. Can you explain about what drove your first reaction to this new technology? >> Yeah. You know U. some of you all know how Kahn Academy got started. Almost 20 years ago, it started with me tutoring a cousin. I tutored one cousin, before I know it I'm tutoring 10 or 15 cousins and I started making videos and writing tools for them. If you think about that journey from then till now, even right before we could start working on generative AI, everything is, how can you style that type of personalization I was doing with my cousin? And we were approximating it with software and video. But to some degree there was going to be, we were going to -- on how far you could get with pregenerative AI tools. When we saw it it was GPT 4, Greg and Sam from OpenAI showed it to us end of summer 2022, and there's things that had to be worked out, but it could get that much closer to emulating what a real tutor would do. And it was obviously could be used as a cheating tool, and you have to worry about privacy and safety. But I told the team, let's put the guardrails on it, because this could get us that much closer to our mission, which is free world class education. Displi think one of the other things you all have done, and this is a really important thing to internalize about these models and systems, is the model isn't a product, and the systems aren't silver bullets. You still actually have to understand who your customer is, what problem you're trying to solve, and how to go deal can with a whole bunch of gnarly things on top of the incredibly interesting tools so you can do something useful. Do you want to talk about what you had to do there? >> I have to admit, maybe everyone, a lot of people in the room are experiencing this, every now and then you see these demos and you're like, does my application even have relevance anymore? This thing is going to be able to do everything. Then when you sit down and you really think about how a school system, a teacher, students are going to use it, and what are the guardrails? How do you make sure it does the tutoring interactions appropriately? You realize there's a lot to do at the application layer. I think we're all discovering together this new world of developing applications on terms, on top of Large Language Models, you have to have evals, test it, but we're realizing there's so much to do, it really is a bit of a very exciting time. >> One of the things I am especially excited about is this mission that you all have for ubiquity, and the partnership that we're doing with you all is going to enable you to get the hand -- get every teacher in the United States hands-on Kahnmigo. A personal anecdote for me, my daughter is in the ninth grade, she's taking biochemistry and is in love with science in general. She, on her own, without prompting from dad, figured out how to use the free version of ChatGPT to take a bunch of biocongressmen papers that were -- biochem papers that were more complicated than a 15-year-old can usually do, and dump it into ChatGPT and ask a million questions. Her learning acceleration, because she's figured out how to use this tool is extraordinary. I want every kid in the world to have the same experience my daughter has. >> Absolutely. We realize at Kahn Academy there's a subset of students, if you give them the tool, they will run with it. But what you really need in most cases is you need caring adults, primarily teachers in the room, motivating students, driving that usage. So what we're excited about this partnership, and this is a big deal, I want to make sure, we are using state of the art models that use real compute, real costs associated when we launched Kahnmigo. It's a tutor for students, a teaching assistant for teachers, what but what we're launching today is these state of the art teacher tools, we're going to be able to give free to every teacher in the United States. So that they can get productivity improvements. [applause] >> Big, big deal. >> Big deal. I actually think teachers will be the first mainstream profession to benefit from generative AI, lesson planning, progress reports, grading papers, et cetera if we can win teachers' hearts and minds, it gives us that much a better chance to reach students. >> One last thing before we go. I know that you have just written a book, and like having written a book myself, it's a lot, a lot of work. Like everybody should pay attention to these fantastic endorsements, the has gotten, go read a copy, it's a fascinating work, not just about education and your mission, but like I think also it has a bunch of really interesting lessons about how you can ambitiously use AI to solve hard problems. Why did you choose to write a book now? >> You know, this is the second book I wrote. The first one I wrote in 2011, I remember when the publisher had reached out to me, why would I write a book? I can put it on YouTube and share it with the world. But there's something about writing a book that lets you frame the problem. And I felt that 12 years ago when Kahn Academy first came on the scene. I think this moment, we all feel, even more overwhelmed. You mentioned these inflection points, exponential growth, we're all feeling things are changing every week. I wanted to take the time for myself, to understand where we are and where we're going, and hopefully a reasonably timeless way. It's not going to be dependent on whatever the frontier model of the day is. Especially anyone who cares about education, work, what skills their kids should learn to keep up, how we can all be more productive, what the future of admissions and recruiting is going to look like, hopefully this will be useful for them too. >> I'm incredibly grateful for the partnership we have, and more importantly for the work that you're doing in the world. Thank you so much for being with us today. >> Thank you. [applause] >> So another really incredibly impactful area where these new AI tools and platforms are going to have an enormous impact is healthcare. So I just wanted to share another personal anecdote with you all. So I grew up in rural Central Virginia, and my mom and brother and most of my family still live in the place where I grew up. My mom is a 74-year-old southern woman, and has been suffering from a thyroid condition for 26 years, which you know, entirely under control, she's been taking medication for it. And just last fall, she had some sort of change in her system where all of a sudden her medication wasn't working as well as it used to. Which resulted in her spending a bunch of time in the hospital, like, trying to figure out what was going on. And the healthcare system in the part of the world where my mom lives is super overburdened. Like, it's not a place where tons of people are sort of moving for economic opportunity. It's one of those places where tend to people -- people tend to move away from to seek opportunity. Which has impacts on everything that is happening in that part of the world. And I sort of, as I was trying to help my mom navigate this situation, I was looking at how could AI have helped relieve the suffering that she was experiencing? And if doctors everywhere had access to these tools, like a lot of what she went through could have been immediately alleviated. Like, if you just take her symptoms she was presenting and put it into ChatGPT 4, along with her chart, it would immediately say, go get this test, which is going to help find root cause. And then the results of the test could be input into the same session, which would then sort of give a set of recommendations to doctors about course of therapy. And if that had happened in her case, like what was six visits to the hospital, could have been compressed to one. And I think about this a lot, because I worry even whether or not my mom would have pulled out of a health spiral that she was in if she hadn't had me for a son intervening on her behalf. And I worry about all of the people in the world who don't have someone to intervene on their behalf, like who are interacting with one of these resources that is overburdened. And so like, I just want us all to think about, as we're imagining what the set of possibilities are for what we go do with AI. Things like what Sal is doing, with Kahn Academy, and some of the amazing potential we have to reduce suffering in the world and to help make things like high-quality healthcare more equitable and accessible, just super inspiring to think about. So the last thin I want to chat about before we get to conversation with Sam Altman, is how we at Microsoft have been thinking about building applications on top of this incredible platform that is emerging right now. And so the challenge I think for us, and I think it's the same challenge all of you face, is that you really want to focus on things that he made the transition from impossible to merely difficult. Like, that's where all the interesting stuff is. If you look at the history of platform revolutions, that's where all the interesting companies emerge from, it's where all the innovation happens, it's where all of the value gets unlocked. And in the case of technology platforms that are sort of exponentially progressing, it's like the only reasonable place to go aim, because if you're aiming somewhere different, like the platform is becoming so much more capable and so much cheaper over time, that everything that you sort of have in your imagination that's too expensive to do right now, or too fragile, is going to become cheap and robust before you can blink your eye. And so like, that is really the thing more than anything else that I would say to all of you to take away from what I'm saying here today. Really focus on those transitions. So while you all have been out there grinding away, building, really extraordinary things over the past year with all of these AI tools that are coming, we've been hard at work trying to make forward progress on our AI platform. So we talkedded a lot about how we're optimizing the current frontier, making things cheaper and making them more powerful, and complete. But we've also been hard at work building new spiewrt computing infrastructure and working with our partners at OpenAI to push that frontier forward. Like we showed this slide at the beginning, there's this really beautiful relationship right now between the exponential progression to compute that we're applying to building the platform, to the capability and power of the platform that we get. And I wanted to, without mentioning numbers, which is sort of hard to do, to give you all an idea of the scaling of these systems. So in 2020, we built our first AI supercomputer for OpenAI. It's the super computing environment that trained GPT 3. We're going to choose marine wildlife as our scale marker. So you can think of that system about as big as a shark. So the next system that we built, scalewise, is about as big as an orca. And like that is the system in -- that we delivered in 2022 that trained GPT 4. The system that we have just deployed is like scalewise about as big as a whale relative to the shark-size supercomputer and this orca-size supercomputer. It turns out you can build And so one of the things that I just want everybody to really, really be thinking clearly about, and this is going to be our segue to talking with Sam, is the next sample is coming. So this whale-size the supercomputer is hard at work right now building the next set of capabilities that we're going to put into your hands so that you all can do the next round of amazing things with it. With that I'd like to bring Sam Altman to the stage. [applause] So you are one of the busiest people on the planet. >> It's a wild week. >> It's a wild week. A wild year, man. But -- I really appreciate you taking time out to chat with us today. I guess what I really wanted to start our conversation about, and like I asked you this question last week, there's just been an extraordinary amount of change over the past year and a half, year, what has been the thing that has surprised you most? Particularly relevant to an audience of developers? >> I mean, I'm delighted to be here. Obviously great to see you, but developers have been such a core part of what's been happening this last year and a half. There's millions of people building on the platform, what people are doing is totally amazing. And the speed of adoption and talent and figuring out what to build with all of this wheefer has really not been very long, when we put GPT 3 out in the API, some people thought it was cool, but it was narrow. And Steven Green what people have done with GPT 4, and seeing now what's happening with GPT-4o, even though it's new and hasn't been out that lodge, is quite remarkable. I've never seen a technology get adopted so quickly, in such a meaningful way. What people are building, how people are finding out how to do things that we never even thought of possible, which is why it's always great to have an API. >> What you just said is one of the most important points to me. There's a version of AI that could have existed, that is like a bunch of smart people building things at extraordinary scale, and just building it into a bunch of products where everybody gets to passively use them. The really brilliant thing that you all have done is taken the exact same set of things and decided to make it available to any developer who is able to sign up for an API key. >> Yeah. We try to be really thoughtful about what makes a good API. There's going to be all kinds of ways people can use this, but the more this can be a layer that gets built into every product, every service, the better, and we've tried to make it such that if you want to add intelligence to whatever you're doing, any project, any service, we make it easy. >> And again, I think the progress has been stunning. I think the set-up for introducing you on to the stage here was -- >> I saw that big blue whale. >> Yeah. You're making good use of the whale-size computer right now. Without getting too specific, which we can't be obviously, what are the category of things that people should be expecting over the next, you know, few months? >> So the most important thing, and this sounds like the most boring obvious trite thing I can say, but I think it's much deeper than it sounds. The most important thing is that the models are just going to get smarter. Generally across the board. There will be a lot of other things too, which we can talk about. But if you think about what happened from GPT 3, to 3.5, to 4, it just got smarter. And you could use it for all these things. It got more robust, it got much safer, both because the model got smarter and we put more work into building the safety tools around it. It got more useful. But the underlying capability, this amazing emergent property of, we actually are seeming to increase the general capability of the model across the board, that's going to keep happening. And the jump that we have seen in the utility that a model can deliver with each of those half-step jumps in smartness, it's significant each time. As we think about the next model and the next one, and the incredible things that developers are going to build with that, I think that's the most important thing to keep in mind. Also, speed and cost matter to us. So with GPT 4 we were able to bring the price down by half and double the speed. New modalities matter. Voice mode has been actually a genuine surprise for me in how much I like the new voice mode. When people start integrating that, I think that will matter. But it's the overall intelligence that will be coming that I think matters the most. >> So you for a while have been one of the most successful start-up investors in the world. And like now, you are one of the most successful CEOs of one of the most important companies in the world. You've got a room full of developers here, I think there are 5,000 people in the room and 200,000 onhave line right now. What's your advice to them, as they think about how to spend their precious time, given what's happening in the world? What's your advice? >> Two things. Number one, this is probably the most exciting time to be doing building a product doing the start-up, whatever it is, that we have seen at least since the mobile boom, and probably I would say since the internet. And maybe even bigger than that. We don't know yet. But the big opportunities, the big -- ability to build something new and really kind of change the landscape, that comes at the platform shift times. And we haven't had a platform shift in a while. And this looks like it's really truly a platform shift. And so my biggest piece of advice is, this is a special time and take advantage of it. This is not the time to delay what you were planning to do or wait for the next thing. This is a special moment, and a few years where a lot of stuff is going to happen. And a lot of great new things are going to get going. The second thing, also about platform shifts, is when the mobile phone revolution started, or really got going, 2008, 2009, you would see people say, we're a mobile company. We have a mobile app. A few years later, no one said they were a mobile company because it was table stakes. And amazing new technology, which I would -- I'll put AI in that category, it doesn't get you out of the hard work of building a great product or a great company, or great service. You still have to do it. AI alone does not automatically break the rules of business. So you can use this as a new thing to do, but you have to figure out how to build value into everything you're doing. It's easy to lose sight of that in the excitement of the gold rush. >> Before we let you go, you and I and members of your team and members of the Microsoft team have been doing an extraordinary value of work over the past -- volume of work over the past year and a half, two years, thinking about safe deployment of a lot of AI capability. Everything from APIs and developer tools to end products. And I think we have accumulated a really interesting volume of experience, like experiences sort of hard to get if you're not doing deployments at this scale. So I -- and I think you just mentioned something that's really interesting, part of the interesting and surprising progression of capabilities of these models means that there are more useful and helping to make AI systems safer. I don't know whether you had some thoughts to share there as well. >> You know, when we first developed this technology, we spent a lot of time talking about, all right, we've made this thing, it's cool. Are we ever going to be able to get it to an acceptable level of robustness and safety? And now we kind of take that for granted with GPT 4. If you use it, it's far from perfect, we have more work to do, but it's generally considered safe enough for a wide variety of uses. And that took an enormous amount of work across both teams, and fundamental research. When we started this, we're like, we've got this thing, this language month tell, it looks like impressive, and kind of not, how are we going to get it aligned and what does it -- is it going to take to deploy it? The number of different teams we've had to build up to go from research and creation of the model, to safety systems, to figuring out policy, to how we do the monitoring, that's a huge amount of work. But it's necessary to be able to deploy these and use them. Like when you take a medicine you want to know it's going to be safe, when you use an AI model you want to know it's going to be robust and behave the way you want. I've been proud of the work the teams have done together, and it's amazing how fast this much work has happened. We can all now use this and say, basically it works. As the models get more powerful there will be many new things to figure out as we move towards AGI. The level of complexity, and I think the newer research it will take will increase. I'm sure we'll do that together. But we view this as a gate on being able to put these things out in the world, which we want to do. >> It's definitely table stakes. Thank you so much for being with us here today. I really appreciate your time. It's awesome to hear from you. [applause] I will -- I think this is all that's separating you all from the rest of your build and probably lunch. So my very last thing for you all is the following call to action. Microsoft and our partners like OpenAI are spending an extraordinary amount of energy and investing capital at an unprecedented scale, trying to make sure we are building a genuinely valuable platform. But like all we're doing is building the platform. And I don't even think that's the most important part of the AI revolution that's happening right now. It's you who are doing the work. You're the ones who are making all of these things matter. Like, we could build platforms all day, all night, and if you all didn't have the great ideas like you didn't understand the concept -- the impact you wanted to have on the world, it would all be for nothing. So I'm incredibly grateful for all of the things that you all have done on the platform over the past year, and I am incredibly excited to see what you all are going to go do in the year ahead. Thank you all so much. [applause] >> We want the user experience on it sign-on to be delightful. We want Etsy to be the destination for gifting. When buyers come looking for some special gift, we want to be able to match them to something unique and special. We have about a hundred million listings, and process billions of events every day. At that scale, it's challenging. >> With again AI, we can understand our inventory better. We can understand our buyers' mission better, gift mode is a part of our product where we serve can I verse ideas for anyone who likes to buy gift for their loved ones. Our Gift Mode team come up with hundreds of personas. For each we're using LLM to generate what will be a suitable gift and we are fine tuning all these ideas. We also use LLMs to generate synthetic queries to queer aye all of our inventory. It helps us generate a lot of ideas quickly, and I believe we are at the beginning of a new era to connect our buyers to our inventory in a better way. >> Hello, to Microsoft Build, the show floor, where it all happens. By the Quay, if you're here, you'd be here to meet these amazing people. My good friends Sam and Alex. Welcome to Build. >> Thank you. Thanks for having us. >> They're from the Surface team, and you had a major day yesterday and this morning in the keynote. Tell us about that big announcement. >> Yesterday we actually introduced our two first Copilot+ PCs, the new surface laptop and pro. They're amazing devices, they're the fastest most intelligent laptops we've ever built. They have the longest battery life, and of course the most powerful MPU in the market right now. Which will unlock a lot of AI goodness, and we'll talk about it. >> Okay. So nerd time. Specs. Why are these so much better than the powerful Surfaces that are out there? >> We're excited, starting with the fundamentals. They are so much faster. This new Pro is 90% faster than the Surface Pro 9 on the market. With more battery life, and a beautiful new display, we're excited to bring OLED to the first time to sur if as, and what I'm personally most excited about is our brand-new Surface Pro Flex keyboard. We know you get the ultimate laptop set-up when you attach your keyboard to your Pro. And now we've taken that to the next level. This keyboard keeps on going when you detach it. >> I can use it over here? >> Yeah. Keep typing. Go for it. You've got favorite hot keys -- >> I'm going to press the cold front button theatrically. Did something happen? It did! >> It works. >> It actually does work. >> Yeah. >> Are you doing that? >> No. Hands up. >> whoa. Okay. Super exciting. >> That enables new creative work flows, if you love your hot keys and you can use and touch at the same time. If you're working in nontraditional productivity set-ups, think on an airplane where you've got that tiny tray table, pop your Pro and put this on your lap. With added layers of carbon fiber so it's more stable than our previous. Much it's got a larger touch pad, and the pin is always visible. >> I love. This my -- step one is lose my pen. It's the first thing I do. And then say I know it's somewhere. But this is me on a plane. Which is, I am like this on the trayable trying to write code, send a status updiet, Copilot something P. but now I can put it in my lap. You just need the Surface to put it on your surface and you can put this on your lap. The lappability goes up. Which is a technical term. >> Totally. Let me tell you about this one. >> Please. I got so enthusiastic. I got my eye on that, because that rose gold color, I like that. >> We have the new sapphire, in addition to our classics. Let me tell you, this is a brand-new design for the laptop. People love our design, so we evolve it. We make it more modern, streamlined, elegant, probably the thing I love the most is the display. What we did here, I don't know if you can see how thin the vessels are. So we're expanding the view. So our size is 13.8 and 15, and in both devices, we increased the viewing area so you can see more, but we shrink device. So you get a smaller more portable device. >> More screen without some hulking beast of a laptop. >> And the display is stunning. HDR, so it's incredible. We're known for our -- we made a few edits on the keyboard, we have the Copilot theme, they have in, which we introduced, which is across portfolio and it's our most inclusive touch pad. >> I love that. The color  is stunning, the form factor is amazing. I have the burgundy one and I use it all the time. EveryUWP stops to ask, what is that? And I know everyone is going to stop me. I'm going to do the demo of the Copilot button and the whole thing. >> We love it. >> So why are these great for Devs? We're here at Build, and Devs are asking themselves the question, do I need this machine? >> Yeah. So we talked about this before, but we have the most powerful MPU in this device. We can't wait to see what the Devs can do on this device to build on top of them. And of course they're portable, so you can carry them, whish ever you go, and work from wherever. We're looking forward to see what they can build. >> We've already partnered with a bunch of ISAs who have offloaded features on to this Imagine Cup, already. Available today on this MPU. Soda Vinci, with Black Magic Design, some incredibles, who are taking advantage of the MPU. We're excited to see what other people do next. >> That makes possible certain works that people wouldn't be able to do in this type of device. Come into the portable device. >> What I love about this is that is a light device. That is not a hurky beast. Here's a scenario. You tell me if this is a terrible idea. I think it's not. Announced is the AI toolkit, you can get a small language model, run it locally and build an app around it, all offline. But if this machine is so powerful I can do proper AI development on it. >> Yeah. >> Really? >> Yeah. >> What? >> Go for it. Turn the wi-fi off, sit on a plane. >> I'm going to do this and send you a video. That is cool. I'll be building AI on AI. >> Right. >> On AI-powered laptops. Spectacular. I love that. That one disappears, nothing happened to it. You know I love inclusive design, it's something the Surface team is passionate about. Tell us about the inclusive design story of these. I'm sure there's things. >> Inclusive design is built into the fabric of the hardware and software for Surface. When we build products that are more inclusive, we empower everyone with great experiences, we make them more comfortable, and we don't exclude anyone in that process. So these Copilot+ PCs are no exception. We've already talked about adaptive touch mode coming to the newer keyboard, and the new laptop. And we're excited that we're also extending the bold key set across the new Proflex keyboard. Bolder font and brighter background for greater readability. And of course you just think about the combo of this flex keyboard with Pro, that makes it our most inclusive Pro we have ever made. And we're excited to see how people adapt these devices to make them work best for them. >> Okay. Limited mobility friends, this might be really cool for you. You don't have to go like this, you can have it on your lap, I have arthritis, so I'm really into limited mobility functionality nowadays. And we're all going to have arthritis or something strange happen to us, right? Okay. I love the bold font and everything, because I'm dyslexic, and it's just a thing that will benefit everybody. Whether you're doing a demo, or showing someone or just using it. >> Yeah with. >> I want one. >> Exactly. It's one of those things where designing for inclusivity does benefit everyone. >> 100%. And it's just built into the product. It's not something extra you have to buy, it's just like using a color. You choose a bold -- >> I'm going to make my way over here with this. I have a Pro 8. Will this work with it? >> It sure will. >> It will? >> Yeah. >> I thought that would be a trick question. What do you mean? >> It will work with Pro 8, 9, the Pro 10 for business, and of course the brand-new Pro. And your existing keyboard that you have with your Pro 8. >> That's magical! I love that. Sustainability. Sustainability in action. >> Yeah. >> Every time we design a new laptop or new device we try to make strides and make it more sustainable. These are the most sustainable laptops we've ever built. They actually have the first time 100% aluminum on the enclosure. We actually reduce our carbon emission by 78% per enclosure, which is great. They have the most recyclable materials we've ever had, and even the packaging we took a step to the packaging, minimizing plastic, having all recycled papers, it's in every step of the way. >> I love that. You're living sustainably, and that is one of the reasons that carbon announcement this morning really making progress is happening. Because you work on this every day. >> Yes. >> So what is the call to action? Homework, that you two have for our Build audience online and here. >> If you're online, head to surface.com, take a look at these devices, there are some beautiful websites you can explore. If you're here, many could and see us. We're just over to the left of the stage here, in the expert zone, come and get hands on with these devices. They're also available for preorder right now. And they're shipping on June 18th. So it's not long until you can get one of your own in your hands and start that Dev. >> If you preorder right now, June 18th shipping, that's three weeks. You could be more, I don't know, creative, productive, having more fun, lugging less such in three weeks. I love that. Get up to the fifth floor if you're here. Come to the Ask the Experts area, and get your hands on one of these. All right, Build, thank you so much. It's been insanely fun. >> Absolutely. >> Thank you. >> Have a wonderful Build. >> The moment we hit the button to launch, Twitter flooded. >> I literally saw their jaws drop. >> Holy [bleep] might be the phrase. >> Being faced with a lot of opinions. You need a lot of opinionses from developers. >> Can we actually do this? >> I think this is smoke and mirrors. You're doing something in the background. >> More than that, there was a whole lot of excitement, but what -- about what the technology could do. >> We opened the doors to think about AI as something that makes our life better. For the first time a team could become reality. >> Another industry revolution. >> This is going to change the world. >> Hello! Welcome back. Guess what? I'm here with two of my favorite people in the world, legitly in the world, this is Stephanie and Gaston. Who are you and what do you do? >> I am the director for Microsoft -- at a consulting firm, we bring consulting for clients, value centric industry, technology, business, humanity. >> In the data and analytics space. >> In the data and analytics space. >> Very important space. This is going to be important later. >> I am also a data platform MVP and I'm a BI architect withie link digital. Really I'm a data witch. That's my true identity. >> She just said data witch. I love this for you. This is awesome. You both are just thought leaders, role models, spiritual guides in the data and analytics community. Tell us about how that has impacted your careers. Because we've talked about this a lot. Joining a community is one of the quickest ways to grow your career and very unexpected ways. Daston, I know you have a fascinating story. >> I grew up in South America, so back in the days I remember workforce training, training people in Excel, databases, and I bring this kind of -- Peru, Chile, Argentina, around user groups and community, that's bringing a lot of magic. So it's great to see catching up on all this kind of knowledge sharing, to when I saw in Seattle, five years ago, I went right away and created a group, and that is that sense of global community where we have hybrid community, a lot of speakers all over the place, I'm talking about Power BI, now Fabric and AI space, it's amazing how much the energy goes in community. >> And of course data is the backbone of all things AI, right? So thank you for doing that, because you joined this community, crossed lots of boundaries, came here and said, you know what? This is a quick way to make a lot of friends in your new home. By the way, there is still major data culture and major data culture, people study it, do work in it, it's huge. Because when you farm a community, it doesn't just disappear when you leave, it permeates throughout the culture. >> Exactly, yeah. >> Stephanie, tell us. >> For me, my background was in nonprofit for a long time. I was in I.T. in a nonploft, in my own world, I wanted to learn more about data. So I went to my first community conference, fully expecting to learn a lot, but then to go back to my room. Which didn't happen, because I did make myself step out of my comfort zone, go to the newcomers mixer. And just through that one event, then I met a bunch of people and they all wanted to help me, they wanted to help the work of the nonprofit I was doing. And the community is just so warm and kind. And then at another event I learned about this program through Microsoft where Microsoft employees can go and do work in Africa, which is where our nonprofit was primarily based. So the next thing I knew we had members of the Power BI product team traveling with us to Kenya, to deliver Power BI trainings to our field teams there. >> That is amazing. Because here you are, you're think, I'm going to be a wallflower, and everyone is like, we're friends now. And not only are we friends, but we're going to do stuff together. And I think that's really special about a community. It's not just oh, yeah, we're at this meet-up, let's just hang and have a happy hour. But let's actually go and do impactful things that changes the world. >> Definitely. >> Thank you for your work. Thank you for your work. I love how both of these beautiful people have these stories of communities not just being where you are, but cross canning borders on to other continents and countries, and leaving major data culture wherever you go. I think that's fantastic. Africa of course can major source of data culture, and we've hired a lot of people from east and West Africa to do data work at Microsoft. So we never leave the audience without homework. What is your call to action? For our audience today? Don't involved in the community. Absolutely. I never thought I would, and then now here I am a threat platform MVP. Step out of your comfort zone, join a community, meet some people, they're going to want to help you. >> How would you say what's the best way to do that? >> If be friends, and go out there, meet with your local community and if it's not, create your own. >> Look at that, he's assigning homework now. You heard this. Go find a random victim, we call them a friend, you can find them here or in tech communities, go and join a local meet-up group, or start one. Do the thing. Thank you both so much for being here. >> Thank you. >> Thank you. >> I loved every part of that video. Community, Microsoft Build, all coming together. Fantastic! >> I agree. One of the best parts about going to a conference like this is that it gets you outside of the Microsoft bubble, where everyone is like, yeah, this product is totally fine. No problems, and then you get to talk with actual customers who are using your tools and it's like -- >> You get that feedback, and not just from -- there's a technical issue, but sometimes even helping drive your future planning and things. We never really thought about that potential scenario. The other cool thing that I love about community, particularly technical communities, is you never know in the future where that connection that you make at an event like Microsoft Build is going to take you. >> I agree. And so if you want to keep those connections going, like actually keep them, you can go check out our attendee directory, which is on the Build website, which is your go-to place for being able to make those connections with people who share similar interests with you. Whether that's data science or AI, or that one project nobody has heard of except for two or three other people, you can make those connections and -- >> I don't know what you're talking about. >> Of course. But in the event they don't, you got a person there who can connect with you and make that project the next best thing. >> You're going to want to make sure your profile information is filled out and you've checked the appropriate boxes of the things you're interested in so that you can connect and grow that community. >> Yeah. >> After that -- >> Once you're connected with your new best friend, you're probably going to need to learn be new skills to get that app off the ground. That's where you can go check out Microsoft Learn, which is a really cool hub to access as bunch of different scaling opportunities. >> Absolutely. If you have questions for the Microsoft learn team, they are right here at Microsoft Build, and of course as you continue to move forward, things like certification, validation of skills, going off, like you said, learning something new. Do you have a favorite module on Learn? >> I'm working on the C sharp module. That's great. Pretty relevant to my job. It's buffing up my personal knowledge. >> That is super cool. We'll cheat about that later. We've been doing a bunch of work on the security models, so super cool. Listen. We have got some cool stuff coming up at Microsoft Build. Tell them what's coming up. >> Did you know AI can help predict flooding? >> That is so super cool! Scandeck is going to demonstrate their flood predictor. >> Speaking of scandeck, we also want to give a special shout out to other featured partners such as lucid software, sonar and confluent. >> To get more about our featured partners, visit the featured partners section of the Build website. >> Up next -- >> Seth caught up with researchers to learn how AI is used to unlock scientific discoveries. >> Hi, I'm super excited to be here with Dr. Nathan baker, how are you doing? >> Good, how about you? >> Fantastic P for those that look at quantum as super futuristic, tell us what it means. >> It's a new way of computing, it helps us address hard problems that have plagued computing for a while, specifically quantum mechanical will -- for us it unlocks a whole new realm of accuracy in those calculations. >> And that's amazing. What is Microsoft's involvement in the space? I know there's a two-pronged approach. Tell us about that. >> We're building the quantum supercomputer, we've got Azure, quantum and ecosystems, but we're also building elements. Elements is the platform powered by HPC, AI, and quantum that lets us solve problems in chemistry and material science today. >> That's cool, because one of the things, I love quantum, I went down the physics rabbit hole, but I was trying to understand what -- why chemistry as a use case, and I think it makes sense. >> It does. It's all about electrons. At the end of the day, it's hard to think of a bigger space to have an impact than chemistry and material science. 96% of manufactured goods have their roots in chemistry and material science. And maybe more importantly, if you look at what's impacting society, climate change, the need for renewable energy, new drugs, clean water, all of those problems have solutions in chemistry and material science. So it is a perfect area for us to be taking high performance computing, artificial intelligence, and quantum computing and make a difference. >> I don't think people know, I learned w about this, simple chemical processes we need just to live, we can't compute over because of how difficult it is. >> That's right. Quantum is hard. It's not just hard to understand sometimes, it's hard for classical computers to compute on. When we try to solve quantum problems on classical computers, we have to make approximations and that can hurt accuracy. >> Talking about scientific discovery and accelerating scientific discovery, how is quantum helping with that? >> Our goal is to accelerate scientific discovery using the elements platform, compress 250 years of chemistry into 25, and we do it by addressing four challenges. Three of them are technical. One is scale. The scale of computing, trying to understand, looking instead of at a few chemicals, many chemicals for a new drug or new solution, that's hard to do. That's something the Azure cloud speeds up, and allows us to scale out. It's also something AI helps with. The next one is speed. We've shown with some chemistry work flows, we can accelerate the problem by 500,000 times. That's taking a year and compressing it to a second. That allows us to look at things we couldn't have looked at before. Accuracy, we've touched on. Quantum computing allows us to relax the approximations that hurt accuracy and chemistry calculations. But the bottom line is productivity. It's not sufficient to develop all these cool technology tools without making them usable. And so elements is built to have Copilot and an easy-to-use platform that allows scientists to focus science and take best in class tools and use them to solve problems. >> That's amazing. Folks, chemistry is nferg. We're sitting here walking -- there's a ton of amazing things. You mentioned something kind of slyly and quickly, you said Copilot, tell me more about that. >> Copilot is essential, some of these tools are very sophisticated, and we think about Copilot in helping out scientists in a few different ways. One of them is helping them find the information they need to do science. That's information retrieval, using natural language to get scientists answers. What happens when you don't have the answers? Copilot can help build out that calculation. It can take tools scientists maybe aren't familiar with, configure them and put them together so the scientists can focus on the science problem rather than figuring out a user manual for a new software package it. >> feels like I'm living in the future. Are there any customers or people doing stuff like this? >> Yeah. There's a lot of good examples. Maybe the one we'll talk about here is Pacific Northwest National Lab. We had a collaboration with them to discover new battery materials. We used the speed enabled by AI, and we took 32.5 million materials and screened them down into 18 new materials, and one material that actually was a working, real life electrolyte we could use in a battery. Woe could use it to power clocks and other things. That process typically would take 20 years if you used the traditional computing technique. This took less than a week. Very exciting story. >> This is exciting. I struggle with quantum because I went down the physics rabbit hole, but physics and chemistry become kind of the same thing at the end, and being able to do this in a week would have taken 20 years is impressive. >> We were so excited. And the collaboration with PPNL was a crucial part for making this possible. >> This has been amazing. I know there's a video coming up, can you give us a 10 seconds on what that is? >> It's a story about how this battery material came to life, how we worked with the experts to make it possible, how we used, paired their deep scientific expertise with the new A I HWC and quantum Elements to make it possible. >> This is amazing. Thank you for watching about Azure Quantum Elements. Let's look at the video. >> Imagine if every scientist had access to their very own personalized supercomputer. How much faster could they go? How much further would they get? At Microsoft we're actually doing it. We're coinnovating with the world eats leading scientific institution like Pacific Northwest National Laboratory to reduce the impact of climate change, get to net zero emissions and find new ways to create, to store, and use energy more efficiently. >> We're joining forces with Microsoft to explore this convergence of artificial intelligence, high-performance computing in the cloud, and this is a shift that the world of science hasn't seen since really the dawrn of super computing. And for us, it's helping us tackle these challenges in chemistry and material science that are embedded in the search for new energy storage solutions that the world needs. >> I am a material scientist here in Pacific Northwest National Lab. I'm focused on designing next generation battery materials. Electricity generation needs to be renewable, but renewable energy is not constant. There's a lot of rain, there's no sun A. lot of wind. The battery gives you an opportunity to store energy in a compact way and 35 it whenever, however you want. >> Microsoft was really excited to work deeply with an organization that has strong roots in chemistry, material science, and how those disciplines relate to sustainability. Our goal was to work with PNNL to take the burden of exploring vast chemical or material spaces. Computational tools allow us to put the emphasis in the most promising parts of that discovery process. That's going to require a new way of doing chemistry that's computation-first. Our team discovered a new molecular lite that uses 70% less lithium. Because it replaces part of it with the earth abundant compound, sodium. Azure quantum elements accelerated the initial face of the process. It took what would have been 20 years of computation and compressed it down into one week to identify the most promising candidates for later exploration. >> Battery has a multiple -- we're trying to put completely different type of materials together, and then you're asking them to work together as. One part of the battery is lithium, lithium is fast, and its ability to move within solids is what makes lithium more attractive. But lithium is not something that did you can easily go and dig it up. The scientists are thinking about how can we make it to the next stage? Can we use something else? That can work as good as lithium but without the package of safety issues? >> Tackling this approach through the traditional trial and error method is something too time consuming. The ability to narrow down the playing field from millions of potential combinations of elements and structures to dozens in just months, something that would have taken decades, the acceleration aspect of this can't be understated. >> This coinnovation model has the potential to transform every discovery-based field. Chemistry and material science impact nearly all manufactured goods. So think of areas like pharma, life sciences, transportation, manufacturing. All of it is in play. >> What we're most excited about at Pacific Northwest National Laboratory is the ability to accelerate scientific discovery not just in chemistry and material science. This is where we're starting. When you think about the convergence of artificial intelligence models, coupled with high-performance computing in the cloud, running alongside of Copilots trained in specific scientific disciplines and having all of that come to bear at the disposal of the individual researcher or scientist, that's a paradigm shift. >> How cool is that? Thank you for being with us, Nathan. Learn more about Azure Quantum Elements we have links below. And if you want to sign up we also have another link, follow that, thank you so much. >> Thank you. prove you can keep pace with evolving roles, and that you're the best person for the job? For over 30 years, Microsoft certifications have provided proof of technical proficiency and remain one of the most highly regarded credentials in the industry. Certifications are role-based and validate a plod range of skills required to be successful in jobs that are critical to organizations. Here's how to earn your Microsoft certification. Augment your on the job skills with training by following free learning paths at your own pace, or choosing instructor-led training taught by Microsoft certified trainers. Build confidence with free exam readiness resources, then check your knowledge and skills with free practice assessments. Schedule your exam, and when you pass, you'll earn your certification. Some certifications may require more than one exam. Remember, your new certification and skills are verified by Microsoft. A signal of trust to your organizations, colleagues K. hiring managers, and recruiters. So be sure to celebrate your Microsoft certification by sharing it on social media like LinkedIn. Don't forget to renew your role-based and specialty certifications annually to keep skills current, and stay Microsoft certified. No need to renew your fundamental certifications. They don't expire. Earn your certification to showcase your competency for in-demand job roles. Continue your journey with applied skills credentials to showcase scenario-specific skill sets. The complementary credentials of Microsoft certifications and Microsoft applied skills are all you need to take charge of your career and become indispensable. Learn more at learn.microsoft.com/credentials. >> Hello! I'm excited to be joined on the Microsoft Build stage with Sandra and Allison, from the Microsoft Learn team. We're going to be diving in all things Microsoft Learn. So now that we're diving in, can you tell me a little bit more about what Maslow's hierarchies can offer -- partnership Microsoft Learn offers across the world? >> There's so much. We're excited to be here. Really Microsoft Learn is the hub for our training, documentation T. resources, credentials, across the technology suite for Microsoft. So anything from self-paced training that's available, we've got instructor-led training, we do virtual training days, we do events, challenges. Resources, documentation, there's so much that's there. And it's just a wealth of resources and information. >> That's amazing. And I know Microsoft Learn has been pivotal in my career, and learning Microsoft technologies in particular, but it also just learning about technology in general. That's -- I didn't realize it was so extensive. Sandra, can you tell me more about how -- given AI and the focus on AI, how can organizations focus their learning to improve their work flow and what they need to be accomplishing? >> Absolutely. AI is changing so many things, changing every industry, every sector and organizations -- and organizations are willing and eager to get everything AI. There are so many opportunities for organizations for technology professionals, and one of the things is that organizations are looking for people that can help them execute all these projects. And they are not finding them. They've been struggling for a while on finding the right people with the right skills. There is a skills gap, it's real, and AI is just making it bigger. >> Interesting. >> So we are seeing, actually, some organizes, customers and partners we work with, they are using this skills-first approach to deal with this challenge of finding the people with the skills, and this is pretty cool. It's something that we use at Microsoft. Skills first means focusing on skills, not only on degrees, not only on your job history, your title, and we do use this at Microsoft, so what we are doing with Microsoft Learn is that we are using everything that we are learning from our customers, from our partners, from the way we do it internally, and we are helping customers and partners to build the skills they need. And we are providing them with the resources, so they can build skills, demonstrate skills, very fine skills, and they can use and lead all these projects. >> From understanding you correctly, the change in the industry is necessitating a change in the skill sets, and they can find that on Microsoft Learn. >> Exactly. So the way we think about our credentials and our training is skills-based. What are the skills that customers, organizations need for the roles that are critical for AI, for the projects that they are embarking? We design our training and credentials in a way that's easy for them to take all this information on Microsoft Learn and gain these skills. >> Awesome. Where should they start? >> Gosh, there is a lot. AI, obviously, is top of mind. And there's so much on AI. We think about skilling being a personal journey. And AI is absolutely no different. No matter where you are in that journey, we've got content for you. Whether you're looking for Azure OpenAI, Copilot, we've got a lot of content that's available. The second area I think is important to bring up is around security. So we definitely want to make sure that our customers, our partners are securing their data, their organizations, so there's a lot of resources that is specifically in the security space that we want to make sure folks are getting and getting those skills really making sure you're ready to go there. >> Okay. And there were also some announcements today, there's a lot going on with Microsoft Learn. >> Oh, yeah. >> Give us the tea. >> We're super excited, we have made some announcements here at Build, they are all on the Microsoft Learn blog. It's everything around how to build AI skills. The first announcement is we continue growing our portfolio of Microsoft Credentials, because we know people want to prove they have the skills. So we have release haded today five new Microsoft applied skills credentials for AI and for cloud. We are very excited about this. Second, we just released plans to build AI skills. So plans, you know, is a recent feature that we released two weeks ago on Microsoft Learn, and we give you guidance in a structured content, milestones, and reminders, because it's important that you stay focused on your training. So you don't need to figure out oh, I want to learn this, where do I get started? We're giving you everything with explans we released today plans for AI specifically. And we'll keep releasing more. And also the coolest announcement that we are doing, we are very excited about this, is the new Copilot Learning Hub. This is a space inside Microsoft Learn just dedicated to resources to learn Copilot. So this is where technology professionals need to go to find everything to find which one is the Copilot they need to work on, what is the experience that fits them better? And they're going to find training, videos, tutorials. It's amazing. We just launched these today as well. One of the things we were talking about how AI is disrupting everything, getting ready for AI is pervasive to every organization. Not just to technology people. So we just released today also, we are announcing training for nontechnical roles. Because it's super important that they actually get to learn how to use Copilot. So we have a new training series for line of business users. So they can use Microsoft Copilot according to their role. So we have for marketing, for HR, for operations. People that are not so in technology, and they can use Copilot. And we also have a new training for business leaders. Because companies are trying to figure out, okay, this AI thing, what do I do with them? So we have training for business leaders, so they can get the skills and the knowledge to plan their AI strategy adoption. Everything super happy with this announcement today. >> That's exciting. It's like these announcements were made for me, you are doing the learning for me! I appreciate that. Thank you from me. But also, thank you from our audience. There's stuff going on this week. What's happening this week here? >> Yes. There's lots of stuff going on for Microsoft Learn, even here. And so if you're joining us in person, head down to the third floor. There's instructor-led labs on-demand labs, an assessment area, you can take a practice assessment, or an applied skills that we talked about. In addition you can also take on-site certification. If you're here on site there's a free exam for anyone who is here on site. So definitely head on down. And then the Microsoft Learn Experience, we're going to demo all the new AI features and functionalities that we have, we're going to talk about the Copilot Learning Hub. If you're here, definitely come check us out. >> I've heard such cool whispers in the halls! I'm so excited to check it out! I'm going to scurry away when I get a chance. There's also things online. >> For our digital audience we want to make sure you're not feeling left out. All of the sessions we have, especially the breakouts, they're Microsoft Learn -- that's where you take the rich resources and information, take that home. So every session has a collection available. And then in addition, no event, no big event like Microsoft Build would be complete without the Microsoft Learn Challenge. It's very focused on AI, but super excited, so check out the skills challenge. >> I will check it out myself personally. You got that promise. I'm so thrilled, I got a chance to talk to you. Thank you everyone for joining us around the world. Here and online, and our digital audit yellow jerseys. There's so much to do. How can people learn more? >> Great question. >> Absolutely. So we are learn, so learn with us. AKA.ms/learnatbuild. It's a place where you can -- people here attending can go and check and remember all the stuff that they learned here, all the resources are there. Of course that Alison mentioned, collection, the Microsoft Learn Change, everything is in that space. So if you came to -- if you don't come, if you couldn't come to the event, it's the same place you're going to find all the information, Learn at Build. >> If people are having FOMO, that was so considerate of you all. I appreciate it. It's been so lovely talking to you. I'm having a blast, I'm excited to learn be on Microsoft Learn. >> Thanks, Dawn, for that awesome session with Microsoft Learn. As a gamer, one of my favorite parts about Microsoft Learn is the gamification of it. You earn badges, experience points for continuing your growth, and personally as someone who struggles to get motivated with certain topics sometimes, it's a really nice incentive to see my badge collection grow and see my certifications expand and all the leveling up I'm doing. >> I've not gotten insane, I've not gone crazy, I've got two people on my team literally pride themselves on taking every single module. They're like looking for the mass XP, grind it out -- anyway. There is so much cool stuff on Microsoft Learn. You can start your journey with AI, you can start your journey with -- you've got cool stuff you've published. >> C -- there's as module for everything. >> Absolutely. It is a really great place to start your journey. All the way from sample tutorials to going into the deep dive so you're prepped and ready to go for those certification exams. Those can be a little tricky at times. >> Absolutely. >> Even the batch questions! >> I thought I knew what I was doing! But then once you get the certifications, you can print those babies out and show them off to the world. I haven't gotten a certification or a nice piece of paper since college, probably. So just more ways to show off to your peers. >> Do you have all the barrages on your LinkedIn profile? >> I don't, but I should. That's a great idea. >> That's the whole point of getting them. >> What's the point if you can't show off? [laughter] So up next, speaking of learning, we have learning modules for everything. But specifically we're going to talk about a central place to learn everything there is to know about Copilot. Dona has more, let's take a look. >> Hello, friends. Welcome to Microsoft Build. Thank you so much for joining us, whether you're here with us in the event space, or joining us in the digital venue. I'm Dona Sarkar, and I wrangle Copilot here at Microsoft, looking after specifically the extensibility program. How do you use Copilot on your own data? For the last year, my team and I have been dialing in virtually to team meetings or coming to you in person. Always the talk comes up to AI and Copilots. With Copilots, one of the main questions you've had for us is what is the best way for me to learn how to use this Copilot on my own data? Which is a very legit question. And one of the interesting things that we've learned is that every single one of you is using a different Copilot experience to solve a different kind of problem. So we decided that inbound stead of trying to understand every single business case and create all kinds of different learning tools, we're going to create a Copilot learning hub for technical practitioners. So for all of you Devs I.T. pros, deatd friends, there's one single place to go where you can learn how to use the various miefort Copilot experiences across the products you're already familiar with. So if you're in front of a computer, I would love for you to follow along with me. Go to Copilot -- not Copilot. Go to learn.microsoft.com/Copilot. And if you're here in the digital venue, make note P you're only going to hear this a whoafl bunch more times. So once you're there, you're going to get introduced to what looks like a very standard learning hub. And we have divided this into a four-part activity. So four parts, ready? First part is understand Copilot. What even is it? Let's just dig in a little bit. Here on understand Copilot, you're going to get a good feel of the fundamentals of generative AI what is generative AI, how does it work, et cetera then you're going to get an overview of the Microsoft Copilot itself. So what's in there? Let's have a look. It's going to be something like what is Microsoft Copilot with commercial data protection? What is commercial data protection? What are the feature differences with commercial data protection or not? This is your standard practitioner information. So once you have a good idea of understanding Copilot, you're going to move on to the next phase. Say you're a technical manager, one of the things that's going to be interesting for you is to look at how do you prompt Microsoft Copilot? Once you go into the adopt tile that I've shown you before, click explore the collection. Come down to prompt, prompt your Copilot tutorial. So we've created for you a set of tutorials, let's click on this one that says Microsoft Copilot for Technical Leaders. We've created a taut that helps you do a business case that's probably very common for you, which is create a skilling program in AI for your organization. This is probably something every single one of you have been tasked with this year. I know I have. And most of the people I've talked to in this venue have. What we've done is created you a video about 10 minutes, not too long, and it walks you through step by step how to do five different things. You're going to create a six-week skilling program using the Microsoft Copilot, you're going to compare the pros and cons, you're going to change the format into a different way to see your data. Then you're going to draft an email and you're going to identify good skilling content for your program. For all of these, you're just going to use the Microsoft Copilot. I'm going to use it with commercial data protection, it's absolutely up to you how you do it with yours. But the entire tutorial is return here and we've included every single prompt that you should use. This is going to get you very used to what the Microsoft Copilot can do and more specifically what it can do for you. So we've got many other tutorials coming. The second one is a bit more advanced, where it uses the Microsoft Copilot, Copilot in miept 365 to actually implement that skilling program and track who's actually using their Copilot in your business. Over the next few weeks and months, you're going to see a lot more tutorials show up, such as Copilot in Azure for I.T. pros. Cawpt in GitHub for Devs, Copilot in Fabric for data professionals, and so many others. This is a pro tip for all of you, if you're implementing Copilot in your enterprise or business, and you've got a use case, hit us up, because we love to get you creating these tutorials with us and dial you into the studio so you can share your use case. All right. So once you understand how to use -- how to adopt a Copilot, you're going to think about how to extend it. Because at some point you're going to say, I have some realtime data I'd like to bring into this Copilot. So for this, you're going to dive into this collection here. And you're going to learn how to use plug-ins for the Microsoft Copilot, extend Microsoft Copilot for 365, with different extensibility connectors. Once you do that, you're going to say like all right, cool. I've adopted Copilots out of the box, I've leshed to extend them over my own data, but now I really want to build my own. I feel like I have a good idea what I'm doing. Then you're going to go to our build your own Copilot collection. And here you're going to first look at how to build your own Copilot with Copilot Studio and this will bring you to how do you do it, here's a lab that you can walk through. And this is the same lab that we've been doing on our AI tour. So a lot of you have asked, how can I do this lab at home? Here it is, live for you. Or you can go and do this online workshop, or you can kind of follow along at home doing a standard learn tutorial. One of the things I really encourage you to do in this space is to check out our videos. I'm going to show you. We've got this video collection where you can learn all about the Copilot Studio just the underlyings, all of the pieces and parts by our friend Dwayne, who has created this beautiful play list for all of you. The second one you could do is learn about -- learn how to actually build your own Copilot using Copilot Studio, just in the step by step play list that Dwayne has made for you as well. If you are more of the high-code variety, we hope that you check out -- where did I put it -- right here. You're going to go to create custom Copilots with Azure AI studio. This is a brand-new tutorial, it's in preview so we appreciate your feedback. Just go through it step by step. What is AI studio? How do you choose a model, do content moderation? Et cetera once you are at a point where you feel like you understand Copilot, you've adopted it, you've extended it, you built it, you can have a look at all of our other learning resources. I'm sure you've heard about the AI Learning Hub. If you're ready to deploy Copilot within your business or organization, check out the adoption kit, which has learning tools on how do you set up an internal user group, how do you deploy, email templates, et cetera and if you're in a specific role in your company, I just walked you through a tech manager role, since Build is full of tech managers, I am one, you are one, all of us U. there's also Copilot learning across all of these other jobs that people in your organization do. Like we know there are a lot of app makers, so many. And there's a series of Copilot experiences that are ideal for app makers. Same thing for Devs and security engineers, same thing for data professionals. And if you just want your basic documentation hub for cold fronts, we've got that as well. So each of these is going to lead you to the basic documentation hub, like Copilot for Azure, which got quite a bit of air time in the keynotes, we want to show you this because Copilot for Azure is coming out of preview, and is now open to all of you. And you can figure out what are some good capabilities, what are some cool prompts to try, et cetera so that is the Copilot learning hub. We are in very much in the early days. We launched this just this week, so we could come and show this to you. What we really want you to do is go to learn.microsoft.com/Copilot, try it out, go through these four steps, send us feedback. And if you're doing some Copiloty thing in your organization, let us know, because we'd love to get you on air with us. Thank you so much for joining us. Go to learn.microsoft.com/Copilot. Thank you, and have a spectacular build experience. >> Ever wonder what a day in the life of data is like? When data lives in the Microsoft intelligent data platform, it works around clock to Drive innovation. First stop, the Azure Deandre Ayton database ecosystem. Data is prime for its processing adventures ahead with flexible and secure options and hyperscale performance. Cyberattacks and stranger danger, not in this database. AI-powered end-to-end security keeps data safe at large scale and high speeds. And built 95 in protection controls and flexible policies ensure responsible data handling and access at role level. So much to do, but where to start? Microsoft Fabric unifies and simplifies the data landscape, clearing the path to critical insights. By joining forces with machine learning and advanced analytics, data unlocks new information to drive decisions that solve problems, fast. Up next, data delivers more value with AI in Azure. Microsoft cold front is always by data. A generative AI joins the party, working with data to whip up new experiences, fast and responsibly, using advanced models like Azure OpenAI service and Azure AI Speech. Azure AI Search jumps in to retrieve the most relevant data. Data's job just got easier. Thanks to Azure AI studio, data has access to all of these AI services in a single unified platform. And with Azure Kubernetes service, new app features deploy quickly and scale with customer demand. With cutting-edge capabilities and end-to-end services, Azure helps data do more than ever before. >> One of my favorite parts of Microsoft Build is talking with members of our community. It's why we do conferences like. This I'm super excited to be talking with two of our MVPs, this is Karl, you're from Switzerland, though I guess now technically New York? And you are a cloud security architect? >> That's right. >> You're from France, and you are also a cloud security architect? Awesome. So there have been a ton of announcements we've seen just so far today, and it's just the first day. I'm going to ask you what you're most excited about. Karl, I'm going to start with you. What has you most excited about Microsoft Build? >> I think it's been a great day already. It's going to be a great week. It's great to be back in real action. Person lirks super excited to hear about all of those hardware announcements that we heard at the beginning of the week. But much more important I'm very excited to get back into Lumen Field, play some of that sports ball so I'm so enthusiastic about that. It's great to be back in this community action. >> We're happy to have you here. Karl might be here for the fun at the sports ball, I'm here for the partying. What about you? What announcements have you most excited? >> About the news of new area of miecht,ing a you know, Copilot, Copilot, and Copilot. And I'm excited about the -- we share with communities and Microsoft groups, and it should be a great week for everyone. And we will take our time and -- >> Fantastic. And speaking about this in this new knowledge area and the new world of AI, for both of you, that's changed things with security both in ways that makes things easier and harder, right? It's both easier maybe for us to secure things, but also it makes some things maybe more vulnerable potentially. How do you think about how you approach security in this area of age of AI? Karl? >> Fantastic. I'll take the first one. We have five hours, right? >> Yes. >> Fantastic. No. I think the main thing is from a defender perspective, and we're building new things. It's one of the things when we have new technology coming in, we are always relearning the things. It's from a security perspective, it's seeming isly always the same things, you think about access, you think about logging, but we need to rebuild these into our systems, rebuild into the tools that we are building as consumers of this AI. But at the same time, the tech side, they don't have these limitations. They have as much or even more of a productivity boost as we are getting. So how do we combat that? It's one of those fantastic things that I think we are here to learn as a community. >> Totally. And as you said, we could talk about this for five more hours. Do you have any thoughts on that? How are you in your consulting business approaching AI security? >> It's harder because we need to make an -- to 10 able any platform of AI. Like a quick example, the classification to use Copilot, because we need to make a lot od something. For me this is good news because we need to -- we will have a new challenge to trust our technologies, but we need to make a real focus on the security part. >> I think that's great. I'm glad we have people like the two of you who are part of our MVP program and giving our teams feedback and sharing things with our customers. Really appreciate that. So are there any sessions you're looking forward to going to? Or better question, are either of you presenting any sessions while you're here? >> I will be helping to make a new lab -- application integration for the security part. >> And you can catch my demo session on securing Azure OpenAI on Wednesday. >> Fantastic. So both of these gentlemen are going to be here all week. Thank you so much for being here. And you can learn more about the MVP program at kka.ms/Mvp. Thank you. >> Thanks. >> Awesome. Love hearing from our very own MVPs. >> I agree. >> I've got something. This is one of the first Builds that has a big huge boat, ton of content around the security topic. Particularly with developers. The security is very important, particularly in the age of AI. So you'll want to head over to the session scheduler and do that little sort on the security topic. There's a few things out there you might want to look at. Some Mark person is doing a talk on securing AI, I might want to brag, but there's data considerations for AI adoption, I know the speaker, a pretty good guy. >> I think he's all right. I don't know. He might be wearing the same outfit -- >> A little bit. [laughter] >> Speaking of AI, later today we've got Eric Boyd andasha Sharma, unlock hadding AI innovations across industries. >> And coming up we've got this flood prediction demo. >> AI flood predictions, speaking of boat tons. You might need a boat. Or maybe you won't need it this time around if AI is able to predict the floods. >> Absolutely. Before we get to that demo, we'd like to thank our feature partners, F5 and all the rest of our partners, head over to the featured partners section of the build.microsoft Flowedbuild website and look at all the cool stuff they've got there. >> Once you see the great upcoming fireside chats, the AI improving flood prediction, and more, we want to hear about it. Whether you're a new attendee or a veteran of Microsoft Build, you've been here 20 times already, we want to hear your feedback. So please share your unique event perspective by taking the short post session survey, it's fast, easy and you'll be done before you know it. Please help us make Microsoft Build the best that it can be. >> Hello! Welcome back to Build. Guess who I corralled? Two of my good friends, Jonathan and Duncan. And they're here to talk about something very interesting. Say hello. >> Hello, folks. >> Hello. >> To you two are working on one of the most interesting projects I've heard, which is using, actually using AI to solve a real world problem around sustainability. That is fantastic. And specifically you're on coastal resilience. Can you tell everyone about this? >> I'd love to, Dona. It's not just important to you, it's important to me, it's important to the world. Flooding, sea level rise, all are increasing the hazards that people are seeing globally. And what we've done is partnered with ALTML and Microsoft to build a system to see if we can use the same approach we've done with Flash flooding. We can take that same approach through the coastal AI model that can better predict AI or sorry, better predict flooding, flood probability throughout the world. And roll that into our existing service offerings. >> That is fascinating. Because you're taking a burning of data you've had for how many years? Long time. >> People have been running physics-based coastal models for decades. We're using that engineering experience, the domain experience of hydraulic modeling and coastal engineering, and seeing if we can take that same experience and put it into an artificial intelligence. >> So you're building your own model from this data that's been collected for a long time, and what have you found AI to do pretty well in this >> Wannest reasons we want to use AI is how much faster you can get the result. That's really the big benefit to it. The other one is we're hoping we don't know this yet because we're still in the development process but we're hoping that is going to be generally applicable. We want to take the same model we build in the southern U.S. or other areas and apply it globally just as we did with our flash flood models where we found we could create a model that would be generally applied. The speed is the big one. Cost is lower toe run it versus running the conventional models. We have we want everyone to be able to use this model for lots of serves. Smaller services that cannot run the classic physics models. >> And I think the interesting thing that we're doing the applicability of what we have created here is not just about modeling for assessment. General applicability pieces one of the things we're trying to create here is democratiesing the access to the capability. We're taking the new format we're working on timely access which is critically important and driving down cost. >> The real timely angle is interesting. That's a cool thing to invent. Real time access. So tell me a little more about. That how does this work? >> So let's talk tech for a little bit here. Obviously the vast majority of what we have built here is based on the Azure platform. We're using a large chunk of the Azure tool box, forever dev ops through to data factory. We're using pipelines, we're using ML flow for things like recording and testing out some of our experiments. So we have to have provability and reducibility in the models. There is a huge investment in the Azure platform to get us the functionality that we're after. We're using GPU and clusters for speed and processing. At the heart of it we're using data bricks for processing and transformation. >> You are using the full stack. You are using everything that is available to solve this problem. And you are able to identify how to put them together. >> That's right. That's the applied AI part that we are particularly passionate about. And so we're using regression analysis. We're using time series data and skill sets. We're using computer vision all in combination so we can get this real time speed and access to the tools which we haven't been able to do before. Historically a model would take 20 minutes to run on a 2,000 core super computer. We're now able to run these things near real time which is pretty cool. >> So what does this mean for users. How can they benefit from this? Not everyone can train these models because they don't have folks like yourselves. >> That's why we're building this. We're building this model and so that it is accessible so it can be included in the services that we're offering. And it creates a lot of interesting derivatives, things that we can do now that just wouldn't be possible with the conventional physics approach because it takes so long to run those models. Talk about real timement real time means a lot of different things to a lot of people. When we think about anytime terms of flood predicter and coastal modeling, it allows us to do things like emergency management logistics operations. So you can do what if scenarios and see the effect of the storm coming as that forecast is being updated. And our expectation of this effort is it will be fast enough and lower the cost that you can watch that storm come N. you can see what the flood effect is going to be. You can see what the impact is going to be on critical infrastructure access to emergency management services like hospitals. See how it's going to be impacted so that during that storm you can support whatever logistics that you need to get in place. In addition during the storm is one thing. There is lots of other services. Before the storm. Before the storm hits. After the storm hits. Before facilitating that planning cycle so that you can run it, you can run more mold faster and see the impact. And then after, how do you mitigate these effects? These are all services that will be enabled as we take the mod that will AI nucleus and wrap the product itself around it. And then make it available as a data product people want to consume that model then by all means. Or they can do so through the products that we're developing. >> And let's talk about the model because there is very complex stuff. And so if you think about some of the things that we're trying to do in a super computer model versus AI driven model here. When you are tracking a storm in this particular context, what we're looking at is a bunch of things like how high is the water going to be, how far is it going to travel inland. The analysis is very important. Because then you have to overlay things like what if the velocity of the wind is not what we expected it to be or what if the size of the storm suddenly grows much larger than we expected. All these variables and inputs materially affect the outcome of what the predictions looks like. The ability now to do very extensive what if analysis in real time or near real time in emergency response scenarios is pretty powerful. >> You know what is interesting about this whole thing? It's so applicable to all these other industries as well. Natural disasters, like we see this all the time where how can you predict the impact of this we know a natural disaster is coming. What will the impact be given decades and decades of data? I can see this being used for all kinds of sustainability things. And justifying you'ring out how do you allocate resources, how do you allocate people to be in certain places. >> That's right. >> A lot of these things are causal. One environmental thing causes this other environmental thing, etc. >> Yeah. If you look at the spinoff stuff as well. You look at things like how do you tie in with the mitigation piece of let's do an analysis. Let's look at that time mitigation of that analysis. That extends to things like insurance. So the cost to develop something becomes much clearer in terms of the risk that you are assuming when you run these things. Applied AI. You have homework for everyone. What is the call to action? >> We've been working on this science developing and integrating coastal with flood predicter and river and flooding. The action is to learn more on aka dot ms slash flood predicter and see how you can use it and build it into your systems. Make it available to your people. >> Go try it. >> What an incredible first day. >> I'm having a blast. >> So throughout Microsoft build up to this point AI has been where he felt AI can do everything. Coming up something that every developer here loves coding. Live coding. >> Live on screen, live on stage. Stick around as well because later today fresh off the keynote stage Rajesh joining us talking about Copilot for 365 empowerment and involving work. First Qualcomm so you can learn how snap dragon can help developers innovate faster than ever. >> Thanks so much. I'm so excited. Earlier this week we announced a bunch of new devices running snap dragon elite processers. This is a great opportunity for developers to build and import their apps to this new platform. Went to talk about that. I'm joined by Qualcomm to talk about what this process is like and why all the devs out there should bring their apps to the latest snap dragon platform. Why should they import their stuff into snap dragon? >> Look. So windows on snap strange a powerful combination of all the versalty of windows that you have plus all the powerful applications you can run on our processers, what you have seen on the mobile side we're bringing to our compute side with better efficiency and performance. Coming to developer side of things it's great opportunity for them. Their apps are going to run smoother. The top 300ISVs today, I think everybody has realized the potential of this platform and they are already porting their apps native our platform so that is huge. That's where the ecosystem is building for us. Now I would also say the way we are developing our tools and ecosystem. This is a great way for our developers to get started on our platform that way. >> I love. That and so I'm excited by that. We were seeing as you say the power efficiency is great. It's going to lead to better performing apps, battery life. What is great about this. You have done this. You've gone through the process of porting your app to this new platform. Can you talk to me about what your company's motivations were and why you wanted to make it a native port? >> No problem at all. Mack fee is a household name in online protection. We're experts in taking our threat intelligence and AI and ML to produce protection for phishing, Trojan, malicious files, content. Those kind of things. All of those are candidates for porting but we wanted to do something brand new, something applicable to this new AI era that we're in. We wanted something that was going to be practical to go into the cloud and impossible to do without AI so we settled on deep fakes and analyzing those. Important time to do it. They are quite easy to create now. The effectiveness of them is just getting sky high, week by week. A lot of users are don't have a good way, they are not confident in their ability to spot a deep fake or not. And so just think about this year. We have presidential election. We want people to know a campaign ad is real, not macrophages huge implications. Scams, misinformation, malicious actors can really convince someone to do something or think something they wouldn't otherwise. Financial, personal standing, relationship issues can come from that. That's the direction we decided to go and that's what we produced. This is really important to a lot of things. We're impressed with AI but it can lead to people having a hard time. What is real and what is not. Having our security software be on alert is great. Can you talk to me about your process of bringing your code over and what you did. There was anything you couldn't do before? The main thing that came out early on is we realized we were able to produce and use really intense AI content in the same way about CP usage. That was really the thing we were getting out of the MPU at the time. >> We want all this stuff to alert us but we don't want it to take up a bunch of ever of resources or slow us down. The MPU will allow. That developers were want to get started, what are some of the resources you offer and what do you have for the developer, I've got an app. And it can run on the platform but not going to run its best. What resources do you have for them to start porting over? >> That's a great question. We are having our own developer page this hads all the information about what are the isvs that imported their. All the getting started guides, the sample application, codes for developers who want to get started. Not just that, we have a bunch of tools as well. This profiler will help to you profile your CP U. You can understand thousand memory complications are part of the code. We have bunch of resources, blogs, videos, we have a video course for developers to develop on our platform. Come over to developer.com and check out the resources. There is plenty of resources for them to get started. So got a lot of resources. I like that you are doing the video tutorials and taking people through every steepiest process. This is exciting. For some you will have to reconfigure some things. You were talking about how you are using the MPU for the architecture to detect deep fakes. Can you talk about what your approach was and why you made a decision to use the MPU and how? >> Understandably a lot of users are concerned about personal private data making its way into anyone's cloud. It's quite a nervy prospect. All users depending, doesn't have to be security software. All users are concerned about the performance of their PCs, their devices. They don't want us to use battery. We're depending on that throughout the day. Big value add for customers was privacy latency and performance. We're capturing audio and doing all the processing locally. We're gathering results locally. So I said that a few times. But it's easy for to us reassure users they are not going to have a privacy issue if we're doing that. The second thing latency. Imagine doing this in the cloud. You have to capture the audio, process it, package it up, send it to cloud, do the inferencing, get the results, takes a long time and a lot of band width. If you are doing this locally no round trip. We're in a much better spot and we're not going to be causing internet band width problem. We're doing real time processing as well. Final thing power and performance. MPUs and I've seen this in my experiments they quite often runoffser. They run low power. So we're giving use terse performance benefit. >> That is so important. We need the performance but you like what you are saying about the privacy. You want to keep it private on the device and the latency is important too. Only way people are going to adopt these tools is if it's going to happen in real time F. you have to wait people are going to turn it off. You want people to use these features taking advantage of the MPU is important. And actually that gets to the next question I have if you are. It's not just about getting your existing apps running really well on new processers but there are new AI capabilities that you can take advantage of. Can you talk to me about what the capabilities are? >> Add to MPUs, that's our flagship on the value chain of the process we have. It's real and you have already seen the Copilot plus PC announcement we can run up to 40 tops. That's a big deal. Now if you are a developer and want to get started on the AI journey, I would say our developer port system the right place to start. The first thing any develop for they have a model or want to download a library of models we have an AI hub. Go get started there. AI hub is very fast. Five to ten minutes you'll deploy on the device. People are using it on development platforms. We support so if you can bring your model and run on multiple inputs and so we support as well. If developers want to bring their models and start running, it's a good process. We have AI engine. It's a flagship sdk if you want to optimize on our devices. Really fine tune the models and get into profiling. So AI engine direct is the right way to go about it. And to end with it I would like to say if developers are using optimum library from hugging face we support optimum lie briar as well. There are options for developers to come get started on. >> They are bringing hugging face. The only way we can get adoption is to meet people where they are. Only way to have people use things is if they perform well. Making it easy for people to bring their own models great. Those resources are on AI hub. What advice do you have for developers to run their apps or integrate AI capabilities into their applications? >> What advice do you have for them? >> What we do at the moment is we convert and it takes a lot of work. Using AI hub would be a good start. The other thing is make sure you have an infrastructure ready to do all of this in place. I can't tell you how many times I've used the wrong command line and produced a model we were not hoping for. Always use the latest version of the sdk. We had a problem where a conversion step needed an extra command line and leaving from the snappy convert eliminated that step. That worked really well. The other thing is we had some amazing help from Qualcomm. Most people won't have access to that so be intimately familiar with the tools. Read all the documentation but it will get you off to a great start. And obviously hub. That is how I would do this going forward. >> I love. That thank you for the great tips. Now I think you have something what can you tell us about the future? You have something to show us? >> Can somebody bring the good stuff for me? >> Yes. >> This is something that we launched today. This is snap dragon dev kit. This comes with the C PU and MPU as well. And it has 32 gigs of ram and it can run up to 40 tops of all your API model. This is a real power house. I'm super excited to see how our developers start using this one. >> Great announcement. Thank you for showing this off. This is how people can start testing today especially with AI. I love this. All right now I want to thank you so much. Thank you so much. I'm really excited about. This I think theJ generation of apps we'll see are going to be really great. If you want to dive in deeper into learning all about all the things you can do in snap drank, head over to the AI hub and check out the partner directory. Thank you so much. >> We're back. >> Yes. And we're going to have a poll for you. Don't forget to interact in your chat. We want to hear from you. Where are you in your tech career? Four options. One, I'm just starting my career. Two, I worked in other industries but I'm new to tech. Three, I'm transitioning between roles. I like. That and four, I'm an expert in my field like her. >> We're both experts. I love chatting with you with all the things you know. We've been talking Chat GPT and Copilot. >> All things Copilot. >> Do you think build just for experts or everyone in. >> It's for everyone. It's for all the experience levels. I've talked to all levels today already. >> You know what is a fun thing to do, go to the session scheduler and look at level, choose things maybe above a level you are at. Go for it. Do the thing. >> I've been using the session scheduler and it's been cool to see all the sessions. Some are recorded. Some are not. There is edge on people who get to hang out here in person or there is extra special options for people online. >> That's right. And there is all these levels from foundational to expert. I think what is special when you are an expert in one area look at a foundational one for a different area. >> I would say I might be an exnetter dev but I'm not an expert in data. >> So exciting to hear from you. Now we're going to the guest. >> Hey, everyone. Joining me is a man who probably needs no introduction. I'med by EVP of experiences and devices. >> How are you? >> I'm good how are you. >> Good thank you. >> You got an applause applause. You don't even have to do anything. That's great. >> You gave a great keynote an hour or two ago. You talked a lot about Copilot. I think we should dive into that some more. You had three 90's. You talked about Copilot evolution, Copilot extensibility and Copilot plus PCs and windows and how those can work together. We have some footage from the keynote in case you need a recap. No worries. We're going to ask you a couple of questions. >> All right. >> Before we get into the clips, you talked about how we started to change how we look at Copilot. On the one hand we used to think of Copilot as a personal experience. But now we're evolving that to be thinking about how that impacts teams and how that impacts agents for process automation. Can you tell us more about why that evolution is important? Copilot is private to us. When you invite a Copilot to join a team whether a meeting or moderated chat, be part of a project, the Copilot gets to do things on behalf of the entire group. And so what that enables is a set of new scenarios. Whether it be note take on behalf of everybody out in the open, anybody can edit the note. Or whether it be helping assign tasks and keep track of what is doing what next. We think this is a very important evolution because the way work is done in large organizations is in context to groups. We want every organization to advance with Copilot. We want to invite the Copilot to participate in work flows that are at the partner level, organizational level. >> That's great. I think it helps the team get on the same page. >> Absolutely. >> Nice to have that. You are not spending extra time messaging your coworker, what did you get from that meeting. >> Or if you are in a series of meetings, thedalety stand-up, the team Copilot can take the notes from one and get you ready for the stand-up the next day. >> Perfect. Especially after you get back if you had a meeting conflict or got bk from vacation. >> That's right. Up next you talked about behind the scenes under the hood. The Copilot architecture. Let's take a quick look at Copilot architecture. >> In addition to being in the web it's grounded in your work data through Microsoft graph. And when the Copilot is in an application like office or teams or edge, it also understands the application context. So for example in PowerPoint it is able to draft a slide deck for you from a document. So the Microsoft Copilot is arrange ticketed to compose or inherent capabilities based on context. As a developer, you can build Copilot extensions to further extend and customize a Copilot. >> It's always weird watching yourself back. >> It is weird. >> What are some of the key take aways that people should take from how Copilot is structured and how does that benefit developers? >> So the key thinks thing here is that there is one Microsoft Copilot. And the Microsoft Copilot is context aware. So when you are in PowerPoint or teams meeting, when you are in context of outlook triaging messages, it's still the same Copilot except it's context aware. The way we architected that is set of compossible skills. It's important because as a customer you can augment, you can inherit all the capabilities whether it's graph capabilities, web capabilities and augment that with what is unique about the work flow or the function or the department that you are carrying the Copilot. To so the user thinks there is one Copilot that adapts to their needs in this specific context of the moment. That's why -- otherwise you have this notion of dueling Copilots, everybody trying to help you except they are getting in each other's way. This architecture allows to us have one coherent user experience which is again powerful but simple. >> Excellent. And I think coherent. That's the theme of Copilot right now. That's exciting. I feel like that's a good transition to the extensibility story which is one of the things I'm excited about that was announced today. In regards to Copilot extensibility Jeff came on stage to talk about the extensibility story so let's take a look at that. >> We're very excited about all of you doing this and Copilot studio is generally available today to build Copilots. The new capability to publish Copilot extensions from your Copilots is now today in public preview and as you heard Satya announce earlier, Copilot connectors are also in public preview to make it easier for you to connect Copilots to all your business data apps and work flow. Last, I want to show how you build a Copilot extension as a professional developer with full control of your models, data, actions and experience in visual studio code. >> Cool. Good stuff. I know the first thing I want to do is check out Copilot for Azure. That would be so helpful for my own development work flow. I can't wait. There is a lot going on with extensibility and Copilot studio. How can developers best get started and take advantage of the new tools being introduced? >> Go -- the reason extense is also important is you can now extend the Copilot for your personal work flows and your tasks, for your specific job functions. The tools don't really matter. You can use Copilot studio and add knowledge, add actions, be a professional developer, add a Copilot it to. You can add capabilities to the Copilot and extend the Microsoft Copilot. Working with extensibility story as adore you now get to reach not just users who are on Microsoft Copilot but also on people who are on teams. Because we did the work to make sure the platform it was same. Whether you were extending Copilot or teams. As a developer what you care about is distribution and visibility and getting to the users. That's why we want to maximize the possibility for you to reach the right users by having your extensions show up in teams and Copilot. >> And it sounds like between the architecture and introduction of Copilot studio it's easy to make those? >> Absolutely. This is locoed, no code, the entire power platform all that stuff has been brought to Copilot studio. Whether your information worker extending a SharePoint side, no code, locoed develop, professional developer, you can extend the Microsoft Copilot. >> Perfect. >> Last question or second to last question. Let's talk about windows. And again if you haven't seen the keynote check it out. Rewatch it. Lots of great highlights. We talked about yesterday the new Copilot based PCs. Let's talk about that. So the notion of windows Copilot run time is a relatively new experience. So can you share more about how you think about it and what the key take aways should be for the audience? >> Windows Copilot run time is up leveling the windows API set for you as developers to take advantage of on device silicone and the most extensible set of models. We have 40 mod that is ship windows Copilot run time. It's set up whether you take the on box models where they use an open source models, we is it up so you can take full advantage of the silicon and provide AI as well. If you need index this run time has that index available for you. To what end? The end here is to bring the full power of AI, the natural language. Today windows graphic user interface environment. That is now being able to be augmented with multimodal natural user interface in addition to graphic user interface. We want to be able to do all of that without compromising the fundamentals of battery life or performance of your device. So the windows Copilot run time is about the next generation of graphic user interface and natural user interface coming together taking advantage of the silicon and core services in windows. >> Thank you so much. Unfortunately that's all the time we have. If you want to learn more, the 365 blog is out right now. Where can people learn to learn more about Copilot? >> Go to our blog and you'll find links to things that you can start doing today with the Microsoft Copilot. >> Also check out aka dot ms/team Copilot for more. >> That was so cool to hear. What was the most interesting thing for you from this chat? >> As cool as all the software stuff is, I can't stop thinking about the hardware and the way we can use this to do things together. We are in this area where all these beautiful devices where we can do all these great things with Copilot studio but I want a new toy. >> Someone please give her a new toy. >> Putting her in front of the toys is a poor idea I'm just saying. You know what I liked about it and this is selfish. Every customer I talked to this year asked how do you extend three Copilot on data sources and I give them a list of 7 ways to do it and they are like isn't there one way. Turns out there is, Copilot extensions through Azure Ai Studio. I love. That people have been asking for this. We will see so much innovation. It's going to be so good. >> Coming up we've got dev in the cloud coming up. And we've got this really interesting after this conversation about Azure AI. You don't want to miss that. And then of course selfishly I get to interview the imagine cup semi finalist and finalist and get their back stories. >> Fantastic. First we're going to what developers can expect in the world of AI. >> Hello welcome back. This is the build live stage. No pressure from me because this is my boss and then my boss' boss. So today is a really good day to maybe how is it going my friends? >> Well. >> Introduce yourself. >> I'm Eric. I lead the AI platform team. >> Let's go with what is the now of AI. There is the is a lot of stuff going on want to get your thoughts. >> There is so much going on in AI. And I think some of the most exciting things to think about are what are our customers doing. If I start with Mercedes Benz, everyone has been in a car and tried to talk to the car voice interface and it doesn't understand you. Mercedes Benz integrated with GPT4 so now you can have a natural conversation in the car to get directions and get things done. They even integrated GPT4 vision into the dash cam so they can see things going on around the car and near you. It's exciting things like that and you can go from car manufacturers all the way to developers with the unity platform which is now made abbot that can help developers figure out things you are doing on unity. Helping you figure out the APIs and how things work within the unity environment and not having to leave. When you look at the extremes of how much the applications are all over the place, it shows you how quickly companies are adopting AI across the spectrum. And so we're building tools as quickly as we can to serve those needs. Companies need things like search to be able to get that data in and store it. So Azure AI search which is 12 times as much storage for the same price all integrated in. The Azure Ai Studio making it easy. There is so much going on in AI really bringing all the applications together is fun and exciting to see. >> It feels like applications are feeling broken when they don't have AI as part of it. We're seeing organizations going from experimentation now to scale. And even think about customizing the experiences. So a lot of the tools we're working on are going towards how do they fine tune, leverage data to ground their application and things like that. >> What are some cool things that people are doing now that you are getting a sense for? Because we talk about AI all the time. Everyone is AI, AI. But what are things people are doing to soften the edge around software and hardware and people? >> You just see it in all the different use cases. I talked about a couple where Mercedes Benz and unity is doing. There are so many other examples where they are trying to build solutions to make it easier to interact with people. I love the example Satya gave this morning of the Khan academy. The ability to have an individualized education tutor connecting directly with each student is really powerful and the types of things that the applications you couldn't have dreamed of a few years ago until AI got to this point. >> I think multimodal is becoming a big aspect of that. The power of GPT4.0 and open AI and Azure studio. There is going to be new possibilities to interact with your AI more fluently than ever before. >> They let me play with these models sometimes. It's fun to imagine the kind of things you can do. >> We started talking about GPT4 omni but there are other models we're looking at. Why don't we start with the cool things out today and maybe some ways we're helping people use those things. >> Some of the things we're excited to see today we announced the Phi series of models. Phi-3, mini, small and medium which are 3, 7 and 14 billion parameter models. The thing about the Phi series models we took a different approach to training them where we tried to think of the data they train on as a curriculum like I would give to a student where you are trying to teach the model step by step, how do we make it learn everything about the world. In doing that we got a model that is much smaller and more powerful. All the Phi-3 models punch a full weight class size ahead for their size. Customers looking for the most pow Eric get from a model at the right price point so looking at that, where are the places the model will work well so it's exciting to see what we've done with that. Multimodal, Phi-3 for vision is available today. You can still get rich vision capabilities you are used to seeing really excited to see that. >> We also exfanned our partnership of hugging face so there are open source models. We're doing a lot around the tool chain. I think that is most special. We have to teach people to get the right model for the right job at the right cost. Then if they can do that it's about the tool chain to build the applications. We announced the general availability of Azure AI studio. But we're announcing a lot around responsible AI to keep those safe. Content filters, prompt shields, all of those things are going to become more important as we start to scale. >> As we look at this from a perspective of developers, I got to use AI I don't know what to do. I've been to conferences around the world and people are literally being told by their management you need to use AI and they are like. What what is some of the stuff we provide to help developers get started? >> There are all these different tools we build to make things easier. You can go to Azure Ai Studio which is the place to go and build your generative AI applications. The most common pattern that we're seeing is retrieval of mid generation, RAG pattern of how do I take data and put it in a search engine. That is why Azure search is helpful for building applications. It's a rich search that brings all the power of vector search with all the things we've learned over decades of doing key word search bicycle platform and has a ranker on top to retrieve the most relevant results. Then you feed that to your model and the model has all the information for your application, all of that built in. That's the pattern developers are going after. How do we make it easy for them to build that, to put all the pieces together and start experimenting and iterating and learning how do I tweak this to get the best quality out of it. >> Seems like the sophisticated developers are turning to tools to solve complex task. I saw coke is doing somethingle cool where they have templates for every department so it makes it much easier for a decision maker to get started with the tools in a non-scary way. >> And did you want to saying? >> You mentioned prompt shields. The whole capability of building tools responsibly and safely, we provide the Azure content safety system which is built into the Azure open AI service and you can add on to any other model you want. It gives you the full set of safety tools you might want. Things about different levels of control around violence or sexual content or how do you want to manage that to reducing hallucinations to managing prompt shields and controlling jailbreak. All those are making the developer's life easier as they build applications. >> I want to lean in before we get to the other questions about safety and responsibility. Can you tell me how Microsoft is taking this particular task seriously and helping developers do it as well? >> We've been working on it for the last 8 years. This is we think about this as cutting edge technology means cutting edge responsibility. We're still early in it. After 8 years we have 90 tools, hundreds of features and we do a lot of the work ourselves. So before we release a model there is a lot of work we do to provide the Azure promise. Then we provide tools so developers can customize their needs. Custom felt 76ers a big feature that we released today and that's allowing to you set up different tools for moderation for things we haven't thought about yet. >> That's cool. The thing that I think now I want to dive into if it's possible. Is the notion of what are customers doing with this. I know we spent a lot of time talking about all this good stuff but what are customers doing? >> We keep telling all the customer stories of all the amazing things they are able to deliver on top of these tools. It's been in every industry that we've worked with. You see obvious cases in customer support where people are trying to build customer support bots to help answer users questions or even for their own agents to help them develop that. But I think the interesting things are the new applications, the things we couldn't imagine being lit up previously and now seeing how those are coming to light with the way the customers are pulling all the different tools together in incredible applications. Some of the most interesting things are this new space of having multiple agents talk to each other and sort of string different conversations together. I think that's a really interesting space where we're starting to see the standard computer science abstractions and separation of control. That's starting to materialize into these much richer applications. >> We have more than 53,000 customers on Azure AI. And one of the things we're thinking deeply about is how do we do safety and security by default so removing as much work as possible from our customers. Microsoft runs on Azure AI. So all the Copilots, millions of users we're getting a first class ride at learning and using the technology for our customers internally and we put it in the platform and extend it to our third party customers. >> Microsoft is customer zero right? >> From the start. When we first started building out our capabilities with the open AI service. We launched bing chat and then M365 Copilot and GitHub 18 months before that. We built that on this same platform that we make available to our customers so they know we bet our business on it so they can trust it with their business as well. >> I use this stuff and I know what it does and every once in a while it's pretty surprising what you can do. As people are sort of getting immersed in the RAG parent and getting that to work, what are some things people should look forward to Orlando cent their thinking when it comes to experiences they may be able to develop? >> One of the big things is I feel like we have to be thoughtful to not do AI for say sage it has to create values. Improve the way you live or work. There was a study that showed skilled workers using again AI show a 40 percent improvement in their work. How do we help developers solve real problems. Don't lose sight of. That the second thing to look forward to and we showed this in a session, we're Hoveying code first. We want to meet developers where they are. We're seeing all applications becoming AI. We have the best IDs in the world. We want to make that really simple to wire up your applications, change out your models and do so without any thrash. >> This is something that we've been kind of seeing coming for a while. Really with GPT4.0 it brought home how powerful this could be to have that much fluency with voice talking to a model and having it talk back. There are inflection points in all technologies where you get to a point where it's good enough that opens up scenarios that didn't used to work. In the early 2,000 speech recognition had to be word at a time and now it's much more natural for me to talk to my phone. I think this level of voice fluency going to change the way we interact with machines where we'll talk more naturally as opposed to machine speak and making it work that way. That is going to be really interesting the times of things we can build. >> I agree. We've taught ourselves to prompt engineer queries for a search. Then your demo this morning was amazing because it was you expressing yourself to an application that now becomes much mart smarter over time and that can help new any language you want. >> I I coded that up. It's a real thing. It's amazing. Le as I was interacting with it, I like forgot the interface. It wasn't a keyboard thing anymore. Where should people go to get started with this stuff? >> Azure Ai Studio is the best place. We have a playground so you can play with the models then consume the model. That's a great place to get started. >> There is so much happening in AI these days the main thing for develop 76ers they have to get their hands wet. Dig in and start building something and just start to see what you can do with it. Because until you have that experience, until you are seeing how things compos and how you can use it, you are not going to have that full understanding. That's the main thing I encourage people to do, try the tools, build applications and you'll be surprised at the power you can create with things. >> He took it. I think that we need to imagine the world as every application becoming an AI application. Think at a bunch avenue much bigger scan scale than we have before. >> Thank you for letting me work with you on these cool models. We'll see you after this. >> That was awesome. I loved what was said about don't just use AI for AI sake, use it when it makes sense. That makes sense. Can we talk about how the future is bright for windows devs again? In case you missed it and look this up, the windows Copilot run time WC R. That's how you are going to build AI apps on windows for windows using this Copilot stack that runs on windows. Just biased, a little plug. >> What was your favorite announcement about Copilot other than all of them? >> All the announcements were great. But I was enjoying now Copilot is not just a personal assistant. It's a service for your entire team. The implications are endless on that. We have agents so the world is your oyster, you have all this content. Now you are able to nail that scope for what your end users need. OK last but absolutely not least the Copilot hub. >> I didn't pay her to say this. >> Your stop to learn about Copilot experiences across the Microsoft family. Learn dot Microsoft.com/Copilot. Go there. You'll see all the experiences Copilot, don't Copilot, etc. We're going to update it with updates from build in the next few weeks. >> You had a hand in making sure all that magic happened. We can thank Donna for that. >> What is coming up next you are excited about? >> We're going to be walking through some building some apps from the cloud. I love that. >> I'm joined by Anthony who is from the Microsoft dev box team. How you doing? >> If you are going to talk about my name. >> So you are my former manager, so we're not complete strangers. It's cool. When we talk about Microsoft dev box I use one. So we're all on the same page can you tell us what it is? >> Microsoft sev box are cloud developer workstations ready to code. You can configure the dev boxes to have all your tools, software, even your source code can be on them. It like getting in the seat of a car and stepping on the gas to go. >> Don't even need to put on the seatbelt. >> No safety belt. We got to go fast. >> A love it. What can you do on a dev box? >> You can do so much. It's your workstation in the cloud. You have entry level machines up to high end 32 dev boxes. Front end development, back end development, data engineering work. You've got all the compute you need build any application from the cloud. And then the other big part about dev box sits not just a virtual machine. It is under the covers. We wanted to make it something unique for the developer. When we looked at that; it was about giving developers the tools they need to make it a self-serve tool. When you walk up to dev box, you have an experience where you create your dev box from any number of projects and kind of configurations of dev boxes. >> We can talk a good game and say that dev box is the greatest. It means nothing if Microsoft is not using it. How is Microsoft using it? >> They use it a little bit. I'm proud that we have over 25,000 developers in Microsoft alone using dev box. That's 25,000 using it, 2/3 of them United States as their daily driver. Daily driver. This is what they drive in and out of work on where they are getting all their work done. We were able to increase satisfaction for our internal devs for their environment set of experience. They don't have the toil of configuring their environment. Work that takes days of setting up. That is done. Who is that person that knows what the updates are to that wiki? They've got it prebuilt. You sit down inside visual studio and hit build. That just worked. >> So you said it just allowing teams to all get on the same page quickly regardless of how you come into it. The steam a big part -T of it. I talk about ready to code developer workstations but you have to be able to do that for every team. It's not just one image that gets pushed out. Each team in Microsoft builds their custom environment. They have thousands of developers using dev box building the native versions of office from inside of a dev box. And take our team, developer decision. Studio has their own projects with a different configuration. They have three versions of visual studio working on the latest version, builds. If you create a dev box today you get 100 gigabytes of source code all predeployed into the environment for you custom and ready to go. Think about the time it takes to clone that. >> What a might mayor. And I think for me what I like is it's a nice sand box to experiment. I use mine a lot for visual studio, code and any Azure things I want to play around with. And it feels like a safe space to be able to try that stuff out without it impacting my base machine sometimes. Do you feel the same way? >> Totally. You can create one dev box or three. You can create a second one for experiment, proof of concept, a demo. You know Scott. He was telling me a story about what sold him on dev box was he was doing a demo to a customer and as he was doing the demo he was on a dev box and his machind device he had. Logged back in and kept going. Didn't lose a beat. Everything was there. It wasn't just from his listens. You can walk out of a movie theater and have a dev box on your iPhone, iPad, wherever you are you have access. You can do it on your iPhone. That's exciting. You can take your development anywhere. >> Work life balance. But it's at least peace of mind. >> We wouldn't advise it. It's going to mean you are going to be doing stuff 24/7 but it's nice to have. So I understand like dev box can do a lot. How customizable is it? >> Pretty much everything you can customize on it. We have base images that have digital studio on them. We have images from custom images that integrate docker. From there you can layer on all the customizations you can think of. Anything you can run from power shell you can run to dev box. One of the things we're announcing is the private preview for a built in imagining service where you can build your own custom images with just code to define what you want on there and the service will discover them and make them available for dev box. >> Cool. >> Anything you can imagine, anything to your heart's desire, you can put it on a dev box. I don't want to scary away the IT guys the devs can run while. There are all the controls in place. There are some companies that don't give their devs admin access. They have standard user. Oak ply that to a dev box and you can only configure what you can do as an individual developer. The other thing exciting for companies using dev boxes, every dev box is enrolled in in tune. You get all the device management you use today on a dev box as well. >> It's a great product. The service enrolls it for you, you know your device is enrolled. You have your identity as well. You log on to the dev box service with your corporate identity. You are already logged N. even VS is logged in. You get smooth experience. >> Perfect. So you mentioned announcements at build. I hear you might have a breakout session coming up right? >> We do. >> Can you tell us about what people should expect there and why they should come to your session? >> Come to the session, hopefully I don't number my opening lines. You can come to see. That it's breakout 184. It's build any application from the cloud with Microsoft dev box and visual studio. We're going to cover three things. We'll go Mitch deeper. Where we're going with platform for teams using dev box, how you as a team can leverage it to customize the environment. How dev box is personal and powerful. How you can customize it for yourself and how dev box is built for enterprises to be able to control and set the guardrails to delegate more to teams to own their dev boxes. >> Cool. So that's cool. You talked about what is new. I'm sure you want to keep some of that when you demo that. >> There is so much more in the dem moment it's 40 minutes long. >> Check it out y'all. >> If people want to learn more or get started with dev box where should they go? >> Why haven't they started yet? If they want to get started there is an aka link. >> It's below if you are watching the screen. I'm pointing probably not to the right thing. But that's OK. Thank you Anthony. >> All right. It's us. We're back. I love dev box. For anyone who knows me know I love dev tools. I've been getting into tweak and understanding and loving my environment. We have so many options for that. Dev box is a cool one. And in my past life was a consultant and dev box would have been so nice jumping from team to team ramping up quickly. But I love to get to learn and I hope everybody gets to join in. >> She has a good on the love dev box. I love dev box because I'm lazy. I don't like setting up my environment. I find it extremely annoying for new projects. I'm building a bunch of random apps and I like them not touching each other. I want to mess with the new SLMs in the AI tool kit and I want to do this in a dev box because fit doesn't go well I want to close that and leave acting like it never happened. >> Let's jump into polling. >> OK. >> I want to ask the question. I get to choose the question. How are you using AI in your career? Options. >> Option one, totally focused on empowering workers. Option two, just starting to think about it. Option three, it's not even on my radar. Or four, I see the opportunity so now I'm training myself. >> Which one of these are you? Put it in the chat. We want to hear from you. Which one of these are you? >> I'm starting to think about it. >> Just starting to think about it. I like that. >> I'm very much in category one, totally thinking about empowering workers. That's why we made Copilot learning hub. You like that segue? >> Absolutely. >> Once people find a great use case they are just all in. >> I'm going to cue off the Christina who is about to have a fascinating conversation. >> Thank you. I'm super excited. I'm joined by a team who we're going to talk about empowering scientific innovation. That's a pun topic. You are the VP of product innovation. We're been hearing Microsoft talk a lot about accelerating scientific discovery. I'm going to ask you about. That can you tell us more about this mission. What does it mean and what it's about? >> Firstly, I'm excited to be here. The aenergy amazing. Let me start by saying it's very complex to understand nature and everything in nature really boils down to understanding the laws of physics, biology and even scientist to a certain extents. Whether it's about discovering lek ro lites or climate changing or finding a new drug it comes down to scientific innovation. For decades researchers and scientists have been racing against time to really accessibility and lead this innovation. We're empowering them with the combination of platforms and be able to bring these products to market faster. Our real big vision is about accelerating science and that is what we're after. >> How does Microsoft fit into that landscape. >> If you think about Microsoft they are bringing the best of AI and super computing to build platforms in a hybrid manner so everything is under one roof. If you think about we've made massive investments in super computing. If you heard Satya talk over the last few months we've announced billions of dollars invested in AI and computing. We're on the roadmap bringing quantum to bear. We're focused around bringing all of our research to make quantum a reality. Finally if you think about all the research we're doing on the AI side of things, that is deep verge that we're bringing to AI models to really accelerate the scientific. These are trained on 200 million data points. That's huge. Finally we're looking at hybrid, meeting customers where they are. Combination of these three things is what we bring to bear. It leads to development of Azure elements. It's the service in client preview that you can use. Our goal is to accelerating and compress 25 years of discovery into the next five. What is this going to mean for how are we going to be able to support industry leaders by doing this? >> If you talk to industry leaders they care about a few things. They care about making sure that we help them with traversing the world. They care about managing cost expenses as well as making sure that there is not a lot of throw away work. And they care about getting better outcomes. We're empowering them with these three things it's three buckets. First is making sure that they have traversed the wide world of possibilities and narrowing it down to the one or go candidates that leads to better outcomes. It's about making sure we're guiding the right sort of innovations. One of the customers we work with were inspired to use a chemical compound. And it was used for decades. Couldn't fully understand the process until AI showed up. We understand the chemical process, tweak it and lead to better and faster outcomes. That's how we're working with industry leaders. >> That's great. So and I love that that is what we're able to do and unlock. What are the kinds of companies we're working wand what sort of impact are they seeing from your digital R and D? >> It's important to note it's not just R and D. We're helping make societal advantages. I'm proud of the work we've done with national labs. Working with them we were able to sort of go chase down and really build a battery that uses 70 percent less lithium. What better than to show you. This was done in 80 hours. Before AI showed up it's like finding a needle in a hey stack. This is just really scratching the surface of the possible. >> This is so impress I have. This would have taken so much longer before. 80 hours you were able to create this battery to power this clock? >> Yep. And we're also working with other CSUers in addition. We're working for better research and bringing drugs to market faster. If you think of the drug manufacturing process. It takes billions of dollars. We're looking at compressing that and making it possible. >> How much of this innovation happened in the last few years? It feels like this happened overnight. I know it's been a long process. How much of this is something we've only been able to unlock recently? >> It's been a journey. I think the real unlock has been decades of AI research to bring these models to bear. There is more to come. >> So how do you think that this R and D landscape is going to grow and evolve in the future? >> As we talked about AI is just one piece of the puzzle. We're just scratching the surface. We talked about AI super computing that is in the now. We can't imagine the future without talking about quantum. We look at really three stages of how we want to bring quantum to bear. Level one is foundational. Those are the traditional machines. You can use those for simulations and they are great at that. Last month we announced a real break through. We work with our partner and we use their hard, a used our data collection and we were able to really get to the demonstrate stable logical kites. That's the first of its kind. And Microsoft is proud and humble to get to that stage. We were able to run 14,000 experiments without hitting an error. This is 800 times better from an error rate standpoint than what exist out there. There this is level two. The real unlock comes from level three when we get to quantum super compute they're puts AI at that time next level. Even with level two today, we're able to do a lot of computation, scientific discovery and we couldn't be moreen excited about what is to come. We believe our unique approach will get us there. >> That's really fantastic. And so when you think about do you have anything where you envision the future , what are you hoping we'll see moving forward? >> In a nutshell, it's going to be about AI, super computing and quantum. Quantum takes it to the next level F. a today standpoint we're barely scratching the surface with AI. I couldn't be more excited about the possible when it comes to chemistry and bringing that to market. >> I like. That can you talk to me more about how you see these two roles intersecting? We have spoken about these things as separate scientific advancements even though I think you are right, they are going to be converged. Can you talk to me about how you see that happening? >> If you think about the AI models today there is a lot that needs to be done to train the models, traverse using the data, with quantum it's going to take a quantum leap. So I think we couldn't be more excited when these three things come to life and you couldn't look at scientific discovery without one, two and three. It's about applying all of these things to the entire scientific method, not just about the front end or back end. >> And I know you talk to researchers all the time. What is their response been to the possibility and what are they excited about continuing to disCOVID? >> Discovering a lot of use cases. This is groundbreaking tech. As we think about this tech, researchers get excited about can we apply it to that. The use cases they are seeing are varied and the applications are many. We're excited to build this platform. Get it in the hands of researchers. We have a scientific Copilot that is grounded in the scientific domain. Without the Copilot I think it's hard for researchers to collaborate. What we're excited about is bringing that Copilot in the scientific domain and getting to innovation faster. >> I love. This I love how this is all working together. How can customers get started today? >> Azure quantum elements is in private preview. I encourage developers and scientists to try it. Go to the Azure web page and get started. Try our scientific Copilot and go from there. >> Thank you so much. >> Thanks for having me. >> Thank you for being here. [Music] >> Welcome back live Microsoft build on the fifth floor. This is where it's at. Because this is where we have beautiful people like. This all of you saw the imagine cup final this is morning in the world championship. Did you know we had tens and thousands of student startup as ply over the course of the entire last year and we have some of the runners up here with us today. What I'd love for you to do is introduce yourself and the name of your project. >> Our project is called apiece. >> I'm part of apiece. >> I'm part of apeed. >> So I know these projects so I'm going to act like I don't know about them just for you. >> Your projects are so impressive because you are not just use technology to build something random. But you are actually using AI to solve real problems that you see in your countries and communities. I think that is really impolice officers and please keep that spirit throughout your careers and lives. Tell us what just a quick one minute pitch about your project. >> It's a developer first student information system. So the biggest advantage is that it's an open framework which developers with use to extend its capabilities. Also we use multimodal Copilots to empower students with actionable insights grounded in data. >> I love. That moderning a education which needs to happen all over the world and this solution can be used in every country in the world with local data? >> Yes. >> All right. >> So we aim to bridge the digital gap by using AI to bring quality education to isolated communities that don't have access to internet. >> You know what is important about this, that is much of the world. There is so much we can do with small language mold running on device. This problem you are tackling can apply to so many plies in the world so I love that. >> We are a legal tech startup that builds systems for justice systems that helps with backlogs and improves access to justice. >> You are improving access to legal care and it's often so skew and biased. That's a thing in the U.S. and all over the world. What are some things that you all found interesting while working on these projects? >> The pace of development of AI, especially Microsoft Copilot and other generative AI experiences just a week back GPT4.0 come out. We implemented it the next day in our Copilot and saw a dramatic change. The significant evolution of experience is what excites me in my own startup. And what we are doing here is to use these technologies to really improve academic welfare for universities all around the world. >> 4.01 magical for you. All that multimodal you can do voice input, video input versus typing all the time. >> Yes. >> That is an equity thing. Because not everyone has that literacy but most people can speak. >> Marginalized languages, minority languages. >> I didn't know. That. >> It's really good at that. >> That's interesting. >> What about you? What has been interesting about this journey you've been on? >> I think in our project the most interesting thing is we're creating an infrastructure that is optimized for AI. So it's analogous to an internet infrastructure. So we have to think from ground up what it would mean to is have an AI internet. That's one of the coolest parts of it. Also extends to stuff like UX and UI especially because we're bringing into isolated communities. We need to understand how we create a UX and U.I for someone who never had contact with internet. >> How do you design UX for someone who never saw a screen. We can't say log in. What is that. Submit. Error. What are these words. We have to design something intensely human. And I think GPT4.0 could be interesting because voice based is more natural for these scenarios. I don't think voice is relevant all the time. But sometimes it makes sense. >> What did you learn that was >> I think nowadays a lot of focus is on generative AI. In the limited context of using it because of hallucinations we haven't talking enough of the nongenerative AI stuff. Our models a speech to text model which helps become a Copilot to judges and stenographers. The gains are huge value add in terms of productivity and times taken to resolve cases. I think we should talk more about the non-again AI stuff which is unleashing a lot of productivity in the world. >> AI has been around for 50 something years and the way we act it was invented two years ago. Predictive AI has been around a long time and it's a lot more predictable and a lot lower cost like train and use etc. Real quick. Homework for the audience. Next again imagine cup people? >> I'd like you guys to read up about the semantic which is what powers our Copilot. >> Check out the speech to text revolution that is happening, the error rates have gone down for minority languages and a lot of productivity is going to come out of that. >> I would say let's think of people who don't have the same privilege and always try to use technology to help them out. >> These are the themes of the conference. Thank you. >> Thank you. [applause] . [Music playing] >> Hello. I'm here with director at fusion. We had a lovely conversation before talking about your journey. Tell me more about how people can use sync fusion and what is it like? >> It's a pleasure to be here with you and the entire Microsoft developer community here at build. Exciting to have so many wonderful thought leaders here today. Sync fusion is founded on the principle of delivering innovation with ease. We provide software developers the tools and skill to be able to build custom software applications more quickly. Productivity is a huge issue with us of course. AI can be an even greater accelerant. We help developers do what they do best which is to focus on innovation, software development, without getting bogged down with extra details. Customer support of course is very important in any industry. We're no exception to that. We're extremely proud of our live 24 hour support that we give to the entire software developer community. Also we have special services for mission critical applications like video conferencing for example. Speak about mission critical applications, sync fusion is used worldwide in some of the most amazing ways possible. Just the healthcare industry for example. There are applications right now that are tracking people and monitoring people's heart beat. They are monitoring people's insulin levels for diabetes N. some developing countries it's being used to monitor clean drinking water for small children. It's very special to us of course to see how we're being used all around the world in so many different ways. Developer by developer, application by application. >> That's amazing missions, you have amazing initiatives you are taking part N. I'd love to know more about how do people get involved and understand? >> How do they learn inner? >> Go to our website. Or even more importantly than that it's reviews. Used to be years ago we used to try something out and then decide. The world has changed. Now we go to reviews first. We see other people's experiences, other people's journey and make our decision. There are thousands of independent reviews where software developers share their experience, they share their journey. People here, people watching online can go to the reviews and learn more. >> I'm so excited. Thank you so much. We're going to cut to our next part. It's been great. >> Enjoyed it. >> Thanks so much Don. I'm here with Scott from cognition AI. If people have been under a rock and haven't seen Devin why don't you tell us what that is and we'll play some. >> We have a clip of setting up an Azure AI end pint helping the user through that. In this case the user was asking how to set one Azure and get >> I want people to see this actual video. There's a video you brought, there you go. >> So Dev sin an autonomous software agent. Devin has all the same tools a human engineer would have to >> Taking into account those four things, super cool, great stuff. Guys, thank you so very much for joining us. And for those of you here in the room, and also for those of you online, you want more information about this Intel cool stuff that we've just seen, you want to see the code? We have an answer for you. It is called the feature partner directory, it's located on the Build.microsoft website, you can go, there hit that link, take a look at all the things. And if you happen to be in the audience, go harass these guys, learn more, go see that codes. Gather it and move forward. Thank you so very much. We are going to be right back with more from Microsoft Build, in just a moment. [applause] >> All right. Right now I'm joined by James, who is a principal product manager. >> Hi. >> So we've got good news and bad news. The good news is, we're going to try to do some Q and A, either live in person or via chat. The bad news is, we're going to try to do some Q and A. So we've got a lot of content we're going to be talking about, that's really cool. We may or may not have time for a lot of it. If we do, NASA great. If we don't, don't worry, we've got a link to learn more about everything that's new in Azure cosmo. Speaking of which, what are some of your top highlights being covered throughout Build? >> So you may have heard we announced earlier today that we're building the universe's most scalable vector database in Azure cosmo DB. We announced native vector indexing in search, integrated into the core database. We also announced the preview of the Scandeck index, it allows vector search at high accuracy at any scale. We also have lots of integrations with our favorite Large Language Model orchestrators. >> Sweet. So the elephant in the room here, there are other databases out there that have vector-based index searching. What makes Azure Cosmo DB stand out? >> It's a great question. In Cosmos DB you can store your data and vectors together. This eliminates the need of using a separate vector database and having to worry about keeping your vectors and data in sync. Furthermore, it has a rich no SQL language. You can conduct vector searches and filter them based on any filter query ranges, date times, numbers, strings. Even spatial indexes. It's very diverse, very complete. And finally, we offer many types of flexible indexing. We have flat or brute force indexing for very precise 100% accuracy. We also have compressed brute force, the state of the act vector indexing. And you combine it with Cosmos DB, global replication K. our fine 9SLA, and announced today, the seamless transition from a serverless option to a provision through-put option. The two combined give a huge advantage over existing vector databases. >> I think the favorite for me was being able to keep everything in sync with each other without having to remember to update the database or the vector piece. >> Exactly. >> That's really nice. >> Keeps your architecture nice and simple. >> I agree. So you mentioned disk A and N. Can you talk about that? What makes it special compared to other vector index types? >> Sure. So disk A & n is a suite of advanced algorithms developed at Microsoft Research for efficient and scalable vector indexing and search. It starts with a -- ingest vectors into your database and it compresses them or quantizs them. The data structure, the graph that powers this search behind disk A and N resides on high-speed SSDs. That are the backbone of Cosmos DB. The graph index on the SSD is developed using the full prevision vectors. Not the compressed vectors. When you search the graph, the results are reranked using those full precision vectors. What this means is you get incredible computational efficiency by leveraging the compressed vectors in memory, but you get the full precision of using the full uncompressed vectors stored on the SSD. And this is all enabled through a suite of algorithms developed at Microsoft Research. >> Excellent. So I love that. It's like you're taking the best of multiple worlds without really a lot of the cons in terms of having the precision. >> Right. >> So how is disk A and N being used today in the real world? >> It's used extensively inside Microsoft. So it powers are multimedia search, it powers Microsoft 365 experiences. For the first time in a Microsoft product, we're bringing disk A and N to you and allowing you to use it at incredible scales. >> Cool. So I think it's time to do some live coding demos. >> All right. >> Let's talk a bit -- see how vector search works in action. >> Yeah. All right. So to get started here, I have a Jupiter notebook running so I'm going to use our Python SDK. We have a rich set of SDKs for Cosmos, so we're going to use the Python one here to do some simple vector search. I'll go ahead and set up some of my configurations. Then I have something tbhu here for vector search in cosmos DB. Define a policy to tell Cosmos DB where to look for the vectors. Then define an index, just like in the other property, and this I'm I'm going to define the disk A and N index for this container. I'll set up my connection details, I'll have the helper function here that helps me create embeddings easy using Azure OpenAI, and then the meat of it. We're going to be using -- here's my vector search query. We're going to be using a new system called vector distance that executes the vector search for us. So we can project that as a similar score in the select statement. We can add aware clause and say we don't -- only want to see results above a certain similarity score, and then it can order by vector distance. This is what leverages that powerful disk A and N index. >> Like the higher the vector distance the more similar the values are? >> That's right. We're going to use cosign similarity, which is a recommended distance metric, so the most relevant results will the highest score. And the least results will have the lowest score. We'll run a quick vector search. I have this database, I have a container that is full of these products, so I can search for show me red phones, that maybe are in this database, and I can see the documents that come up. There's this plus red phone 2000, bright phone ultrared, so a lot of great options here. And one thing you'll notice, if we search through here, is that not only have they done a vector search, but I'm also using a query filter to get the right content. Because sometimes vector search is really useful and really relevant, but sometimes it doesn't meet the bar. You notice what I'm doing is adding a where clause, where it contains C.name, red. I'm looking for a substring in the property name, and I can just combine any query filter I want with this and run it with my vector search. So it's really similar to execute vector searches that way. In this notebook we've done a couple of other things. We're going to build this simple chatbot, or shopping assistant, and we can store our chat history in Cosmos DB. We can also orchestrate our chat completion, Large Language Model and implement a similar antic cash to save time and cost for making LLM calls, API calls every time there's a user question. And then we can deploy this in an Azure web app, but we can also have a simple function running here in Gradio, and we can add this chatbot I have for my marketplace demo and say, show me red phones you have in stock. So it will execute the vector search, and the vector search and the retrieval is fast. Because I'm using GPT-4 -- >> And because we're doing a live demo. >> We're not the only ones using the internet at Build. Cool. Now we can see all the options we have. Let's put it in a nice format and we're able to store the data in Azure Cosmos DB, with our vectors, execute a search and connect it to our RAG pipeline for our LLM. >> That is excellent. I love it. You came in with 1:30 to is a s, which means we might have Q and A time, like one or two. Starting with the chat, have you got anything? >> Yeah. One interesting question came in, can I use any of the Azure Cosmos DBs as decoys for vector search? >> Great question. Today you can use the Python SDK, .NET SDK, and the java SDK, and go will come plater. >> Let's do an in-person one. >> My question is, how would this work if you have a multitenant application? >> It's actually really a great question. Cass mows DB is designed for a multitenant application. You could maybe start serverless, which is great for apps you don't have tons of demand for every tenant. And then we have a natural progression, seamless integration where you can move from our serverless to throughput model, and there's multiple different flavors, everything from isolation on a partition key level, index level, container level, database level, even resource level. >> All right. Great questions, y'all. And that concludes our Q and A. Very short and sweet, but great questions. If we didn't get to your question, where can people go to learn more? >> You can check us out at aka.ms/cosmosdb disk an, or go over there and ask me questions. >> Thank you so much. Check out the booth if you're here in person, and also go check out the website. Thanks again. >> Thanks, Leslie. [applause] >> All right! That was awesome. I loved that. That was cool. >> That was fantastic. >> By the way, so much news in the world of Azure, right? What's been your favorite? >> I really like the Azure AI studio enhancements, I know we've talked about it a little bit, but there's the toolkit, and that includes Azure MSDK, as well as visual studio code, which I love, and are both critical to my deploys. >> These are all your wheelhouse. >> Yes. >> You live in this all day. >> This is my thing. This is my wheelhouse. >> You know what I loved, Azure AI studio went into preview, and to see it go live is pretty cool. Full circle. So everyone go for to use Azure studio. If you're not using it, go and use it. Speaking of, GPT for omniO is going to be available for everyone in Azure AI studio, it's in the early access program, but while you're waiting get real familiar with how to use vision and all of these multimodels -- multimodal models. There's a bunch of them already available. As well as small language models, open source models, etc., etc., in the Azure model catalog. If you haven't gone and taken those and built your own little AI app, you could do it very easily. >> And it's decided a low-code activity. I'm really excited about the responsible AI enhancements, make sure you check out that dashboard, give us feedback. I'm so excited to hear about the audience diving into more of that stuff we're sharing for you. >> I like that. The content moderation dashboard. Let's talk about that. You're building an AI product, hello, you're building a content moderation -- you're building an AI app, and one of the things you have to think about is, okay, what kind of content moderation do I want to have? What do I want to bloc explicitly? I don't want to talk about war, violence, this, that, and the next thing. But I'm okay, I have more tolerance around these other topics. >> Absolutely. >> I like that level of freedom. It's not just high, medium low, but there's all those individual levers. >> Absolutely. You can go in there and have the granular fine tuning, different type of fine tuning, but you get to really own that model and figure out what's the needs of the -- >> That's right. So funny information, fun fact, do you know that our team worked very closely with OpenAI to make sure inclusivity is factored into responsible AI? Yeah. And a big part of inclusivity is people with disabilities. So we made sure that our AI models are not -- we're trying to make sure, we're doing our best to make sure our AI models are not ableist towards people with disabilities. Because that is important for our global audience. >> You know what? Joey is waving at us, so we're going to bounce to him and Nvidia. >> Hey, thank you so very much. I was just waving because I saw Dona over there. Hey, we'll cut right to me anyway. I have got an awesome cool segment with my friends efrom Nvidia. Before we do that, they brought us a video. Let's check that out. >> Microsoft and Nvidia are hoping the global $46 trillion manufacturing industry digitalize their processes. Industrial work flows require highly skilled teams working across many tools and applications. Nvidia omniverse cloud APIs on Azure bring data interoperability, collaboration and physically based visualization to software tools for designing, building, and operating industrial digital twins. To build an operational digital twin, designers first design, engineer, and simulate products and manufacturing processes using hexagon nexus. Facility planners use hexagon scanners to capture the real world, and render in reality cloud studio. Engineers work in rockwell automations emulate 3D to simulate production systems before deploying to the physical factory. Then with omniverse APIs, data from each applications flow transcript seamlessly into unified omniverse digital twin in Microsoft Power BI, where teams can see their 3D data in context. When the factory comes online, data is live linked to the omniverse digital twin in Power BI. And when connected to Microsoft Copilot, factory operators can gain insights into their production data using natural language. Together, Microsoft and Nvidia are bringing AI and collaboration to the next era of industrial digitalization. >> We're here with Moh Highighat and Adam Lash. Let's start off, talk about -- talk a little bit about your role, particularly at Nvidia, and Adam, you at Microsoft. >> It's great to be here, thank you. I'm part of the omnipartnership team and I lead strategic alliance and Microsoft is an important than pa that we're working closely together to drive massive adoptions to our ecosystem partners. >> And my name is Adam, I'm a principle program manager here at Microsoft, within the platform team. My team helps build the products that help you get the data from your request industrial systems on the edge into Azure, as well as begin to find analytics there and working with Nvidia is a massive partner for us as we try and help our customers find value in that data for industrial systems. >> Super cool. I'm going to ask the typical first question, why are we here? Why are we having this talk? I'm going to throw in an interjection. Why is this relevant to our developer friends out here? >> So entire heavy industry is going through a massive amount of transformation. And the transformation is happening to the process of actually building a digital twin for physical space. As we're embracing all the great things related to AI, there's a lot of changes that are happening where people want to drive more efficiency and reduce costs. So instead of building a brand-new factory, how can cool would it be to build that in the digital twin, rapidly in the virtual world before you actually lay any foundation. That's what we're here about, massive transformation happening in the $50 trillion industry. That's why we're talking about omniverse and the partnership that we are having with Microsoft. And I know there are various ways of actually enabling that. >> And before all that, a lot of these kinds of things, the reasons we do it, optimizing these designs, creating these operations, some of the mechanisms we do this with, and these technology enablers we have, are these open standards. This concept of USD, open USD that we'll talk about more in a second. As well as the generative AI and the use of robotics. And the ability to essentially use robotics and create environments within omniverse that you can use to train these robots later doubt line without having to commit all these resources to doing it. As well as of course RTX with Nvidia. >> RTX at Nvidia play as major role in building these digital twins and allows us to create large-scale massive real world simulations in the digital world. And these are the kind of underlying technology enablers and foundation that Nvidia and Microsoft is bringing to bear. >> Looking at all this crazy industrial things, you're doing all of this in a world before you even stick a shovel into a piece of ground. >> That's right. That's the power. >> That is amazing. Share a little bit -- talk more about the role of data interoperability and open standards like, Adam you talked about open USC. >> Yes. So open USD, for those who don't know, it's universal seam scripter. It came from the media and entertainment industry. Pixar created it for movie making. If you think about movie making, it's a team sport. There are several different kinds of collaborators that actually come together to build an incredible movie. Guess what? In the industrial world, you actually -- it's also a team sport. You have several different functional expertise that comes together to build a factory. So open USD is the standard of the digital world of creating these 3D workloads and 3D use cases, and USD, open USD is that standard. Nvidia, along with other industry partners came together to create this alliance of open USD, and it unlocks a way to create these digital twins in a collaborative way. And that's essentially the foundation for a lot of things that we're talking about around AI, and simulations, because open USD becomes that de facto  industry standard. >> This is crazy, because when you think Hollywood, you're like, they're the ones who create these fake things, and we're almost flipping it in reverse where you're doing it kind of in a not real world and bringing that to the real world. >> That's right. That's exactly right. >> Technology that Hollywood built. Super cool. >> That's right. >> Did you have something, Adam? >> Within USD, it's amazing essentially the special effects world has this great pipeline. They've been doing these things for decades, and the industrial world is getting their head around this 3D world, it's a very complex, difficult world. Open USD helped democratize it and allowed everybody to start contributing to that. And there's so much functionality. And Nvidia is doing amazing things with omniverse. >> Now we've got this collaboration. So to the next level. >> Exactly. So what we're doing, we're working closely with Nvidia here at Microsoft to help bring that omniverse reality to all of these industrial systems and all these industrial customers that are looking to get involved in this. And to that end, we're started working very closely on some of the projects to help first bring a lot of their industrial data in to the omniverse experience, as well as help you do these predictions, these had synthetic generations like we discussed before. >> Microsoft and Nvidia are uniquely positioned to go after this new era of, as we said, the new era of building these digital worlds, and tapping into the $50 trillion industry. We're uniquely positioned because if you think about the power of what Nvidia is bringing to the table, through its GPU and the power of what Microsoft has done for decades around data and platform play that has been ubiquitous in the enterprise industry, now you're bringing those two worlds together to unlock this incredible potential, where people are actually going to be not thinking about the physical space first, but creating all of that in the digital twin as a digital begin in the virtual world. And through this partnership, we are actually as Satya was mentioning in his keynote, we're actually bringing omniverse cloud API first on Azure, which is essentially going to be allowing for our end customers as well as our ISV players to bring a massive amount of workloads running on Azure, on Nvidia BTUs. >> This is a great vision and what we're trying to achieve alongside Nvidia. And you can see here this doesn't include just Microsoft Nvidia, there are many other partners and other people involved in this awesome ecosystem that's currently going on here. And to that end, as you can see here, the omniverse cloud in the center, bringing in some of that physical asset data from Azure operations, which is one of the products mined to help grab that data from the Edge into Azure to be able to do awesome things like this with it. But once you have that data and once you have all these things, there are so many different experiences via these omniverse cloud AIs you can start using this with. With the one on the right, it's the awesome ability that we've had to embed this within Power BI. What you can achieve is the data living inside Power BI, which is a traditional way many of our customers today use to consume this information. >> We've been took this for a hot minute. >> Yeah. Now you can bring in this awesome, rich 3d experience with that data context beside it. And you've started to elevate your general consumption of how you interpret these singles and things you're seeing within your site. >> All right. We saw really cool video earlier, are there other kind of examples of the work that y'all have been doing together? >> Yeah. So we're going to talk about this joint work that Microsoft and Nvidia came together and we showcased this, a live operational -- just last month in Germany. So what you're seeing here is two robotic arms built by Microsoft ground-up, where we actually are showing how the whole simulation to real gap was fulfilled using omniverse where we simulated the robotic motion and the whole operations of that robot in omniverse, even before the robot was actually programmed. And then I'll let Adam fill in the pieces how Microsoft and the Azure stack was used, and we actually used Power BI as the end customer experience where we were streaming omniverse embedded view port into the Power BI. So you are seeing two different really powerful use cases come together, one is the how do you fill the simulation similar-to-real gap, and how do you use Power BI and create the operational twin in a real factory in action? And do you want to talk about the Azure stack? >> Of course. I think it's really cool, a lot of these robots you see here, they were trained -- this is an evolution. What you're seeing here was a live representation, so the actual video is the a recording of when we had the physical machine at Hanover, so we had people come up to our booth and say that's a video, this doesn't seem right. But we would stop this, this whole thing would stop, those pucks would stop moving around, this is one-to-one, a representation of what's happening in the physical space. This isn't any video, this is a true articulation, everything is there that we're representing. >> It's essentially where you can see potential issues, any of those things that may come up as if it was happening. >> It's a great point you bring up. The use case we're talking about is remote monitoring, remote operation. Imagine if I was the executive VP responsible for my entire factory operations, worldwide. And if I have a team of people sitting in my HQ trying to figure out the KPIs and problems that I need to deal with on a day-to-day basis at a production level, now they actually don't have to send humans and people into a factory. They can actually remotely look at the entire operation as they are happening, h through this experience. And that's the ultimate goal that Microsoft and Nvidia are coming together to bring the two platforms together to create that experience. >> By using the data, coming from that Edge to enrich it, by using the Nvidia ecosystem, but also because it's in this format, we can start simulating things in the future, we can start building brand-new things, or with that same -- all with that same USD in the middle that is helping articulate these connectivity piece poos together. >> This is mind blowing. It's amazing. I'm not quite sure the guy who used to travel to the thing, because -- [laughter] >> They can take more travel vacations. >> There you go. Personal vacations. Anything else you want to add before we wrap up? >> We're super excited with the partnership with Microsoft, and it's really exciting that Satya and Jensen at that executive level are aligned with the vision. There's more exciting things coming and we're excited to bring those as we -- as the two teams work closer together and bring those to general availability in the coming months and year. >> And there are so many awesome things we're working with Nvidia, internally they're building on the concepts here, and we're just super looking forward to getting them out to everybody to be able to allow all of our users to have the experience of being able to build something like this and use it for all of their industrial systems. I think together we're going to make some really amazing stuff. >> This is so super cool. I love this story. I love hearing oh, hey, we're going to take things that were invented in Hollywood and we're going to bring this to you, to a manufacturing world and change not only how you do things before you build, all the way through building, to actual realtime execution and delivering that with the data and the power and the tool set, a lot of these tool sets are already in use. We have Azure, we have Power BI, and you just expand upon it with the Nvidia experience. >> Exactly. >> So super cool. Thanks for being here. For those of you in the audience and those of you watching at home or wherever else you happen to be watching, looking at Power BI data, you can get more about the Nvidia partnership that we have through our partner directory, the featured partner directory on the Build.microsoft website, go there, get cool demos, information, so check it out. More from Microsoft Build, coming up. >> We have so much planned for you today. This is the first day, so much is scheduled. Coming up, we have an interview with the founder and CEO of arise AI, and more conversations, a winning conversation -- >> Oh, yeah. I get to do something really fun. I think this is the best part. I'm biased. Maybe not. I get to talk more to the Imagine Cup finalists and winner. That's pretty cool. >> That's super cool. >> How impressed were you by the projects? >> I was just going to say, I've been seeing all of these presentations, and they were standing up on stage and talking about their values, and their mission, and their tools they use to accomplish it, and the audience, they were able to engage with. It's been so exciting. >> Exactly. All right. Can we do a poll? >> Yes. >> Ready. I'm going to choose the question. How about this. Are you ready to start the Microsoft Learn Build Challenge? Do you know what that is? >> Yes. But tell the audience. >> The challenge is, if you -- we want you to skill up using the Microsoft Learn collections, we want you to earn a digital badge by completing a whole collection, and there's collections around. And this is my favorite. Collection around Copilot, do that one, because I want to win the collection thing. Second, GitHub. Microsoft Azure, and Microsoft fabric. Choose one of those collections to do, and then you will be the Microsoft Build Challenge winner. >> I love that you get the leader board, but tell me whether or not you're ready, first off, yes, I've been waiting for this, it's on my radar now. The second option, tell me more on how to get signed up. 3rd option, or fourth, I'm registered and ready to go. >> Which are you? Which are you? >> Yeah. And I love Microsoft Learn challenges. I've been able to engage with some of them, and they have this leader board -- >> Which one are you going to do? You have to do the cold front one. We made that collection just based on everything that we've shared today. And we've plucked very specific learning paths that line up with everything shared across autopilot, the keynote, breakouts, the demos and labs. Let's go chat with Christina from Nvidia >> Thank you so much. I'm super excited to talk about AI model evaluations with Jay and Jason. Jay, you are a technical fellow at cohere, and Jason you are the founder and CEO of arise AI. What is arise? >> Arise is one -- the leading platform for evaluation of LLMs and AI. >> Fantastic. So we actually have something really cool, Leslie did this earlier, if you have questions for Jay and Jason, you can ask them in person, we've got a Microsoft and if you are online, you can do it by tapping on the Q and A tab in the chat. Just type those in. So we're talking a lot about AI models, I'm going to start with you, Jay. How are the language models in 2024 different from previous years? It seems like to me, new model comes out literally every other week. How are the 2024 models different than what we've seen in the past? >> We can talk about a few axis where the models are improving. What is capability? These models are getting much better and better across many different axis. This can include things like context, the steerability, how would the model answer prompts and directions and how it is able to be guided by prompts. There are things like the capability of code, the quality of the code that the models generates. But there are also improvements in terms of efficiency and how this is -- we focus on enterprises and for enterprises efficiency is important, that smaller model is fast, it outputs results very quickly, and so more and more the industry is figuring out better and better ways to have the smaller models do much, much better performance across various tasks. >> Which is exciting to see that. And I love that trend, because I think it's good for all of us. We get more apps out there and usage. Jason, when it comes to evaluating these models, how are teams evaluating their LLM applications? >> You should not put something in production, should not build something without model evaluations. What teams are doing, the best teams in the world these days are using LLMs to judge their LM applications. I know it sounds crazy. But you need something intelligent to judge something that's creating intelligence. So they're part and parcel with anyone going to production, and arise Phoenix is one of the leaders in the eval space. >> Very cool. And Jay, rs you mentioned the focus on enterprise, how are enterprises thinking about RAG, Retrieval Augmented Again Ration? >> When the enterprise or when companies are started to deal with generative AI and generative language models, they started -- people starting chatted with the models but the next thing they wanted to do how to make their output more factual. Or how can I chat with my own data? Internal data? So retrieval augmented generation makes that possible. Over the last year we saw a lot of trying to do demos and POCs of initial RAG demos, but there are civil ways to make those better and keep improving them. So we have let's say a road map of advanced RAG techniques that people can do to improve the capabilities of these models beyond just doing a search step and then a generation step where you answer -- enter the context. And so focus on reliability, on improvement of the search step, and the generation step, as well as things like multihub RAG, and multiquery RAG, which all come together to make RAG systems that are more and more capable and reliable for the enterprise. >> That's what they want, right? It's great to be happy as models, but we want it to be tuned to our data ask what we're doing, not just generalist sort of thing. Jason, when we're thinking about, we were talking about this earlier before we got on stage, when you think about observability for AI applications and LLMs, how do you tie that into evaluation? And why does that even matter? >> I 30 it's really hard to go from a Twitter demo to a product. Really hard. And harder -- in the AI space, incredibly hard. You need observability to trouble-shoot and debug these apps. You night observe built collect the data to evaluate in the first place. These frameworks like LangChain and Llama Undecks are complex. Debugging a one-line code app can be a hundred distributed system calls underneath. So of observability is used to collect the data and use it to dribble shoot to bring it from demo to production. >> Yes. Which I think is important. I think we've all been there, we build this thing, it's almost there. And the bedug is going to take us forever. >> The last 20% is tough. >> Because of how the systems are built and because of the -- I'm hearing we do have questions. We're going to start on the digital side. What is our first question? >> We do actually have a question. This may be a good one for Jay. What are the best practices for evaluating RAG systems? >> That's a great question. A lot of people deply and they need a way to measure RAG. And it's not a straightforward evaluation. But there's a number of ways to look at it. There's the -- RAG system is basically two components. A retriever and generator. And it can be language models in both of them. So thinking about evaluation for the retriever on its own, with classic information retrieval metrics, and then the generator itself with things like faithfulness, but end-to-end evaluation of the entire RAG flow, our team has been putting out research, one of them is the AILT kilt bench mark to evaluate RAG systems. So that's a good way to decompose it into all of these trouble-shoot each of these components on its own. >> Very cool. Our next question is going to come in person. Please step up. What's your question? >> Thank you. This is a question to Jason. Jason, in past two years we have seen a shift in a lot of things from traditional ML to LLMs. What is the major shift you v seen in terms of observability? >> So we hinted at it in the beginning. We're in a performance metric, like performance or accuracy. In LLMs it's an eval. Using an LLM to generate that performance metric versus something that's traditional. I would say that's one big area that's come up. I would say the other one is just, there's a proliferation of frameworks, the LangChains and Llama IndexEs make what goes on under the hood more important to trace and understand what's going on in each part of your chain. So I think those are the two big differences as I look at this space observability-wise. >> Thank you. >> Our next question from the digital side. >> We actually have another one for Jason. What are the biggest challenges in moving an AI product from demo to production? >> Great question. >> So I do think it's -- I think some of these frameworks, I would say a LangChain, I see a lot of times that have built that proof of concept on it. But as they go to production, it's quite hard to debug. The abstractions are so complex, in production environments, it's hard to figure out what it's doing. So I would say making something simple enough that you can bring it to production, getting evals right so the evals you do in development translate to production, and that the tracing and debugging that you had in your development environment actually work in production, are some of the biggest challenges. But those are the -- those come to mind for me. >> Jay, do you have anything to add to that, anything you've seen in your experiences? >> Focusing on reliability is a major thing. I love the Twitter demo. >> You're correct. >> It's a common thing. >> It is. >> Reliability and measurement is key for business use cases. >> I think you're right. We all get kind can of star struck by these demos, and it looks great, but it's not going to be ready for production certainly not in enterprises. So that's the why we need testing, that's why we need to do reliability and these evaluations. So final thoughts from both of you. Jason, where can people go to learn more? >> AKA.ms/ariez is the link for getting -- to check out the product. Check out Arize Phoenix. It's gaining in massive popularity. >> And Jay, any -- >> We love people to search for Coherent Azure, they can do advanced augmented generation privately on Azure. >> Fantastic. Jay, Jason, thank you so much. >> Thank you. >> Thank you. >> I love that session. I was supposed to be paying attention here, but I'm listening to them. That was really interesting. >> I've been talking at you the entire time. >> This is true. Okay. Everyone, I heard the funniest thing in the whole world. Someone said, Joey as a unit of measurement. Someone is like, that thing is 1 Joeys. >> Correct. >> You're a unit of measurement. >> At least I'm not an AI model yet. >> wow. >> But I'm not sure how you would attest that. With another AI? >> AI inception. >> Yeah. >> We have AI inception at Microsoft Build also. Okay. You know what was interesting about their talk? All of the different ways you can RAG stuff. >> A lot more -- I'll be honest, my RAG knowledge is lacking. So I got a lot more expansion of my knowledge, and use cases that I didn't know. >> I just didn't know, you can do this pattern, that pattern, and a lot of it is orchestration. You can RAG more than once, which I didn't know that until right now. But I love how we learn more at Microsoft Build than we teach others. >> Exactly. >> It's fascinating. >> Exactly. And don't take it right to production. >> Don't do that. >> Hey, I hear you're going to meet the Imagine Cup world champions. >> I am. So that is definitely the favorite part of Build. I'm going to be interviewing the winners in a little bit, and we're going to talk about what their project is, who is the first person they called once they won their ginormous trophy this morning, and what they're going to do next with their project. >> I'm so excited for this. When you talk to the semi timists and runner ups, I was like, how did they not win? Now we've got the actual winners. This is absolutely amazing. All right. We're going to send it over to Don, Don, it's your turn. Dawn, it's your turn. >> I'm here with Peter McDonald, VP of Cloud and strategic partners at Snowflake. I'm so excited to chat with you. I hear you have some initiatives with AI and Microsoft, and all of that. It's really exciting. Can you tell us more? >> Absolutely. Just about a year ago, Satya and Snowflake's CEO announced a new partnership focused on bringing AI to our customers with the Snowflake platform. Snowflake has great capabilities and scalable analytics, easy-to-use data collaboration we've seen wide adoption, including many thousands of customers on Azure. What we want customers to understand is whether you want to use the Microsoft AI stack, the snow flak AI stack or third party, Snowflake is the best or the ideal platform to build on top of. On top of that, just last month, we launched Snowflake Arctic. Snowflake Arctic is an open, Large Language Model focused on enterprise use cases. Things like instruction following SQL generation, we're at the top of all industry benchmarks. And it's open. It's licensed under Apache 2.0 and we provide cotemplates and other things for customers to use. That's been fantastic and it's available not only in cortex, which is our own AI offering, but also on other model gardens, including for the folks here at Build, most importantly, Arctic Model Catalog. >> I'm smashing benchmarks, good news, I love open source. That's great news. And I also know you have new news from today. >> Yes. So just this morning, we had another big announcement at Microsoft, and that is regarding how fabric one can interoperate with Snowflake using the Apache format. This provides for interoperability in data exchange between fabric and Snowflake so you don't have to go through the costs and otherwise manage for data silos. When you enact access through Microsoft 365, data and Snowflake, so great costization, great collaboration, super happy to partner with Microsoft. >> I'm so glad we got the latest. Thank you so much for joining me. >> Great. Thank you. >> We're back, Build stage, best stage. I'm here with two of the most famous people at this conference. Because they were part of the biggest news of the day. Will you please introduce yourselves and what you're doing here at Build. >> Of course. We are world champion of the Imagine Cup 2024 this year. [applause] >> That deserves a round of applause. Everyone is clapping for you. Okay, you're the world champions. Please tell everyone who you are. >> Actually, I'm the founder and CEO of from Your Eyes, and it ir mobile application developers. We have an amount I company we trained our own custom AI model in order to customize and localize the video image processing. Also we use -- we have solutions, the first one is API for developers and -- in order to give them the -- and also the second one is a -- in order to make -- and the third one is the mobile application, it is -- access the descriptions with AI. >> Okay. So what is so interesting about your project is that you actually use this. >> Yeah. >> You're not building this for some random group of people. You live this every single day. >> Yeah. Actually I think the most important thing is our story, rs our goal. I was born with limited sight so I learned how to see on the computer screen, which means I was 4 years old, after this I lost my vision, and I started to use artificial vision solution in order to get descriptions. And I realized we couldn't get -- with my -- in order to close the gap -- >> I love that. So you're creating augmented vision. You're creating augmented vision, which is amazing. Because you're not just doing this for -- with you tend in the U.S. to build products that work well in the U.S. But you're building something that works where you live in Turkey. And because it's going to work there, if it works in the U.S. it's going to work in many, many parts of the world. And I think that's very special about your solution. Because we can't just have people in the U.S. building solutions, right? We need people like you from all over the world who speak different languages, who have different backgrounds, culturally experiences to be able to do this. >> Exactly. Yes. >> So now you went up on stage in front of 4,000 of your friends, won a ginormous trophy. How do you feel? >> Actually, it's kind of feeling that -- for example, we feel we need to, for example, keep all of the -- build great networks with -- from this good community. We're proud of our team, and also we believe that we will attain much more than this because we know our vision is more than vision, actually. >> I love that. Our vision is more than vision. Ooh! Okay, that seems like a little road map hint. What's next for you all? What are you going to do? >> We have three next steps. The first one is that we are in the investment rounds, so we have to close this investment, and the operation, and the -- at the second half of this year, we are going to launch our processing. Image processing. Before doing this we had to gather our team, and we need to get this required funding. >> Okay. So step one investment, step two, refine the model, add functionality, step three, investment again. Because that's unfortunately things cost money. Nice things cost money. >> Yeah. >> I love that, because you've already got a plan, and when you came in you already had a detailed plan, and you've fought customers. What I think is interesting, do you want to share who your customers are? It's a big deal. >> Of course. Actually, especially on the vehicle vision part, we have special customers. The first domestic car of Turkey, which is TOGG as well as our customers, because -- we start with two -- operating system of the vehicles, and to reach out to -- in order to assist the drivers and passengers in case of virtual assistance. And also St. biggest -- one of our partners, we integrate our API to the mobile application in order to make sure that fully accessibility for the visually impaired people. For example, finding the right exit, passport control or shopping. There are so many cases. >> Do you think you would use this app to navigate the airport by yourself? >> Yes. Of course, actually. >> She's like, obviously, how do you think I got here, fool? Thank you. I appreciate that. All right. So Imagine Cup 2025 is now open for business. What is your advice to next year's applicants? Next year's students? >> Actually, they just need to trust themselves, and build, imagine, and live, and actually Imagine Cup is here to support them. >> Look at that call to action. So clear. Have a vision, build the thing, and really lean into the Imagine Cup community. The team, the program, to help you. Thank you so much for joining us. And thank you two. >> Thank you. >> Welcome back to the Microsoft Build stage. Question are in full swing in day one, and our previous interview, they are so cool, the Imagine Cup participants, and the winners. >> The winners, what they're doing is incredible. I'm blown away the tech is so impressive, and I love them. >> And they already have customers. >> I know! >> How cool? >> Very, very proud. Very, very cool to see. So we've got a bunch of stuff coming up. We are going to be learning about the latest from Microsoft Copilot studio, that's something we've got going on. Because this is the Copilot show, basically. And so you definitely want to stay tuned for that. What else do we have going on that I know you're excited to see? >> If you're interested in a career boost, I know we all could use a little bit of juice sometimes, you can do the applied skills on Microsoft Learn to really get that level up you need. I think it's really encouraging, I've had the pleasure of talking to the Microsoft Learn team today, it's been so rewarding. And they're also really great people who just invest so much energy into really learning the landscape. >> And what's really great about Microsoft Learn is that they update the stuff all the time. So if you're looking to get upskilled especially when we talk about AI, the Microsoft Learn resources genuinely are fantastic. They're some of the best. And especially as we get more into the LLM space, it's a really good place for people who might not have a lot of background, but want to do that upskill. So take that challenge for sure. >> It's not just for students. It's for people of all skill sets, and especially if you're like an expert in one area, but want to do the beginner content in another. >> That's the thing. Well, we've got more next, but first we're going to kick it on over to Joey. >> Hey, thanks. Man, I miss her. So earlier this morning I was sitting there watching the keynote with Satya, and he talks about this thing called WebNN. And I went, self, what is a WebNN? I thought to myself, hey, let's bring my good friend and Intel fellow HMoh to the Build stage to talk about WebNN. Welcome, Moh. Thank you for joining us. [applause] Okay. I need details. Talk to me more. The keynote whet my whistle. >> All right. So I am super excited to be announcing here at Build the availability of WebNN for Dev preview. A very powerful API that is going to bring AI to the web platform. And all devices, and on all browsers, taking full advantage of hardware capabilities of AI PC. >> Okay. Ready, now. >> All right. So today between 60-65% of the time people are on PC, they are actually on the web. Duh. >> That's me, all day. >> Video streaming, video entertainment, education, search, and all the applications that are there. Bringing AI everywhere means bringing every AI to the web platform. In fact, with age of AI PC has begun the device, the IPC is best suited for running a lot of those experience under device. The way it is done right now, it's through the ma sick of a URL, you go to the cloud, and you execute your insurance in the cloud, but the device is capable of doing that. But with latency, less cost, why do you have to pay service when your device is capable of doing that? Much less overall energy consume, and better privacy protection. So with AI PC, the Intel Core Ultrahas three engines, CPU, MPU, and GPU, each having its own sweet spot. If you want to do something quick, turn around, light lightweight -- if you -- GPU might be the best choice. And if you want sustained power efficient, AI experience, MPU might be the best choice. This complex system to program that by web developers, they need an API. And it is my privilege to be announcing today with Microsoft the preview availability Dev preview availability of WebNN. Standard API across all devices, operating system, and fully capable of taking advantage of hardware capabilities. It is intrinsically supporting the heterogeneous execution engine of the system, PC, it is already integrated in the most popular machine learning frameworks like onyx run time web. It's one of the back end execution providers. And it delivers near native execution characteristics. Near native performance, near native power. You will see the results now. More importantly, its methodology is general, and it supports computational graph. So any model can be translated to WebNN, bringing your own model. That is WebNN. >> Okay. I want to ask you, how big of a deal is on device web AI, and in particular, WebNN? >> It is absolutely transformational. Now the developer for the fist time doesn't have to worry about the back end service. The application itself is equipped with with the software to run on the AI PC, delivering AI experience with near native performance. I think with 17 million web developers, we will see a surge of web applications that are designed with AI integrated in them from scratch. So it is an API, standard web API, it can be used directly by the developer, it can be used as part of a framework, use onnix run time web. Then it runs on WebNN and takes advantage of hardware capabilities. It can be used inside the browser, outside the browser, the implementation takes care of that running that efficiently mapping it to the hardware platform that the system is running on. It's a JavaScript API, any machine learning model can be translated to that. Its performance is near native. By that we mean above 80% of native performance. Here you see across 15 WebNN models, it is about 93% performance of native, through WebNN with all those additional advantages, cross platform, open API, et cetera on GPU, here you see across these 26 models, above 83% performance of native delivered by WebNN. And on NPU, the same. About 80% of performance of native delivered by WebNN. sohere is a website hosted by Microsoft, I high he encourage everybody to explore this excite can AI experience. It gives you a glimpse of the more exciting web is that is going to come very, very soon. So now here I'm going to show you a number of these demos. Basically the idea is you click on a point in an image and you want that part of it get segmented for you. Here we government WebNN provider of run time web, running on the Edge browser. You click anywhere, and that part gets segmented. 30 mill I seconds, 40 milliseconds. Why do you not want this and you want to go to the cloud to execute that? 40 mill I seconds. One simple example that you saw that here. Now I will show you stable diffusion. Here through a prompt We ask the system to generate a picture of a cat. You get different cats. Blue eyes covered by snow and here you see in three seconds the images are created. In fact, it is faster than three second, it is less than two second. Because the individual Joe being recorded on the same machine that is generation is happening. It's two seconds to get. That and here you basically see a different generation of state and diffusion on this demo. And you can by booth and play with. That anything you want. Next I will show you NPO execution. We will show you object detection in live camera running on NP U. In that demo we show a phone that is having a movie to the camera laptop. More than hundred string per second running on MP U. You see utilization high. GPU utilization high because GPU is capturing the media screen and MPS doing the object detection. This is AI at its best. It's delivering this experience, each part of the system is executing what it's good at and you get basically this experience. As mentioned before MPU is designed for sustained AI experience power efficient AI experience. Next I'm going to show you a demo of MPU running. It was great to see Kevin Scott and basically the C.E.O. keynote. As a collaboration with Khan academy and Microsoft we have proof of concept demo of speech to text done on IPC using WebNN. Today teaching assistant for students for teachers and for parents. You can interact with the system through speech. You record your speech. You submit. It goes in the cloud. Goes to the cloud. It gets translated and sent back. This is a proof of concept that the same experience you can actually do it better latency on a P C. Here I stay quiet and speech detect is under device. To make you confident it's happening on the device with wifi. You see without network it is delivering the same experience. >> Let's debate if this is necessary or should be banned. >> I'll take the side that homework is necessary. It's like the extra practice you do in sports. That is some of the dome mows that we have and there are a lot more at the website. >> I want to point out that second part of that demo if you saw it, completely disconnected. Everything is happening there. And it was so fast. The response was so fast. >> The speed of speech detects on this demo is three times faster than speech itself. So it is perfectly real time speech detection on device on AI PC. >> Three times faster. >> And I talk fast. >> Faster. It's faster. >> I have to ask this. Is WebNN an intel only thing. Is this an intel Microsoft technology, what are we talk about here? >> WebNN is an emerging web API stand up AP I. It is open AI for all devices, all browsers, inside browser, outside browser using web technology. It was initiated by intel and Microsoft. They are the editors of this but since vexer two of WebNN we are great participation from other industry leaders, google, hugging face and many others. It is an industry coalition to bringing AI to the web. In the spirit of observe web platform, like video on the web. I think it is much more transformational than video on the web. It can be an essential part of everything, not just video, every experience on the web can now become intelligent. >> Can you talk a little bit about other web for AI. What about machine learning? >> There are other APIs there for execution on CPU, web GPU is for execution on GP U. WebNN is the one and only AP that I mean to can target all these hardware execution provider, vpu, gpu and mpu. It's the only general purpose for AI that can target MP U. We have spent a lot of time with Microsoft w google on ensuring the efficient interplay between these APIs. So all those can be used. Depending on the model, depending on the context, different execution can be the better target for that. API, WebNN is just unified web API and supports all the platforms. I encourage everybody to try it. Please join us in defining it, shaping it the future. Visit our booth and make sure tomorrow you attend the breakout session by Microsoft and we'll talk more about WebNN. And also please go to our labs. >> Real quick when is WebNN going to be available? >> WebNN is already available for dev preview. Download the right edge dev channel and chrome dev channel. You can experience that. You have any question please contact us, please contact me myself directly and I'll help you get started. This is the beginning of an exciting time. >> Thank you very much. If you at home want to learn more about WebNN and intel, visit our features partnered page on the Microsoft.com website. We're back with more build after this. >> Thank you so much Joey. I miss you too. Great stuff. >> We have some really cool stuff coming up. >> We do. >> What are we talking about? >> We have more feature partners. You can check them out in the feature partner directory and more from the Microsoft surface team. >> I love hearing you talk about the toys and the consumer lek trining goodies, are you excited? >> I'm super excited and I'm really excited to find out about how they were able to build the next generation of AI features into the hardware. It's all over the place. It's not just AI in our software, it's also in our hardware and that's the best. >> It's like a full story on where we're putting this Copilot from AI and all of our different tools. And we are talking to a lot of developers so there are reasons why this Microsoft surface can be helpful for developers as well. >> We'll be back after this. >> Welcome back everyone. I'm joined by Tommie who is a developer advocate and support engineer for the lead tools SD K. How are you doing? >> Great. >> I'm fabulous. We're midway through build day one which is exciting but makes me tired. What are you going to be talking about today? >> I'm going to walk through our technologies, what we offer, show you guys a brief glimpse at the demo we're going into more tomorrow. That's about it. This is actually my second Build conference. But it's my first time being on the stage. Super excited to be here and share the awesome ways that our sdks handle document processing. >> What a way to level up on trip number two. Can you tell us about the sdk, where leads tools came from and how it stands out amongst its peers? >> We're based out of Charlotte, North Carolina. We've been around for 34 years. The original idea for the sdk started with a pant for an image algorithm in 1981. Since then we've been expanding to get to where we are today being a world leader in image document recognition and sdks. >> What are some of the unique parts of lead tools? Why should somebody consider using lead tools? >> A big point I like to make is most of the technology is offered is cloud focused. We sell libraries. So we sell dlls which means we don't require an internet connection or any cloud connectivity. Super important for banking and medical industries to protect their customer and patient data. That's one of the biggest things that sets us apart is ability to not require the cloud. >> The cloud is cool but not every scenario benefits from the cloud sometimes. It's cool that you are leading in that department. >> Exactly. >> Sweet. So it sounds like you offer a lot of different components and features. Can you explain a little bit more about some of the highlights? >> Absolutely. So we're on our website here. This is just the main page lead tools.com if anybody is interested, feel free to check it out. You can see we cover a lot of features. It's a broad sdk. It's hard to find some things sometimes. So I describe it as being a need until a hey stack. We cover everything from document image processing to optical and intelligent character recognition as well as forms recognition and we can read bar codes, we can scan invoice, passports, ID, we have a full multimedia sweet for play back capture and version controls and a medical suite for viewing x-rays, mri, all that patient data. A lot of cool stuff. From there I think where I come in is I'm on our support team so I help develop alongside the customers using our sdk. I'm there to help them explain how to use it, to find documentation resource like I said that needle in the hey stack feeling is where I come in and make that less stressful for our customers. >> Sweet. So I know you said tomorrow you are going to be doing a longer demo session. Can you tease what people can check out tomorrow? >> Absolutely. We'll open up our document viewer demo. If we give it a second to load. This is our java script document viewer. We're going to do a quick work flow and open up a portfolio statement so we can see now this is open. This has all kinds of fake juicy information on it. Account numbers, Social Security numbers, all type of data we don't want to get out in the world. What we're going to do is use the lead tools document analyzer and we're going to apply a rule set and what we're going to do is say we want to look for all of that PI, find it and redact it. When we hit apply and commit. Under the hood that is using machine learning and pattern matching to find all that sensitive data we were talking about. You'll see our final document comes out perfectly redacted and ready to go wherever it needs to go next in its work flow. Just a teaser. >> I could use that personally. I just had to do some redacting in a statement I was sharing with somebody. That's great. Sorry Billy Bob. Cool. So since you talk with customers, you probably have talked with a lot of them about some of their current frustrations and how to make things better, what is up next? >> I think the biggest thing is bridging the gap between the technology and the end user. That's kind of like I said, my personal goal is to make that developer experience as streamlined and painless as possible. Continuing to move forward, create great technologies, give them to our customers and have somebody that can show you how to use it. >> Thank you so much. And drop by your booth definitely. >> FP53. See you guys tomorrow for a demo. >> Cool. Thanks y'all. >> Welcome to the hottest party at Build. The Build stage. If you are not here come up here because you are missing out on a good time. Speaking of a good time, I'm with my very good friend and I know I say that about everyone but this is actually true. She acknowledges knowing me in public. Please tell us about you and your product Copilot studio. >> So yes, I'm the principle group product manager for Copilot studio. I recently transitioned. I used to lead the product design team. Transitioning over to the product side of the house has been awesome. And just have an incredible team. And I am so excited about all of the announcements that we're making this week. We've been working really hard. So a little bit about Copilot studio, it really has two main opportunities for what you can build and customize in Copilot studio. So the first is really building that fully customizable Copilot that you can deploy externally on your website or teams or any sort of social media channel. We have a number of channels available. All locoed. >> All locoed by the way. >> Actually we do now embrace the fusion team. We know that developers and nontechnical makers work together. We have gone a long way to not only democraties conversational AI but do it in a way that supports building how you want to build. How are you comfortable, how do you want to collaborate with your team. And we've also done a great job, I'm a little biased. But we've done a great job in fusing generative AI at every single step. So if you are like all in and you want to go full you know gen AI and not have any rule based topics, great, you do it. If you are a little apprehensive and you want to have a hybrid approach, we give you the ability to benefit from some of the generative capabilities right there in topics and do a great job there. I love the products so I could talk for a while. I know we have a limited amount of time. The other one I want to mention because I think a lot of folks saw this in some of the keynotes is the ability to extend first party Microsoft Copilot with Copilot studio. That is so important because you are now able to give Copilot Microsoft Copilot access to your proprietary data and enable it to handle common scenarios for your organization that out of the box it wouldn't be able to do. >> It's the number one question I get. Which is how do I Copilot my own data. >> A lot is this real time data source and I say do you have an api, if you do new business. You can do something about it now. >> Absolutely. What I like is you are taking a product you've been teaching people to use for about a year since ignite. >> Since ignite I do have to give a little nod. >> By theway, these shoes, we were talk about it before. Look at these shoes. These are amazing. >> Homemade. >> She made them herself. >> I did give a nod with my predecessor to Copilot studio. We've really been in this space for the last six years watching the evolution not only of AI but also building, conversational experience in the industry. >> I love that because you are building on something that you've been working on for so long. >> It's my baby. >> It's literally my third baby. >> After her real human children at home. But conversational experiences, Copilot Studio and now we have Copilot connectors. Tell me about this. >> Yes. >> I'm so excited about Copilot connectors, there is a couple of reasons why. From a personal perspective this is begin myself and my team the opportunity to work with some really incredible people across the organization. But what it means to you all within the audience is now previously you only will the power platform connectors which over 1300 plus I think now is the number. There is a lot of option. But you didn't have access to the graph connectors. And so net, net. The TLDR is now you have all of the ways you can connect to your data and leverage the information there or complete actions right there in one place. And so we are we have taken a step to introduce a fully customizable, manageable, extensible knowledge experience where you can really tap into the data that you have. Further saving you time of manually authoring topics to be able to handle scenarios. >> What I like about how you've done this is you are trying to reduce complexity for devs and makers. One thing we love to do at Microsoft is we love to give people 17 ways to do something. >> We really like to do that. >> We love options. You should have all the options. And the booths on the show floor are full of stations situated to help people walk through their many options. I like you are trying to reduce complexity and say companies don't want 17 options. They want to know the recommended way to do this one thing. I want to build a conversational experience, I want to plug into these three data sources, Kendra teach me how. >> We're trying to be that single starting point, entry point. If you want to build a Copilot start here. If you hit a cliff and want to go fully pro code, we have tons of integration opportunities to really empower any maker to build the way they want to. And at the end of the day that is really what has been a powerful kind of principle as we think about what features to build, how do we introduce them, where do they live in the product. And we're really trying to think about who is the persona, who is the person that wants to use this feature. I'm really excited. We are reducing, reducing, reducing complexity. And yeah, the new UI is beautiful. I'm so proud of my team. >> Just a conversational way to build it. I thought that was very Meta. Conversational UX to build a conversational experience. That was wild. >> Meta, Meta. >> Inceptioning. >> About three years ago we did this I don't know pie in the sky exercise. And this Meta idea using a bot to build abbot or a Copilot. And I'm like oh my gosh. Three years later we're here. >> I remember this conversation. We were talking about it two or three years ago right after pandemic. Why isn't it easier to build this thing. Every rule if I say this do. That that's a pain. I don't like. That you all have been trying to make it simpler but this is the simplest way to get going fast. >> We want to make it powerful, expensable, innovative. And safe. >> Speaking of, responsible AI. Big topic in the use right now in general. And you all do think a lot about responsible AI. Tell us about the principles you put into place. >> Absolutely. >> Truly I can say that the principles and the processes that we go through is why I work at Microsoft. It's why I'm proud to be building this product here in this company. Because I think it's a differentiator. We go through rigorous reviews with legal. We do rigorous reviews with sensitive use to really find of this feature are there vulnerabilities there that we need to mitigate, that we need to look at. We do a concept called red teaming where we do a number, large number of tests. Both manual and automation. I'm looking at one of my PMs. He's like yes. >> Say it louder. >> So we go through these processes to make sure that there is no harmful content being surfaced. >> I like the content -- >> They make it really simple. You choose do you want high moderation, medium, low. >> I like that you can go as broad as you want or narrow, nitpicky as you want. I'm nitpick can I. The start person may not be as nitpick can I until they test it so I like that you give the option. >> I think it's super important to my VP, he does a great job of prioritizing like we want to be at the forefront. We want to be innovative and cutting edge but we need to do it in a safe and secure way. So we're announcing a number of security features that I am so excited for. I know we're almost out of time but I'll give a little nod to you are going to have safer defaults and we're going to alert you in the product if any of these defaults have been changed. So an example is Copilot is now out of the box require authentication. Which is huge. >> I like that. >> Safety, security big deal. >> Safety, security, big deal. We're also now out of the box when you are having your data grounded in a SharePoint, we are adhering to the security policies and settings. >> Within SharePoint which I love. >> When you get an answer back, we're only returning information to you that you have access to. >> I like. That because it comes from that authentication at that time beginning. >> We adhere to the security trimming. >> People have been waiting for. This thank you. I just learned this right now by the way. This is awesome. >> This is big. We have the ability to set your authentication for various automation to your end user. >> Only access you have. >> Instead of the maker which has been huge and a must requested feature. Last but not least we have this now in preview but it's going general availability. It's a game changer for admins to have a fully audit log. >> We're getting hollered at. >> I'm sorry. >> Try Copilot studio today. Over to you. >> Thank you so much Donna. And those shoes are reduce complexity. I want them immediately. >> We're supposed to be talking about how great Copilot stud Joe. More stuff about that in the session scheduler. I want to talk about the shoes. >> Yeah. I want some immediately. >> Especially for.net that would be cool. You know what sells cool. Microsoft learn. Really great place to level up in your skills whether that is an existing skill that you have or you want to learn something new like something in the realm of AI and more, you can do it. You can earn badges. Show them off to your friends. Post them on LinkedIn. Honestly the AI content is good on Microsoft learn. Highly recommend if you are trying to get into that area. Really recommend. They have stuff about GitHub as well. If you are into the best Copilot, GitHub Copilot, check out Microsoft learn. >> I have to agree with that GitHub Copilot is the best one. Learn D.O.T. Microsoft.com is the place to be for all of your skilling needs. Up first we're going to be talking about skilling even more this time with how Microsoft applied skills can open doors. >> Yeah. And how is your build going so far? >> It's been a minute. I thought you were going to be Joey for a second. >> Not quite. It's kind of refreshing. My build has been going great. A lot of exciting announcements. >> It's been going great but we're ready to go to Don who is going to talk to us more about applied learning with Microsoft Learn. >> I'm so excited to be joined we senior director of worldwide product management of Microsoft's worldwide learning. I'm so excited to be chatting with you today. Tell us a little bit more about what we're going to get into. >> First, let me say the excitement and energy at Build is awesome. Thanks for having me. We're going to talk about Microsoft applied skills. Excited about that and love to go deeper on it. >> The way that AI has permeated every facet of our industry, every corner has necessitated individuals and teams to up skill. Your team is expert on technical up skilling and you provided some opportunities for people to get credentials and then earn them. Can you tell us more about that? >> We're excited about Microsoft applied skills. We launched them at ignite last November. What they are is aver final credential focused on validating skills on real world scenarios. In this skills based economy that we are living in, it allows learners to really show case and put their skills center stage and allows them to demonstrate what they can bring to the market and within their company on the key strategic projects. And for organizational leaders, by having a Microsoft verified credential, they can have the trust in the credential itself as they recruit and look for talent in the marketplace. It helps them identify the right talent for these most critical projects particularly in the world of AI and emerging technology. >> And earning those things; how do people go about that? >> The process is simple. In order to earn a credential, the learner effectively completes online on demand assessment that requires them to complete a number of tasks in an interactive lab experience which is exciting. And that experience is available to everybody. And so it makes it very accessible and flexible to earn in whichever way you'd like. It's really cool. >> On the surface level, I'm seeing so many benefits. You are really in this field, you are the expert on it, can you tell me more about what are the benefits people are finding from the credentials? >> From a learner's perspective it comes down to having the confidence that they need to executed. If you are someone within a company, you want to have the confidence to be able to execute on the key projects within that organization. And you want to be able to prove that you have those skills. So this applied skills allows you to prove anytime a different way than historically done so that is exciting. For organizations it provides a number of benefits. One it allows organizations to identify the right talent in a different way. Whether that be within their existing employee base or looking for new talent outside of their company. It allows them to get more targeted around the skills they need and what they are looking for. It allows them to bring products to market faster. And allows them to retain and up skill their talent because now employees feel like they are being invested in. They are getting the skills that are most in demand in the market. So they feel great about. That and they are able to have impact within the most important thing within the company particularly in AI and emerging cloud. >> That's key. I love. That. >> And so it's been out since ignite and that means you've had a little bit of time to get feedback. What have you been hearing? >> Overwhelmingly the feedback has been positive from learners. They are excited about potential to boost their career and keep pace with technology in an on demand flexible way. And organizations love the focus on real world scenarios. And so we've heard a lot from them it's helping they are applying it and seeing the benefits in terms of employee productivity and skill development in their organization. We've heard great feedback around the flexibility and accessibility of it and creating a sense of equity amongst all people that learners. >> I love. That and I love the idea and the through line that you kind of highlighted that people are able to really take matters in their own hands, organization, team leads can take matters into their own hands to up skill their teams where they need. I'd love to know more. The audience I'm sure would love to know more, how can they learn more, how can they follow up on the advice you are giving. >> Being that AI front and center, a big part of our strategy for this is AI and their credential strategy. So we have a portfolio credentials across all the solution areas with almost half of the credentials focused on AI specifically. We launched three new credentials today at Build that are AI focused which is exciting. And there is more to come from that perspective. And in terms of learning more, Microsoft learn is the go to resource. If go to the credentials page on Microsoft learn, that will tell you everything you need to know about credentials including certifications and Microsoft applied skills and how they are complementary and build on each other. >> Learn on Microsoft.com/credentials. It was great chatting with you. >> You too. It was awesome. >> Thank you so much. Skilling is such an important part at events like Microsoft build. I love to learn. I love to learn too. And I love how MS learn game miffiest it inner me because my motivation level takes a dip unless I see the XP or badge. >> I need a reason. I don't need a reason to learn. But if you give me a game, I'm going to go harder. I'm competitive. >> I know you are very competitive. >> I get super competitive. I have to collect all the badges now. >> You have to do it. >> It's really bad. I have to get all the trophies. I don't care how hard and miserable it's going to be. >> It's what we do. >> Coming up later this hour, I'm actually going to be doing the session on troubleshooting with Microsoft Copilot. And you can see Copilot detect, diagnosis, troubleshoot and optimize work in Azure. Hanna is going to do a live dem employee with us for that. >> Awesome. That is not going to be a teedous thing in comparison to being a completionist right. >> It's going to be one of those things I think the idea is instead of having to search around the Azure portal and figure out what you're trying to do and what is wrong, Copilot will tell you what is wrong and how to fix it. >> Thank goodness. >> The Azure additions make me so excited because I get lost on the Azure portal no matter what. Streamline it for me please. So first before we get to that though. We're going to be talking with technical fellow Steve who is standing by. He leads the AI team and windows and is responsible for MPU accelerating models, recall and cocreator that you probably heard about a little yesterday. That is coming up in just a couple of minutes. We have a new poll for you so check this out. We want to get to know you in the chat. We want to know how many Microsoft learn challenges have you completed? Are you a completionist? Your options are A., none but I'm excited to do my first. B., a hand full, I know the ropes. C, five at most I'm a veteran participant. Or D, none but tell me more about this. >> Tough choices. >> You are five or more. >> You get to my level of 50. >> Check that out more at Microsoft Build digital venue for more information. >> Thank you for coming. I'm Steve. I'm a technical fellow in the windows and devices organization. And we are changing the way people use computers through Copilot plus P C. Little bit about what interaction technology is. It's enabling two way flow of information through an interface between the computer and the person. And that can be transduced mechanically, electrically or allegory rhythmically. It was not that long ago this was the interaction technology for computers. It was a punch card. This piece of card represents 80 characters or one line of code. And a stack of them was a program. It's crazy. This was not long ago. Like talking about in the 70's and 60's. And to actually compile your program was quite an or deal. You had to write it. Take it to the punch card puncher. They had to coalesce it, bring it to the computer, get the printout. Finally at the end of the steps you realize you made one syntax error and the thing didn't compile. That was how we used computers not too long ago. If you look at all the different computing form factors in our time, they all had this pattern. This pattern was when you had a step function increase of compute ability, a write software that changed how we can interact with the computer, abstracting the functionality of the PC itself and that enabled us to build new types of computers. You see this pattern repeated over and over again all the way from mechanical computing to vacuum tube to microprocessor to when GPUs came to GUI and the mobile and now cloud. And today the big thing that happened with the step function and compute is processing unit. You see this pattern repeated over and over again. With MPUs this is a massive leap in compute availability at the edge. And the reason is newer processing units are really specific for the computation behind neural networks. They are basically accelerators, if you think of CPUs generally as great for scaler, GPU is great for vector. MS built to handle tensors from the entire silicon architecture to the software stack is about managing this data type. It gives us a tremendous amount of efficiency as a result of it. Here is comparing cloud GPUs in terms of total tops but the efficiency of tops to what? Total operations per second. Miles per gallon and top speed. The things that are happening inside of Copilot plus PC is extraordinary. This is a log scale graph so you can see in the snap dragon X series a leap, a jump in performance. It's also a jump in performance and efficiency and that is really remarkable. That is going to allow us to do a bunch of things. Here is a workload my team did. So this is an MPU running the same workload on the GPU and CP U. You can see how fast it is. But it's not just fast. It's very, very efficient. If you compare it to the amount of processing power required to do that speed on a core i7 you need 20 core i7les. That would cost a lot of money and also that would take a lot of power. Or even on a GPU it would take a couple of hundred Watts and a lot love money. Newer processing unit integrated into the sock it's fractions of a dollar -- fractions of the cost of the CPU and under four Watts what you see in the Copilot+PCs. That's good. The thing we know is the great ter model, the greater capacity it has to work across these different domains, smaller models have less capacity, larger mod versus more capacity. And when you have more a larger model you have a lot of compute you have to handle. And you can kind of see what is interesting happened in the AI field is at a certain size, you get these kind of emergent operations happening, the model leaps in itself ability to do pretty magical things. And we call that the sparks of intelligence. Right now we like it around 2 billion parameters. The cool thing that has happened with our devices especially Copilot plus PC is that we have kind of crossed that threshold. So now our devices can run these types of models locally, on the device to do amazing things and that is what is really cool. That allows us to do a whole bunch of neat things with interaction technology. The mouse and point and click has been the paradigm for a long time for us and how we use computers. With AI we're going to go from being programmatic to piloted. We're going from exact to being fuzzy. From explicit to implicit. We're going to go from commanding to asking. And that is going to change how people use computers. This amount of compute allows to us do these low latency transform, these neural networks built into the operating system in a performn't manner so we can do better privacy and work offline. It's the underpinnings behind our banner feature called recall. And the way we built recall was having models run consistently in the background to detect your region, to OCR, do imagining coding, text encoding and natural parser all running in the background without burning up your battery life. A tremendous amount of compute so you can help remember what you have seen, the stuff you have seen and go back. So this is really kind of the underpinnings that enabled recall to happen. And it allows us to create on the fly a vector database that allows you to very quakily and easily search the things that are on your machine just like the things you are able to search on the internet. It's in fact the same sort of database technology that we use in the cloud that powers bing is running here locally on your Copilot PC device. It's pretty incredible. And this allows us the combination of the step function and compute with the new interaction technology you saw yesterday with recall, cocreate and a whole bunch more coming, you allow this to build a new category of PC. This is really the next PC and serve all in in making it happen. It's super exciting. It's got a certain minimum bar to actually run all these experiences which is great for our customers. And it can do some pretty amazing things. This is a demo we've never shown before. This is the first time I'm showing this. We're running all the 40 models simultaneously on the device. You see image creator generating images on the fly on the device. We started silica which is a small language mod that will approaches GPT3.5 abilities and the NPU screaming on the top right-hand corner in the resource task manager. All the while this is happening, in fact I have studio effects running in the background. So the things like denoiser, blur, background segmentation is literally happening in the back. The thing I want you to pay attention to on the bottom, there is no workload on the GP U. What does this mean? By the end of this demo while I'm running this entire workload, I can run a game and that is awesome. That's the type of power that sits in these Copilot plus PCs. This is a laptop for crying out loud doing this workload. It's pretty incredible. [applause] . >> That's awesome. Thank you. This wouldn't be a developer talk without developer slide. This is my developer slide. So what is really neat is these are the things as adore you can access on the device. We have win sdk where you can use small language model on the times ocr that runs fast on the device with multiple languages. You have the ability to use live translation in your applications as well writing into the vector index you have so you can enrich it even more. Then there is a whole bunch of really neat windows core audio APIs for beam forming, noise suppression, etc. It's a high quality audio pipeline built into all the of the Copilot PC devices to help person to person and person to machine communication. And finally we have studio effects that you can use and integrate into your application the experiences such as back segmentation, teleappropriate and framing. That's the call to action. Use these experiences, buy these devices and make magic happen. Thank you so much. [applause] . >> Thank you for a great conversation. And if you just woke up from like a two hour cat nap or food coma you had from all the food you are having at home or in person, welcome back today one of Microsoft Build coverage. We're on the Microsoft Build stage or adjacent to it right now. Close it to. Close to all the action. >> We've been watching a lot of cool stuff. Demo, presentations. We had just a great conversation with our technical fellow. That was awesome. >> Lots of great interviews. And just latest greatest stuff making headlines as we speak. >> Check out the book of news. There is a lot of news. What are some things you've been excited to hear about? >> My goodness. GitHub work spaces I think is really cool. >> It's amazing that end to end experience. 100 percent. I've been really excited about the AI studio and the tool kit. It includes AZD which is the Azure developer CLI and there is a story with visual studio code which I love. My favorite technology. >> My favorite addition to the Copilot family is Microsoft Copilot for Azure. Part of the extensibilities story. >> All of these agent capabilities. So now when you have this huge well of responses that can come back, you get to put yourself in the seat of your user and narrow that scope to the functionality that you really want. I really love they are putting the tools in the developers and the teams and agent's hands so you get a better experience for your end user. >> One more. All the cloud native application folks, people who need to write them and don't want to run into the problems that can arise with cloud native applications. Shameless plug. >> I'm so excited. We're going to cut to Christina live with our colleagues at oracle. Over to you. >> Thank you so much. Azure and oracle two, greats together. To talk about this I'm here with Erin and the SVP Orlando Cal cloud train. >> It's great to be here. >> Super happy to have you here. Let's talk about the partnership. >> It's exciting. Our partnership really brings Azure's robust cloud capabilities together with oracle databases and applications. Every customer journey to the cloud is different. This flexibility allows customers to choose their own solution for their own unique journey. By bringing hardware into the Azure data center we're bringing the application together, those latency barriers that happen wean the database and application are broken. By deploying in two Azure zones, we have the zone resiliency that supports the mission critical applications and workloads that are powered by oracle databases at Azure. It's really exciting that we are streamlining and simplifying that integration through the migration tools that handle the migration and certify solutions like data guard or golden gate or zero down time that bring them the oracle workloads. >> She said it perfectly I think. Fust r customers have been asking for this for a while. This relationship is perfect. The same customers that use oracle stack are on Azure. They wanted the same experience they've had their developers use Azure for a long time. They want to be able to use Oracle tech with the same guarantees, mission critical capabilities that the database brings. You can get that through Azure. You can log in and launch an autonomous database and it's going to be available in all the regions. >> When can people expect this to be available? >> We're generally available in north America and Europe in our primary and secondary zones. >> We just launched today. That brings our tote toll five regions. We have a couplele in U.S., west and east. We have Frankfort, London and now France. So throughout the year what you are going to see is Microsoft and Oracle work together to expand the capability set and expand the number of regions for high availability and in country D R. Lots of government customers, public sector customers and mission critical workloads in financial services require that resiliency and high availability. We're super excited. By tend of summer we'll have dozensover regions that will be amazing. >> I'm looking forward to that. Where can people go to learn more about this? >> You can sign up to Azure and start launching computers now. If you have reps you can talk to them. We often our customers are also Azure customers the ability to bring in a lot of the capability to bring in to Azure. If you have a support contact with oracle you can apply that to your Azure spend into your oracle support. All the capabilities will move over. It's seamless for them. It's as simple as going to the Azure portal and launching a database. >> If you are here on site I'm headed over to the cloud platform community booth. Please come by and have a conversation. >> If you are here on site check out Erin. She'll be at the booth and you can go to the feature partner directory to get more information and go to Azure portal. Look for Oracle and click something. Thank you so much both of you. Appreciate you being here. >> Thank you. It's great to be here. [Music playing] [Music playing] >> Thanks for catching up wit Oracle. Where can people learn about more feature partners. >> They can learn more about the feature partner directory. Check out lead tools. Now if you are interested in learning more about using Microsoft Copilot in your everyday development which chances are you are. >>> Keep it here because coming up we're going to be show casings Microsoft Copilot in action developing for Microsoft Azure. Microsoft build you are part of a global community. We're going to Donna for more. >> All right we're back on the build stage. The best place at that time conference. I say that effort. This time I mean it because I have these beautiful people doing something useful. Now they are going to do something more use can feel is explain themselves to us. >> How are you doing? >> You used the microphone. >> Yes. >> You are the founder of the global AI community. That's a big deal. Please explain to everybody what that is. >> The global AI community is a worldwide community is over the hundred thousand members. And consist in how many countries are there? Almost 100 countries. And we organize events which reach 250,000 people this last quarter with over 100 participating. It's a great place to be. And global communities leading to connect all these communities together to do great things. >> I love it. Where do you get these two beautiful people? >> These two people are part of the global AI community and I invited them to here to tell their story about the global AI community and how they are connecting and what they are doing. So. >> We've been doing this for I think now for 7 years. So that's a lot of boot camps, a lot of conferences. It's a rewarding time when people come to you and say you jump started this AI journey for me and helped me get started. That's very cool. And just last week we had AI community day which organized which was kind of a different format. We got together 14 communities local communities in the Netherlands for topics around AI. We had over 200 entities, 20 speakers and it was so much fun. >> Just getting these groups together and learning from each other and meeting new groups. Amazing journey. >> That's a lot of people. You trying to AI everyone in the Netherlands? >> Everyone wants AI. >> That's a scheme. Look at this shenanigans you did. I like that. Good. Tell me. >> So as a good segue, you have this huge communities of communities. I'm a small community so I started a community about two years ago called the south Florida generative AI user group. I was an early tester on Copilot during COVID. I was like we should get people together to talk about. This and there was about 12 people in the group. And they were mostly my friends relatives. However it started to grow Chat GPT dame out. People got very excited. We grew really fast. But I was running it and I don't know how to build content. I don't know what to teach. I have lots of ideas and I'm excited to teach but this is when I met hank and the work he's doing. They have this workshop anyway box that we use. We've done it twice. And it allows everyone. One of the mice things about my community it is super inclusive. It's not just ethnically inclusive and gender inclusive. But we had ten-year-olds talking about robots in mine craft. 65-year-olds talking about how they were using Copilot in their work. It was inspiring for everyone who joined I. couldn't have done it without being attached to a bigger community that gave me all the tools I needed. >> Other than the friends and family you reared to join your community, how did you grow that community. Is it just people got excited about AI and they are like look up this thing? How did they find you? >> This is a great question. One of the most important things we did that you did with the blown community is attach it to meet up. The meet up. I was already in meet up. So people were finding me organically. People interested in social immediate y I started to tell every single person I knew and their family to join in AI for everyone type of community. And that's how we grew it. Went to almost 350 members which is good for someone who is not trying to do that. >> That's a lot of people in south Florida >> . >> Yes. >> That's amazing. >> So I see what you are doing. You are doing the everybody and their actual mother meet up groups. That's cute. I like that. So how do you feel about this? What is your plan for world domination what you are doing other than the world domination part? >> That has gone quite well. We're going to give more accessible content for everyone. So that everyone there is not an expert on AI can organize one of these events. And let everyone do a workshop. >> Yes. >> Or let's play with Chat GPT and those kind of things. >> You know there is a little resource called Copilot learning hub that might be useful for. This I think it's so important those of us who do create content figure out a way to do this workshop anyway box thing so it can scale for others. Do you have a call to action. >> Yes learn more about global AI community and how you can join. >> Go join your global AI community today. 195 countries. Do the thing. >> Thank you so much Don. That and do the thing indeed. I love that talk about community. And one way to find community here at Microsoft Build is the attendee directory. So you can use it to find people with similar interests, you can make a connection, make friends. I've made friends so far. You? >> I've made so many friends. That was an excellent segue. I love talking about community and the friends that I've made are in the directory. And if I wanted to I could put those friends in my backpack. >> Yes do it. >> Speaking of directory, we've had so many feature partners we've been able to talk about. You can check them out in the feature partner directory. And the things we've been chatting about we're going to continue chatting about. Stay here. >> Don't go anywhere. >> You might be able to go and handle your business. But then come back OK. Because we'll be talking about news, all the things that they are offering us in person and online. It's going to be great. >> We have great demos coming up and in just a couple of minutes we're going to see the AI developer tool kit with we've. We're going toless Lee right now. >> I'm joined by Alex who is an AI evangelist. >> How are you doing? >> Good. >> I know you have a lot of cool content to share so I'm going to let you have at it. >> Awesome. Hey, everyone. I'm Alex. I'm here to talk to you about iterating on your power applications using Weave. You can read the code and deploy a fix in real time. LLMs building in production tends to give you results and they are a black box. How do you deploy something on production you don't know what it's going to do ahead of time. We call this experimentation. This is something we build great tools for for a long time. You try stuff that works. And how these models will answer in production. Then it's important as you iterate a lot to track everything that you do. If you don't you will get lost and won't know what is going on. And as you build those you have to build those you have to have robust tools to be able to inspect individual examples. To be able to dive in to specific user case and look what the users did and what they talk with the model and what the model answered. It's important to measure progress. Measure progress to know whether or not you are doing great and how do you measure progress of something that doesn't have a right or wrong answer. Sometimes LLMs just respond with a lot of text. When there is no right or wrong answer we do metrics. Instead of testing we do evaluations. Here is an example. You build few questions. This is example from our chats that we built LLM tool for. We have a bunch of questions. For each question we asked our LLM to generate a responsible we add a score. The score can be a hugen generated score or use another LLM for a judge. Six years ago started with a realization that AI developers need new tooling. Back then they used sheets to track all their machine learning experiments while software developers had cool tools like. This we started with this idea that machine learning engineers and developers need new tooling. It was done well. Nerve most foundational model build LLMs, they adopted weights and biases tooling for observability. Companies like Microsoft, met taxer open AI. They all track millions of runs across hundreds of thousands of metrics and some metrics go with millions of data points as well. We know a thing or two about building robust tools. Now including companies like open AI users to give you tools that you probably use every day with Chat GPT. Now we bring this observability, expertise in tool building to you the AI developer. We're introducing Weave. It's for the LLM tracking evaluating in production. First of all like I said before you have to trace everything. We have traced things a simple way for to you do that in weave. One line of code. You have that function with weave decorator and we'll track and trace everything So you don't have to introduce any abstractions or different tools. It's simple. Just one line of code and you get this out of the box. Then we do evaluations for weave as well. Simply in this example you have a data set like I said before questions and answers. And then do you scoring or grading functions programmatic or LLM as a judge. You run evaluation and it looks like this. Let me show you a live demo. This is a demo dashboard of an open source project we introduce called open U. I. You can see the developer ran these evaluation. Each evaluation had a lot of stuff in there so you can dive in and see that we call them open AI model here and it gave us images as well. You can go into evaluation and look at scoring. In this case you see he scored this response with a value of three, contrast is one. This gives you ability to understand what is going on production and change your product in according to how you users use this. We build this for AI developer. I hope you get to use this. Please simple to get started. Install weave. >> That was cool to see weave as an accessory is really cool. I love seeing simple clean lines like. That if you'd like to learn more check out the weights an biases booth that is at the expo hall. Otherwise check out ak dot ms slash weights and biases which is written on the screen behind me. Thank you so much Alex and thanks y'all. >> All right. We're back. Questions for you all what has been your favorite dev tool announcement today? >> I'm going to give a shoutout and say.net aspire. >> Tell me about that. >> It's like the next generation of.net for building cloud native apps and it's really exciting. >> I'm excited you said this. You should hang out for 30 more minutes for reasons. >> For reasons. So hang on. That also keep plugged in. We got plenty more sessions coming up including in a couple of moments Donna is going to be with our feature partner and this is all about generative AI platforms across various industries. We're going to Don right now. >> I'm so excited to be here with Peru. We're going to talk about deep dives into AI and we're going to have a demo. Tell me more. >> Hello. I'm here to present a six-year-old startup. We've been building generative AI apps and platform for the enterprises. I'm going to start with customer demo and the customer demo is coming from the auto insurance industry. They've been our customers for last one year. And the challenge they had was they found out through research if the claim processing doesn't go well the customers are likely to change. They wanted to make sure that the claim processing really happens smoothly for the customers. So I'm going to give you the quick demo and Tech TC then we can just jump into what we do and how we solved that problem. >> That's a cool use case. I'm going to pepper in a few questions I'm sure. >> This is John who is a customer who is an end user. And he had an accident. And he wants to file a claim. So he came to the bot which the insurance company has on their mobile app. He's going to basically file a claim for it. And when he's filing the claim it's going to upload some pictures. This is where the model comes into the play. It's basically going to automatically understand the pictures of the car. His car, the other passenger car. Identifying all the details. And all of this being done automatically just by looking at that time pictures. >> With all of this happening automatically, there is this thing I've heard in the news. There is hallucinations happening with AI basend  to context, there may be things you weren't expecting, how do you reduce hallucinations in this? >> Great question. The way they've done is building this specific LL M. That's one of the ways you can reduce the hallucination. Once you have an understanding of a given domain, say in this case an insurance domain, you can understand what the users are asking. Having the user context like know who the use series coming from, that helps you reduce the hallucinations. >> Interesting. That's so cool. You are giving tools in the hand of the users on how to implement. But sometimes these things are about security on remember can help that. Can you use this on prem. >> We support the Copilot into three environments. You can run your own VPC environment, ux run in our cloud. We run in Azure and you can run on prem as well. You have flexibility to run wherever you want to run. >> It shows the demo is going. There is so much they are interacting with with this insurance Copilot. I'm so thrilled that you were able to bring that to us. This is in the marketplace. How can we get a free trial? >> So we are listed on the Microsoft marketplace, Azure marketplace. And actually you can come and do a trial with us. And start using Copilot. >> I love free. That's a good ad. Thanks for the demo. I love those. So what are people going to be able to do. Ever where do they go for more? >> You should always go to try demo. You can get the demo and go from there. >> Cool. I love that so much. So let's keep chatting a little more about what we saw in the demo or things you know that people will enjoy about arks serks ra. >> The key things is we offer AI Copilots for enterprises systems. If you look at any enterprise it has applications. And that is why we really shine. The second is domain specific LLMs. AsWe have more than 25LLMs out f the box. That's where I.P shines. >> I want to make sure everyone visits the url below me to check out more. Get your free trial. Thanks so much for joining us. Give a hand clap for the demo. I love a demo. >> We love demos too. You know what we're missing? Lots of stuff. So much content. >> There are so many sessions I want to see. We're missing many sessions. >> If you are in our boat, be sure to check out the digital backpack. You can throw in everything but the kitchen sink. >> You can probably add the kitchen sink if you want to. >> On the website did you notice there is a Copilot? >> I didn't know that. >> There is. There is a Copilot so you can look stuff up. You can say what is the summary of this session and you'll get what was in the session. >> Amazing. That's so clever. >> Do you know what the team did? They got a transcript of the session, used it to RAG the Copilot and they are able to get a real time rendition of what was in the session. >> In addition check out the scheduler as well. To get all of your sessions where you need them in that backpack. Now we're going over to Christina who is going to talk about troubleshooting. >> Yes it is very exciting. Thank you so much. We're going to be talking about troubleshooting with Copilot in Azure. I'm joined by a product manager at Microsoft. Thank you so much for being here. >> Thank you for inviting me. >> If you are a developer like many of us are, you might wonder how can you utilize Copilot to help diagnosis, troubleshoot,s optimize your work in Azure? You are going to answer this question for us. >> Exactly. >> First set the stage for me. What is Copilot for Azure? I'm going to be honest we have so many Copilots I don't know what all of them are. Give me background. What is Copilot for Azure. >> We have integrated Copilot into the Azure portal. And with that you are able to learn how to deploy resources, optimize your cost, learn to troubleshoot and a couple of other features as well. Essentially what we want to do is make it easier for to you access the things that you want to access on Azure and answer those kind of questions. >> And this launched last year? >> Yeah, we launched it last year. >> There are new capabilities? >>> Correct. >> What are the new capabilities you want to talk about? >>> I'm excited about that. Last fall we did troubleshooting experiences. But for the spring we're excited that we were able to create a troubleshooting experience where we could guide you through the process. >> I'll jump despite. >> Show me. >> Right now imagine you have a healthy resource and people are able to get to the home page. People are able to get to the rating page. Can't get to this counter page. This is realistic. Usually everything is running smoothly and all of a sudden it breaks. >> And so then you are flooded with a bunch of questions from your manager, from customers. Where should you be looking, even yourself, what is the root cause, do I know how to solve this. And it's a very stressful overwhelming frustrating experience. >> How do we solve that? >> Exactly. So we were thinking what if you could start with Copilot. If we run that back, what if you could just type my web app is slow and then Copilot could do some of that heavy lifting like understanding what you are asking of it and actually pull in diagnostics, maybe information from the web. Azure docs and format that in a way that is meaningful and helpful. That is what we're seeing here. It's  and below that it's showing some possible solutions that we could take advantage of. So we could enable CPU monitoring, the UWP thing I'd like to highlight is that you're always in control. So nothing happens automatically. >> Nice. >> And you're able to get to whatever you want. So now we're taking a look at the web app tool, and this is a wonderful page. Our team of product groups and support engineers have helped cultivate, curate this experience, and on n page we'll show diagnostics relevant to this type of issue. So I would like to pause here and show that I highlighted that this diagnostics set might be because of the application code. And actually, for this scenario, this was in fact manufactured. So I didn't put in infinite loop, and hence the high CPU usage. >> That's why. >> Right. >> Awesome. So you can see that right there. Now, what if I need a little bit more context about the information that I'm seeing? >> Exactly. That's a good question. Oh, I guess one last thing, this experience, I just wanted to highlight the difference between the Copilot experience versus the traditional. You can go to the diagnose and solve blade but if you're not aware of that -- >> If you don't know where it is, I didn't know it existed, and I worked on Azure for years. If you're not sure where to go, this is a great way to highlight that. >> Yeah. >> But if I want more context, what can I do? >> Let's jump into that. We have a summarization experience, so if you type in give me a summary of this page, when you're on the web app page, it can give you a breakdown of the top root causes and their respective solutions. You can also ask it for a further breakdown for a specific diagnostic on this page. >> That's really cool. I like that. Not only is it going to give you forks but you need more information about, that okay, we're going to break it down so you know where to go and what to do. >> Exactly. >> So what other types of prompts should we maybe be trying out in Copilot and Azure? >> That's a good question. For this initial release, we kind of have five main categories. There are certain trouble-shooting scenarios we honed on in, if your web app is down, slow, if you're running into high CPU issues, if you are running into latency issues, outside of that, we also make it easier to find some of the tools that can help you through this process. So if you need to take a memory dump, if you want to enable auto heal, if you want to see your event logs, you can use these prompts, and then we also allow you to be proactive. Before there is an issue, getting a sense of what are the risks for your application, the best practices, making it future proof, and the summarization and explanation, you kind of have seen it earlier. >> I like that. Let's focus on that proactive part. I think that's interesting. If I'm understanding correctly, you can say, hey, Copilot, look at my app and tell me, is there anything I need to optimize? >> Exactly. Yeah. So we've actually built an experience where you can see these are the areas of opportunity to do better, so that your application remains as healthy as long as possible. >> That's great. That's really cool. I really, really like this. Can you give us hints about what might be coming up in the future? >> Sure. So if you want to take advantage of this experience, it will be live in about two weeks. The full trouble-shooting experience. The summarization and explanation experience is you actually live right now. And it's available on any diagnose and solve page and any research that has that experience. I'm excited for it, for everything else we'll be releasing in Azure and Copilot system. >> Fantastic. Where can people go to learn more? >> Feel free to visit us at the booth. We have a bunch of experts who are answering questions. Please take a look at our documentation that has a full comprehensive list of what we're able to do in Azure Copilot ecosystem. And just sign up if you're also interested, but I think we're making it available for most people. >> This will be available for basically everybody in the portal, some is already available now. Visit Hannah and her team at the booth, get questions answered. Thank you so much. This is really cool. >> Thank you. >> Okay. Those were some dang good prompts. Those were amazing prompts! To this day, I've been trying to figure out the best ways to use Azure Copilot and I've come up with five ways but those were 20 ways. I screen shotted that slide and I'm going to tweet that. Letting you know. Those were very good slides. >> Did you know there were more demos tomorrow with Copilot? >> No one told me this. You didn't tell me. >> You need an updated schedule. >> There's Copilot demos I don't know about? You know who I'm going to take this up with? Jeremy a. I'm calling can you out on air. Mechanics is a YouTube show where you go deep into the tech stack of how things work. It's not marketing, it's not here are some features, it's how does it actually work? They did a fantastic individual Yankee on how Microsoft 365 Copilot works. So you type in the prompt, then it goes to the LLM, them you go to the graph to figure out what is in that graph, is it one Drive for business, SharePoint, is it Exchange? Then coming out of the graph, you combine with the prompt what's it called, a response using the graph data as the RAG, then it passes through responsible AI, filters out any nonsense, then it shows up with the user. >> I learned that from a mechanics video. Each step of the way, there has to be more. I can't believe it. >> Yes. So that -- that's mechanics. You should -- if any of you haven't, you should binge watch the play list because you're going to learn more about Microsoft tech stack and how things work. >> But we're going to Leslie to talk about new Alec. >> Thank you. I'm joined by Jemiah Sius, who is a senior director of product management at New Relic. How are you doing? >> I'm super excited to be here. >> Welcome to Build number two. >> My second time. >> Great. What are we talking about today? LLMs I'm guessing. >> We're going to talk about solving some of the problems that software engineers are going to face as they're exploring AI application and developing LLMs. >> Great. AI applications are becoming ever more present and that usually involves integrating an LLM into the app. So what are some of the roadblocks that people can run into? >> I think with -- we should all be aware with every advancement in technology, the move from monolith I can apps, distributed services, migrating to the cloud from on prem, even moving into streaming apps, everything comes with new challenges. And that's where we're also going to see with AI applications. Thinking about the differences in between developing the two different applications. So AI apps are dealing with more latency, slower response times, things like that. So some of the challenges that developers really need to be thinking about is one, how to properly scale those applications, so making sure they have the right infrastructure in place to understand what's what's going on within their systems. How to address some of the issues with latency, understanding that from the user request into the LLM, into the data babess, you're going to be dealing with user experience at that point. Our users aren't necessarily thinking about, this request is taking a long time because there's so much more happening on the back end. They just want an answer. More importantly, they want it right, the right answer, and now. And that's also another challenge we face, making sure the answers are accurate and you have the right information going back to users, because if not, then you deal with trust issues, and you have one shot before they move on to another tool. And there's so many tools. So those are some of the key things that software engineers are facing as we move further into the exploration of AI and the power that it truly brings to our lives. >> That makes sense. I know accuracy is a big deal for me. Is this right? So how can developers effectively address latency and performance issues, and also scalability when it comes to integrating those LLMs into the AI base applications? >> There's a few things. It's a mixture of following current best practices, also advancing your tool set. And then building in just core processes into the way that you're doing things. On an accuracy side, you want to be trying to provide the best response possible. So it's identifying gaps inside of your training models, to be able to provide additional context using things like RAG, right, so making sure that you can close those gaps and get rid of the possibility of hallucinations. But then also you want to be pruning your dataset on a regular basis, and that's going to help with the latency in the back and forth, starting to reduce that time. So it's thinking about the information that you're training your model on. And then, observability comes into play with understanding all of the other things. From scalability standpoint, you want to make sure your architecture is strong enough to provide the computational power needed, and that you understand what's going on there. Observability is going to give you insight if your end-to-end traces, and then you want to also be looking at things like cost management, understanding how many tokens am I spending on this request, or how are we managing costs, should we be using pay for, you negotiation LLMs, should we be training our own models? So those are some of the things they should be thinking about to solve some of the challenges. And it's really a mixture of everything above in order to provide the right need for your particular use case. >> Cool. I know we're running low on time, but do you have a quick demo you could show us? >> I can show you what some of this looks like within the New Relic platform. >> Sweet. >> So just to give a brief overview, like the landscape of all of the services through reporting data, I can see applications, hosts, things that are instrument with agents, but I want to go into a specific service just a sample AI app, where I'm building a chat service. And this is going to give me a view of all my requests that have come in within the last 24 hours, but I can go deeper directly into the AI request, looking at my total response, the amount of time it's taking, whether it's going up or down, my token usage, it's going to allow me to manage costs, but I can actually look at the different requests and then start to find any ones that had errors that I want to actually dive into the question I was asked, all the different steps that it took to get through this transaction, and I can expand it so it's not only the AI -- so I can absentee my entire stack within here. And so the platform makes it easy to then identify issues that you may have had. So I can see there's an error, and quickly get into kind of the error details, or go into the logs for this particular application that's going to make it really easy for me toe find the information I need to make decisions around what's happening, what's causing my users trouble, how can I possibly reduce token usage and manage costs. So we make it simple to see all of that within one space with the rest of your entire stack being shown as well. And it's all in context. >> Cool. That is awesome. I love seeing the centralized dashboard. If you want to learn more about New Relic and the work they're doing to alleviate the troubles of integrate thing LLMs, check out aka.ms/Build24fp/-- that's right behind me. Thank you. >> And come over to our booth if you have questions. That will be easier. >> Check out the booth too. >> Thank you so much. >> Thank you. >> I have no idea there's so many ways to integrate an LLM into an app. >> Have you checked out the New Relic booth yet? I'm over there next. >> Let's go right now. >> Okay. No, we gotta a couple things to say. >> Have you seen all the MVPs? I love MVPs. >> I love the MVPs. It's another part of our community that's integral, just like our featured partners. We get cool insights and conversations from them, they are under NDA, they get all the cool tips and tricks and features, and they're like part of our feedback loop on, like, really vetting the first-level alpha versions of our products. >> Exactly. Also what's interesting is that MVPs are generally customer facing, so they go out there and teach people how to use Microsoft products all the time. It's like, that is their job. So when they come to us with feedback, we know it just doesn't represent one person's opinion, the opinion of millions of people that they support. Dear MVPs, we love you. Thank you for coming here and supporting us. >> Thank you for being a subject matter expert on all the cool things we get to put out. I appreciate it! >> When we were talking about the cold front booths I always said can we have MVPs do at least one person per shift? Because they're going to have insight for what customers want that us product team nerds will never have. >> Yeah. I've been in the other side of scheduling some of those meetings internally with our external, let's call them family. I love them. They get to be part of that kind of work that we do. And we get to teach them, and all of that. It's been really great. >> I love it. Awesome. >> Next we're going to be talking with some muchs with Christina, we'll be talking with eve party and Priyanka Shaw. >> Thank you so much. As promised I am here with two of our MVPs, and how are you both doing? >> Thank you. We are great. >> Yes. >> We are very excited to be here. >> This is your first Microsoft Build? >> Exactly. This is my first time. >> You've been here before? >> Yes. I was here before. My second time if I'm not wrong. >> Fantastic. And both of you -- eve, you focused on advanced analytics and you lead the AI practice? >> That's right. >> So I want to ask both of you, because it's been really busy day one, it feels like day fowrks because there's been so much new stuff. I know we've been -- you guys have been busy talking with customers, and seeing all kinds of things. But what is the one announcement at Microsoft Build you're most excited about? >> Is it really just one I need to name? >> Right? Right? >> But if I really need to name only one, I would say the Copilot agents. And I'm so excited about that, because in the past few years I have been working a lot with agent and multiagencies items, for work and school, and now these new Copilot integrations and everything, it feels like it is helping me so much in my everyday work as well as my studies. So I'm really excited about hearing more about that. >> I love it. What are you studying? >> I am studying at the University of Liverpool, and master's of AI. >> Fantastic. Fantastic. I love that. What about you? What -- of all the announcements what has you most excited? >> There were a bunch of announcements which I'm excited about, but if I had to pick one or two, that would be around small language models. >> Yeah. >> It's extremely exciting to see Phi-3, 53 version going live, and do see that tremendous spot of small language models being able to do multimodal tasks, and handle vision alongside text. That's one announcement I'm extremely excited about, and the second one being realtime intelligence in preview in fabric, which is like in the moment decision making for your data, which is at the realtime high-density, highly granular data decisions for -- as a SAS offering for local developers. These are two things. >> I love that. What I like about that, both of those things meet different levels of developers and customers. >> Absolutely. >> Because the small language models are great for people wanting to run things on device, and you can get a lot of power, customize things, keep things on prem without having to worry about where it's going. But the other solution is great for people, I need that realtime information. About what my data is. And making that available. That's really -- I have to think that's really exciting for potential customers. >> Yes, that's right. Bearing in mind the scalability and cost options, go-to-market options, I think some of these announcements are extremely make sense for a lot of diverse customer landscaping we have out there. >> And what do you find, when you talk with customers and when you see people, what are they excited about? And what's been changing, this next -- in your studies and your work? >> I think what I can see nowadays is first of all, responsible AI always hold topic everywhere, and the other thing is that AI can be integrated into everything, and mostly the Copilot what I can see as a thing for clients that they want to have Copilot in everywhere. >> That's exciting. And yet -- I imagine you see similar things, you hear similar things from -- when you're working with clients in your AI practice? >> Absolutely. One of the other things, they are all talking about -- and customers also in the booths are asking about the GitHub Copilot in Azure. So -- which is like again, in private preview, but nonetheless it's a promise you can create applications using an LLP and deploy it on an Azure cloud using VS Code and Visual Studio. That's a very, very big announcement for the developer community. >> Thank you for mentioning GitHub Copilot. I appreciate that. >> One more thing I have seen that is coming into very, very hot topic is automation. And using the integrated services. So the multimodal and DevOps and all that. >> That's really exciting. We're going to have more stuff. If you Dwan to learn more about the MVP program so you can hear more, go online. Thank you so much for joining me. >> Thank you so much. >> Thank you guys. >> Bye bye. >> I love when MVPs do segments with us. We have such interesting insight that I do not have. Your MVPs are good. >> I gotta say, shout out to all the .NET MVPs and the visual CEO MVPs. They're awesome, they're doings some really cool stuff with the products we build and they're helping evangelize them for even more people to take advantage of them for all their development needs. That's really exciting. MVPs are doing a lot of great work behind the scenes. >> MVPs are the real MVP. >> For real. >> Here's a question. Is it true that Aspire was cocreated with feedback from muchs? >> It was, actually. Very much created from a lot of feedback from MVPs, over the years and as we started to build it from scratch. Yeah. It was very community driven. To the point it's still community driven. It's all open source, anyone can get involved and make it better. >> I love that. >> I love it too. I get excited. >> I have a deep dive in a little bit on Aspire and I'm excited about it, because it's going to help me dot things I hate doing as a Dev, like dashboards and measuring. >> Yeah. >> It lets me do the coding part. >> You don't want to miss them, they're a lot of fun. They think they're not a lot of fun, but I think they're fun. >> Should I terrorize them a little bit? >> Sure, maybe just to keep them on their toes. >> That sounds reasonable. >> But first we're going to talk about Qualcomm, so here's -- oh, well, we're not. >> I'm not handing back off to Christina. >> No. >> What's been your favorite announcement today? >> GitHub work spaces has been my favorite. >> That was mine too. >> That is so cool. I love the end-to-end, from planning to product. Basically. That is so wild. And how it integrates with your traditional GitHub experience that you're probably used to. That's super exciting. >> I really like it for projects where you don't actually know how to start or how to end. >> It's great for brainstorming, here, I got you. So now we can talk about Qualcomm. >> Christina, please take it away. >> Thank you so much. I'm super excited, I'm joined by the -- I think you have the coolest job, you're the head of AI and ML product management at Qualcomm. You guys have announced amazing stuff in the last couple days. Talk to me about the new Snapdragon, the X elite platform. >> Snapdragon X Elite platform is built for AI, it's the most intelligent, efficient, and powerful processor ever built for Windows environment. It has got an integrated hexagon Rupp, the custom Orion CPUs, powerful GPUs, all of this lays the foundation for some of the most innovative and influential AI experiences we launched this morning. Some of them being the base recall, our transformer and convolution-based language translation, transcript, which supports 40 plus different languages. Image cocreator which even makes my 65-year-old mom a content createor. We also have this mapped up with a Qualcomm stack that pushes for performance and scalability. >> I love it. It's really good. That's so impressive. You were just mentioning some of those demos that you got at Build, can you give me a quick overview of what some of the demos you're showing off are? >> For the last 12 to 18 months, the Qualcomm AI team has been working with solution providers, ISVs, equal system partners and also with Microsoft OS teams to build some interesting and immersive experiences. Really I urge your audience to pay a visit on Qualcomm booth, where you'll be seeing an interesting set of experiences around DJ Pro and not to mention be the most coveted Copilot+ that only runs on Qualcomm on the Microsoft on the left-hand side. >> Can we take a look? >> Absolutely. >> Let's take a look at this. Yeah. >> This is a Qualcomm developer kit. And this really helps support a lot of platform innovation that really brings in a lot of developers to drive a lot of application in development. >> What's great about this, this can do so much. This is a small device, but you can run a lot of AI models and do a lot of building on it. >> Absolutely. The Copilot+ launched on Snapdragon X elite platforms which is what the developer kit is about. >> This is a great way for developers to bring their apps, make them better for AI as well as the latest platform. >> That's correct. >> That's cool. Can you tell me about the AI hub that Qualcomm has? >> Absolutely. AI Hub is a platform where in we are making sure that most -- we provide a platform wherein. Developers can optimize and deploy their model with ease. We actually started this journey in a mobile environment for Android OS, and we launched this in mobile world conin February. The team has done some fantastic job, wherein they've ordered the same experience on the Windows platforms to make sure we can drive innovation in Windows as well. >> That's awesome. And that's incredible, you had it on mobile in February, and now here we are in May and we've got it on Windows. I love it. So you want to learn more information about this, where can people go? >> I would really implore the audience to go online for plenty of information on that. >> Developer.qualcomm.com, you can stop by their booth and check out their demos and find out more on the partner directory. Thank you so much. >> Thanks for having me. >> Hello devs of Build. We're back on the live stage. And this time I have two of my favorite friends in the Dev space. We've got Garvin Glen from the .NET team, and they've brought something really cool and very interesting. Major announcements around this fancy new thing called .NET Aspire. Would you mind sharing what that is? >> Thank you for having us here. It's been so energetic to go meet people, talk to so many partners, customers, developers. So when we think about cloud native development, one of the things that we heard from a lot of developers was building cloud native applications is not easy. It is pretty complicated. So .NET Aspire is our stack that helps you build, distribute it, cloud ready, cloud native applications. >> Okay. What's very interesting about this, devs have a lot of choices, too many choices. So say I want to build a cloud native app. What stack do you use, what language do you use? Also, you have to measure cloudiness. Up time, down time, et cetera so how does Aspire tackle these challenges? That is the biggest issue being a Dev, it's not just writing the code, it's the shenanigans around it. >> I think it's even worse, I think, than what you described, which is not only is it picking a tech stack, but within the stack there's five ways of doing X and three ways of doing Y. And does X work with Y? I have no idea. As we were preparing for Aspiefer, that was a big thing people kept telling us. Within Aspire we have several pieces that make it up. One of them is components, Aspire components. The components are the idea of having a kind of aspect for what a good library for dependency should do. It should make sure you're doing logging properly, set up with Intel. So we've put beta -- baked it in, a whole set of defaults making your apps observable, giving you a set EF-optioning you know are good and work together, all that stuff. That's how we try to tackle that problem. >> I love that. >> Thanks, Glen. I think the thing I was about to add, you stack to a higher level, what you could think about, is today if you look at the cloud native landscape, developers have to pick and choose so many different components. They have to bring things together, they have to spend so much energy working on the infrastructure, thinking about how do we -- what we're trying to do is provide developers a set of tools and libraries that helps bring the peoples together for you. To have very quick onboarding. So that's the place where we are starting. But we want to also make sure that we are giving developers the flexibility to edit things. >> Okay. I like this. Because you're kind of -- you're giving them a get started today in a box, but enough that they're not trapped into it. So they can adjust and make changes as they want, based on the areas they care about. >> That's correct. >> I'll give you a real example where I want to use Aspire. I'm building a travel agent. Someone that books an agent that books my travel for me. Sounds great. What I don't want to do is deal with observability. What is the uptime of Azure at this moment? What is the resource allocation? So I want Aspire to do these things, but testability, I would want to micromanage because I want to make sure it's accessible, all these things. I feel you've built something so interesting, because it makes it easy for devs to get started, but still gives them all the freedom. Was that a goal when you first started building this? >> Absolutely. We had this set of principles early on, and one of them was developer first. >> I like that. >> Developer first and foremost. It was almost the core of everything we did. Because often in this space, ops is such a big concern, it leaks into all of the DevTools and all of the ecosystem, and what we set out to say was, okay, when I run my app, and it's -- I want to see a dashboard, I want to see the metrics, the things I need as a person sitting at the keyboard to figure out what's wrong. What I don't need is long-term monitoring, all of these things the ops people need. In fact I aggressively do not want to learn those things. >> Right. >> And that's what we were focusing on from the beginning. >> I love that did you said this. I love DevOps as much as the next person, but I am not a DevOps person and I don't want to be. And I don't want to learn ops when I'm supposed to be a developer. So apparently you brought some sort of video that shows all these dashboards and charts and graphs. >> We should run it. >> let's roll the video and take a look. >> Easier and more productive than ever. Whether it's a single project or an entire distributed system with all of its services and dependencies running together. Here I have a cash running in a container an API service and front end running on my local machine. Aspire orchestrates these together so I don't have to worry about spinning on multiple projects, it does it for me from a single . net project. The dashboard is a one-stop-shop, monitoring, and so much more, enabling me to inspect various states and status of my application. We enable health checks, teletri, resiliency automatically with our service defaults. We can see telemetry information is coming in, thanks to Aspire components. And traces are a good way to pinpoint performance, problems, or failures, especially when they span multiple processes and machines. Additionally, service discovery built in converts user friendly names into network addresses so we handle everything for you. When you're ready to publish, you can right-click publish and it will take your application, convert it to containers and publish it to Azure Container Apps or other places you want to deploy. >> Okay. So I love that. And I have terrible shiny object syndrome, as all of us. So .NET Aspire, I love it, I'm obsessed. How is this going to integrate with what I already use so my boss isn't, what are you thinking, introducing a new thing? >> Glen talked about one part around our principles, which is being developer centric and the other big piece in terms of thinking about the principles that we have applied, how can we make sure that developers can adopt the product that we are building? So we partnered -- whether you're transforming an existing .NET application into being cloud ready or building a new application, whether you are on Mac, on Linux, on Windows, you can apply it everywhere. Whether you are on Azure, AWS, or any other cloud, you can apply it. So for us, the biggest thing has been to give the choice to developers to meet where they are. And make sure that the technology we are building is really adoptable. >> I love how inclusive this is. I didn't know this worked integrated with AWS, et cetera. >> The folks from AWS committed the code for AWS to ca cap aspire. >> That's cool. Okay. That's new information. You know those companies, every company I guess, is multicloud. So they're going to be able to use this without it not just being for the Azure .NET code base, but for all of it. >> That's correct. >> Huh. That's very clever. Look at you all! I like that. You've thought about lots of things. So today's Build, what does the future look like? The next three, six months? >> November, every November, new version comes out. Put that in your calendar. That will be the next version of Aspire. And what we really want to do between now and then is it's not very long, but between now and November, there is a mass of feedback. We want to desperately hear and incorporate into what we then ship again in November as we figure out all of the things we need to work on going forward. >> Okay. So between now and November, you're doing a giant cocreating activity. You're saying people go try integrate into your viemplets, use it for real, not just for testing, give them feedback, because they're going to do the next rev based on your feedback. >> That is absolutely correct. We -- I think as we've been developing this, the basis of Aspire was learnings from a lot of Microsoft internal things we brought into the product, and now bringing to the community. And we really want to cocreate and cobuild with the community and get feedback. >> I love this story so much. This makes me so happy. Do you have homework for anyone? >> One thing from my side, if you are new, if you've not tried, go to aka.ms/aspire ga, that will give you the information to get started. So please go check it out and give us feedback. >> Do the thing. Thank you. Thank you. >> Thanks. [applause] >> Thank you, Dona. That was such a great interview. Shout out to the Aspire team for creating something awesome. I'm so excited it's GA. So yeah. That wraps up actually day one of Build. I think we ended on a pretty high note. >> It was great. A full day of stuff, but we have a demo from the Microsoft mechanics on stage tomorrow, so don't miss this, join us back here at the same place. >> Also we're going to have an interview with Microsoft leader Charles, plus we're also going to have Mark Radbourne on security day, we're going to be talking about security with Mark, who is going to be diving inside AI as it relates to security. >> That's inside the brand of Mark. >> So you don't want to miss any of it. It's going to be a fun-filled, secure, adventure that we're going to be having on day two tomorrow. So thank you all for watching, and see you all tomorrow! >> See you tomorrow! Bye, friends!