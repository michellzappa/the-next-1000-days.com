Patrick over to you all right thank you Graham um and uh and thank you Sam for being with us uh last year I actually interviewed uh Sam bankman freed which was uh which was clearly the wrong Sam to be interviewing so it says good to correct it you know this year with the right Sam uh so um so we'll start out with the topic on uh on everyone's mind uh so uh when will we all get our world coin uh I think if you're not in the US you can get one in a few weeks if you're in the US maybe never I don't know it depends how truly dedicated the US government is to Banning crypto uh is it World coin launched around a year ago or so it actually the the it has not actually it's been in beta for yeah maybe a year but it will go live relatively soon outside of the US and in the US you just won't be able to do it maybe ever I don't know all right um so which is a crazy thing to think about that like this is you know think whatever you want about crypto and the ups and downs but the fact that the US is the worst country in the world to have a crypto company in or you just can't offer it at all is sort of a big statement like historically big statement yes yes it is yeah it's hard to think of the last technology for which that was the case maybe like the Europeans are supposed to do this not us yeah supersonic air travel or something for like yeah then yeah um all right so uh I presume almost everyone in the audience is a chat GPT user uh what is your most common chat gbt use case like not when you're you know testing something just you actually want to get you know where chat gbt is purely a you know an instrumental tool for you summarization by far uh I I've gotten like I don't know how I would still keep I wouldn't still keep up with email uh and slack without it um but you know posting a bunch of email or slack messages into it hopefully will like build some better plugins for this over time but even doing it the manual way works pretty well uh have any plugins become part of your workflow yet browsing in the code interpreter once in a while but honestly they have not for me personally they have not yet kind of like tipped into a daily habit um so obviously um it seems very plausible that we're on a trend of um I don't know super linear you know realized returns in terms of the capabilities of these models but who knows maybe we'll asymptote soon that's likely but it's at least a possibility if we end up in the world where we ask them toad soon what do you think kind of x-posed we will you know look back on the reason as having been too little data not enough compute what's what's the most likely about the mic so so yeah look I really don't think it's going to happen but if it does I think it would be I think it'd be that there's something fundamental about our current architectures that limits us in a way that is not obvious today so like you know maybe we can never get the systems to be very robust and thus we can never get them to like reliably stay on track and reason and understand when they're making mistakes or you know and thus they can't really like figure out new knowledge very well at scale but I don't have any reason to believe that's the case and some people have made the case that we're now training on kind of order of all of the internet's tokens and you can't grow that you know another two orders of magnitude uh I guess you could counter with yeah but the synthetic data generation do you think data bottlenecks matter at all I I I think you just touched on it like is as long as you can get to like over this synthetic data Event Horizon where that the model's smart enough to make good synthetic data I think it should be all right we we will need new techniques for sure I don't want to like pretend otherwise in any way um but like naive plan of just like scale up a Transformer with pre-training tokens from the internet that will run out but like that's not the plan if um so one of the big breakthroughs in I guess uh GPD 3.5 uh and four is rhf uh um you know if you Sam uh personally SATs down and did oral all of the rlhf would the model be significantly smarter like does it matter who's giving the feedback uh I think we are getting to the phase where you really do want smart experts giving the feedback in certain areas to get the model to be as generally smart as possible so uh so will this create like a crazy um you know battle for the smartest grad students I think so I don't know how crazy you have a battle it'll be because there's like a lot of smart grad students in the world but smart grad students I think will be very important and how many how many like how should one think about the question of how many smart grad students one needs like is one enough or do you need like 10 000 it's we're studying this right now we we really don't know uh like how much leverage you can get out of one really smart person where kind of the model can help and the model can like do some of its own uh R Ellen like this is we're deeply interested in this but it's a very open question um should nuclear secrets be classified um probably yes I don't know how effective we've been there I think the reason that we have avoided nuclear disaster is not solely attributable to the fact that we classified the secrets but that we did something we did a number of smart things and we got lucky you know the like amount of energy needed at least for a long time was like huge and sort of required the power of Nations and we made the iaea which I think was a good decision on the whole and a whole bunch of other things too so like yeah I think probably anything you can do there to increase probability of a good outcome is worth doing classification of nuclear secrets probably helps um doesn't seem to make a lot of sense just not classify it on the other hand I don't think it'd be a complete solution what's the biggest lesson we should take from you know our experience with future non-proforation the broader sense as we think about you know all the AI safety considerations that are now Central so first of all I think it is always a mistake to draw too much inspiration from a previous technology every everybody wants the analogy everybody wants to say oh it's like this or it's like that or we did it like this so we're going to do it like that again and the shape of every technology is just different um however I think nuclear materials and AI supercomputers do have some similarities and this is a place where we can draw more than usual parallels and inspiration but I would caution people to to overlearn the lessons of the last thing um I think something like an iaea for AI like and I and I realize how naive this sounds and how difficult it is to do but getting a global regulatory agency that everybody everybody signs up for for extremely powerful AI Training Systems seems to me like a very important thing to do so I think that's like one lesson we could learn and if it's established you know it exists tomorrow what's the first thing it should do any systems over we the easiest way to implement this would be a compute threshold the best way to implement this would be a capabilities threshold but that's harder to measure any any system Cape over that threshold I think should submit to audits um full visibility to that organization be required to pass certain safety evals before releasing systems um that would be the first thing and yeah some people on the I don't know how one would characterize the side but um let's say the uh more pugilistic side I would say that all sounds great uh but uh but China is not going to do that uh and uh and therefore will just be handicapping ourselves uh and you know consequently it's a less good idea than it seems on the surface there are a lot of people who make incredibly strong statements about what China will or won't do that have like never been to China never spoken to in someone who has worked on diplomacy with China in the past uh really kind of know nothing about complex high stakes international relations I think it is obviously super hard but also I think no one wants to destroy the whole world and there is reason to at least try here so one of the things also I think there's like a bunch of unusual things about this is why it's dangerous to learn from any technological analogy of the past there's a bunch of unusual things here there's of course the energy signature and the amount of energy needed but there aren't that many people that are making the most capable gpus and you know you could require them all to put in some sort of monitoring thing that would say if you're talking to more than 10 000 other gpus like you got it whatever there's options yeah um so one of the big surprises for me this year uh has been the progress in the open source models uh and um it's been this kind of frenzy Pace the last 60 days or something um you know how good do you think the open source models will be in a year or say uh I got well actually I'll just ask that first yeah good I mean I think there's going to be two thrusts to the development here there will be the hyperscalers best closed Source models and there will be the progress of the open source Community makes and it'll be you know a few years behind or whatever a couple years behind maybe um but I think we're going to be in a world where there's very capable open source models and people use them for all sorts of things and and the creative power of the whole Community is going to impress all of us and then there will be the frontier of what people with the giant clusters can do and that will be fairly far ahead and I think that's good because we get more time to figure out how to deal with some of the scarier things David Luan made the case to me that um like the the set of economically useful activities um uh is a you know is it well is it Theory a subset of you know all possible activities uh and that pretty good models might be sufficient to address most of that first Set uh and so maybe the super large marbles will be very scientifically interesting and maybe you'll need them to do things like generate further AI progress or something but for most it's like practical day-to-day cases maybe an open source model will be sufficient How likely do you think that future is I think for many super economically valuable things yes these smaller open source model will be sufficient but you actually just touched on the one thing I would say which is like helpless invent super intelligence that's a pretty economically valuable activity so is like cure-all cancer or discover new physics or whatever else and that will happen with the the biggest models first should Facebook open source llama at this point probably um should should they adopt a strategy of open sourcing their Foundation models slash llms or just llama in particular uh I think Facebook's AI strategy has been like confused at best for some time but I think they're now getting really serious and they have extremely competent people and I expect a more cohesive strategy from them soon I think they'll be a surprising new Real Player here hmm um uh is there any new discovery that could be made that would meaningfully change your P Doom probability either by elevating it or by decreasing it um yeah I mean a lot like I think that's most of the new work between here and super intelligence will move that probability up or down okay is there anything you're particularly paying attention to any kind of contingent fact you'd love to know if we could so I first of all I don't think rlhf is the right long-term solution I don't think we can like rely on that I think it's helpful it certainly makes these models easier to use um but what you really want is to understand what's happening in the internals of the models and be able to align that you know say like exactly here is the circuit or the set of artificial neurons where something is happening and tweak that in a way that then gives a robust change to the performance of the model well that and then beyond like there's a whole bunch of things beyond that but but that direction if we can get that to reliably work uh I think everybody's P Doom would go down a lot and do you think sufficient interpretability work is happening no um why not you know a lot of people say the very word of AI safety so it seems you know superficially surprising most of the people who say they're really worried about AI safety just seem to spend their days on Twitter saying they really worried about AI safety or you know any number of other things uh there are people who are worried about very worried about AI safety and doing great technical work there um but we need a lot more of them we're certainly shifting a lot more effort inside a lot more like technical people inside open AI to work on that um but what the world needs is not more uh AI safety people who like post on Twitter and write long philosophical diatribes it needs more people who are like going to do the technical work to make these systems safe and reliably aligned and uh I think that's happening it'll be a combination of people that have that good ml researchers shifting their focus and new people coming into the field a lot of people on this call um are active philanthropists and most of them don't post very much on Twitter uh you know they hear this exchange like oh maybe I should help fund something in the interpretability space you know if they're having that thought you know what's the next step one strategy that I think has not happened enough is Grants like grants to single people or small groups of people that are very technical that want to push forward a technical solution um and are you know maybe in grad school or just out or in undergrad or whatever I think that is well worth trying they need access to fairly powerful models and opening eyes trying to like figure out programs to support independent alignment researchers uh but I think giving those people financial support is like a very good step to what degree in addition to being somewhat capital bottlenecked is The Field's skill bottleneck where there are people who maybe have the intrinsic characteristics required but don't have the I don't know four years or learn of learning or something like that that are also projected for their being effective I think if you have a smart person who has learned to do good research and has the right sort of mindset it only takes about six months to make them you know take a smart physics researcher and make them into a productive AI researcher um so we don't have enough talent in the field yet but it's coming soon we have a program at open AI that does exactly this and I'm astonished how well it works it seems that pretty soon we'll have um uh agents that you can converse with in very natural form low latency full duplex you can interrupt them like the whole thing um uh and obviously we're already seeing with things like character and replica that you know Pro even nascent products uh in this direction uh are getting you know pretty remarkable traction it seems to me that these are likely to be a huge deal and maybe we're substantially underestimating it um again especially once you can converse through voice um do you think that's right and then B if that's right um you know what are you what do you think the likely consequences are yeah I do think it's right for sure like I've you know I think someone said to me recently that I stuck at them is that they're pretty sure their kids are going to have more AI friends than human friends and I don't know what the consequences are going to be uh I one thing that I think is important is that we we establish a societal Norm soon that you know if you're talking to an AI or a human or sort of like weird AI assisted human situation um but people people seem to have a hard time kind of differentiating in their head even with these very early week systems like you know replica that you mentioned uh it's whatever the circuits in our brain are that crave social interactions seem satisfiable with like for some people in some cases with an AI friend is tricky someone recently told me that a freaking topic of discussion on the replicas I've read it is uh how to handle the emotional challenges and Trauma um of upgrades to the replica models uh because suddenly your friend becomes you know somewhat lobotomized or at least a somewhat different person and you know presumably these interlocutors all know that replica is in fact an AI but somehow to your point the uh sort of um uh our emotional response doesn't necessarily seem all that different what I think we're heading to is is a society like I think what most people assume that we're heading to is a society with one sort of Supreme Being super intelligence you know floating in the sky or whatever and I think what we're heading to which is sort of less scary but in some senses still as weird is a society that just has a lot of AIS integrated along with humans and yeah there's been movies about this for like a long time like there's like you know C-3PO or whatever you want in Star Wars like people know it's about AI it's still useful they still interact with it it's kind of like cute end person like although you you know it's not a person and in that world where we just have like a lot of AIS that are contributing to the societal infrastructure we all build up together that feels manageable uh and and less scary to me than the sort of single big super intelligence yeah yeah um well this is a financial event so um how will um you know how well this kind of debate in economics as to whether changes in the working age population uh push real interest rates up or down um because uh you know you have a whole bunch of countervailing effects and you know yeah they're more productive but you also need capital investment to kind of make them productive and and so forth um uh will how will AI change real interest rates I try not to make macro predictions I'll say I think they're gonna change a lot okay well uh if um how how will it change um uh uh measured economic growth uh I think it should lead to a massive increase in real economic growth and I presume we'll be able to measure that reasonably well and we'll we'll at least the early stages of that be a kind of an incredibly Capital intensive period because you know we now know which cancer curing factories um or you know Pharma companies we should build uh and you know what exactly the right you know reactor designs are and so forth I would take the other side of that again we don't know but I would say that like human capital allocation is so horrible that if we know exactly what to do even if it's expensive you mean like the present-day Capital allocation done by humans yeah or or or you mean uh like the allocation of the actual people themselves across Society into different roles uh no I meant the way that we allocate like like how much do you have an application done by humans Yeah by done by humans how much do you think we spend on cancer research today Cancer Research a year um I don't know probably well it depends if you have the Pharma companies but it's it's probably about like eightish nine billion from the NIH and then I don't know which the drug companies spend but I don't know probably some small bottle of that again but if it's like under 50 billion oh okay I was gonna I was gonna guess total guess between 50 and 100 billion per year um and if an AI could tell us exactly what to do and spend like 500 million dollars a year for one single project which would be huge for a single project but yeah it was the right answer yep that would be a great efficiency game yep okay so so so um we will actually become significantly more Capital efficient uh once uh once this technology that's my guess yeah interesting um for open AI uh you know obviously you guys want to be and are a preeminent research organization but you know with respect to commercialization is it more important to be a consumer company or an infrastructure company uh I I am a believer as a business strategy in platform plus killer app I think that's like worked for a bunch of businesses over time for good reason I think the fact that we're doing a consumer product is helping us make our platform much better um and I hope over time that we figure out how to like have the platform make the consumer app much better too so I think it's like a good cohesive strategy to do them to do them together um but as you pointed out really what we're about we'd like to be the best research org in the world and that is more important to us than any productization um and building the org that can make these repeated breakthroughs uh they don't all work you know we like went we've gone down some bad paths but we have figured out more than our fair share of the Paradigm shifts and I think we're have the next big ones we'll come from here too and and that's really kind of what is important to us to build which breakthrough are you most proud of openai having made um the whole GPT Paradigm I think like that was I think that was a kind of thing that has been transformative and an important contribution back to the world and comes from the sort of work the multiple kinds of work that open AI is good at combining if um Google I O is tomorrow I think or starts tomorrow and if you're a CEO of Google how would you do I think Google's doing a good job um I think they they they have had like quite a lot of focus and intensity recently and are really trying to figure out how to how they can move to really remake A lot of the company um for this this new technology so I've been I've been I've been impressed it um are these models and and their attention capabilities actually a threat to search or is that just a sort of you know superficial response that um is a bit too hasty um I suspect that they mean search is going to change in some big ways but not not a threat to the existence of search so I think it would be like a threat to Google if Google did nothing but Google is clearly not going to do nothing um how much important ml research comes out of China so sorry go ahead I would love to know the answer to that question like how much does it come out of China that we get to see not very much you say yes yes everything from the published literature non-zero but not a giant amount do you have any sense as to why because you know the like the Cardinal like the number of published papers is very large and for a lot of Chinese researchers in the U.S who do you know fantastic work uh and so why is the kind of per paper impact in the Chinese stuff relatively low I mean what a lot of people suspect is they're just not publishing the stuff that is most important do you think that's likely to be true I have I don't trust my intuitions here I just feel confused um would you prefer openai to um to you know figure out a 10x Improvement to training efficiency or to inference efficiency it's a good question um it sort of depends on how important synthetic data turns out to be uh uh I mean I guess if forced to choose I would choose inference efficiency but I think the right metric is to think about like all the compute that will ever be spent on a Model training plus all inference and try to optimize that right and and you say inference efficiency because that is likely the dominant term in that equation probably I mean if we're doing our jobs right um you know when gpd2 came out like only a very small number of people noticed um as sort of that had happened and you know really understood what it signified uh to your point about Imports of the Breakthrough um is there a gpt2 moment happening now um there's a lot of things we're working on that I think will be gpt2 like moments uh if they come together but nothing there's nothing like release that I could point to yet and with high confidence say this is the gpt2 of 2023. but I hope I hope by the end of this year by next year so that will change what's the um what's the best non-open ai ai product that you use uh honestly the only like product that I think of is like really I don't use a lot of things I kind of like have a very narrow view of the world but um chat gbt is the only AI product I use daily is there a uh is there any eye products that you wish existed and that you think the capability that our current capabilities made possible or will very soon make possible that you're looking forward to I would like a co-pilot like product that controls my entire computer so they can like look at my slack and my email and zoom and iMessages and my like massive to-do list documents and just like kind of do most of my work some kind of Siri plus plus sort of thing yeah yeah and you mentioned you know curing cancer uh is there an obvious application of these techniques and Technologies to science that again you think we have or having capabilities for that you don't people see people obviously pursuing today there's a boring one and an exciting one the boring answer is that if you can just make really good tools like that one I just mentioned and accelerate individual scientists each by a factor of three or five or ten or whatever um that probably increases the rate of scientific discovery by a lot even though it's like not directly doing science itself the more exciting one is I do think that same a similar system could go off and start to read all of the literature think of new ideas do some limited tests in simulation email a scientist and say hey can you run this for me in the wet lab and probably make real progress and that's you know that I don't know how exactly kind of the ontology it works here but um you can imagine um uh building these better sort of general purpose models that are you know kind of like a human we'll go read a lot of literature Etc maybe smarter than a human better memory you know who knows and then you can imagine um you know models trained on certain data sets that are you know doing something nothing like what a human does you know you're mapping uh um I don't know uh Crispers to uh you know edit accuracies or you know something like that and it really is a special purpose model and you know some particular domain and do you think that the uh Apple scientifically useful application of these models will come more from the first category where we're kind of creating better humans uh or from the second category where we're creating these predictive architectures for problem domains that we that are not you know currently easy to work with I I really don't know I I this is like you know most areas I I'm willing to like kind of give some rough opinion in this one I never have on I don't feel like I deep enough understanding of the process of Science and how great scientists actually work just say that I I like I mean I guess I would say if if we can figure out someday how to build models that are really great at reasoning then then I think they should be able to make some scientific leaps on themselves but by themselves but that that requires more work um uh you know open AI has a um has done a super impressive job of fundraising and has a very unusual capital structure uh for you know the non-profit and the Microsoft deal and like all other things are weird Capital structures underrated like should organizations and companies and Founders be thinking more expansively about you know people default or if it's already defaulted like all right we're just like a Delaware C Corp yeah open eyes you pointed out broke all the rules should people be breaking more corporate structure rules I suspect not I suspect it's like a horrible thing to uh I suspect it's like a horrible thing to innovate on like you should innovate on like products and Science and not corporate structures are like the shape of our problem is just so weird that despite our best efforts we had to do something strange but it's been like um it's been an unpleasant experience on time suck on the whole and if like you know the other efforts I'm involved in have always had normal Capital structures and I think that's better um do we underestimate the extent so so a lot of companies you're involved with are very Capital intensive um and maybe open AI is perhaps the most Capital intensive although who knows or particular something but and you know do we underestimate the extent to which capital is a bottleneck the bottleneck on unrealized Innovation like is that some kind of you know common theme running through the various efforts you're involved with I yes I mean that is my there's basically like uh uh there's like four companies that I'm I would say involved with other than just like having written a check as an investor and all of them are super you want to enumerate those for the second audience uh open Ai and healing are the things I spend the most time on and then also retro and worldcoin um but you know all of them raised minimum nine digits before any product at all and and and you know in open ai's case much more than that and I have no and all have raised in the nine digits before as like either a first round or before releasing a product um and they all take a long time you know many years to get to a release of a product and I think this is just like there's a lot of value in being willing to do stuff like this and it fell out of favor in Silicon Valley at some point um and I understand why like it's also great for companies that like only ever have to raise a few hundred thousand a million dollars and get the profitability but I think we over pivoted in that direction and we we have forgotten collectively how to like do the high risk High reward hugely capital and time intensive bets and those are also valuable we should be able to support both and this touches on um you know the question of you know why aren't there more elons uh in that uh you know that I guess the two most successful Hardware companies in the broader side and start in the last 20 years we're both starving the same person you know that seems uh like a pretty surprising fact and obviously Elon is you know singular in in many respects uh uh but do you you know what what what's your answer to that question you know do we like people with his particular set of you know circumstances is it actually a capital story along the lines of what you're saying if it was your job to cause there to be more you know spacex's uh and Teslas in the world uh uh and you know maybe you're you're trying to do some of that yourself but um uh like if you had to kind of uh push in that direction systematically uh what would you be trying to change I have never met another Elon I have never met another person that I think I can that can be developed easily into another Elon he is sort of this like strange n of one character um I'm happy he exists in the world of course but you know also a complex person uh I I don't know how you get more people like that uh like it's I don't know I don't know I don't know what you think about how to make more I'm curious I don't know I suspect there I mean I suspect there's something in the culture on both the founder and the capital side and the kinds of companies the founders want to create and then the disposition uh and to some extent but maybe to a lesser extent that the fund structure uh of the uh of the sources of capital like a surprise from me um you know as I've learned more about the space over the last you know 15 years is the extent to which the um be you know there's a finite or essentially finite uh set of um of funding models in the world uh and each has a particular set of incentives and for the most part of particular sociology uh any of that evolving time like Venture Capital was itself an investment PE in its modern form uh was uh was uh essentially an invention um and I'm sorry I said with investment invention uh and uh and so you know I I doubt we are done with that process of funding model invention and I suspect there are models that are at least somewhat different to you know those that Prevail today that are you know somewhat more amenable to this kind of innovation okay so one thing I'm excited about is I think and you're a great example of this but I think all of the people who became Tech billionaires in the last cycle are pretty well almost are pretty interested in putting serious Capital into long-term projects and the availability of capital for significant blocks of capital up front for high risk High reward long term long duration projects that rely on fundamental like science and Innovation is going to or already has dramatically changed so I think there's like going to be a lot more Capital available for this you still need like the Elon like people to to do it um and like one project I've always been tempted to do um is say okay we're going to identify the let's say 100 most talented people we can find that want to work on these sort of projects um we're going to give them like 250k a year so like enough money to for 10 years or something so it's like you know give a 20 year old 10 year or something that feels like tenure let them go off and without the kind of pressure that most people feel have the certainty to go off and explore for a long period of time and like you know not feel that like very understandable pressure can make a ton of money first um and put them together with great mentors in a sort of a great peer group and then the financial model would be like if you start a company if not that's fine like go be a writer politician think whatever if you start a company the vehicle gets to invest like on predefined terms um I think that would pay off uh and someone should do it that's kind of the University model I guess and I don't mean that is like this already exists you know you're just uh you know Reinventing the bus or something uh I mean that like it's it's me suggest evidence that it can work and you know Universe universities are usually not that good at good at supporting their spin ads uh but it happens to at least some extent and yes one of the Theses for Arc in fact is that uh by you know maybe formalizing this somewhat more than it is by encouraging it somewhat more than it tends to be that that actually might be a pretty effective novel so Silvana um uh you know my co-founder and Arc you know I've known her since we were teenagers you know more than half our lives and uh Patrick sue the other co-founder you know she she did her PhD with and so she known him for a long time and so to your point about sort of the the long-term investment you know part of how I was comfortable with it is uh you know I'd known this person for again a really extended period as you think about something like you know you mentioned retro or some of these other companies where you didn't how do you decide whether the person is the kind of person you can uh you know undertake this uh this super long-term Expedition with actually I had known Joe for a long time um he was like I mean it's a bad example I guess that's the question is that in fact do you need to have known the person for a long time it's it's super important it doesn't always work but I try to work with people that I've known for like a decade Plus at this point you know you don't want to only do that you want some new energy and volatility in the mix but having a significant proportion people that you've known for a long time worked with for a long time I think that's really valuable like in the case of open AI uh I had known Greg Brockman for a long time I met Ilya for maybe only like a year before even a little bit less than we started the company but spent a lot of time with him together um and that was like a really good combination uh but I derive like great pleasure from work having like working relationships with people over decades through multiple projects uh and like it's a lot of fun to like feel like you're Building Together towards something over that has a very long Arc agreed um which uh which company that is not thought of as an AI company will benefit the most from AI over the next five years I think some sort of investing vehicle is going to figure out how to use AI to be like an unbelievable investor and just have a crazy odd performance so like rent Tech with these new technologies yeah is there like an operating company that you look at hmm uh well do you think of Microsoft as an AI company let's say no for the purpose of this question okay I think Microsoft will transform themselves across almost every axis with AI and is that because they're just taking more seriously or because there's something about the nature of Microsoft that makes them particularly you know uh suited to this understood it sooner than others and have been taken it more seriously than others [Music] um what do you think the likelihood is that we will come to realize that gpt4 is somehow significantly overfit on the problems uh you know in the domains that it was trained on or you know how would we know if it was or do you even think about overfitting as a kind of concerned about the code forces problems you know before 21 versus after 21 were you know does better on the earlier ones Etc I think the base model is not significantly over fit but there's we don't understand the rlhf process as well and we may be doing more like brain damage to the model in that than we than we even realize um you know do you think that g like that the generalized measure of intelligence exists in humans as anything other than a statistical artifact and if the answer that is yes do you think there exists an analogous um uh sort of um common factor uh in uh in models I think it's a very imprecise notion uh but there's clearly something real that it's getting at in humans and for models as well so I think we probably like over there's like way too many significant figures when people try to talk about it but you know it's definitely my experience that very smart people can learn I won't say arbitrary things but a lot of things very quickly there's also some people who are just much better at one kind of thing than another and you know I don't want to like debate the details too much here but I'll say as a general thing I believe that model intelligence will also be somewhat fungible um based in your experience you know think about all this AI safety stuff how if at all do you think synthetic biology should be regulated I mean I would like to not have another synthetic pathogen cause a global pandemic I think we can all agree that wasn't a great experience it wasn't that bad compared to what it could have been but I'm surprised there has not been more Global coordination after that uh and I think we should have more so so you know what do we actually do because I think some of the same challenges apply as an AI actually I think this is a a production apparatus for you know synthetic pathogens is not necessarily that large and the observability and Telemetry is difficult and no I think this one's a lot harder than the AI challenge where we do have some of these characteristics like tremendous amounts of energy and you know lots of gpus I haven't thought about this as much I would ask you what we should do I think that like if someone told me what you know this is a problem what should we do I would call you so what should we do I don't know that I've a ready prescription we clear I mean the easy thing to save I'm not sure how much it helps is we need a lot more General observability Wastewater sequencing uh things like that we should do that regardless you know it doesn't help us you know uh synthetic biology attacks uh and the fact that we don't have a giant correlational data set uh of the you know pathogens that people are infected with and then sort of longitudinal you know Health outcomes uh is just like a crazy fact in general um uh and then obviously there's a somewhat innumerable set of you know uh infectious diseases like classes of infectious diseases uh that you know people uh tend to be most susceptible to and you know obviously covet itself uh being being an example of this and so I think we could make a lot more progress in um in 10 variant uh both treatments and vaccines than we do and then we have um and so I think the particular thing like if it is true through that covert was engineered I think you know instances of that set of slight modifications to already existing infectious diseases we can probably significantly improve our protections too um obviously the concerning category would be you know completely novel pathogens and that's presumably a and sort of an infinite search space then you I think get into how do you I mean there's a again finite set of you know ways to enter cells and uh and you know receptors and so forth so maybe you know you can use that you to kind of tile the space of possible treatments but uh and then you need to invest in you know a lot more Surplus manufacturing capacity than we have uh for for novel vaccines and hopefully you know mRNA platforms and similar make you know easier to have general purpose manufacturing capabilities there but as you can tell from this kind of long answer I don't think there's a silver bullet and it's I think plausible that even if you did everything that I just said well you you still would not have enough so I think it's hard getting way better at rapid response treatment vaccination whatever that all seems like just an obvious thing to do that I would have again hoped for more progress on by now yeah I I I I very much agree with that and and clinical trials um uh like that was the you know the the limiting step uh in uh in covert and I think it's you know or it's it's at this point been widely you know reported and remarked upon that you know we had the uh we had the vaccine candidate in January uh and you know everything after that I mean so some of what happened after that was obviously manufacturing skill up but but much of what happened after that was just like how long it took us to tell that you know this actually works and this is uh this is sufficiently safe and um and I know that seems among the lowest hanging fruits in the entire you know biomedical ecosystem to me 100 yeah but I guess um I guess your your investment in trial spark is uh is uh consistent that observation um so as recline and Derek Thompson um are are writing a book um about um sort of the idea of an abundance agenda and that you know so much of the um of the left of of the liberal sensibility uh is about uh sort of [Music] forbearance and you know some kind of you know quasi-neopuritianism Etc uh and you know they believe and I guess are you know well have been making the case in some of their respective public writings thus far but but you know for the purpose of this book uh the argument that actually for uh for society is equal and prosperous and environmentally friendly and you know so forth to you know actually realize May these values we care about will lead us like a lot more stuff um in many many different domains um more kind of the Henry Adams curve realized uh and they frequently observe that permitting in the broadest sense all sorts of you know well-intentioned but self-imposed restrictions uh are are the you know rate limiting factor in making this happen um maybe most obviously with the energy transition across all the different things that you're involved with you know to what degree do you think this Dynamic of self-imposed restrictions and strictures is um is you know the the relevant variable in the progress that actually ensues it definitely seems huge but I don't I think also there's a lot of people who like to say well this is the only problem than if we just could resolve like permitting writ large we'd all be happy and I don't think it's quite that simple either um I do think that the current system so I totally agree that we need much more abundance and you know my personal beliefs are abundant energy and abundant intelligence are going to be two super important factors there but there's many others uh certainly with as we start to like get closer on being able to deliver a lot of fusion to the world understanding just how painful the process to like go get these things out is like disheartening to say the least um and it's pushing us to look at all sorts of like very strange things that we can do sooner rather than like wait for all of the permitting processes that will need to happen to connect these to the grid it's like much easier to go desalinate water in some country that you know just has their nuclear Authority or whatever all right I think it is a real problem and I think we don't have that much societal will to fix it which makes it even worse but I don't think it's the only problem um if uh Ezra and Derek interviewed you uh and I guess they should uh for this book and you know uh asked you for your number one diagnosis as to you know bash which is limiting uh the abundance agenda uh probably you uh dominate um like societal Collective belief we can actually make the future better like at the end the level of effort we put on it at every every like additional sort of like gate you put on something when these things are like fragile anyway I think makes them like tremendously less likely to happen and so you have like you know it's like really hard to like start a new company it's really hard to convince people it's a good thing to do like right now in particular there's just like a lot of skepticism of that then you have this like regulatory thing it's gonna take a lot and you know it's gonna take a long time so maybe you don't even try that and then you know it's gonna like be way more expensive so it's just like there's too much friction and doubt at every stage of the process of idea to like Mass deployment in the world and I think it makes people just try less than they used to or believe less when we first met whatever it was uh 15 or so years ago uh Mark Zuckerberg was preeminent in the technology industry and in his 20s and you know not that long before then uh you know Martin's recent was preeminent in the industry and in his 20s and you know not that long before then you know Bill Gates and Steve Jobs and so forth and like generally speaking and you know for most of the history of the of the software sector and you know one of the top three people has been in their 20s and it doesn't seem that that's true to me today I mean there's some great people in their 20s but but I'm not sure this problem yeah it's not good it's it's something has really gone wrong and there's a lot of there's a lot of discussion about what this is but like where are the great Founders in there in their 20s [Music] it's not so obvious uh there's you know there's definitely some I hope we'll see a bunch I hope this was just like a weird accident in history um but maybe something's really gone wrong in our educational system or our society or just like how we think about companies and what people to Aspire to but I think it is uh it is worth significant concern in study on that note I think we're at time uh thank you so much for doing this interview thank you very much uh and thank you to Folks at selling and to uh and to Graham for uh for hosting