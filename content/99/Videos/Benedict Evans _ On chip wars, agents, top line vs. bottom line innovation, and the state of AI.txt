it's time to introduce our first Speaker one of the world's most respected technology analysts I'm sure there are many of you here in this room who are subscribed to his Weekly Newsletter read by 175,000 people across the globe uniquely skilled in identifying patterns and Trends there's no one better equipped to help us make sense of the frenzy of the past year and help us understand what might lie ahead I am of course talking about Benedict Evans um so thanks for that introduction it's exactly the way I wrote it um I hope you now all understand what an enormously big deal I am and how lucky you are that I've come to talk to you um I was asked to explain everything that's going on in AI um and do it in sort of 15 minutes and um not talk too fast um I'll probably manage two of those um maybe three everyone here actually does speak good English so I can talk quite fast other places like America where it's a bit more difficult um I I thought a good historical analogy to be historical reference to begin with might be um a short story written in 1946 by a man called will Jenkins who used used the pen Nam Mari lster who was one of my grandfathers and he wrote a story called a logic named Joe um he was a science fiction writer he was the kind of science fiction writer who would write under four or five different names so that he could get multiple stories into the same magazine at the same time um he was very influential which means that science fiction writers have heard of him but there are no royalties anymore um and the and the story that he wrote um a logic named Joe um everybody in the world has a computer which is called a logic at the time um these Logics all connected to a global um computer network they were all connected to database to databases and you can do anything with them you can book flights you can read your bank balance you can read the news you can call up on demand TV shows you can consult encyclopedias um basically he's describing home computers in the internet more or less in in 1946 which which wasn't too bad for the time um my other grandfather incidentally um was working in intelligent the intelligent services using computers spire on the Russians um so it's kind of an interesting mix um anyway the point of the um this this this short story is that one of these these logic shifts with the manufacturing defect and so it starts answering any question asked anywhere on the network as helpfully as possible which means um what would be a good way to murder my wife without getting detected and it says well here is an undetectable poison that I've just invented for you or what would be a good way of robbing a bank or making lots of money um didn't actually describe Bitcoin but there was some of it in that um and so the sort of General panic and the quote is um you know check your censorship circuits the censorship is broken and and eventually they work out which of these computers it is and they go they go and unplug it um and I read that story now and it's actually a very good description of content moderation and everything that people worry about looking at um AGI which is not something I'm going to spend much time talking about that talking about um but I think it is kind of useful to think that we've been talking about AI for as long as we've had computers in fact since computer was a job title a computer was somebody who sat at at a desk with a pen and paper and did math they were Computing um and every sort of 10 or 20 years we've had the idea that these sort of machines might somehow reach some level of intelligence um that's something like what we have um and so we used to call that artificial intelligence um and in the 60s people said we would had artificial intelligence the same level of people in a couple of years um and that didn't happen um and now people are saying it again and we'll see um but the interesting thing about artificial intelligence is is a quote from Larry Tesla in the early' 70s um who said AI is whatever doesn't work yet because once it works people say well that's not AI That's Just software um I flew here this morning from London and I scanned my boarding pass and I didn't say I'm going to use a database now it's just a computer it's just a database it's just software and so AI has kind of gone through this process of anything that doesn't work yet is AI once it works well that's just image recognition that's just speech recognition that's just data retrieval that's just information processing um and meanwhile we got an awful lot of that so we had um databases in the 50s and 60s we had information processing in the 60s and 70s and 80s and now all of our banks and our taxes and our plane tickets are all processed through these computers but we don't think of it as artificial intelligence um and as we went through the introduction of those Tech Technologies it took a while to work out what they really meant so we use terms like data banks or information processing and what we first did with computers was we use them to replace paper records and to replace paper processing of documents um but over time once you were able to move information in these ways you could do things a lot more quickly and you could do different things and so to begin with what happens with every tool um you start by forcing the new tool to fit the way you work and then over time you change the way you work to fit the tool and so databases for example give us things like just in time Supply chains they give us containerization they give us your supply chain moving to China or maybe back from China but that wasn't all particularly obvious in 1950 or 1960 we had something similar that sort of struggled to work out what this is um with the last wave of machine learning indeed the last wave of AI um which started started working sort of 10 11 years ago um when um newal Network started winning the image net image recognition competition new networks incidentally were one of those sort of dumb ideas from the 80s that had never worked rather like VR um except suddenly they did start working and I would show demos of image recognition um demos of early machine learning to big companies and I would say look now you can recognize a picture of a cat and people would say Well done like why is this useful that's very clever but what is it that we do with that and it took the industry collect L A couple of years to work out that this wasn't just image recognition it generalized to every a whole other class of problem in fact it really generalized to every other quote unquote AI problem which to say it generalized everything else that wasn't working so speech language translation and so on and then it we kind of realized no the right way to think about this this is patent recognition and so a whole class of problem that patent recognition that previously we couldn't automate we were able to automate and so it turned out that it wasn't cat pictures or or rather the thing that recognized cats that underlying technology also gave you a much better way of doing fraud detection in credit card networks or um optimizing the layout of data centers or better ways for planning power stations and so it kind of generalized to to to what we now sort of think of as patent recognition and sort of the last five six seven years every new software company or most new software companies have really been saying okay we've identified this problem deep inside this industry like Banks or cement or shipping or aircraft or something and we've worked out that we can turn this into a patent recognition problem we can turn it into a machine learning problem and then we can build a company around that and we can go out and solve that problem in 50 or 100 or 500 companies or inside some entire industry um to begin with we call those AI companies now they're just software companies um if you're using machine learning to do patent recognition to look for strange emails when you're suing somebody and they've given you all of their emails you don't think of that as AI anymore that's just um legal case management software or Discovery management software and so machine learning that wave of machine learning in the course of the last 10 years has gone from being science fiction and Magic to something that just works and it's just software and now if you pull out your phone and you um type in a word you will find that word on the cover of a book behind somebody in a photograph you took 20 years ago and of course that's just what software does of course it does that even though 10 years ago that would have been science fiction um when now all of which is to say we're now kind of at the beginning of of another of these waves we have a new as we all know kind of a new generation of machine learning around Transformer models and large language models um that mean we have a new wave of things that we can automate and there's a new wave of things that um previously computers couldn't do that now we think we can get computers to do and again we have that question okay what is this and why is this interesting and you have again the amazing demo so you can instead of recognizing cat pictures you can make a cat picture um and you can ask for it to write you a song or to explain a picture or to write you a terrible um undergraduate level essay or write some really really great LinkedIn content for you um and it will do all of that and this sort of looks like a kind of a great demo um but we're trying to work out like what is it conceptually that this is how do we think about what it is that we have here so that we can work out what we can do with it um the things that we saw last year we saw the sort of the early obvious places that you can apply this so we saw um using llms to generate code and we saw using llms to generate marketing material which is kind of an interesting contrast like on the one hand the most logical and the most rational on and on the other hand software developers um but both of those sort of worked very well but we we had of had a struggle to work out well where else can we apply this what do we do with this and how do we think about it meanwhile well unlike say other places you where you might have had that conversation like say sort of smartphones or the iPhone or 5G this is remains a very this remains a moving Target um the state of the science keeps changing we don't quite know what this is going to be capable of in six months or a year there's a sort of small number of people um who think that this might go all the way to what we sometimes call AGI artificial general intelligence which is kind of a word we had to create because AI had become meaningless so now we call it AGI um but you don't have to believe that to believe that this is a very big deal um but the question is well what is it that we do with this how do we think about what what this is what we could do with it what we could build with it um there is incidentally um an Old English joke about a Frenchman who says that's all very well in practice but does it work in theory and so here we're sort of trying to work what theory we should have around this at the same time as working out what what what practice we should have about it and at a very high level I think you could kind of divide this into two kinds of question there were sort of inside Tech question questions and outside Tech questions um and there sort of a fairly small overlap between the two So within the inside Tech questions there's sort of well you know open source models proprietary models what the is going on at open aai what's going on at Microsoft is m going to do okay um is the future multi- a agentic self-referencing models um all sorts of kind of internal engineering questions as we've kind of proliferated from kind of the base concept to actually thousands of clever people actually try to build software and build build engineering out of it out of all of that I think there's kind of a couple of things that are kind of questions or observations that matter outside of the tech industry and inside the tech industry the first of them is that I think as I think everybody will know um large language models are really really expensive to build and really really expensive to run I think most people in this room weren't born the last time the tech industry had marginal cost every time the user pressed okay you kind of have to go back to main frames um in the 19 70s to get that kind of economic kind of situation but today it does it actually costs money to press okay in in an llm which is why open era and everybody else were charging for it um and of course the reason part of the reason for that is um that the way that openai got that result with chat GPT was to say you know let's just throw an implausibly large amount of data into this and see if it works and it did and but of course then you that kind of gets you two questions one of them is if you throw even more data in will it get even better and the other is that's great but how do we do this without spending a billion dollars and how hopefully how do we get do it without having marginal cost so we've got these kind of multiple pressures on the one hand let's drive the um performance the capability of the models forward and how do we do that especially given that we've kind of run out of data and we certainly don't have an order of magnitude more data and that's not even thinking about who actually owns that data and what that means and then the other side is how do we get the models more efficient how do we get them cheaper how do we get them smaller in particular how do we get to the point that we could fit an llm onto a smartphone or certainly some kind of an llm onto a Smartphone um because after all last year the hyperscalers say that's Google Microsoft um AWS spent about a hundred billion dollar building um data centers but last year consumers globally spent about $400 billion buying smartphones and those are not directly comparable numbers but it's kind of a relevant comparison that effectively as an app developer you can get your computer onto the user's device and it doesn't cost you anything as long as you don't heat up the device too much much and so we've got these kind of pressures around how big the models are how fast they are um how we trade off performance versus adding new capability we've got the research model versus the production model versus the mobile model and within that of course we also have open source um the old yokin cellicon value is that everybody is giving away somebody else's business model for free um and so clearly what we're seeing at the moment is meta trying to give away Google and open Ai and Microsoft business model for free by open sourcing llama which is basically as good as GPT um as good as Gemini but they decided to give the whole thing away um I think the underlying motivation for this really is rather as meta did a couple of years ago with something called open compute meta thinks that an llm is basically commodity infrastructure while the like a data center itself and so they want it to be commodity and free and open source and everybody to working on it in order to be standardized and it to be as cheap as possible and the differentiation is what you build on top of it product that you build on top um but make the LM itself as a as freely and widely available as possible to everybody um and of course there's a kind of a natural competitive pressure in the industry to push that towards everybody meanwhile um there then you get all the kind of the questions outside of technology so if you're outside of Technology well okay you've got these models that do stuff it's not quite clear how much better and how much faster they're going to keep on improving or whether the rate of improvement is going to slow down it's also not quite clear how we should think conceptually about what they should do what we probably can do say is see right now we're in the kind of the feeds and speeds phase of um of large language models everything is getting much faster and much cheaper like orders of man do cheaper really really quickly and meanwhile we have to work out what it is that we can build with it um and I think I sort of alluded to earlier you know we have these kind of two very early um Paths of adoption which was coding and and marketing um as we sort of sit outside um the tech industry there are kind of various ways that you can look at this one of them is you can say we're thinking about bottom line Innovation versus Topline Innovation so bottom line Innovation what is it easy to what can I automate with this and again this is something that's kind of easy to see because you already know you're doing it how do we automate our um call center how do we automate our marketing interns how do we automate these process that we already have and that saves a couple of points of margin generally in a competitive industry when you save money that drops straight through to lower prices to the consumer rather than being taken out as um as high profits incidentally um meanwhile you have a little bit of evolution and that where people are saying well what are things that we kind of theoretically could have done but it would have been cost prohibitive and now with an llm we're going to be able to do that so this will give us this new component for to be able to process information ask new kinds of questions so we'll be able to do things that we kind of wanted to do but couldn't do before um and one of the ways that I think about those kind of processes I've used this analogy talking about the last wave of machine learning is that AI tends to give you infinite interns um you want somebody to look at every call coming into the call center and tell me if the customer's angry you want to write 500 ideas for a slogan for this new brand you want to give me 50 ideas for your latest piece of really exciting differentiated content marketing to publish on LinkedIn well you don't need an expert for that you can probably get a 10 or 15y old to do that except you couldn't automate it you didn't have a million of them well now you kind of do and llms kind of give us another wave of that um but the other question is well what's the Topline Innovation how is it that this comes and fundamentally changes the nature of your product or the nature of your business the way mobile did or the internet did or social did or search or Cloud um and the answer to that is is is is always kind of difficult because it's always easy to say in hindsight why it was obvious that this thing was going to destroy you um I sort of was reminded recently of the the story in Herodotus that that king cresus of Lydia um went to the Oracle at Deli and asked the Oracle if I invade Persia what will happen and the Oracle said if you invade Persia you will destroy a great Kingdom and King Lydia didn't realize quite how ambiguous that answer was um sorry King crus did not realize how ambiguous the answer was um and all of these kind of frame I could give you many Frameworks for how you can think about whether an llm will disrupt this industry or that industry are you more about information are you more about physical assets there's an Arbitrage opportunity these are all kinds of analyses one could have done in 1996 about the internet the problem is you'd done that analysis and you said well travel agents are screwed but hotels will be completely untouched and so taxes um and then of course somebody came along with soft a way that software actually could change what sof what a hotel or taxi was and so I'm kind of nervous about saying these are the fundamental changes that are going to come from this what I think we can say is that we have a period of sort of five or 10 years in which this will go from being very cool and very exciting and very sexy and very interesting to being really really boring um that's kind of how software has evolved um Apple will announce new iPhones this September um they could be made of diamonds and fly and we would say oh another iPhone um and that's kind of the evolution of Technology now unless we believe um as I think Jeff Hinton may be suggesting later um that this is not going to follow a standard S curve that this technology is going to continue to scale indefinitely or at least much further than we normally think then this is going to turn into software it will be a new wave of automation it will be a new database a new SQL a new Cloud a new image recognition um and we'll have a whole kind of new class of pieces of software that will change everything um but we won't notice they will just disappear inside what what we're already doing and they will be the thing that software just does because of course you can ask the computer to explain this to you in if you in it can explain it to you um the counter idea I think and then I will um stop talking is to think more about quite what it means that a computer could look at things and explain them and synthesize them to to you so what does it mean if you have an agent on your phone that sees everything you see sees every image everything you browse every message every order everything in Instagram and Amazon and then you can ask it questions like where would I like to go on holiday or what restaurant would I like as opposed to hey AI assistant what are five restaurants near here which is always the demo people like to give um but when it can actually see everything you're doing and it can know about you what could it synthesize out of that um that will be magic for a year or two and then we will look at it and say well yeah that's just what computers do of course it can do that um and then we will wait for the next thing that will change everything with that I will stop talking thank you