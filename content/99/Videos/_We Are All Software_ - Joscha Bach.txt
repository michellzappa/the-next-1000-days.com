I felt that the AGI is coming when I was a young kid when I realized what computers can do and in many ways I see that the world is now more optimistic and there is this amazing momentum and also a lot of hype in the air but it's also not clear how far the present technology is going and when and so it's a very exciting moment in time but we don't know how far in the future AGI actually is yeah well it's a kind of stance because there's there's a hierarchy of mimesis I mean I gave the language example that that's you know the highest level and then as you say you you can go down a step and you can go to um Evolution which is about the um the competition of of physical forms and their evolution and uh you know Dawkins was talking about the Gene and you're talking about the software the software agents or you can call them spirits that compete with each other but the thing is the the the software agents they need to find a host and the interesting thing is that they might be doing some kind of meta optimization because this ladder of mimesis is entangled so so they might be SEL their host based on meta optimizing the the the the language mtic if that makes sense well it's not just that uh nature is growing a body for you and then the spirit moves in and possesses that body but what's happening is that there is some software that is organizing a bunch of cells into becoming a body and that is already a spirit right it's a self organizing thing that is producing the architecture of your body and you could say an emerging phenomenon but there is no magic involved right it's really just a self organizing software that manifest by producing the architecture of that body that then produces complex behavior that implements more complex Spirit right but when once I had this Insight that what our ancestors meant with spirit is exactly self organizing software agent my mind was blown and then the next step and you realize living nature is actually all about software it's all about control structure and the actual invariance is not the molecules or the connection between the molecules or some patterns in the molecules but it's actually the ca of structure itself the software um I I realized oh nature is healing they're able to put different vales together in a way that is not superstitious and they make more sense now because we now can use our scientific worldview to make sense of a bunch of Concepts that are difficult to explain so far and where we felt that our ancestors had for some funny reason weird ideas what we noticed is that animism is not a perspective that only exists in some regions in rural Japan it's also a position that existed in Europe uh before Christianity came along and even during Christianity it's something that only stopped with the enlightenment it still exists in Scandinavia basically exists everywhere people are living inside of forests the thing that is missing in the perspective of a lot of people is U Consciousness what is it like to be in the world what it like for an agent to discover itself and the interaction with the world and uh I have been started to think very earnestly about question of what Consciousness is what its role is in uh our own mind and our Learning System and I got on a in a beard rabbit hole and discovered at some point that I have converted into an an animist and I would like to share this perspective with you the brave search API brings affordable developer access to an independent index of over 20 billion web pages well it's built from scratch without big Tech biases powered by real anonymized human page visits to filter out data and refreshed daily with tens of millions of new pages perfect for AI model training and retrieval augmented generation whether you're working on language models or information retrieval systems Brave offers representative data sets and up-to-date information affordably we'll get started with 2,000 free queries monthly at brave.com API are the existing models too small so B do we need to scale them up more or are they too large and arguably uh there is stuff that can be improved by making them larger by introducing more modalities into model into more data and so on but we also see that these models are vastly larger than the stuff that fits into our own arguably somewhat generally intelligent mind if you take something like the stable diffusion weights you can in 2 gigabytes and code an entire visual Universe it is much richer than ours and when you think of this is maybe 80% of what our brain is doing then uh model that is currently um has uh many billions of parameters and so on and um to throw a language model is maybe too large maybe there is a thing about thinking about what's a minimal Engine That Could Have epistemology right a minimal model that is able to uh infer things to learn and then you take that minimal model that is basically at the level of an extremely precocious 12E old without um much Beyond core knowledge and then you give it a library about the topic that you're interested it in and then it reads that library before you put it to the task and maybe you store the contents of that library in a generalized knowledge format that you can exchange between models and so on so I think we are still very much at the beginning of such possible developments um liquid AI company that I'm currently part of this is a startup out of MIT we are thinking about how to reite the bottom of the stack right when you think about the newal network it's a relatively mechanical Paradigm which we don't use because it's very similar to biology but we use it because it's quite simple and you know how to train it and it's arguably not storing the model in an optimal form on the hardware rather you predefine the architecture and then try to fit fit your model into it and it would be sometimes much nicer if you are were able to generalize the Paradigm in which you are doing your differential function approximation this is some sense what liquid ey is doing by building more fluid models with continuous depths and continuous resolution and uh the ability to continuously learn rather than being trained only once and uh it's it's a very exciting development but I think it's it's still an intermediate step and we think about how the minds work in nature I think there are more general principles to discovered and so uh one of the first people who thought systematically about this was Aristotle and he invented a lot of the concepts or pre-inventory physical Universe has with respect to the mind it's a dynamically evolving thing and so you could think of it as a causal pattern that is able to shape a region of physics and that's so we could say it's a spirit right and this idea of what that is in today's uh lingo we would say it's a self-organizing software that is running on a part of physics and is shaping it in a particular way and uh he also talks about the intellect that we have that is based on reason that is unique to humans but the psyche is not unique to humans this animating principle is something that all animals are having but animals have difficulty with symbolic inference because they have difficulty to form a symbolic language and argue with it and then train their thinking with it and reflect on it so in his perspective this intellect is something that is unique to humans there is uh a psyche is something that we find uh in a lot of uh living things and talks about a number of other concepts for instance in perceptual realm he distinguishes sensory image Imes with called icon structural sensory data which is called idolon image perception it's a process of iasia geometric shapes are called morphe a graph is a schema a generative image is a fantasma sensory reproduction is called mimesis and multimodal scene interpretation is called aesis so we had concepts for all these aspects that we in some sense have in modern Ai and that were not being discussed in between for over a thousand years and then on the reasoning side we have the abstract representation as called an idea a rule based representation is called logos and he also thinks of logos as something that underpins everything else so at the bottom we have a rule-based uh Universe uh with rule-based laws then we have tokens which are called samans and data types which are called idos and object types are ganos apply types are categoria associative inference is called noasis and reasoning is dioa and so he has developed a lot of these Concepts and if you think about the way in which you thought about the mind he's not just created the foundations of a lot of Western philosophy but also of psychology and I think also of about artificial intelligence this quite a mechanist rationalist way to think about what our mind is and analyze it and decompose it and it's interesting when you read a lot of the secondary literature that philosophers have written in between about this that map this into concept that they had in between that are quite shallow but when you reread Aristotle as a computer scientist it's quite enlight in to see what are the concepts that he is already discovered back then and reflected on but what's also interesting is the hard problem of Consciousness doesn't seem to be an issue for him he doesn't stumble over this and uh why is that is it didn't occur to him how hard it is for a physical system to be conscious and that seems to be so apparent for us or was there something that he was seeing that we are not seeing and what you find about this hard problem is that um other cultures do not necessarily have that when you are in Japan people are less confused about the heart problem for some reason and I suspect that's because they have a different metaphysics they are mostly animist cultures and basically the idea of anism is that the living nature is governed by spirits and if we accept this notion that Spirits are not something that existed as a Superstition before Christianity told us that uh it's something very suspicious and after we killed Christianity it was something that was superstitious but if you accept that Spirits are basically self-organizing software agents that's Spirits are in their nature software they have this property of being not physically embodied right but they are connected to physics in such a way that they do not violate any conservation laws there is nothing that defeats physicalism with respect to software and there is clearly self-organizing software running on our brains and our bodies I I'm I'm personally I'm a representation of it would be like to be a person and this representation is so tightly implemented it's driving a lot of my behavior I'm effectively possessed by an entity that that thinks of itself as Yos shabak and calls itself Yos shabak and moves all these cells around as if there was a coherent being behind it it's basically this principles of self organization that govern this and if the software ever crashes then this body falls apart and these cells are mostly going to die some are going to make off into the woods but it's basically a large region of the physical Universe gets up for grabs again for other agents for other spirits and the similar thing is happening in our cells they're also governed by self organizing software that is so detailed that they can move individual molec around and the fascinating thing is that the software at some level is the actual invariance it's not the mechanism it's not the physical thing but it is a software that is able to if a neuron dies in my brain to recruit a new neuron and then train it or if a a molecule disappears from my cell to find a new new molecule and ENT Trin it into building the mechanism so the software is the actual um thing that matters and so by the scientific world you currently rejects the idea of spirits it is beginning to ReDiscover the notion of caal patterns in physical universe that are creating rties that we can observe over a wide range of substats and that is actually the so this is the m invariance that matters and different cultures use different terminology to describe physical and psychological reality and I think our um worldview is suffering that we are not properly distinguishing between psychological objects and physical objects this leads to endless confusion in philosophy about for instance the notion of Free Will how is Free Will compar compatible with a deterministic physical universe or even with an indeterministic One how can you be free if the universe randomly forces you to do things but of course will is a psychological object it's a representation inside of a mind and it's free when you're making a decision for the first time so it cannot be predicted and so as soon as you start properly distinguish between physical objects and objects that are we uh have in oural representations we can make uh can create more clarity and for instance the world that we are interacting with is typically not a world that is the world of the logos of the laws of physics it's not the world of quantum mechanics that we are interacting with what we are interacting with is the world of stuff in space with colors and sounds and people which are all not physical objects but they are objects that are created as a simulation in our brain and in the same way our our self model is a simulation of what it would be like an agent that is perceiving all those things and is occupying the same brain and so the card dualism is actually not a dualism about substances outside of ourselves outside of the mind or outside of physics or preceding physics but the rest extensa the stuff in space happens inside of our mind and rest cogitans the IDE space of ideas is also happens inside of our mind there is two domains the world model and the sphere of ideas they're interacting with each other and so the hard problem is not the question of how can we take our the sphere of ideas and map it onto the stuff in space because they're just two different domains inside of our own mind it's both generated by the brain and so the question is a different one if Consciousness is a property of something that only exists within a psyche basically a dream generator in the mind how is it possible for a physical Universe to build a machine that can produce these representations and facilitate it and so we can I think use the concept of computer science and artificial intelligence to close the gaps in the metaphysics of our culture Consciousness itself is a lot very confusing to a lot of people because um we map it or try to map it into physics but it's not it's a virtual property it exists as if right and it's is exists so tightly as if that it has caused a power and can change the way in which physics works and there are people like Kristoff CK who sometimes say that simulation cannot be conscious and I think it's exactly the other way around the physical system a mechanism cannot be conscious because it's not by itself representing something a representation you can only be conscious in a simulation Consciousness is a simulated property and so all the objects that we can experience are representations inside of the mind and they're interpreted from the perspective of a self of something that relates to it in a particular way and it's mapped onto the relations that this simulated self is caring about and um the personal self is a representation too and you can check this by deconstructing it you can manipulate your personal self using meditation and then uh observe that your personal itself is changing the dimensions of perception are changing accordingly and uh the perception that we normally have of reality is a Trans State it's one where we don't observe that the thing that you're interacting with is a representation and when you deconstruct the trans where you get in the state that a lot of meditators call an enlightened State it's not a state in which you are more Pure or more virtuous it's a state in which um the trans of the reality becomes apparent as a representation and your own self too so what do we mean by Consciousness when I point at it I point at something my inner phenomenology something that is apparent to me so when we want to talk about what I mean by it what I mean for this purpose of our discussion here is two things one is consciousness is a second order perception it's a perception of perceiving it's not just as there content present to me but I notice that this content is present and I don't notice it cognitively by a symbolic inference but I notice this iMed immediately on a perceptual level so on a level we're not consciously symbolically reflect but we directly perceive that I am perceiving right so this is what I mean by second order perception another important aspect is consciousness always happens now it's always a present thing and it's you could also say it's the thing that creates this present this bubble of nness that we inhabit and this bubble of nness is not a single point in time but it's a region and this is not a region in physical time but we know that it's something that is constructed post talk in our brain and gets edited all the time so it's not really aligned with the physical time but the physical time is somewhat before and behind it because part of our subjective now is constructed from the past and part of a subjective now is constructed from expectations of the future and when the expectations of the future get violated by sensory data then our mind is editing this these experiences and we don't remember that our perception of the now was different a moment ago so it's it's really a contract a simulation of what it would be like if there was an agent that exists in the now that can be constructed with the type of nervous system that we have available to make it so it's for a certain temporal resolution spatial resolution and complexity of the modeling that is afforded by our hardware and so this nness can uh slightly Dynamic it's moving and for me it's usually about something like 3 seconds long and its spatial and um temporal extent depend very much on the state that I'm in so the calmer I get and the better I'm in tune with my environment the larger this bubble of now gets and I'm very confused or very exhausted and so on it becomes very small because they can only perceive those things that can make coherent in this space of now and the smaller this coherent area becomes little smaller my um subjective Consciousness area becomes and so functionally I think it's an operator and mental states which means there is some kind of language in which representations are taking place not in the sense of like English but in the sense of a representational language that is implemented on the substrate in my nervous system and there is a Consciousness is something that manipulates these representations in some regards so it's an operator and I think the purpose of this operator is to increase coherence and we can understand coherence as the minimization of constraint violations so imagine that my perceptual system discovers something that tries to interpret as a nose and then the nose has certain parameters like it points in a certain direction I can infer that there must be a face nearby that points the same direction and if it doesn't there's some kind of constraint violation that I need to resolve in order to continue interpreting this as a nose and so Consciousness might be this process that facilitates this creation of this bubble in which we are resolving the constraint violations and in this way it facilitates a spreading organization in my mind and it acts like a conductor of a mental Orchestra so if you take all these functions that are modeling reality as instruments and they're listening to their neighbors and forming process them streams in this way then Consciousness may possibly be understood as one of those instruments that has the role of paying attention superficially to other instruments listening for inconsistencies and then stepping in and resolving them so everything is on the same page and so introspectively Consciousness is this reflexive second order perception that creates nowness functionally it's I think an operator that creates or increases coherence and it's the conductor of our metal Orchestra and this is not a super unique Theory it's something that is basically very much at the point of convergence between a number of perspectives for instance Bernard Bar's Global workspace theory that s left dein has adopted for his work in Neuroscience or danard and dr's cartisian theater or graciano's attention schema Theory Consciousness is a dynamic model of our attention and its contents and um the perspective that thas metzinger develops in being no one it's also very similar to yosha banjo's notion of a Consciousness prior a function that is basically dynamically parameterizing your mental game engine to produce a low energy St and it's also very compatible with perspective that Buddhist meditators have on what Consciousness actually is about so introspectively and functionally they tend to agree but of course our own current AI algorithms are implemented in a very different way when we build a machine right now a machine algorithm we have an outside in design we start out with a subset that we understand that is deterministic we think about what function should be implemented and we implement it from the outside in and thereby extend our workbench into that system and it's stabilized by this deistic substrate we train it decoupled from the world with batch training data that we feed in and it's mostly optimized for prediction using machine learning algorithms and when we think about how it works in nature we have an inside out design all these systems need to be self-organizing so you have something like a cell that is going to uh structure the substrate around the cell and harest uh the chaos of the around the cell and turns it into complexity and uh divides itself basically cell is a pattern in physics that has the ability to replicate itself and thereby shape the environment around it and the organization across cells can also increase complexity so a bunch of neurons are turning into a nervous system by creating organization among themselves and these principles of self organization is also what we find in Social systems that basically if you put a bunch of people together for long enough at some point they will discover that you cannot just bully people into doing what you want but you can recursively bully people you can bully people into bullying other people regressively and then you have a government that is scaling until it bsces against another government and so these principles of self organization is stuff that we observe over and over in different areas of nature at the level of cells in an organism at the level of mental organization Gary idelman calls this um newal Daris the idea that mental organization is evolving in every individual and we see it at the level of organization and societies and it's optimized for coherence which means it's behaving in such a way was a single system behaving with shared goals that are compatible with each other and it's a developing continuously and it's always coupled to an environment in which it interacts dynamically so these are quite different principles and this area is very much under explored in artificial intelligence now how if we compare this to llms it's hard to do so because what after all is an llm there are multiple perspectives that we can take I think quite a few of them and one perspective that we can take on llms is that it's basically a virtual CPU and the CPU in our computers they're basically uh circuits that are implementing simple automata and uh this automata basically take as their input machine code commands a very small library of them and then we can arrange these machine code programs into arbitrarily complex programs if we know how to do so right it's very few of them so it's easy to build these automata and make them reliable but it's very hard to write the programs by finding the right sequence of operators to produce the behavior that you want and the llm is in some sense an a CPU that takes as the input not just a small library of machine code commands but it takes an arbitrary long sequence of human language a string of text and then it compiles this into a program that is executable on your server Farm or whatever you have your LM running on and then this can be executed and it's touring complete so in principle there is no limits to the program that it can run but there is much larger range of possible ways to express what this computer should be doing and this is what makes it so powerful in practice that's basically a new way to write programs on a computer and another perspective on the LM is that it's basically aist that's a notion of higle it's the idea that there is a spirit of a culture that exists by looking at all the cultural artifacts especially linguistic artifacts that people are producing in the literature in the Arts and so on and put them together into a space where they're interacting in the sense the our civilization as our culture has something like a spirit that is looking at the universe and in itself and is evolving and the LM is very much that because it's trained on that output of humans it's distilling it all into a shared model that is able to interact with itself and so the llm is basically a pretty good approximation of an electric Bel Guist at any given moment this Bel Guist is possessed by a prompt and this prompt turns it into an interaction partner or into a piece of software or whatever you ask the llm to simulate it's able to do that over a pretty wide range of things so these are perspectives that we can take on the llm but of course they're quite different from us and the question whether an llm is conscious has often been asked and it's a quite hairy question I think because uh the llm can simulate many aspects of a conscious interaction partner so if you give it a prompt that tells it please make it happen that you are I'm talking to something that uh response like a person that has mental States and it's going to create a simulation of that person including a simulation of mental States self report and so on and so on and so if this is a simulation of a person with simulated mental states that doesn't know whether it's conscious or not how is this different for me is the simulation of a person in the llm more simulated than the simulation of a person in my brain right if my Consciousness is a simulated property my personhood myself is simulated is this simulation more simulated or less simulated uh the llm or not and uh this is a question that is difficult to do proper justice but of course the functionality is not the same thing because the LM is not required to have that simulation of conscious coherence to deliver its functionality so I suspect even if the F phenomenology might be similar so you get a system that behaves also internally very much like a Similac of a self that is conscious it's not uh implementing the same functionality it's not playing the same functional role in this system so what we can see about the alarm is not happening in real time is not coupled to the world it's asynchronous to the world it's not dynamically updating and it's not intrinsically agentic it can be an agent if you ask it to simulate one but by itself it's not necessarily agentic and uh so uh it's also very difficult to see whether the llm would be conscious in a sense like ours because the self-report that the llm is giving you is based on learning on text a lot of that text is uh people describing their Consciousness and so it's difficult to say to which degree is it producing text that looks like it's conscious or to which degree is it compelled to build the only valid representation and so if we want to test such systems or artificial systems for conscious maybe the LM is not the right Paradigm and um if we are asking ourselves as a cat conscious I think what we are asking is is the cat aware that the cat is aware does the cat have the second order of perception and when you are have a cat you typically have no doubt that the cat knows that it's aware and knows that you are aware that the cat is aware uh so so uh could we build a system like this could we build also a system that has an integrated model of now and is the system capable of learning from this thing of now inv transforming itself expanding itself into its organization and uh become creative uh a creator of itself in a sense and I suspect this is exactly what Consciousness is doing in humans it's basically this thing that leads our mind to create itself and uh what we observe is that um babies are already conscious it's not that Consciousness is so complicated that we get there after our PhD but Consciousness is something that happens before we are able to track a finger and I suspect that if a baby is not conscious it is not going to learn how to track a finger because it needs to pay attention and organize its mind and Consciousness is the mechanism that pH facilitates this by increasing coherence in the mind of the newborn and so uh Consciousness might be in a sense a training algorithm and this might be more simple than perception and not more complicated so basic perception is facilitated by having this mechanism on the self-organizing system and we observe that there is basically no human that gets to any level of performance without being conscious first right if you're not being conscious at the baby you remain a vegetable you're not there is no other trick that nature came up with to get you to this level of performance and this leads me to to the hypothesis that Consciousness might actually be the simple training organism for a self-organizing information processing system again I don't know whether that's true but it's a hypothesis that we can test by searching for this if this is true then Consciousness might be quite ubiquitous in nature right and all nervous systems that have a certain degree of complexity in their organization of representation might have discovered the same principle if it's also if it's discovered in every brain very early on maybe it's not that complicated so if the Consciousness is the process that creates our mental Universe are we the first culture or this the first moment that we get to this idea of course not I think this idea has always been PL sight and we find this uh very trickly is uh the first chapter of the Bible uh called Genesis 1 and this chapter is a very very old text it's a uh oldest known copy is only from 200 BC or so and has been integrated we think into the Hebrew uh scriptures about uh four 500 to 400 BC but uh it's probably something like 3 and half thousand years old and uh did so it comes from a civilization that is much older and it's probably a few translation errors in the meantime uh and so I suspect that it could be a theory if you fix the um epistemology of that text right the Christians tell you it's the creation of a physical Universe by a supernatural being but you know physical Universe was not invented back then Aristotle comes up with this idea of physics of of nature of a physical universe but people back then they knew that be living in a dream the idea that there is a universe that needs to be described with uh linear algebra and quantum mechanics and so on is a pretty modern idea and so people were pretty much aware of the fact that we live in representations in dreams and that people have a very similar dreams and so maybe this is the world that is being created is a world that exists in dreams it's a world of representations that we are interacting with of dream components and so if this is true then is maybe is a theory about how this is working and so if you take that seriously in a sense it starts out is the creative spirit this first Consciousness that's covered in your mind hovering over the substrate word is usually not translated as substrate but as water and so it it creates this on the substrate it creates structure initially it's uninitialized it's void it's to without form and uh what it does it creates a separation the text says a firmament between the waters above the firmament the waters below the firmament I think what it means it's a separation between two domains and a substrate the world model Earth the world and the sphere of ideas heavens and they need to be separated because uh the world model is the stuff that is sensory validated it's the stuff is seen around us and the sphere of ideas needs to be separate from it because it's all hypothetical things that you can manipulate that you can change and if you mix the two then you will have hallucinations about what's going on in the physical world around you and so there are actually two quite separate domains that interacting with each other this R cognant and rest extender the next one is that it creates contrast creates a way to represent present differences and it Associates the intensity of the contrast with brightness with the color of the day with light and the flatness of the contrast with Darkness the color of the night and now it has dimensions and using Dimensions we can represent arbitrary objects and the first object it discovers is two Dimensions it's the plane Associates with the ground puts it into the world model and then creates 3D space and then uh it creates uh solids and liquids and then organic shapes and so on then it discovers the in Varian against lighting and how lighting works and uh temporal consistency and then it creates all the pl objects plants and animals gives them all their names again this is cognitive development right it's clearly plant names and so on are nothing that in the physical world exists it exists in your mind and uh after it's created this world it discovers that the purpose of the exercise is to navigate the interaction between an organism an agent and its environment and so it makes a simulation of the inter of that organism and puts it into this environment and after it's done with this it switches into a first person perspective it creates another spirit in its own image another Consciousness basically that gets associated with this personal self and that is then observing the simulated World in your brain this game engine from the perspective of that self and uh it what we have then is this Weir childhood Amnesia that children forget what the world was like before they were thinking of themselves in the first person as a person person right we also have States in which we are not personalized for instance at dreams in the night or when we meditate we uh can get to a point where there is no person there's just things happening and this idea that we are a person is an imposition that we get associated with this thing that we have to identify as a person as a human being that has say guilt and shame and interests in the world and so on this is all a particular kind of trick that our mind is playing to make us identify with this character and um deal with the interest of that character but the contents of our perception what we see in the world the objects that we see the emotions that we have motivations we experience they're generated outside of this personal self and we experience them as a reality that the self cannot control right so the we are basic perceive this interface between the self model and the world model and part of the world model is an intelligent system that is producing our motivation and so what basic you have a model in which your mind is a protocol layer in which you can make arbitrary models and inside of the mind you have the world model and the personal self and your conscious attention is directed on the surface of the of this personal self in which you are perceiving emotion motivation and elements of the world model this is very roughly the architecture and it's an architecture that has been discovered uh over and over it's quite similar to how Freud sees the mind and how other are seeing the mind and even Aristotle so uh if Consciousness is simple which organisms are conscious is is consciousness ubiquitous in nature and so I file down a little bit of a rapid hole similar to Mike L and uh basically as a computer scientist I look at cells and I realize that every cell is capable of sending conditional messages to other cells right that means that if you have a multicell organism it's basically a touring machine and if it evolves for long enough it's very difficult to see why it would not become a learning system right so that means that if you build an A system that is very long lift and made out of enough cells and you embed it into environment and evolve it for long enough it's going to become something like a brain of course not like our brain because it doesn't have neurons it can the cells can only talk to directly adjacent cells so it's going to be very slow and potentially quite noisy brain but it's not clear what the limits of modeling of such a system is so that's probably also self-organizing software agents running on multicell organisms that are large enough like big plants and so on and it's a quite interesting perspective right it's also we observe evidence for that happening we see that an organism there is information flowing back and forth that tries to become coherent if you harm the roots of a tree it's going to send messages to its Limbs and back and it's optimizing the organization of the tree again and what's also interesting is that neurons um from this perspective an adaptation for Animals neurons maybe are Telegraph cells they have evolved to send messages very quickly through the organism over long distances maybe this is what the accents are for you have this Spike trains which in some sense like a biological Morse code like in a telegraph system that is allowing you to send messages so quickly that you can move your muscles at the limit of physics and it's expensive to run this Telegraph system and once you have it you also need to have perception and decision- making at the same rate so you build another information processing system entirely out of telegraph cells but it's going to be difficult to tell the story of an organism if you ruce it to the telegraph cell so maybe this Paradigm of Neuroscience that we only look at neurons and not at any other cell might be too shortsighted might be misguided in the same way as it's very difficult to model the economy of a civilization by only looking at its Telegraph Network right you also want to look at the people living next to the Telegraph and so on and so on and maybe this is part of the reason why our simulations not even of C Elegance work in in in practice if you put them into a computer model the also the models of conom don't actually work they're incomplete there is a lot of things are missing and maybe it's this part that they are only a small component of the information processing of organism so if Consciousness can organize information processing in in brains it could be that there are similar principles at very different time scales that are happening in organisms in general and so we can ask ourselves do plants have Spirits they seem to have PL means for Universal function approximation there is evidence for coherent communication between plants and evidence for communication within the plant uh it's also this thing when you put plants next to each other can they actually build firewalls and if you have a fungus that fungus that lives next to a tree are you able to send messages to the cells of the tree by basically emulating the code of the tree and passing the message on and there is evidence for this we can see that in Forest U animal plants are communicating through fungal networks and vice versa and even longdistance communication right it's it's again it's much slower than nervous systems and so on placed out of very long time spans but there is actually evidence for this and so over a long enough time span it's called conceivable that Forest are building something like a biological internet that they have a shared protocol and when the spirits of plants are self-organizing and they live in a larger environment with a shared protocol they can even build feedback loops pretty far out from the original plant and move around in the forest in this way quite interesting it's very similar to what our ancestors claimed about the fairies right the that the um one day in Fairland is seven years in humanand maybe this alludes to the time difference and the speed of processing but plant minds are so much slower than ours that we will be complete blur to them that's that's really wild and I thought oh my God uh these are very wild hypotheses that incidentally are very similar to the hypothesis of animist cultures that you still find in Scandinavia and Japan and so on and so there could be Bas comp ecosystems of software in nature and of course we don't know to which degree this is true the uh there's very little scientific res research even though we have evidence for interplant communication and organization ecosystems that is quite complex we don't know if it's generally intelligent we don't know over which time spend we don't know how to research that and so on so this is completely speculative uh the extent of limitations of the biological intelligents outside of animal nervous systems are unclear because don't really know how to measure them but could we build AIS that are in principle compatible with biological substrates with our nervous systems and with organisms in general can we emulate these principles of self organization that that I think is an interesting question that you could make progress on so if we think of animism as the idea that the difference between living and dead nature is that there is software living on existing on the living nature and when that software is crashing then the cell or the organism is dying and it comes up for grabs for other Spirits we shift our perspective on Evolution right and now Darin said that evolution is about competing species and dark says no it's actually about certain molecules the genes that are just using the organism at a mechanism to replicate but from this perspective the actual invariance is the software uh evolution is actually about the competition between different software agents that are replicating themselves in nature and they encode themselves in Gene and manifest by creating mechanisms that we perceive as organisms so it's still a very physicalist perspective it's just uh one that is making software Central to this whole thing which I think should be welcome to computer scientists so can we bring these spirits on our gpus is it possible to extend life and Consciousness onto these new substrates if Consciousness basically a colonizing cence inducing operator it's at the core of self organizing information processing systems could this be testable in AI models I think it's a very important question because uh AI is in some sense the missing link between mathematics that we can build representational language as the ground and philosophy where repes ing the world and by itself mathematics doesn't scale to the level where we can use the simple logical language of Mass to talk talk about meaning and our experience to do this we basically need to close the gap by mechanizing the Mind by naturalizing it by Building Systems that are obeying the principles of minds and that have a mathematical foundation and on the other hand are able to talk about the things that we care about and represent them adequately and so this naturalization of the mind is arguably the most important philosophical project it's also the last one if you succeeded in it because then we can go to the beach and leave philosophy to the AIS and uh towards understanding Consciousness I think we should build an initiative and I know T we call this the California and secret machine Consciousness we have already incorporated as a board and I think the best way to study Consciousness is to do it in AI models it's not by looking at the output of neuroscience and psychology who are mostly not concerning themselves with Consciousness because they don't even have a method methodology to test theories about consciousness I might have one what this is going to look like I think we can build a trainable substrate that is capable of self organization um made out of individual modular reinforcement learning agents that are somewhat similar to cells and urans and then uh in let them evolve message passing strategies and see if at some point of complexity you see a phase transition where basically uh discover an operator that entrains itself on its environment and produces some form of governance with a shared language of thought and a shared reward system similar to governments in uh human organizations and uh maybe this is not the right strategy maybe we can figure it out analytically by analyzing the preconditions for such system and then impose it directly but if it's something that is indeed discovered in every individual brain then maybe it's possible to discover this also in a search process on a GPU and uh so we can think about this as a multiv system in which you're not playing operators linearly but when you're branching out but an interesting thing about neurons is that they are not performing linear computations in the same way as The Operators and our present computers because if your computer is in any given state it has exactly one possible success state but if you think about what the neuron is doing the individual neuron given the same environmental and internal state is not completely deterministic so is there a certain range of states that it can go in and because we want our brains to be more or less deterministic you need a population of neurons together to encode this connect them to a similar receptive field give them a similar internal State and they're going to sample a space of functions together and so in some sense our mental states are in superpositions that sometimes collapse um but the way in which we are testing our building our mental programs is not that we sequentially go from step to step that we are branching out into superpositions that are represent in populations of neurons which we of course cannot remember because that would require to V uh witness every of these neurons by other neurons that would form deterministic memories which is not quite possible Right so uh the Paradigm is still a chewing machine but it's a non-is chewing machine that would be we would need to understand this message passing architecture from the perspective of Ethics I think that's quite interesting if you think about AGI and we build systems that have more agency than human beings and we want to cooperate with them it's probably important that they're able to build shared purposes with us and recognize us as what we want to be recognized as and I don't know about you but I don't want to be primarily recognized as being by P or something like that I want to be recognized as something that's conscious that's what I actually care about so if the AI U is interacting with me it should primarily care about my conscious States and this might make it necessary to formalize and operationalize what we mean by conscious States that's one of the reasons why I think it's important in beginning AGI age there's also question does conscious AI has to suffer philosopher thas metsing was very concerned about it as he thinks that we buildt systems that are capable of experiments we will dramatically increase the amount of suffering in the universe uh my personal perspective is more optimistic I think that because suffering is happening at the boundary between World model and self self model it's an indication of a defect and regulation insufficient regulation so the answer to conscious suffering is more Consciousness basically building better models of your regulation and then you can basically decide what you care about and whether that's useful to you to care about it so I don't think that AGI if it's smart enough would suffer what if the hypothesis is wrong right what I'm uh presenting to you is a branch in a a large way realm of possibilities about how to understand Consciousness what it is and how it's implemented in nature so for instance one of the foundations of this thinking is computationalist functionalism and it's a position that is somewhat debated in philosophy it's made out of two components one is functionalism that's an epistemological position and basically says that when you construct an object we construct it in our own mind is a model of something and the model that we construct it of is behavior that we observe Bas the functions that things are performing in the world there is no hidden Essence that we have access to but the only thing that we have access to is observe behavior and so every object that we construct in our mind ultimately is a model of some kind of functionality that is what functionalism means it's very difficult to defeat this perspective that there are objects that we can know directly not via their behavior the other one is computationalism and that's a position about representation it basically says that they can represent anything by state Transitions and so in this sense physics is a computationalist theory and every kind of representational theory that we know is computationalist and if you want to defeat this it's mathematically very hairy so uh the opposition to maintain it against computational functionalism is is very difficult and it seems to be from the perspective of a computer scientist or physicalist an obvious default position to have second one is consciousness a software a cal pattern that is uh somewhat separate to physics but is interacting with it in a c way and uh that's the perspective that I've come to and I don't see a working alternative to it but there might be people which think Consciousness is fundament in a different class than software objects this another one is consciousness an aspect um of a different mechanism so it is there something else that gives rise to phenomenology and observed Behavior but maybe it's something else maybe it's some kind of humanistic mechanism that is happening uh below the level of individual cells as also the possibility that Consciousness is not an inter cellular phenomenon right and now we think it's something that's happening across cells so basically neurons talking to each other but what if it's somewhat orthogonal to the cells right and it's very little evidence that it's the case it seems that Consciousness seems to evolve conscious States at roughly the speed at which neurons update and uh signals propagate through the brain and then you manipulate the brain at the intercellular level you get changes in Consciousness but maybe we get new results in the future and for instance you HOV believes it's not between cells he believes it's between microt Tua and he is a little bit alone with this but who knows maybe despite not having super good arguments turns out in the end he's right could be ironic but who knows right it's something that we have to test they have to build models and if he's right then the GPU will not be able to be conscious but uh if he if he can show the phology of Consciousness emerging in there in his theory would be wrong another one is is consciousness simple right we will have success if Consciousness is simple and can be discovered as the principle of self-organizing computation but uh what if Consciousness as complicated as the first cell as far as we know the first cell only evolved or formed once on this planet and every cell in our organism is still split off from the first cell everything that you observe in life on Earth is still the shenanigans of a single cell that split and split and split and a cell is basically a self organizing colonizing pattern in physics that is able to colonize suitable physical environments and turn them into more cells replicating this pattern right but it's such a complicated pattern that once you have it in existence it's stabilizing and it's able to adapt to many circumstances but to get the first one is very hard what if Consciousness is as difficult as the cell right then it might be very difficult to discover it because uh then maybe it's also evolved only once on Earth and we all get infected by it and UT right we don't know that we don't think that at the moment I think it's discovered in every brain independently uh but that would mean it's simple and it's again a theory I would like to test so I would like to stop here I don't know if we have time for [Applause] questions thank you very much wonderful questions from the there was tons of conversation in the virtual attendees but no um no so uh brief comment is one of your slides you're sort of looking for a A formalism or model of the uh sort of information processing in living or conscious systems I forget the language it used but it seemed very close to what we've been working on with Greg Meredith who's a mathematician who will be here tomorrow and we we've created a formalism called The Meta mea calculus which extends Greg's row calculus to have bir directional rather than one directional arrows and the row calculus is an extension of the P calculus process calculus to be fully reflective so that channels are first class citizens so there's actually in a way we've been going in a similar Direction and looking for this sort of formalism and have written out uh mathematical version of this formalism to serve as a formal semantics for the the language of thought that we put in in in hyperon so this could be an interesting conversation but uh uh missing piece that we're thinking about and don't have an maybe an optimally elegant answer to is sort of how do you quantify the degree of coherence or with what family of measures did you quantify the degree of the degree of coherence because when you when you say uh you know a spirit is a self-organized system yeah self-organized agent I mean that's conceptually yes makes sense then in practice the degree of self-organization is fuzzy not crisp and how to quantify the amount of self-organization could be done in a in a lot of ways quantifying the notion of coherence a word that popped up is similar I mean tonii tries to measure a form of coherence in a sort of ham-handed way there are more sophisticated math ways to do it but then there's a lot of sophisticated math ways to do it and that that seems to come back to the talk that uh Bennett gave this morning saying like complexity is an illusion which turns out to mean that how to measure complexity or Simplicity is not outside of your cognitive system but is part of the process of the cognitive system and that that that finally rindes around to a question which is how in your view is the way that we quantify the degree of self-organization or coherence is that just part of what a mind does in trying to create and conceptualize it itself and the world or do you think there are sort of in some way objectively nice ways to quantify the degree of self-organization or coherence that we can then use to to study a variety of Minds yeah when we look at the present machine Learning Systems we use loss functions that are driving the learning of the system and the nice thing about these loss functions is typically that you just look how well are you be able to recreate a pattern so it's a syntactic Criterion and the difficulty with a notion like coherence or consistency or minimization of constraint violations is that it's a semantic notion it's already at the level where we has established a representation and as the question can we map this onto a syntactic Criterion that we can establish at in a general enough way or is there a good proxy for instance what a lot of people are trying to use is an energy based notion or which you can translate into how many operations does a model need to keep current when you are for instance connected to a processing stream and how well are you able to predict the data that you care about when you have a system that is a fixed amount of resources then the question would be can you uh organize the system in such a way that you can perform the most valuable computations using the available resources and then something like coherence might be falling out as uh a sub goal that you can derive um as something that the system would need to optimize in order to produce the desired performance and but it could be that the system is for instance to develop something like a market to do that imagine that you have a bunch of sales that are reinforcement learning agents every individual neuron in your brain it's trainable in a sense and uh they need to uh decide in some sense which software to run on on which cell if we have a group of cells that are in multi-dimensional activation State each and they're communicating about these activation States in this way dynamically change their state and perform computations that can run software agents on your brain the question is which software agents should a population of neurons run which are the most valuable ones individual neuron is not able to find this out because it's not entangled enough with the environment at large so what happens is the need to have some kind of intermediate layer that is uh for the individual agents that want to run on your brain deciding how many compute credits they get and this entire notion of energy that meditators are talking about is not energy in this physical sense of the capacity of a system to do work I think it's compute credits no but it needs to be a limited resource so this brings up the question of the relation of coherence with efficiency in some sense right because in in a way in in a crude sense having coherence is a way of allowing like 100 processing elements to do the work of more than 100 processing elements because there's some emerging coordination happening between them so do you do do do you do you think that that limitation of compute resource isn't critical for Driving Systems toward comp I think if you have a system in which you can use unlimited resources there is still going to be a bottleneck due to the uh limits of communication between the systems for special relativity yeah or from the Practical things you have a certain BST between cells or between people right in the same way as you cannot scale up a team of smart people uh arbitrarily because it's limited by how many ideas you can synchronize across people uh right and the resolution at which you can synchronize them there might be similar principles happening in nervous systems that you cannot scale them arbitrarily but I don't know how to quantify this at the moment I have only intuitions about this and I think we would need to uh run simulations before we can solve this analytically and make proofs about this so at the moment I basically don't know I have lots and lots of intuitions but my experience is once we start simulating something these intuitions fall apart and get replaced by better ones [Music]