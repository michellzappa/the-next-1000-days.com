we are thrilled to have our next speaker with us uh Daniela is the uh president and co-founder of anthropic um which recently just launched the really impressive Claude 3 Model uh please welcome Danielle in conversation uh thank you so much for being here Daniela you're welcome M uh yes you do here take this oh that's so nice of you thank you I think everybody in the audience is amiliar with anthropic as probably a customer of yours uh but can you just do a quick refresher for everyone in the audience about anthropic the company what is your mission what's the future you imagine and um how are you building towards that future sure thing uh so first of all thanks so much for for having me uh great to be with all of you today so uh I'm Daniela I am a co-founder and president at anthropic we uh are a generative AI company that is really working to build uh powerful transformative generative AI tools that really have humans at the center of them so we have a huge focus on building this Tech in a way that is trustworthy and uh reliable and we've been around for just about uh three years a little over three years and uh in that time have been able to advance the State ofth art uh across generative AI on a number of of Dimensions wonderful and what are the things that what are the unique approaches that you're taking now that the foundation model space is getting very crowded what are the things that make you uniquely anthropic uh I love that question so uh first of all I would say there's there's a few different ways that I kind of uh like think about or or interpret that question one is really how do we kind of differentiate ourselves at the model level right what do we do when we're training the models or how do we want the models to sort of have people feel when they when they use them and here what I would say is we really uh again thinking about this kind of commitment to trustworthiness reliability of our models we Implement a number of different sort of technical safety approaches to help uh make the models really more aligned with uh what humans want them to be doing so we pioneered a technique called uh constitutional AI which really enables uh the models to incorporate documents like the UN Declaration of Human Rights the Apple terms of service to really make it more aligned with uh with values of of the the sort of human race um from a sort of business perspective we really have tried to make uh Claud as approachable as possible in particular for Enterprise businesses so large businesses uh in particular I think have really resonated with our approach because they also value models that are helpful and honest and harmless right in general very large Enterprise businesses um tend to be uh concerned about models that will you know hallucinate or say something very very offensive wonderful uh let's talk about use cases I think one of the major questions people in the audience have today is uh where companies are finding the most product Market fit and I think you have a unique vantage point on that uh from anthropic what are the use cases that you see that are already reaching real product Market fit and what are the use cases that you think are on the come that are about to reach prodct Market fit so I think it it varies a little bit uh first of all just kind of depending on industry so there's some uh there's kind of some industries that I think are kind of quite advanced in in generative AI um unsurprisingly the technology industry has been you know an early adopter that's that's often how how it goes but I think something that has sort of been interesting for us to see is we we just released this new sort of Suite of of models the the CLA 3 Model we call it the model family and so the kind of biggest model CLA 3 Opus is the kind of state-of-the-art we sort of joke it's like the Rolls-Royce of the models it's incredibly capable and powerful and really what we've seen is you know not everybody needs the kind of top tier state-of-the-art model for all of their use cases is but the times when you do need it is when you need a model that is just incredibly intelligent capable and and Powerful so things like you know if you're doing scientific research or you're trying to have a model uh write very complex code for you at a fast pace or do you know complex macroeconomic policy analysis um CLA 3 Opus is like a great fit for that um CLA 3 Haiku which is the smallest model this is like the Ducati it's sort of the like racing motorcycle is amazing for things like customer support so really what we've seen in the industry is that um you know speed and cost are very important for anything that kind of requires real-time response rates and then Claud 3 Sonet which is sort of that middle Model A lot of Enterprise businesses are using for things like um day-to-day retrieval summary of information if they have unstructured data that they need to uh pull together and analyze and so I would say it varies by industry but it also sort of varies by use case and just how much uh ability C customers have to kind of choose between uh between what's available for them wonderful can you share one or two of your favorite use cases that people have built on anthropic yeah for sure um I would say I'm I'm like a do goter at heart so uh one of my favorite use cases is the Dana Farber Cancer Institute uses Claud to help with a genetic genetic analysis so looking for sort of cancer markers um I think there's also like much more kind of a a sort of boring application but there's a lot of kind of financial services firms like Bridgewater and street that are really using CLA to help them you know analyze financial information uh in in real time I think I like both of those because they really just sort of represent such a wide spectrum right I think it illustrates how truly general purpose these models are right it's a model that can help you to literally try and cure cancer faster but also to do sort of the day-to-day bread and butter of illegal services or financial services firms work Wonderful are you seeing more success uh in your customers finding product Market fit from startups or from Enterprises right now so I would say you know for anthropic in particular uh we have really focused on kind of the Enterprise use case and again this is really because we have felt such a resonance you know in approach um for businesses that are interested in building in ways that are you know trustworthy and reliable right all of the things we we've sort of been talking about um that being said I think there's a ton of innovation that is always happening in the start space and so something that I think is really interesting to watch is sometimes we'll have kind of a startup um sort of prototype something and we'll see like wow that's you know that's a really fascinating use case like we wouldn't have thought that you know you could use Claud that way and then that will become something that like Enterprise businesses sort of like later learn about because they know someone who works at that startup or they've kind of seen it in production so my sense is for us personally we're much more sort of you know building for and pivoted towards the Enterprise but I think there's really a wide wide ecosystem uh of development that that's happening uh in the business space wonderful on the Spectrum from prototyping to you know experimentation all the way to production where do you think most of your customers are today on that Journey yeah um I think on the kind of I think for this I'll like talk about Enterprise and then and then startups because they're a little bit different um I think for Enterprises it it actually ranges like pretty pretty widely um there's some businesses that I would even say have multiple kind of production use cases right where they might be using CLA internally to uh you know analyze health records or help doctors or nurses um you know analyze notes and save themselves administrative time so they can be with patients more but if they're a big company they might also be using it for a chat interface right so depending on the business use case sometimes they have you know multiple use cases in production but it's a little spiky right there might be times where one of those one of those use cases is like quite far along they've already been in production for like a year um they really like know the question right they come to us and they're like we really really want to optimize like this metric or we really care about price or we really care about latency and then there's businesses all the way on the other end of the spectrum who come to us and are like I've been hearing about generative AI like from my board can you help us understand is there a solution here right and so I think it um it does it does vary a lot but I will say Industries I have personally been surprised that some um industries that are not necessarily historically known for being early adopters like insurance companies or financial services um or Healthcare I think are actually um great candidates for incorporating this technology and and many of them have wonderful let's move on to Cloud 3 and and research uh maybe you just you just launched Cloud 3 maybe tell us a little bit about what into what went into it um and how the reception has been so far so uh yes we just uh just a couple of weeks ago launched uh clae 3 as I mentioned it's this sort of model uh family right so there's uh different uh models kind of available for different use cases again for businesses uh and really I think what has been so interesting is uh we've gotten great you know positive feedback about Claude of course there's always things that that we're improving and wanting to do better but some something that I have found you know really um just interesting is customers have sort of simultaneously commented on how kind of capable and Powerful the models are right they're the most intelligent state-of-the-art models available on the market today but people have also commented hey it's way harder to jailbreak these or the hallucination rates have kind of gone down a lot and so there has been this kind of dual language around both capability and safety and then the last piece which I always find um really interesting is um many customers have told us part of the appeal of Claude is that Claude feels more human um and so when people kind of interact with or talk to Claude we've sometimes heard folks say it really feels like talking to you know a trusted person versus talking to a robot that was kind of trained to sound like a human I love that uh and I've I think everyone here has seen all the eval charts I think Claude really one of the areas where it really spikes is in coding where I think the performance is is just off the charts right now maybe can you tell us a little bit about how you made the model so good at coding in particular and then how you see the role uh how you see AI software engineering playing out and anthropics role in it m so I think something that uh that is interesting that I've like learned from my research colleagues so I don't sort of pretend to be an expert uh on this is as the models just become generally more performative they kind of like get better at everything and so I think much of the same training uh techniques that we used to improve the model's you know accuracy and uh reading comprehension and general reasoning were also used to to improve its ability to code and I think that's something that again is kind of a fundamental interesting sort of research thing which is like Rising boat sort of lifts all tides that being said there's a lot of variety in these models and something I've always found interesting is certain models like people are like I always use this model for like task X right at the consumer level and other times folks will say this model like you absolutely have to use for for task y so I I think they're there is a little bit of almost um pull through personality that happens with these kind of regardless of of the Improvement it's kind of a useful caveat in terms of you know what are people doing in the sort of software engineering space and and kind of what is the role of these models um I'm I'm not a programmer so I feel like I'm I I probably can't opine on this as well as others but um much of what we have heard from our customers is that Claude is a great tool in helping you know people who write code so Claude cannot replace a human engineer uh you know yet but it can be a great kind of co-pilot in in helping love that maybe more of a Phil philosophical research question question um how do you think about the role of transparency in AI research especially as it seems like the AI field has become more and more closed anthropic has always uh felt very strongly about publishing um a large portion of our research so uh we don't publish everything but we have published something like two dozen uh papers the vast majority of them are actually technical uh safety uh or policy research papers and the reason that we choose to publish those are um as a public benefit Corporation we really view uh our job as helping to raise the watermark really across the industry in areas like safety so uh we have a team that focuses on something called mechanistic interpretability which is uh essentially the art of trying to figure out you know what is happening inside the black box that is these neural networks and it's a very kind of emerging field of of research uh there's like two or three teams in the entire world that work on it and we really feel like there's a lot of opportunity when kind of sharing that more broadly with the scientific Community to just increase understanding around around topics like that particularly in sort of the element of of safety so we've shared uh all of these research papers and then additionally we do a lot of work in kind of the policy sphere and try and publish uh research results papers our you know red teaming uh red teaming results as well thank you uh one of the big themes of today's event is trying to think about what's next um so I was hoping to ask from your from your Vantage Point what are the biggest challenges that you see your customers facing or your researchers thinking about when they're trying to build with llms like where are they you know hitting a wall uh and how is anthropic working to address some of those problems so I think there's a a few kind of classes of ways that that these models are still sort of they're still not perfect right um I think one big one is there are just fundamental kind of challenges to how these models are developed and trained and used so the kind of prototypical one that's talked about is this hallucination problem right I'm sure everyone in the room knows this but models are just trained to predict the next word and so sometimes they don't know the right answer and so they just make something up and we have made a huge amount of progress as an industry in reducing hallucination rates from like the gpt2 era but they're still not perfect I'm not entirely sure like what the sort of like decrease Curve will look like for hallucination rate right we keep getting better at it I'm not sure if we'll ever be able to get models to zero um that is a fundamental challenge for businesses right if your model is going to even very occasionally hallucinate for some of the highest Stakes decisions you probably wouldn't choose to use a model alone right you would say hey we need a human in the loop and I do think something that's kind of very interesting is there's there's a really small set of cases today where llms alone can do the majority of the task right like their best again I think in t with a human for the majority of of kind of use cases I also think there's just sort of this interesting um it it almost feels a little more philosophical which is just what are humans actually comfortable with giving to models right I think part of the sort of human in the loop story is also about helping um you know businesses and industries and individuals feel more comfortable with an AI tool making fundamental decisions thank you for sharing that uh a few of the folks here uh spoke about plan and reasoning is that something you all are thinking about at anthropic and could you share a few words on that yeah definitely um so that can obviously mean a a few things so I think on the kind of dimension of like how do you get these models to sort of like execute sort of multi-step instructions right I'm assuming that's kind of what what planning means um you know it's it's really interesting there's a lot of research and and kind of work that has gone into uh this this sort of concept of like agents right like how do you give the models ability to like take control of something and like you know execute multiple actions in a row and like can they plan right can they can they sort of think through like a a set of steps I do think that Claude 3 sort of represented for us a leap uh between kind of the last generation of models in it sort of ability to do that but I actually think that level of kind of agentic behavior is still really hard like I think the models cannot quite quite do that reliably yet again this feels like such a sort of fundamental research question that I don't know how long it will be until that's not the case but I don't think it's the the sort of you know the dream of like can I just ask Claude to book my flight for me like please go book my reservation hotel just plan my vacation I don't actually think that that's like immediately around the corner I think there's still some some research work and and uh engineering work that needs to go into making that possible yep yep okay so the the future is coming but maybe not as quickly as we think the future is coming quickly it's also coming choppily it's a little unclear exactly which parts of it are going to come where okay very cool uh can we talk about AI safety for for a moment anthropic really made a name for itself on AI safety and I think you were the first major research institution to publish your responsible scaling policies um how do you balance Innovation and and accountability and how would you encourage other companies in the ecosystem to do that as well so something that we um that we kind of get asked a lot is is you know how do you all plan to compete if you're you know so committed to safety and something that I think has been you know really interesting is many fundamental safety challenges are actually business challenges and rather than sort of thinking of these two as something that is you know two sides that are kind of opposed to each other I actually think the path to kind of mline success in generative AI development runs through many of the safety topics we've been talking about right uh most businesses don't want models that are going to like spout harmful garbage right like that's just not a useful product the same thing is true like if the model refuses to answer your questions if it's if it's uh if it's dishonest right if it makes things up those are sort of fundamental business challenges in addition to kind of technical safety challenges I also think something we have really aimed to do as a business is sort of take the responsibility of developing this very powerful technology quite seriously right we uh we sort of have the benefit of being able to look back on several decades of social media and say like wow much of what social media did for the world was incredibly positive and there were these externalities that nobody predicted that it created which I think are sort of now widely believed to be quite negative for people so I think anthropic has always aimed to say what if we could try and sort of build this technology in a way that better anticipates what some of those risks are and helps to prevent them and the responsible scaling policy is basically our first attempt to do that right it might not be perfect there could be things about it that are sort of laughably wrong later but really what we've said are you know what are the dimensions on on which something can go wrong here right and um you know our CEO my brother Dario testified to Congress about the potential risks for generative AI to develop things like chemical and biological weapons and what we've said is we actually have to do proactive work to ensure that these models are not able to do that and the responsible scaling pact is really just a way of sort of saying hey we're committing to doing that work thank you for sharing that uh let's see any questions from the audience yes thanks so much um one of the things that I think was really awesome about the the Claude Opus release was that it was really strong specific performance in a few domains of interest and so I was wondering if you could talk more about um kind of like technically how you view the importance of research versus compute versus data for specific domain outperformance and what the road map looks like for where CLA um will continue to get better yeah um that's a that's a great question I think my real answer is that I think you're probably giving the industry more credit than it deserves for having some like perfectly uh sort of planned structure between like we'll we'll sort of you know research area X and like increased compute will improve y um I think I think there's a way in which training these large models is more a process of uh Discovery by our researchers than kind of uh intentional deliberate decisions to like improve particular areas to kind of go back to that like Rising tide lifts all boat sort of analogy um making the models just generally more performative tends to just make everything better sort of across the board that being said there is sort of particular targeted work that we did do in some sub areas with constitutional Ai and reinforcement learning from from Human feedback where we just saw that performance wasn't wasn't quite as good um but it's actually a smaller fraction than you might think compared to just generally improving the models and making them better it's a great question yes Sam um I've been loving playing with Claude 3 Claud Opus it's fantastic and I totally agree it feels way more human to talk to one thing I've noticed that it almost feels like a specific human like it has a a personality and I'm kind of curious as you guys continue to work in this domain and make other models how you see the boundary of um kind of like personality development if people are kind of trying to create specific characters um is there kind of a stance you guys are taking from the constitutional perspective of the boundaries of how Claude can actually play a character other than itself so something that is really I think unusual about kind of Claude is just how like seriously Claude will take feedback about about its tone right if you're like Claude you are this is this is too wordy like please just be very factual and talk to me like I am a financial analyst like try it out Claude will absolutely sort of adjust its style to be more kind of in that in that sort of you or hey I'm writing you know a creative writing story like please use very flowery language or talk to me like you're angry at me or talk to me like you're sort of you know friendly or whatever um I think I think there's sort of an interesting other thing you're asking though which is like what is the default mode that we should be setting these models kind of personalities to be and I don't think we've I don't think we've sort of landed on kind of the perfect the perfect spot but really what we were aiming for was like what is a slightly wiser better version of us kind of how would they react to questions right like some humility I'm oh I'm sorry I missed that um or thanks so much for the feedback like I'll try to do that better I think there's kind of an interesting fundamental question though which is as the kind of marketplace evolves do people want like particular types of of kind of chat Bots or chat interfaces to sort of treat them differently right like you might want to sort of coax a particular form of customer service bot to be like particularly obsequious or um I don't know there there are just kind of other potential use cases my guess is that's probably going to end up being the province of like startups that are built on top of tools like Claude um and I think our stance might might vary a little bit there but in general we've tried to start from a like friendly humble uh base and then let people tweak them as they as they go within boundaries of course hey um so the developer experience on Claude and the you know the new generation of Claude 3 models is markedly different than other llm providers um especially the use of XML as like a prompt templating format how are you thinking about introducing switching costs here and especially in the long term do you want it to be an open ecosystem where it's very easy to switch between um anthropic and your various competitors or are you thinking about making more of a closed ecosystem where you know I'm working directly with anthropic for all of my model needs so I think I think maybe the best way to answer this is what we've seen kind of in the market today which is that most like big businesses are interested in at some point you know some some of them just use one model but they they like to try them out and my guess is that likely developers will have that same Instinct right so I think the more kind of open hey like it's whatever it's easy to download your data move it over um I think that's the sort of goal that we're trying to eventually aim towards the one sort of difference I would say is that often developers particularly when they're just getting started are like the switching costs are just more laborious for them right they're like hey I'm I'm I'm building on this tool it's annoying to switch like it's complicated to switch you have to sort of redo your prompts because all of the models like react a little bit differently just depending on and like we have great prompt engineering resources like please check them out and also it just takes some time and effort to like understand the kind of new personality of the model that you're using so I think my kind of short answer is yes we're aiming for sort of that more open ecosystem but also it's it's sort of tactically hard to do in kind of a perfect way um with interpretability research I'm curious what you think is coming first to the product like what what is looking most optimistic where I could say like turn on a switch and have it only output Arabic or something like that what what do you think is like closest working so interpretability is a is a team that is deep Dey close to my heart despite me like not being able to contribute anything of value to them other than telling them how great they are I think interpretability is to me like the coolest and most exciting area of AI research today because it's fundamentally trying to figure out like what what are these models actually doing right it's it's like the Neuroscience of of of like large models I actually think we're like not impossibly far but like not that close from being able to sort of productionize something in interpretability today right the kind of Neuroscience analogy is a little bit strange but I actually think it's it's relevant in one particular way which is that like we can have a neuroscientist like look at your brain and be like well we know that these two things light up when you think about dogs but it can't sort of like change you thinking about dogs right it's like you can sort of diagnose and understand and see things but you can't actually like go in and change them yet and I think that's about where we are at sort of the interpret level could we offer some insight like in the future I think almost certainly yes probably not even on a a crazy long time skill right we could say hey if you're playing with sort of you know this type of model and it's it's you know it's activating Strangely I think that's the type of thing we could like show a sort of visualization to a customer of I don't actually know how actionable it is if that makes sense right in sort of the same way or like well these these sort of two parts of the model are are lighting up or this set of neurons is activating um but I think it's it's it's an interesting area of like very basic science or basic research that I think could have incredible potential applications like a couple of years from now I'll ask a question uh what maybe give the folks here A Taste of what's going to come on the product road map let's assume that Claude gets smarter and smarter but what are you all going to add on the developer facing product and then what should we expect in terms of first party products from you so uh first of all we uh we are just sort of scrambling day in day out to try and keep up with the uh incredible demand that we have so we are incredibly grateful for everybody's patience but I think really on the kind of you know developer side we really want to just uplevel the tools that are available for developers to be able to kind of make make the most use of of Claud sort of broadly um I think something that's really interesting just sort of speaking to the kind of ecosystem point is there's so much opportunity for like knowledge sharing and sort of learning between developers and between people that are kind of using these models and tools so we're also very interested in just sort of figuring out how to host more information sharing about how to get the most out of these models as well wonderful yes oh you have the mic yes go for it um given your um focus on safety I was hoping you could comment on how you see the regulatory landscape evolving um maybe not so much for you specifically but for the companies that are using your models and others so something that I think is just always an unknown is like what what's going to happen in the regulatory landscape and how is it going to impact like how we build and do our work kind of in in this space I think I mean first of all I don't have any amazing pressions to say like this set of regulations I expect will happen but I I imagine what we'll see is kind of on it will probably start from a place of the consumer because that's really what kind of governments and Regulators are sort of most well positioned to try and defend or protect and I think a lot of the kind of narrative around data privacy is one that I expect will sort of see emerge right around just hey what are you doing with my data right people put personal things into these into sort of these interfaces and they want to know like are the companies being responsible with that information right what are they doing to protect it are they de anonymizing it we don't train on people's data but if C if other companies do like what does that mean for that person's information um completely speculative but that sort of is my guess of of where things will start I also think there's a lot of um interest and activation in sort of the policy space right now around like how to develop these models in a way that is safe from a sort of bigger picture like capital S perspective right some of the sort of scary things I I talked about but again like regulation is is a sort of it's a long process and I think something we' have always aimed to do is work closely with policy makers to give them as much information as possible so that there is thoughtful reg regulation that will you know prevent some of the potentially bad outcomes without sort of stifling Innovation thank you danela thank you do we have time for one more question okay one more I'm getting I'm getting looks from Emma sorry hey Danel Claud fre is awesome thank you um when you think about the model family and the hierarchy of models you have any thoughts on whether um it is effective to use prompts or you've done any work internally on giving the smaller models Insight that larger models are available uh to kind of say hey this is beyond my knowledge but this is a good time to use the larger model that is such a good idea are you looking for a job that is a that's a great idea um that has not been something we have currently uh trained the models to do I actually think it's a great idea something we something we have thought about is just how to kind of make the process of switching between models within a business just much more seamless right you can imagine that over time the model should know like hey you're you're not actually like trying to look at like macroeconomic Trends in like the 18th century right now you're just like trying to answer a sort of Frontline question you don't need Opus you need Haiku and I think some of that is sort of a research Challenge and some of it is actually just a product and engineering challenge right which is how well can we kind of get the models to self-identify the level of difficulty and really sort of price optimize right for customers to say you don't actually need Opus to do this task it's really really simple pay you know a tiny fraction of the cost for haou and we'll just switch you to Sonet if it's sort of somewhere in the middle um we're we're not like we're not there yet but I think that's definitely something we've been we've been thinking about and a request we've been hearing from from customers but I love your idea of adding in the sort of um the sort of like self- knowledge of the models it's a cool idea the callif friend exactly yeah wonderful thank you so much Daniela thank you for sharing with us today thanks for having appreciate [Applause] it