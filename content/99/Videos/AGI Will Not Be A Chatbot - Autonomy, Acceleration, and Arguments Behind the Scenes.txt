in the last 48 hours there have been a flurry of Articles and interviews revealing key details about our march to artificial general intelligence I'm going to extract out the most interesting parts and Link them to a series of other recent developments and if there's one theme it's that the AGI these companies are creating is not just a clever chatbot and is coming much sooner than you might think if AI is a lot more than just a clever personal assistant what actually is it well let's turn to this bombshell article in wired they say open AI doesn't claim to know what AGI really is the determination would come from the board but it's not clear how the board would Define it Sam mman who is on the board of open AI said I would happily tell you but I like to keep confidential conversations private and then said but we don't know what it's going to be like at that point not being able to Define AGI continues on their website where they first say that AGI is AI systems that are generally smart smarter than humans but elsewhere they say their definition of AGI is highly autonomous systems that outperform humans at most economically valuable work and back to the just relased article it seems that confusion continues with Microsoft it says Microsoft wasn't even bothered by the Clause that demands reconsideration if open AI achieves AGI whatever that is at that point says nadela the CEO of Microsoft all bets are off it might be the last invention of humanity he notes so we might have bigger issues to consider once machines are smarter than we are open AI even have a legal disclaimer that says you as an investor stand to lose all of your money we are not here to make your return we're here to achieve a technical Mission oh and by the way we don't really know what role money will play in a post AGI World in their restructuring documents they have a clause to the effect that if the company does manage to create AGI all Financial Arrangements will be reconsidered but not clearly def finding AGI seems to play into the hands of Microsoft who can always say well we haven't reached it yet I don't think Microsoft is going to lightly allow all of their trillion doll Financial arrangements to be reconsidered and again we have this the company's financial documents stipulate a kind of exit contingency for when AI wipes away our whole economic system but then apparently the company's leadership says this it would be hard they say to work open aai if the individual didn't believe that AGI was truly coming and furthermore that its arrival would mark one of the greatest moments in human history why would a non-believer want to work here they wondered three more quick insights from wired before we move on first that samman was planning to run for governor of California before he planned to build AGI second that in a 2015 interview with the same journalist at wired samman was a bit more clear about what he thought the job impacts of AGI would be he predicted the challenge of massive Automation and job elimination that's going to happen this chimes in with a quote from the new book The Coming wave that I got Early Access to written by Mustafa sullon the head of another AGI lab he said these tools are only temporarily augmenting human intelligence but they are fundamentally labor replacing and finally from wired was this quote that I found really interesting samman's original Vision was not to make a single entity that is a million times more powerful than any human he wanted lots of little AIS not one super intelligent AI but samman is now talking about making a super intelligence within the next 10 years that's as productive as one of today's largest corporations which don't forget have millions of human employees this fits in with his view that AGI is only going to get built exactly once once you've got it you could then use it to build everything else and if you think the the timeline of within the next 10 years sounds wild wait till you hear some of the quotes towards the end of the video and the key thing to remember is that it's not about models just getting more smart it's about them being more capable more able to match a goal with a set of actions as the chief scientist at open AI Leah sukova said the upshot is eventually AI systems will become very very very capable and Powerful we will not be able to understand them they'll be much smarter than us notice the words capable and Powerful there and his vision by the way is that we imprint on them like a parent to a child so that they eventually feel towards us the way we feel towards our babies now I don't know about you but it's challenging for me to imagine the human race as a baby in the arms of an AGI or super intelligence but some of you may be thinking is a super intelligence just a really smart chatbot that sits on a web page somewhere well no for many reasons starting with the fact that we're we're building autonomy into them I've already discussed on the channel how open AI are working on autonomy and here's Google deepmind recruiting for the same purpose and what kind of tasks are we talking about what about commissioning from a factory the purpose of the modern sharing test is to measure what an AI can do not what it can say capabilities practical creation of real things in the real world or the use of digital tools invent a new product from scratch to get that manufactured by commissioning it in a factory negotiate over the the blueprints of the product actually get it drop shipped and sell the the new product his company inflection AI want their Pi personal intelligence to be your digital Chief of Staff booking flights bargaining with other AIS and maybe even making a million dollars this is particularly interesting to me because sullon says that they are not working on autonomy I do I think that we may be working on those capabilities but they won't necessarily represent an existential threat I I I think what I'm saying is they indicate the beginning of a trajectory towards a greater threat right at inflection we're actually not working on either of those capabilities recursive self-improvement and autonomy and I've chosen a product Direction which I think can enable us to be extremely successful without needing to work on that I mean we're not an AGI company we're not trying to build a super intelligence but aside from autonomy what else might AGI or super intelligence entail well how about matching or exceeding the problem solving ability of the best human mathematicians within a decade wait scrap that 2026 Terren ta who I believe is recorded as the highest IQ human around said this when integrated with tools I expect say a 2026 level AI when used properly will be a trustworthy co-author in mathematical research and in many other fields as well what else well how about self-improving capabil abilities this is from the AI power Paradox in foreign affairs soon AI developers will likely succeed in creating systems with self-improving capabilities a critical juncture in the trajectory of this technology that should give everyone pause open AI agrees saying it's possible that AGI capable enough to accelerate its own progress could cause major changes to happen surprisingly quickly and back to sullon in foreign affairs with each new order of magnitude unexpected capabilities emerge few predicted that training on Raw text would enable large language models to produce coherent novel and even creative sentences few are still expected language models to be able to compose music or solve scientific problems as some now can an order of magnitude don't forget means being 10 times bigger but how about a thousand times bigger than GPT 4 in 3 years right so if everybody gets that power that starts to look like you know individuals having the power of organizations or even States I'm talking about models that are like two or three orders of magnitude maybe four orders of magnitude on from where we are and we're not far away from that we're going to be training models that are 1,000x larger than they currently are in the next 3 years even at inflection with the compute that we have will be 100x larger than the current Frontier models in the next 18 months you can start to see why AGI means so much more than just a chatbot and here's another example this again came from solon's book released 2 days ago he talks about the one a cry Ransom whereare attack that caused billions of dollars of damage back in 2017 and he said imagine oneoc cry being able to patch its own vulnerabilities learning to detect and stop further attempts to shut it down a weapon like this is on the horizon if not already in development let's move on though from sullon to Demis hassabis head of Google Deep Mind and this article yesterday in Time Magazine which was fascinating apparently hbus warned Elon Musk about the the risks from artificial intelligence back in 2012 saying that machines could become super intelligent and surpass as mere mortals maybe that's why he's glad that chat GPT moved the Overton window the window of what it's permissible to discuss in public in 2012 it was probably embarrassing to talk about artificial intelligence let alone AGI we also learned that musk tried to stop deep mind being sold to Google musk put together financing to stop the deal and had an hourong Skype call with hassabis saying the future of AI should not be controlled by Larry that's Larry Page one of the co-founders of Google obviously that didn't happen and we are soon set to see Gemini from Google deep mind that's their rival to gp4 I've got a whole video series on it so do check that out but the Revelation from today was that hassabis said this Gemini represents a combination of scaling and Innovation it's very promising early results and as a Londoner like me hassabis will be prone to understatement so a British person saying very promising early results means it might shock a few people now you remember from earlier in the video where I quoted ultman back in 2015 saying this AI is about making humans better not a single entity that is a million times more powerful well for musk who remember co-founded open AI that was apparently the vision behind neuralink that's his attempt to tie the Bots closer to humans making them an extension of the will of individuals rather than systems that could go Rogue and develop their own goals and intentions another idea for musk would be to build a sustainable human Colony on Mars before anything went wrong speaking of going wrong we also have this from Demis hassabis in Time Magazine he was asked are there any capabilities that if Gemini remember that's their version of GPT 4 or 5 exhibited them in your testing phase you'd decide no we cannot release this he said yeah I mean it's probably several generation ations down the line and then for anyone who's watched my smart GPT series they'd know that I would agree with the next part I think the most pressing thing that needs to happen in the research area of AI is to come up with the right evaluation benchmarks for capabilities because we'd all love a set of maybe even hundreds of tests where if your system passed it that could get a kite Mark and you'd say right this is safe to deploy the problem is we don't have those types of benchmarks currently for example is this system capable of ction can it replicate itself across data centers this is the kind of level we're talking about these are the sorts of things you might want to test for but we need practical pragmatic tests for them I think that's the most pressing thing for the field to do as a whole our current evals and benchmarks are just not up to the task apparently we have plenty of time to do this at least according to sullon who don't forget along with hassabis was the co-founder of Deep Mind many of us more or less expected we're more or less sure was coming which was there'd be a breakthrough at some company like deep mind where we would you know the the people building the technology would recognize that they had finally gotten into the end zone or close enough to it so that they're now in the presence of something that's fundamentally different than anything that's come before and there'd be this question okay is this safe to work with safe to create an API for the idea was that that you'd have this digital orle you know in in a box you know would already have been air gapped from the internet and incapable of doing anything until we let it out and then the question would be have we have we done enough safety testing to let it out but now it's pretty clear that everything is already more or less out and we're building our most powerful models already in the wild they're open- Source versions of the next best model and is containment even a dream at this point it's definitely not too late we're a long long way away this is really just the beginning uh you know we we have plenty of time to address this the more that these models and these ideas happen in the open the more they can be scrutinized and they can be pressure tested and held accountable so I think it's great that they're happening in open source at the moment we have to be humble about the Practical reality about how these things emerge the initial framing that it was going to be possible to invent this Oracle AI that stays in a box and we'll just probe it and poke it and test it until we can prove that it's going to be safe that we'll stay in the bunker and keep it hidden from everybody I mean this is a complete nonsense and it's attached to the super intelligence framing it was just a completely wrong metaphor he might want to tell that to hassabis who said this recently if a system didn't pass the evals that means you wouldn't release it until you sorted that out and perhaps you would do that in something like a hardened simulator or hardened sandbox with cyber security things around it so these are the types of ideas we have but they need to be made a little bit more concrete I think that's the most pressing thing to be done in time for those types of systems when they arrive and here's the key moment because I think we've got a couple of years probably or more that's not actually a lot of time if you think about the research that has to be done I think I am much closer to hassabis than sullon on this one personally I'd love a button where you could click at the exact moment where you want want AI to stop for me that would be after it cures Alzheimer's but before it creates rabies 2.0 it would be after it solves mathematics but before it gets too good at Warfare maybe such a button could be devised at Bletchley Park in November which was the place where the Enigma was cracked in World War II they are being advised by some of the top mines in AI so there is a chance and apparently they want 10 times as many people to join them in the next few weeks but anyway at the very least I hope I've persuaded you that AGI is going to mean a lot more than just clever chat Bots thank you so much for watching to the end and have a wonderful day