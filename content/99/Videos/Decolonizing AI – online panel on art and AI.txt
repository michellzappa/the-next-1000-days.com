Hello and welcome everybody to
Decolonizing AI talk, which is part of »Taming AI« series that
are organized in collaboration with Deutsches Museum and ZKM. I am Raziye Buse Çetin, and I
research the social impacts of AI. I'm also the co-founder of Research and
Art Collective »Dreaming Beyond AI«. And today I am joined by wonderful
guests, artists, and thinkers. There is Nora Al-Badri with us
Mushon Zer-Aviv, and Vulane Mushon. Welcome and thank you so much for joining. So I'd like to start with a quick
introduction about you and your work, although it is brief and probably
doesn't do justice to all the breadth of what you're doing in your practice. So Nora is a multidisciplinary
and conceptual media artist with a German Iraqi background. And her works are research based as
well as para disciplinary and as much post-colonial as post-digital. Her practice focuses on the politics
and the emancipatory potential of new technologies such as machine intelligence,
and Nora's artistic material is a speculative archeology from puzzles to
artifacts or performative interventions in museums and other public spaces that
respond to the inherent power structures. Thank you for joining today, Nora. Welcome. Thanks for having me. Looking forward. And we have Mushon Zer-Aviv, who is
a designer, researcher, educator, and media activist based in Tel Aviv. His love and hate relationship
with data informs his design, work, art pieces, activism, research,
teaching workshops, and city life. Mushon is currently writing a
nonfiction book on friction and flow, a political design theory of
change that I'm very excited about. Welcome Mushon. Thank you very much. And lastly, we have Vulane Mthembu, who
is a creative technologist, composer and musical artist, and he advocates
for open data and worker cooperatives. And he has experimented a lot
with AI in music and also released an album in cooperation with
AI among many other things. And he is based in Johannesburg. Welcome, Vulane. Thank you for having me, and
looking forward to the conversation. Thank you. So today's conversation
is Decolonizing AI. There has been particular attention from
the media artists, colors, activists, and even policy makers to this. Intersection of AI and
decoloniality or decolonization within the past couple of years. Some talked about how AI is creating
a new colonial order because of the market concentration. Some focused on the extractivism that
manifests in the extractivism of data from users and especially from users
from the Global South or inequalities in the value chain or even in taxonomies. But I wanted to ask you how you
understand AI basically, what is this? What, does AI mean to you as a
technology, which is also a big topic of discussion, I think, and it's and it's not
straightforward and in which ways it is creating, in your view, a colonial order. A dynamic of center and peripheryperiphery
which is an important dynamic of colonization and colonialism. So who would like to maybe
start commenting on that? Let's start with Nora,
maybe as she is smiling. No. Okay. I'm happy to. What does it mean to me? I don't know of course, it's
a very complex question. The short answer probably is
it's just another technology. And I think as any technology
it can be used in many ways, but to me it's primarily a tool. I think the aspects, one of the
many aspects I find interesting, I think is for example, and you can
also see it in my works and in other artists works dealing with AI, that
you can now put together a mass of data that kind of mirrors society,
mirrors the people who did the input. And of course in order to work with any
tool, you kind of have to understand it. And even if you want to subvert a
tool, which I would say is part of Decolonizing any technology, then you
certainly have to understand every bit and piece how it comes together. Like what is behind, what
you mentioned, what is that ghost labor that goes into it? Why are we talking about abstract
with abstract words about machine learning, actually as I prefer to
call it not machine intelligence. I want to try to demystify it, but at
the same time, what I find interesting is that with a sheer amount of data,
we can now look, dive into a collective consciousness in a way, without being
anything conscious in the thing itself, in the technology itself. But yeah, maybe later, I go a bit more
deeper into what I mean with this. Or what I find exactly interesting. This is one part of the answer, I guess. Yeah. There are many aspects and we
probably have the occasion to talk about and dig deeper in them. I said, what AI means to you because,
because, besides being a tool I also think that it mobilizes a certain
set of ideologies and ideas and imaginaries and symbols and so on. Oh, yes. Okay. Then maybe because one, one thing I
focus on, I think in AI is the past. In a way they think AI is a very
past oriented technology, contrary to the public, maybe that tries to
picture it as something very future oriented or coming from the future to
us by magic falling from the sky or, so that's not exactly what happens. I, would say the contrary is true because
in the moment you train the neural network, the data is already old, obsolete
from the past, because it had happened. And that also means that everything
the AI can generate is basically based on past knowledge systems past power
structures and so on and so forth. Although I certainly like to point
out always that in every technology there is a huge emancipatory space and
depending where you go, how you for example, train the neural network with
what kind of databases you can create Southern decolonial databases as well. But it's usually not done. The contrary is true. I think with big GAN, like all the
big image based neural networks, more than 90% of the data sets
are from the global north. So we have a kind of visual
hegemony, that's very important to know when we look at all those. Now also in play image
creating networks for example. So it's kind of all the same. And so yeah, if you ask me
what does it mean to me, it's. It's the past, but then it
can be very interesting. In one of my works, Babylonian Vision,
for example, I put in a Mesopotamian dataset from the past, to search through
the image worlds that were created at that time through thousands of
artifacts from very different materials. And for that it worked really well. And yeah, I liked it. Yeah. I'm really excited to talk more
about your work and how you also see temporality past future with using the
emancipatory potential of these tools. But what you said about this visual
hegemony or like the hegemony of the past and mostly the colonial
past and post-colonial, basically continuum of this past in the
dataset and not only the datasets. It's a great way to tie to I
think Mushon work »Normalizing« and other parts of work. Maybe you want to take it on from
here and also tell us a little bit more about how do you see the
intersection of the coloniality and AI? I think the focus on the
past is really important. And in a way you mentioned
my work »Normalizing«. Normalizing is directly
looking at the past and the history of what we call AI now. And you asked how do we define AI? For me it's mainly advanced automation
and advanced statistics, right? So advanced automation that is
based on advanced statistics. And then we need to get to truly
understand it, we need to get to the history of automation
and the history of statistics. With »Normalizing« I'm
trying to do the latter. Just briefly, »Normalizing« is an online
experience, where you go online and you are asked to teach the machine
how does a normal person look like? And you take a selfie and then you're
presented with segments of faces and you need to decide between pairs of
noses, eyes foreheads mouths, and faces need to decide which one of the
two, each time it looks more normal. And that's how you kind of teach
the machine something that we actually do on the street every day. We're probably doing that right
now, looking at each other's faces. And that classification and that the
way we turn our everyday experience into knowledge and then classify
it for machines to automate. I think that requires some reflection. And the focus on the term normal, because
it's so abnormal, the term normal. And through the work itself I found that
the word normal is not normal at all. When I was trying to translate the
word to Arabic for the first time I presented the first iteration of
the work, I realized that the word normal doesn't really exist in Arabic. And, and I'm like: how come? Normal should be the most normal word. And then other words that were suggested
by translatorsinstead were "a tabieiun", which actually means natural and other
words that actually meant regular, but then normal was so abnormal. And today we actually build on
these systems of normalization. So systems that take this statistical
concept of normalization and feed that into the infrastructure
of the world we live in. It's worth looking at what do
these systems produce? I feel like they produce
an image of the past. They analyze the past through,
at the end of the day, the basics of statistics, which is around
deviation from the norm, right? This idea of the bell curve. Which is something we happend
to get from the same person who brought us eugenics, right? Francis Galton. And so there's a very strong tie
between how are we looking at, how are we turning things into data? How are we analyzing them,
and how would we use that to reflect on possible futures? So maybe I'll stop here. You said that we are, as human beings
automatically also, when we are walking on the street or encountering people,
look at their faces and judge and try to also categorize and match them. But I think here the normal that
you're interrogating is more like a historical systematized historical normal. A normal that had consequences in
terms of power and distribution of humanity opportunities dignity
and so on and so forth, right? And there are still people who are
developing, although yours is an art project, applications of AI that would
basically scan people's faces and create a probability that would try to
predict if this person is reliable or a hard worker and so on and so forth. And which is being used, even
at the moment, although it sounds maybe abnormal to us. So I wanted to transition to Vulane
and ask you the same question. What is this intersection for
you and in your work around decolonization, decoloniality, and
AI and also your lived experience? Because it's not only a
conceptual framework, right? Yes. Thank you Buse And I'll try and not
echo a lot of what my colleagues have mentioned as well, because
I think this is very common. It's a common thread throughout all our
work, particularly of people who are not necessarily from the global north. And it's usually, most of the time,
when you are starting to engage with AI in maybe in a transdisciplinary
practice, or in a medium like that you always encounter, one of the
first things you encounter is of course the lack of the dataset. Which is of course, as much as
you want to create something, you have this dilemma now of having
to do a little bit more work. Because you have to gather this
information so that the AI could, you could start actually working on the
project that you really want to work on. And I don't think necessarily this is what
artists in maybe other regions will want. I think this is a very
specific Global south problem. And that's, what we need to address. And I'm glad to see that in the past
few years or so, there's been quite a push in terms of NLP and Institution
Research Institute that are pushing in terms of putting datasets and
getting all this information and all this data from language that's
spoken from customs and everything into training AI, which is great. So coming to your question, what does
AI mean to me and how it applies to my practice and how I do my work? It's definitely, I see it as just
another development technology, which has been long overdue of course. And I definitely welcome it,
embrace it because it allows. I've seen that there's actually
something very interesting about it. Primarily how I look at it from
my point of view is that I, when I first started, which is with »Nguni
Machina«, the third project that is out there of course is coming from
the Nguni, which defines the tribes from the sub-Saharan region of Africa. It's a common sort of ancestry that is
shared with all the languages, most of the languages in sub-Saharan Africa. Well, primarily I was more interested
in the technicalities of it. Because I really wanted to find out
how this is achieved and how the AI implementations are realized. And I quickly discovered that
actually that's not what I find most interesting about AI. It's actually what surrounds it. What is the social impact of it? Like what is going to happen
that we have this technology now. What about this human humanity? How are we going to deal with basic
things like working and how we relate to other people trust systems? How are we going to trust if we talking
to someone, if they are really who they say they are in the age of AI. And of course things like
universal basic income. So I felt that as a tool, that
accelerates this sort of conversation, social conversations also curatorship. Things that we generally have a certain
way of categorizing and defining them, that now will have to be redefined in
this new age and how we're as a society. So I feel like for me, for my work,
most of it, and the current work that I am doing, is actually leaning towards
the actual, what surrounds the AI. And in society, what is the impact? How are people going
to live alongside this? Because it's not going away. So this for me raises a
very interesting question. So I'm very preoccupied with these things,
and most of the time now, more so before, I used to get very technically involved in
the project because at the time, the tools weren't as advanced, as you all know. They advance they're
moving at breakneck speeds. We didn't have much datasets.
So now we do have people that are focusing on these and trying to... They are doing a lot of research in this. So for most of the technical part of
it now, I usually will collaborate with someone who is maybe a data scientist
who will actually be fully involved in that and actually I'll concentrate
more towards interrogating the social impact of what we are producing. So that's why I find most of
my work now going towards... I hopefully it answers. Yeah, exactly. I think I also agree that it accelerates
a lot of societal questions and concerns and makes us basically question things
that we have maybe taken for granted. Like the meaning we also
assign and ascribe to things. Then I wanted to ask you a little bit
of a tricky question because it's me. For me, it's also a little
bit of a question mark. It's the question of positionality
and also in feminist epistemology, is this view from nowhere criticized
like knowledge production? Scientific knowledge that we
understand as objective, and we don't care who said it or who wrote it. Of course I'm a little bit caricaturizing
but since we, we are maybe to a certain extent, if it's fair to say, products
of patriarchy, capitalism, colonialism, or at least we have been socialized
or grew up in environments, where the systems are or were embedded. How do you deal with your positionality
and where are you speaking from today and how this comes up in your
work practice or thinking about decolonization and decoloniality. Who would like to take this? Go ahead, Vulane. Thank you. Oh, no, why did I unmute? Okay.
It's a very interesting question, right? And I think it's actually in my case. So I'll speak for my person because I
believe that's the way the question is more directed towards the individual. I've been realizing during the last
two to three years or so, the position changes every time and how I see myself
as within the work that I'm doing and also what the work represents. And besides the work, just what I'm
trying to achieve. When the project started or »Nguni
Machina« or the work that I've done around this topic, it was usually around
questioning whether AI is good enough to pass off as a human or be decent enough
to be compelling, to make compelling art, which I feel as time has moved. But this is also from someone who is...,
That's why I had to put it in the name that it's »Nguni Machina« and actually
specify this is from someone who is African from the Global South, how they
see their position in terms of what AI is representing, and also what machine
learning and the whole thing is about. But every, I would say every six months
or so, it seems to be changing my position in why, what it is because there's all
the work that is being done by colleagues and other artists and in research as well. In the scientific research field,
there's always something new that makes you see a blind spot in your
positionality that you had before, that you have to confront and change. So it's very fluid. Currently, right now where I am, my work
on the current project, I'm involved in which involves zero knowledge
protocols and how that could be used to prove humanness, for example. Because I feel like every time that we
interact with any screen, there has to be like a mini touring test that has
to be done because you can't trust. So the next person is gonna be
called to not trust the screen, and it's basically around that. But it's not. It's moved from a case of me
being looking at what initially, obviously was how good is AI? And then it moved to, okay, we don't
have data as we need to represent more projects more thinking system, more
thinking systems, more everything from the Global South, to also  what it does
to society in terms of how people are things that, like you mentioned earlier,
are taken for granted that now people can just easily, they  need to be aware
of and consciously think more about actually proving just being a human. And it's more, I think, the core
question where it's all gonna lead. I think this is maybe, if not now,
but it could be a post-colonial sort of question that needs to happen. When is it just being clearly
marking it as a human being. How do we even define it or prove it
when AI, of course, as it drops, as it rushes through towards super intelligence. So I have this one foot in this what
AI socially is doing in a Global South from a Global South perspective,
from an African perspective. But at the same time, I have this very
consuming, all consuming fixation with how we're going to prove humanness
in the not so distant future. So I hope that I'm gonna stop here. Maybe I can jump in. I think the perspective that you
are bringing forward and maybe taste in a bit to the point that Buse was
making about the view from nowhere. It goes back to what Donna, Haraway
was talking about when she was discussing maps as being something
that plays the gut trick, right? The gut trick being the view
from nowhere of seeing without being, without embodiment, right? And now, and she was back
then talking about maps. But I think I'm a map maker in general. And map making, I find it to be very
relevant to our conversation because maps are models of the world, right? Geographic maps are in our
geographic geometric models of space and the other types of mapping. But now when we are talking about
AI and AI is obviously a buzzword. But we can talk about specifics more
specific, like LLMs large language models like it's used with Chat GPT. They are trying to create this
totalizing map of the world, right? A totalizing map of knowledge. And I think that's where the use of maps
and the history of maps in colonialism and the use of mapping and creating
this totalizing view  from nowhere in the case of AI may be useful for us
in the conversation of decolonization. So why are we using this
term decolonization now? What is the territory
that is being colonized? Who are the colonizers? Who are the indigenous. Who's the indigenous community? I think, there is a certain potential
in using terminology that is as kind of loaded, as decolonization. But, but there's also danger,
because it implies certain type of affordances, certain types of political
potentials or certain dangers. And sometimes I feel like it
conceals more than it reveals. It certainly does. I agree. Yeah, absolutely. Intentionally, I'd say. Yeah. Maybe to add to this only another
thought talking about positionality and AI or maybe in my case, I'm
not sure how you meant the question actually, if it is more like a personal
thing on looking to our practice. But I think more generally, this is
for my own practice, but also for how I look at AI in general, is that when
we work with it, it's like where is the Global South can be basically anywhere. There is Global South within the north,
and I think it's very important to realize your own positionality as an
artist to see who we are, how privileged. Like from what, from where am I actually. And we talk about privilege
and class and stuff. And if you ask me this question,
I'm half German, half Iraqi, there is no some simple answer to this. And I'm very happy about it because
actually what AI does to the world and to us is, it starts with the language
we are using and labels we are using. We have to basically put
labels on things usually. And that makes this kind of namings
and dichotomies like you and me, black and white,  here and there,
and Decolonizing anything means basically getting rid of exactly that. So one of my main concerns
actually when working with AI or interrogating more maybe is, that
we come always in the end so far. At least I always come to the point that
we get to this kind of esentialization. In the end, we have to put labels down
or names down or categorize things, and that oversimplifies our world. So I think it's very important to always
acknowledge those big limitations because it's a big limitation when you look at
that kind of technology and other forms. I don't know when you look at maybe
making sculptures your limitation is the material and the space. But in AI, it's certainly our words and
then also how we understand each other and how we describe and languages and stuff. So yeah, maybe this is something
I always get to in the end. And I would love to discuss this more. Yeah. I think that then brings me to my
next question also very nicely, which was about, to also have a critical
stance or look at what different people mean by the colonization. There's the territorial aspect of
it, but there's also the structural aspect in which we look at economics,
language, culture ways of words or ways of feeling and so on and so forth. Or different hierarchies that we created. The geopolitics of knowledge
production and our relationship with others, and also the nature. Then I wanted to ask Vulane:
in your contribution to HERRI magazine »Umshini Uyakhuluma«,
which means the machine speaks. I'm not gonna try to
pronounce the name, I'm sorry. Africa and the AI evolution, exploring
the rapid development of artificial intelligence on the continent". You say that the total and
complete dominance of AI in our lives is inevitable. And you cite this book that I'm not
familiar with, against the Colonization taking African agency seriously. This is only part of your article,
but it got my attention and I wanted to understand what you meant by that. And especially where you say that
the total and complete dominance of AI in our lives is inevitable,
which I find is a strong statement. And maybe others would like
to reflect on that afterwards. Oh
thank you. I always lend myself in these situations
because of this language, I guess. I think this also peels out into
what we were discussing earlier when we talked about certain words
and phrases that I use sometimes to stimulate or start a conversation
and to havesort of a discourse. Sometimes using a hammer to open
a window instead of your hand gets a certain reaction that you want,
and there's a sense of urgency. So I just want to say, Buse yes. So in terms of that, the language use
of course is to get that conversation going and to have it happening. For example, the project Nguni Machina
came out, there was a lot of... Which is around two years ago,
which is in AI, in terms of development AI, like a decade or so. But there was a lot of resistance. A lot of resistance, particularly from
traditional creators and artists that felt that no, this is gonna be like a
passing sort of fed or it's a buzzword. Like of course we have seen such things
come up in terms of the conversations that could be had around NFT's and
the metaverse and things like that. And of course, even in those
technologies, if you are heavily involved with the people that are
working in research, then they find that there are not actually a fad. It's just how popular
media spins things around. So I strongly believe it's going to
be a total takeover of a lot of things, whether we like it or not. Whether with the advantages and the
disadvantages that come with it. Of course. And the best way to deal with something
like this is of course to engage. And most traditional artists and some
of my very good friends and actually the people I've worked with it in
the past, in the music field, as well in fine arts field, do a very... let's say we're not speak terms for a
couple few months after the project drops. Because they, I mean, they
didn't like what it represented. But I also had to overcome this feeling
I had when I saw what it was capable of. And the best way to interact with
a technology like AI, which is just gonna be all encompassing is just
to not be light and full on and deal with it I think in whatever ways. That,  what ways those may be. I do not have these answers right now. But I feel like us engaging and doing,
working with these projects, like with my colleagues, Mushon and Nora as well. Consistently engaging and
questioning, that's all we can do. That's the best we can do. I just feel it's second
alcohol, compassing, juggernaut. That's never gonna go away. Then we were putting together the
article, the edition of HERRI you were mentioning now, which is AI in Africa. There was a lot of conversations with
practitioners across the world , from scientists, engineers to creative artists
and transdisciplinary practitioners. And it seems like people who are
working already on this are actually hurting to this one, this new
thing, which is super intelligence So everybody is actually racing. No one is sort of like slowing
down and taking it all in. Everyone is hurtling towards
this super intelligence. There needs to be an urgency, I feel,
and that's why the words that's worded in that way in terms of addressing
it and actively engaging in it. The other book, I believe I quoted there,
has to do with spirituality, which I do not want to go into it right now because
it might be a bit of a long position. But it's very interesting. And it's something I'm still grappling as
well, getting my head around it in terms of what AI  will do to more traditional
spiritual  systems and things like that, which also is fascinating. I think it's something that you might have
dealt with or dreaming of how AI dreams. A desire to say so, which
is also fascinating. I would like to know more. I think after this we might
actually just want to. I want to find out more about that. So that's what I find very interesting. So that's basically in a nutshell what
I was trying to communicate with that. Got
it. Thank you. So I see that we don't have lots of time. There are absolutely two things
that I want to talk about with you. This question of time, temporality
imagination and what you were saying also Vulane, I guess,
people's reactions sometimes. How we imagine the future, how we
react with it, time, past, present. And when I was talking to Mushon, you
said something like, AI is colonizing our imagination if I'm not wrong. And you talked about the terms
conservative, progressive and how we understand them and maybe how
might we understand them differently. So I wanted to first ask this question
about time imagination and temporality to you and then to Nora who's
dealing a lot with this in her work. I think it's back to what
we started talking earlier. About how AI is basically presenting kind
of proposing a future based on stability. So AI or machine learning specifically is
trying to understand probability, right? And to take actions based on probability. And for that probability,
the only resource that it has is what used to be, right? So, to connect to Nora's point
about about these being technologies of the past. I think there are also technologies
that are mostly focused on conservatism. So there's something conservative
by design in machine learning. Because what it can do is only
say: I've identified a pattern. I can see the conditions for
this pattern to continue, or I do not see these conditions. And therefore these systems are looking
to find probable patterns and bet on them. Now we can see it in financial systems. We can see how that be becomes a
mechanism for the rich to get richer and the poor to get poorer, because it's just
extrapolation of patterns from the past. Now when I'm trying to argue that if
there is a colonization that's going on, it's a colonization of the imagination. Because we are  being presented
with this as the image of the future. And the image of the future is
an image of a continued growth of the past of, of those being in a
position of power, continuing to be in position of power and... These AI systems are unable to really
tell us how to break these patterns. They can they can be useful in
identifying patterns and maybe... When we're talking about creativity in
the context of all the creative process, in the context of AI we we're talking
about creating many options, right? All of these many options based on
these statistical models are, they are not the only way for AI to say,
to pick out of a set of options is through looking at patterns from the
past, not through a more radical or transformative imagination for the future. The focus should be placed on this
idea of what do we want to conserve and what do we want to change? You ask me to talk about these two
terms, conservative versus progressive. So these technologies are conservative
because of this continuation of patterns. But then when we're trying to
say if it's not conservative, should it be progressive? The term, the literal meaning
of the term progressive implies a certain trajectory, right? that, that progress, That progress
is to some degree predetermined. And I think in a way these two terms, when
we talk about AI, are not very useful for us because both of them are deterministic. Both of them are saying like, either
the image of the future that we're going to push forward is based on
the continuing patterns from the past or there's this trajectory that we
managed to identify, that requires more, you know more of that change. I think when we're talking
about progressive politics, we definitely can see
things that we label as decolonization, of anti-racism of anti patriarchy of... And a lot of values that we latch
under the title progressive, right? But there's no trajectory there, the
same way, like there's no trajectory in technological determinism in this idea. And that's back to you,
Vulane, of the inevitable. There's nothing inevitable
about this technology. It is man made and we can say
human made, but unfortunately it's very, in too many parts. The bad parts of it are too much men made
in this approach of totalizing control. I think when it comes to the
potentialities of AI, when it comes to futures, then I think we should  put
aside our classic classification of conservative and progressive, because
when we talk about the environment and, you know, we can talk about
the whole environmental movement as being a conservative movement. It's trying to conserve the thing
from the past and to make sure that it's still available in the future. That is not usually what we
mean by conservative, but it is technically conservative, right? There are things for us to conserve
and there are things for us to change. And we need to make sure that the
mechanisms that we built for that, are not only conservative mechanisms and
not only ones that are based on either technological or political determinism. Got it. I guess you're also pushing us to
see beyond dualities, dichotomies, and have some more nuance. And Nora, you know, this AI  that
I associate,  like maybe the most of people, because it's something
that we maybe encountered with science fiction that we associate
a little bit with the future. You look at the past and you scan the
artifacts from Mesopotamia and the regions without taking permission from the museums
and you make machines dream with them. Why do you do that? How do you do that? Okay But before I start with this,
I would love to respond to Mushon briefly because I would want to know
what he thinks about the other terms. Because when I think about AI,
conservativism and progressiveness doesn't really come to my mind necessarily. It's more what you start
with in the beginning. It's, you know, math and statistics versus
our reality, our human experience also. So I just came across a really nice text
this year that actually comes from South Africa, a scholar from Sabelo Mhlambi. And it's called "From Rationality
to Relationality - ubuntu as an ethical and human rights framework for
artificial intelligence governance". So it's a long title. I had to look it up while we were talking. But one thing he talks about
is the idea to get exactly from rationality to relationality. And I think that covers a lot where
we are kind of heading to,  like working with AI or creating AI in
different ways or in other ways. Because I don't know, for me it's not
as much conservative only and conserving the past only, but it's more the
rational approach towards our experience, towards the world that is in the moment. What we do with AI, basically, even if
we pick really nice words for it, right? Or try to describe it in a playful, or
I don't know what manner with dreaming. Dreaming. Also the term, I'm not such a fan because
it obfuscates many things that go on behind the scenes that are of course
not behind the scenes at all, but that are at the core of the technology. So it's always in Germany we say ein
schmaler Grad a small, a thin line where it's useful to go envisioning
a different technological future. Yes, for sure. We have to dream, we have
to be creative with this. But not projecting any hopes
into the technology at all. But you know, more towards us. I guess this is just something, and
I don't know, what do you think about the term rationality and relationality? For me, that covers it because it's
not "wertend" (judgmental) it doesn't assess and puts values towards things. So I'll definitely need to read this. But without reading the article,
I'll just respond to that. Other dichotomy. And I actually don't see that
dichotomy in the latest models of AI. Like I see a rationality  in
the statistical mechanism that is based on data sets, that
are not necessarily rational. That are, if anything relational. So if we talk about these large models
they are based on their relations. How do bits of information
relate to each other? The models themselves are relational. They are written based on a rational
statistics, but what they produce is not necessarily a rational image
of the world, but the relational image of the corpus of data that
they absorbed to create that model. You know, we are able to point at
these problems when we see when they're being irrational and they got to be
irrational or,  in other cases, biased or whatever, through a rational process
of relationality, if that makes sense. I need to read that article. I just shared it and I
think, we're gonna, see it. So we have a little,
very little time left. So there's the rest of
the question to you, Nora. And maybe then, one minute
we can talk about... Yeah, then I'll chime in again. Sorry, go ahead, Nora. And then I'm gonna have last
question. I think yes. In my, in my practice when I work
with AI in the context of let's say, cultural institutions or museums it is
also a very specific context because those when we talk about canonic
national museums, they are very... come from an imperial heritage themselves,
try to conserve themselves, which is very interesting in a specific way. And in the global north, it's
still like a show of power. And now since many years, an ongoing struggle and debate about restitution it is on the one hand, a public
discussion, and actually the whole artifacts and objects are in public trust. But in the end what happens is we see
how conservative our museum directors are, because in the end it's those people
that make the institutions still act. And not really much has changed. And it's just a very
interesting, for me, microscopic. And and good example, good bad
example of course, how power structure still play in our world. So when I go to the museum, it's for
me, the microscope, of course, of a bigger debate between nation states. And everything is tied together. When we talk, for example, about the
most iconic artifact in Germany it's the head of Nefertiti that comes from Egypt. Then we can see that,  it is just a
little example, but why Egypt hasn't officially announced the statute
back is, because they get a lot of development assistance, for example. So it's like the reality of the nation
states directly comes into the museum but you don't see it, of course. And those relations aren't talked about. Because those museums
are so conservative. They are very old school and
they don't understand technology. And in this case it is actually
emancipatory to use new technologies to subvert the power
structures from the museums. Or it doesn't need to be even AI. One other project of mine a few
years ago with another artist was the hack of the statue Nefertiti. To go and scan the bust and then
release the 3D data set to the world. This was another piece not AI
related necessarily, but another one was, for example the Nefertiti bot
2017, I think, where we were with more early chat bots, let's say. But still they did the job in a way. What I made was a bot with a
dataset head of Nefertiti that where I imagined what would objects
actually say about themselves. Because there is also a lot of fantasy,
which is nice, I think, going on about the agency of objects themselves. And I know that in many cultures around
the world, I think in every culture there are always histories and stories
about the objects and their own agency. So it was a female bot,
which we come across a lot. They're usually the servant bots. But in this case, it was a very strong
and and powerful bot that would engage with you in a discussion about decolonial,
the Decolonial Museum basically. And what happened was that the audience
was in the beginning, because they also weren't that used at that time to
this Talking to a machinic interface that has a face and can respond. It worked that people
were like: Oh my God. It's like a intelligent, critical machine. And of course, after engaging,
after five minutes, they could tell, okay, what's going on here? And of course what happened was the
Nefertiti bot was highly biased. It was my personal bias in a
way, which is a decolonial. But I didn't try to hide
it in between the lines. But it was more obvious and that people
observed themselves, like how they were, for a few moments, forgetting
that they were talking to a machine and to a very simple script in the end. Because this was not based on a general
AI, but the most part of the conversations were completely scripted in a way. And also... Yeah. So those are things you can do, I
think where we can play with our own imaginaries giving us maybe
some, sometimes some illusions, definitely about what's possible. But it all relies in the end on the
creativity of the audience in the end what they respond to and what they like. Yeah, I'm working on a new piece and
sometime because I have small babies now, it takes some more time, but
it's a piece that talks again about identity theft, but more in the manner
that we know it now with deep fakes. You can now also steal
identities back from people who were in the museum in a way. As much as they steal identities
through owning cultural artifacts and yeah, to engage in those topics. For me, it completely makes sense by using
the same technologies that we discussed. Because for exactly that reasons,
because they are actually essentializing the world. But that can be sometimes
emancipatory too. Then we we're over time. But I want to ask a last question. And that maybe you can, if you can try
to reply like briefly is exactly this. Now we have AI generated text, AI
generated music, image sound, deep fakes you know, like all these
also converge and become very realistic with widespread access. Is it, do you think leading to a
sort of reality collapse or how do we deal with this as societies
and what does it bring for you? That is a small question, right? That's the one that is supposed
to generate short answers. Yeah, I mean, you can try just yes or no. I mean, if there is interest and appetite,
if you're already tired, we are over time. I don't have to, but I was a
bit interested in your opinion. I think I'll try to respond to
that through maybe back to the term that we used for this panel. Like this idea of Decolonizing AI and
I think it's important to see that there are quite a few issues that
could be thought of as, issues of decolonization when it comes to AI. And it's worth kind of
separating them apart. So the first one should be the
infrastructural one, like when it actually comes to the minerals that are
essential for creating these machines. And coming back to the embodiment
and the material that should give us another perspective on the question of
inevitability, because these minerals are running out and we are already
seeing shortages of of semiconductors. And all of these dreams might be
just irrelevant because there's no hardware to run them on. And that is definitely shaking the
world and we're talking about, a possible invasion of Taiwan only
to take control of the fab labs that, creates these semiconductors. So that can definitely be. And not even to start talking
about how the Global South is pillaged for these technologies. So that's one topic of decolonization. And another one has to
do with the datasets. And we talked a lot about that,
like how the datasets are becoming. You know, the territory
that is just sucked in. And I know you talk about open
data, and I'm talking about it and I've been proponent for open
data and  open source software. We can see all of these open, this
openness being like the basis for all of these models that we see right now. So that's another question
of decolonization. And the third one and that kind of
ties to your question  about the image of reality.
Technology is always trying to grab hold of new advances, new applications
of cutting edge technologies. What we're seeing now, especially in
the past couple of months with the advancement in machine learning is that
there are new affordances that didn't exist before, and then immediately we
can see a colonial rush towards the low-hanging fruit that, now that we
have  longer hands to reach the fruits. Then there's a bunch of new fruits
that can be seen as low hanging and everybody's running towards them now. These fruits could be finding new
types of advances in medicine and in protein folding and in finding new
discoveries around cancer and whatever. They can also be deep fakes and extreme
ideas about what you can do with weapons that we couldn't do before, because
that's another race that is going on. So there's this rush as well. So we can see quite a few territories
that are worth asking questions about. And I'm not sure that the framework
of decolonization is useful enough to talk about all three of them. And if it is useful in some degree
it could be that we need to use it differently in each one of these fields. And I'm sure there are more
fields that are relevant. Okay. I try, I guess to come from a bit
different angle and to be also short. But let's see. What I would hope for our machine learning
future in a way, that there will be like more an abundance of less large
and less general AI but more colorful, more playful, also more surprising. Because I think the insights
from those data can be fairly surprising and this isn't really
exploited in a good way so far. And also I'm saying that because I really
would hope that this technology at one point, and I'm sure we'll get there,
will be more responsive towards the kind of, I don't know towards the diversity
and the complexity of the world's different worlds we really live in. And it's now in the beginning so it's
clear  it's not there yet at all. And it's not possible like this. And actually emotion, I would say the
post-colonial theory can be a really good framework for this kind of thing. What I'm looking for, what
I would find interesting to see more in the field of AI. And so I'm quite optimistic here. I don't know if I should
say any last few words. If I don't know if I have enough
time, but I'll try and just like two sentences, three sentences, summarize. I feel like moving forward. Definitely we have to learn to live
with this new reality and like, and also focus a lot on what happens to
humans who are not obviously AI, and what happens to us when the job market
has changed and how will we pay for things if people don't have to work? And that's of course discussions
around universal basic income like I mentioned earlier. But
also more importantly as well, I think more than ever now, there
will be a need to really focus on proving whatever entity
you're interacting with is human. And that's why I see zero knowledge
protocols and things like that coming into the fore research done in those fields,
which has been sort of in the back burner because there hasn't been really an
extreme use case, which it is needed in. And this appears to be one of those cases. So yeah. It's gonna be very interesting times. And definitely I agree with the
colleagues here when talking about the decolonization. And when you're speaking particularly
about this topic and what AI is doing, it definitely becomes so fluid to a
point where it's very hard to define exactly what we mean by decolonization. Also in a world that is connected as such. And that has formed sort of another,
if you will, parallel universe which is not necessarily geo politically in
a traditional sense, you know linked. So yeah. I think those are my 2
cent to the conversation. Thank you all. Thank you so much. We have talked a lot. The conversation was
incredibly rich and fruitful. There are still many questions to be
asked, conversations that we can have, but we can maybe stop here for now. Thank you. Thanks