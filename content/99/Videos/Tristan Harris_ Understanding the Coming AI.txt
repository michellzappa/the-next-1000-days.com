[Music] [Laughter] [Applause] so one of the challenges interviewing Triston is there's so many different things we could go to there's a lot of things we can talk about and be at and um one thing I just also want to say about you is you're um you're also kind of a spiritual Explorer I don't know what you would call that like we met around kind of this inner transformational work that you were doing and I was doing around whether it was Byron Katie or meditation I remember that in our first wisdom 2.0 talk yeah and we uh we um we met around that and so I know that's kind of been a deep part of you that you're kind of connected to both kind of the wisdom mindful transformation world and you're also really connected to this this social change world and um I'm curious there's so many different places to go but I'm curious maybe we could talk a little bit about that is there some connection between those worlds and in terms of your own activism how does that connect that's a very interesting question it is I didn't even know I didn't think about it I was ask that you're just like that you always flow with what's the thing that's coming up um you know as I think about what you're saying I think actually the thing that has allowed me to feel to see some of the problems that's going on in technology is the same is the practice of meditation where you're just actually what can you notice um it's as simple as that because for example sitting there with social media and you see that on WhatsApp it says the person was last online four minutes ago and so sitting there you might just say oh I need to message them back they or they saw that I sent this message or I haven't sent and they're still online last online four minutes ago and you're noticing that you have the thought oh they know that I haven't responded yet and I was just online yeah but that's because you can just notice more of your internal experience to sort of see the way it's constituting your own psychology so for me and all the social media work how many people here have seen the social dilemma okay most of you um and what that was really about is how you know technology was constituting the psychological environment that three billion Human Social primates are inhabiting every day and to see it that way um I think actually did come from a lot of my interior Explorations and and just seeing the scale of this noticing that the thoughts that were triggered and coming up or being produced by the machine of social media were thoughts that everyone was having um and as you know I you know I also had this brief stint studying with this uh lab called the Stanford persuasive technology lab where you know you you understood that our mind has these levers uh of influence and so as we look at the situation uh that we're in now I think um the social dilemma kind of presented the best understanding we have then of how the algorithms work this is my there was a lot I took away but just the sophistication of the algorithms and how the AL algorithms are um built for certain actions and all most of those actions are whatever it takes to keep you engaged y right and so how now this as the AI has now entered into this world what are your thoughts concerns uh dangers about what potentially that mentality and that that strategy if you will infused with a more more and more advanced AI yeah so to come back I actually remember you and I having a phone call it's one of our very very first Zoom calls in 2014 uh I believe it was I think I was in London I was visiting Oxford with my friend uh 2014 2014 I believe and even back then you and I were talking about the race for attention and engagement now why am I going here because um you know Warren Buffett's business partner Charlie Munger said if you show me the incentives of a system I will show you the outcome you show me the incentives I will show you the outcome how did we in 2013 2014 predict that this machine would generate a more addicted distracted polarized sexualized uh breakdown of Truth Society because if you know the business model or the incentive is showing whatever keeps you scrolling that's going to produce more people scrolling for a long time if you know the business model is getting you to come back that's going to produce a lot of notifications that get you to come come back right if the business model is attention I'm going to show you beautification filters that make you look more sexualized even if you're 13 years old because that gets the 13-year-old coming back wow and if I show you a personalized news feed just for you versus a Newsfeed that tries to create some shared context think about an app that's showing you just the things that keep you scrolling that's going to be way better at keeping your attention than the thing that creates a shared reality so right there we just laid out six attributes of a future world and my my friend said that um we came up with this phrase I felt like I had PTSD for the future or prsd because I saw in 2014 that this was going to transform the nature of culture in society yeah and here we are here we are and I'm not saying this to take uh credit for I'm saying this because here we are with AI yeah and we're trying to now predict what's going to happen with AI yeah and people say there's going to be the promise unbelievable new accelerations and Drug Discovery we got the First new antibiotic in 60 years from AI recently in this last year we've got new efficient solar cells that just got invented by MIT uh it's just unbelievable how many new amazing things we're going to get from AI so that's the promise side and then people say but we're going to have the Peril you know we're going to have mass surveillance we're going to have drones that can recognize people's faces and we're going to have ai that knows biology and can make dangerous things in biology how do we make sense of the promise or the Peril which one of is why you're here this is why you're here well which one of these are we gonna get yeah and so the the tool I would want to use to try to figure out which future we're going to land in is again show me the incentive and I'll show you the outcome so the question is what is the incentive with AI I mean there's it depends on the person creating it right the people who's creating the drug Discovery is probably their incentive is prob maybe to make money but also to create something that's helpful to humanity yes on technology side and the social media side it's probably the same engagement it's engagement right so so good so we're noticing that there's different incentives for a few different kinds of actors so if you're a drug Discovery company your incentive is to make great drugs that help people um uh if you're a social media company and your incentive is to maximize attention now you have this new tool called AI yeah what's that going to do it's going to take the exact same machine and then just supercharge yeah how that whole thing works so that's that's not going to be great but if we go even deeper um how do we predict the future we at Center for Humane Technologies or organization we focus on how the the races these these competitions for something so in social media Was a Race for attention and engagement with AI we call it the race to roll out open AI anthropic Google Microsoft you know Amazon meta are all competing to R roll out these brand new AI models so we got gpt2 just four years ago that couldn't even count from 1 to 10 and GPT 4 just like four years later is the level can pass the MCAT pass the bar exam and can be basically an early college student level of IQ and capability that's crazy yeah but it's going why you might say why is it all going so fast and it's because if I don't release the next model the next impressive GPT 5 and anthropic releases the next Claude 4 I'm just going to lose and by the way I won't be able to hire the next greatest AI Talent if I'm behind in the race I won't be able to raise the Venture Capital if I'm behind in the race and by the way even if I have a good faith and I care about AI safety I've heard this from the AI Labs if I want to influence policy yeah in Washington DC for safety to get things right they won't listen to me if I'm a third tier AI player so even if you care about the good things that Society needs and policy you have to participate in the race to roll out so if we want to predict which future we're ending up in I would argue strongly that the race to roll out which becomes the race to take shortcuts and deploy things faster than Society knows how to metabolize that change is the world that we are getting and I think we are currently getting and we're starting to see that now so uh I think this was last year but um Facebook had posted kind of somewhat of a brag to the that in Q4 uh their advancements on their AI increased use of time on Instagram by 24% I believe right so say that again so advancements in AI increase time on Instagram by 24% makes perfect sense right exactly and which is how they I'm sure they it was higher than they wanted right the challenge is that not going to I mean we're 24% is bad enough but the challenge is that's not going to stop at 24% right 50% 60% and we live in a potential world where a young person signs on to some kind of platform the intelligence is so so smart and knows so much data about that person it it's like a it's an unfair battle right between their own quality of life which includes friends and being outdoors and meditation and exercise and what the algorithm offers them to be enticing right so even if there's no Killer Robots that's right even if there's no Killer Robots and no craziness um uh there is this capacity in which the system gets to know you and the system uses that intelligence to then keep me for its goal is to stay onard and asking well and asking young people to to me asking young people to um no not be um motivated by that is a little bit like saying listen we want you to eat mindfully we want you to control your diet but you're going to walk around all day with a buffet in front of you yeah and you're going to be told to only eat so much it's like what do you mean it's a buffet yeah yeah and it's not one static Buffet it's a buffet that has multi trillion doll tech companies with hundreds of Engineers going to work every day to rearrange the items and redesign all of the foods to add different combinations of salt sugar fat with the most sophisticated AI that's ever been built pointed at their brain every single day to reverse engineer their how their reptile brain works and what it responds to perfectly for them yeah so when Tik Tok sees your 13-year-old it has already today seen 2 billion other human mammals responding to things bil show them yeah and it's just seen this game too many times before so if you think you know if you imagine you know they have Deep Mind Google's company has a demo of an AI playing Starcraft do you all know what Starcraft is like the video gam it's one of these you know war games and you move your units and your tanks and the AI learned how to play Starcraft better than all the human players because if you sit there and you're thinking okay I'm going to my tank here and I'm going attack their thing but the AI just plays out every scenario and can win at that game I think they said that if you start an AI that knows nothing about Chess by 5:00 pm that day yeah it will be a grandm because it plays itself so many different times exactly self playing that with us that's right now the question I have though is we're being played literally being played now and I think that that's very very true of advertising and social media but some of the AI leaders are like we see this problem we don't like this problem right the fact that when I do a Google Search and I click on to get information I've got to see tons of ads and the information I seek is somewhere in this article somewhere very hard to get to yeah we're going to create smart AI where you say what is the what is the data you need what's the information you need and we're going to just deliver it to you directly and we're not going to have ads we're just going to have you know pay for the certain amount for the highest or for the latest version but we're actually trying to solve some of these problems that you see happening because we're not a we're not we're a different kind of platform yeah do you see that as a positive motion or do you see that well that's still going to go down the same path because they need to bring in money and um because in some ways I think some of the not all the but some of the would be like yeah we're totally with you we're actually trying to help yeah um well uh so there there could be some um potential good news or good ways that this could go that you're pointing at so one is if AIS get so good at producing deep fakes that are genuinely indistinguishable from regular and now social media becomes this Wasteland of now no one literally knows what's true there because it's all user generated content and you just don't know what's real it's all computer generated content computer generated yeah maybe that would result in all of us saying we can't use social media anymore and that could be a really powerful way to get off of social media um because to your point I think you're making is that you know chat GPT can say hey instead of having to scroll through this mindfield of the supercomputer pointed at yourid brain use chat GPT or anthropic and we'll summarize all this information for you and just give you exactly what you need so you don't have to scroll through all that stuff and like you said their business model could be aligned with that by saying if you pay us a subscription fee then we're not incentivized to steer our answers or show you more stuff or product placement in thect in the but I'll tell you you know we're based and I'm just I'm not saying I'm just asking the question because I'm by curious your thought yeah I mean we're just exploring this in real time but the you know we our organizations based in San Francisco in the Bay area and we know a lot of people at the labs there are active conversations and pressures inside some of these companies in which their business teams are saying Hey what if we skewed the answers towards the things that an Advertiser paid us yeah to steer people towards so we saw this whole story play out with social media before sh we should learn a lesson and pass a law now that says let's not have these systems be incentivized to give you things just for what's good at getting your attention cuz know exactly where that that pulls you what I really want to see is an incentive literate Society okay an incentive literate society means we understand where those incentives take us to which bad outcomes yeah so again if you're Racing for attention then we we don't want to make sure we're monetizing attention to the endgame that's the addicted polarized distracted thing and we say we don't want to do that if the incentive is if I Instagram don't go after a 13-year-old user and Tik Tok does then I just lose the race everyone's racing to get 13-year-old and 12 12y olds and 11year olds because the earlier I get them I have them for life if we don't want that to happen we have to change that incentive we don't allow you to monetize you know under teen users yeah and I'm really happy to say that um since the social dilemma there's been a number of amazing positive changes especially for kids Jonathan height um how many people here have read Jonathan Height's book The anxious generation highly recommended you know he was in the social dilemma he's a deep Ally of ours and without passing any laws or having to deal with with the government he's getting schools and getting parents to turn their school phone free he gives you a template text message you can send to the superintendent or the teachers and say get a parents group together on WhatsApp we can self-organize to say we don't want social media in the school and we don't want uh smartphones to be the norm in the school you can Sol your smartphone outside of school just not in the school um and that's already starting to happen um and right now it's happening with the wealthy schools but not with the rest of the world and I think though over the next three years there could be all of this change we start to change those incentives so so on a school level amazing right I think kids if they were in school and they did not have that like lure of the phone and curiosity of the phone would be positive yeah how do we change the incentive structure so it seems like in terms of changing the incentive structure it's either uh there's three things that come to mind for me one is the government just comes in and says here's the regulations when you when you share data or give an answer in the AI it has to look like this and if we see you putting ads in or putting product placement or other things we're going to penalize you right the other is that the public cares about that so much that the most ethical AI gets all of our users right we're going to go to this AI instead of this AI because we understand that they have values and we're going to choose to go with values are you seeing a different model what are our ways of Shifting those larger incentive models um am I missing some or what do you think our best shot is in that yeah so I want to point out a distinction something that's different with social media than with the AI companies um so what you're talking about just a round trip what you said is will people choose the AI that has the business models that align with them so for example if chat GPT starts to say we're going to maximize attention and engagement and they start giving you answers to do all that whole thing people might say we don't want to use you anymore we'll use the ones that we want to use um that would be possible with an AI with AI chat Bots because you're not locked into them so think about by contrast social media if Facebook starts to do the you know aggressive maximize attention thing but all of my contacts are on Facebook and they're not on Snapchat or Tik Tok or whatever else I can't switch out of that thing these are what we call Network effects and the people who designed Facebook and the social media companies Twitter Instagram Tik Tok they know this and they design to rope everybody in yeah it's a collective action problem it's by the way the reason why kids can't just not use one product because all of their friends are also on Snapchat or Tik Tok and unless everybody moves together they're locked in and so one difference is that what you're talking about if if Facebook started to act in an ethical way people would just use Facebook more that's not going to work because of the network effect problem but it could work more with the way that chat Bots work the my concern would be that I think it's all about what we care about the most at the end of the day it's convenience and whatever works the best and if let's say chat GPT worked faster and the response times were faster then I'm going to use that over Claud which may be slower but does it in an ethical humane way and we're just using these examples these are just examples um because it does feel that the the uh incentive structure has to shift but that the people are we're all part of the problem would you say the human humans are part of the problem same more well because for example if we if we care about speed more than we care about values and we're choosing compan that don't have values because of speed we're re it's like clicking ads that say look at this stupid thing this politician did like and we're clicking that we're saying basically we want more of this yeah right and there's there's other articles that we don't click that could be much more deeper so the the people are kind of either we're supporting it or can you tell us more about what our responsibility is yeah well we have to note where there's an asymmetry of power so um what I hear you saying is are people just uh how do people take responsibility for continuing to click on the clickbait or continuing to get sucked into and reinforcing some of those same Cycles yeah yeah um which a little bit like the the buffet thing I I gave example some of it's just like it's almost ridiculous to ask but it it also feels like it is an important piece of the puzzle well we obviously once we're if we all had a cleare eyed view of the situation and then you saw how toxic this was and how much it was hurting mental health and it was and people still chose it after fully understanding all that we obviously have to take some responsibility once we know but the companies right now don't want people to know that all these things are problems because it's not their incentive um we also have to again realize the asymmetry of power it's like I could say I want to have more self-control but I have a supercomputer with a trillion dollar market cap company pointed at my brain that's not a fair fight yeah and so we until that's a fair interaction an equal interaction it's not about personal responsibility and the other way it's not a fair fight again is the Network effect that they caught all of my friends roped in yeah and teenagers who who literally say I saw social dilemma I don't want to use social media anymore but I noticed that when I shut down my Tik Tok account I literally don't know what my friends are doing and I don't know where to go hang out with them because they're only sending messages on that service so that's another way that the fight is unfair but I think the question you're asking is also kind of a defining question of of our spech when we talk about AI we often talk ASA my co-founder and I about how um AI is kind of inviting Humanity into kind of a write of Passage um how many people here know the marshmallow test from psychology a bunch of yeah okay in this community people would know the marshmallow well some people are watching on YouTube so we might want to we'll describe it so it's a psychology experiment that they did at Stanford where you sit these kids down and you tell it's a test of self-control and delayed gratification so they get in front of the kid and they say um okay I'm going to give you this marshmallow now you can have it or or if you wait I'm going to put this marshmallow here I'm going to leave the room I'm going to come back in 10 minutes and I'll give you two marshmallows do you think you can wait to have the two marshmallows while it sits right in front of you well it sits right in front of you and there's this great video online where the people leave the room and then it just watches what do different kids do and a lot of the kids are sitting there and they they smell it and then they like they they touch it and then they like lick their you know and they put it back and but they're like they're squirming some kids are really having a hard time and one of the things that we often say in our work is that Ai and social media are kind of a question of are we the one marshmallow species or are we the two marshmallow species if we are the one marshmallow species we do not have great prospects for the future and I know what many of you are thinking if you look outside you go out there in the world it looks like we're a one marshmallow species but I the reason I'm here the reason we do uh instant gratification now yes instant gratification now so one marshmallow means I want the one marshmallow now instant gratification Society two marshmallow species means we can see the consequences of our actions we can withhold and we can consciously make Discerning choices about what we want I know that it looks like we're on marshmallow species the whole reason I think this community the community you've brought together and what it represents is we are capable of much more than the one marshmallow version of ours sub and social media isn't a mirror of society it is a fun house mirror that has warped and reflected back the image that we've been getting back for so long that we see everybody else caught in that one marshmallow instant gratification thing that it's confused our sense of who we are yeah that's beautiful yeah and the reason that we do this work is We Believe deeply that we can be a two marshmallow species yeah and if you've done the inner work you know that it's possible yeah and the humans are inherently beautiful and conscious and loving yes we're capable of all that we are capable of navigating our way out of this but we have actually collectively occupy that two marshmallow place and then when it comes to everything with AI like us and China and all these agreements we have to sign we collectively need to be as a world to marshmallow yeah and I know how hard and impossible that sounds but that is what we need to do because the alternative is not acceptable 100% now what does government what can what what are the levers to increase the likelihood of that and I know awareness is one like like you you all are trying to present here's here's actually let's become more educated about the potential here so that I would say awareness would be one of those levers but what's your sense of the levers that would increase the likelihood that we would become that more uh less narcissistic less dopamine focused less me me me and more towards a sense of togetherness and more towards a sense of balance more towards a sense of yeah knowing how to love one another and nature and being and all that that was all beautiful I was getting going there for a second yeah yeah um so we just kind of talked about whether a single human being a human mammal can be a one marshmallow yeah version of them or a two marshmallow what it require are incentives that incentivize us to be two marshmallow organizations two marshmallow countries rather than I win Now by reaching first because when you talk about what will enable the good future with AI it's if right now the race to roll out the race to take shortcuts the race to deploy as fast as quickly as possible is like AI companies that are the one marshmallow version of themselves yeah right right and it's not in that case when they're organizations like what's the subjectivity does the does the medit does the organization of open AI meditate and notice that it's wanting the marshmallow to it can't do that because it's not one subjective experience I mean there is a CEO and there's decision- making and there's a board but you know we saw open AI got rid of its board and you know uh so different SE chain different CEOs change um and so um what that means is it's not what what affects the behavior of an organization is that we have different incentives for those organizations yeah so if we have one marshmallow incentive that has everybody race to get in social media you know I have to grab the 13-year-old before my competitor gets them that's the one marshmallow tech company and we need incentives that say no one can go after that because we don't want to go after kids that's the two marshmallow incentives and how does that how does that is that government the only one that can change that incentive well first what it requires is everybody agreeing we live in democracy so you need to have an overt What's called the Overton window meaning a enough of a percentage of a population who say yes that's what we want yeah I'm excited about John Height's book because he's moving the Overton window the social dilemma which is now curriculum in so many schools million views 150 million views around the world is moving the Overton window the Surgeon General of the United States who you've had on this stage he's moving the Overton window he just did a a thing um a few months ago where he asked that we put warning labels on social media products just like the Surgeon General warning on Tobacco just yesterday I believe it was the 42 attorney generals endorsed uh that we need to have a warning label on social media companies that's the 42 attorney generals we just by the way had uh within the last year these 42 attorney generals suing meta and Instagram for intentionally addicting children just like what happened with big tobacco wow so if I want to tell you thank you yeah I think we should all be apping this if if you look back at the history of big tobacco how did it change actually think for a moment in this room in the 1960s this exact room assuming this building was here everyone in this room in the 1960s would have been smoking just imagine that for a second you're in this room it's filled with smoke okay and not saying that's bad I'm saying now imagine I told you on the stage back then 60 years from now no one in this room is going to be smoking you look around you you see what everyone's doing you're like that is never going to happen I sound crazy we turn that around what did that what's that c c c eff coup it a oh the surg General yes exactly and what did that take well a lot of the things that we saw we saw Jeffrey the 60 Minutes whistleblower who who blew the whistle in 1996 we saw the attorney generals file their their 50 state lawsuit against the tobacco companies on behalf of their citizens who' been harmed we saw the film The Insider that kind of publicized that like a social dilemma right we saw um you know media change where media started to tell a different story where now it wasn't cool to smoke inside of buildings we changed social norms um and you flash back and I believe the stat is that um we saw the truth campaign as well the truth campaign remember that the bodyb in front of the tobacco comp's offices um all of that happened and I believe since we just looked this up recently that we went from 20 3% of all teens or 60% of all teens uh used to smoke and now like less than 2% uh of teens smoke smoke cigarettes and that took a ton of time that happened over like 50 years yeah with the social media problem let me rewatch let's really look at the Timeline we don't have 50 years we don't have we don't have 50 years exactly 2017 uh I actually came out on 60 Minutes uh and we did a big interview with Anderson Cooper right who you've had on this stage uh we had the social dilemma you know create mass culture we had the surgeon general's warning for social media now we have now had the 42 State Attorney General suing so we're actually on the big tobacco timeline with social media and I know it doesn't feel that way because the experience inside of social media and the actual products has not shifted in fact you could say it's gotten worse but there's sort of different things in culture the technology might be veering you know further in the race to the bottom of the brain stem but the law and culture are now catching up beautiful now so we need to do much more of that I totally with you in that in terms of that that movement I think the challenge that we have is it's very clear uh when I'm smoking and when I'm not smoking yeah it's often not very clear when I'm immersed in a dopamine uh a world that's AI impacted or not right like I checked my email and I kind of like that AI went through and put all the spam emails away and I can see that but notice it's not that notice that it's not that AI is bad because that's a perfect example AI that detects all that spam that you don't even see now because it's been so good yeah and hides that that's an AI That's aligned with your incentives because people don't make money when they Google doesn't make money when they show you more of all the garbage spam they need your trust they're competing for your trust not for uh just maximizing your email attention yeah so one of the things I I think about and the Surgeon General has also talked about this quite a bit is the more lonely isolated and disconnected I am for myself the more likely the algorithms can play on me because the I'm I'm it's serving something in me that is hollow Y and I'm curious can you have thoughts that if we become actually a more connected loving population would we naturally then expect the algorithms and the AI companies and the the social media companies to adhere to certain basic values but as long as we're depressed and lonely and isolate and where do we where do we begin to shift that this this is actually an interesting thing because you're pointing out a feedback loop right the more you use social media by yourself the longer you scroll longer than you forgot you know long longer than you realized the more lonely and empty you feel and disconnected you feel and from that state the more vulnerable you are to the high fructose corn syrup version of connection that's served up in uh in the feeds and so there's a bad feedback loop and now you might say uh we're just giving people what they want but again that actually is that's what the tech companies think by the way our friends who you know people that we know at that uh the way that you still work at Tik Tok or Facebook every day is you convince yourself of the story that we're just giving people what they want even though we made them lonely in the first place and then now they're actually had stuck in this bad Loop um and again we had this fate where are we actually lonely and disconnected or have we been so deeply trapped in the funhouse mirror that reflects back that version of ourselves that we've forgotten that we know how to belong and be with each other and be kind to each other um and let me give you a very concrete example of how it could work differently if Facebook's business model was not maximizing engagement when you open up a any social media app today it could be just a list of events that you could go to in your local area with friends and communities that you want to be a part of yeah like your existing friend groups it could have your your threads for who's who's basically bringing people together for a discussion night for a podcast that's stimulating us or a movie that we want to watch and make some change together or a knitting club or a sewing club or an Acro yoga group or whatever the thing is and instead of just saying it's a passive event of of um things I can scroll it could be all about making it super easy to bring people together like how easy are the tools to create an event that brings people together in physical space right now yeah they're not that great imagine if we applied all those you know think of the Thousand Engineers who've been working at Facebook to try to make the clickbait machine work better over the last 10 years all that those pH phds yeah imagine taking all those phds and all that engineering and applying it to how do we make it better and easier to bring people together for everybody yeah how fast could you like reforest the social Fabric and China doesn't China do some of that mandate some of that China does not quite that but they um uh I famously talked about this uh in 2022 we did a 60 Minutes interview um in I don't know if you all know this uh they regulate Tik Tok domestically in China so if you open up Tik Tok in China you get what we call the digital spinach version of Tik Tok so if you scroll you get patriotism videos education videos literally I I had a friend uh who's Chinese show me his app he had two Tik toks he opened up the one that was from China the first video was a speech to Jing ping gave the second video was about who won the Nobel Prize in quantum physics the third video was explaining quantum physics the fourth video was uh Financial advice to how to make money wow and and then he closed that app and he opened up the Tik Tok Us app which we call the sort of like digital fenol version of Tik Tok and it was all of the worst things that you all we all know yeah and you know you can have a very pessimistic view of what's going on with those choices you could say they intentionally want that to happen or you could say they actually see that technology is kind of constituting their culture and they're regulating it and we're not doing that I'm not saying we should do what they're doing yeah by the way they also do a thing we at 10: p.m. at night uh it's lights out if you're under 14 so if you open up like a Tik Tok or social media or a gaming app after 10 p.m. it will just say it's closed just like CVS maybe not New York but um and when you open up again at 600 in the morning until not until 6:00 or 7 in the morning it opens back up again and the point is that that stops the social pressure Dynamic is one of the biggest issues with social media is overuse late at night you know you're super depleted you're lonely you're compressed your esophagus you're not breathing your self-control is way down it's 1: in the morning and you just get lost scrolling and they know that and they know the poll of everybody else being in that state so they just they clip out that part of the attention Eon one time I reached out to Instagram because like wouldn't it be cool on Instagram if like every 10 or 15 posts you get some positive message like you're beautiful and like go outside and so I I reached out to them like of course they'd want to do this right like there's all this negative stuff on on team's mental health like I'll help them create like these really beautiful supportive posts and and I can't you will not believe this you will not believe this but when I presented the idea to them yeah they didn't take it I know you're shocked but they were just like yeah no that's not going to happen but even this is actually a great example because this is a great example because even in the case where um Instagram said okay we're going to give people the most positive content that's going to help them be not lonely Instagram will only be interested in people's sense of belonging and connection so long as it involves the same amount of screen time on Instagram yeah yeah that's the incentive thing and that's the incentive thing because the thing that actually you remember from our work back in 2013 we had this movement called the time well spent mov yeah the whole essence of that movement was about technology that's not trying to maximize the time spent but about all the design choices and all of the algorithms and all of the ways that it all works are meant to help you spend your time well as a world yeah now to their credit they do have something we can set a time limit 20 minutes and then it pops up and says you've spent 20 minutes and you can the Apple the Apple version of that I have that but but there is some just to ackn there's a ton of things they're not doing but there there is something that they have done well yeah so Instagram did a tiny thing we actually helped with some of our work early on in 2017 helped catalyze some of the reason why all of you on your iPhones have the screen time feature that lets you set a limit and even shows that back even turning the phrase screen time which didn't really exist in culture as a concept into a concept um but that's not enough because um it's what determines whether you use your phone for a lot or a little isn't just whether you get a reflection of how much time you've spent okay because what determines it is again the supercomputer pointed at your brain manipulating your weaknesses every single day so if you have young people would you your suggest the least time they spend the better knowing that they probably will spend some time because or what's your what's your guidance like for me yeah I want to create a bet I want to find a company I can support and fund that H that's value based and has a different experience for young people because kind kind of given up on on convincing them but I I would love to see that happen now you could say well it's always if the incentives are wrong like but but I do feel like teens naturally particular young naturally need a place to communicate and you could create potentially that with some ethical standards I could be wrong but but that that is an intention but what do you how do you support people particularly young people whove like I can't my whole social life is going to be ruined now trist on I heard you talk and now my life is ruined well no I mean um so this is this is where I defer to John Height's recommendations because he has done you know a decade of the research of of really doing it we're we're an alliance I can't remember them off the top of my head but it's basically uh phone- free uh schools no social media I believe before 16 16 uh no smartphone until uh I can't remember what the the age is for that one maybe 16 is a smart or social media is a smart yeah I know and then there's maybe a time at night where something goes off I can't remember um I don't know I can't remember that one we we did a good podcast episode with John we by way have a great podcast called divided attention uh and we did a great interview with him and he walks through all of it so I highly recommend if you care about that you might say how are we going to solve this this this problem how if we're all just if we have a supercomputer pointed at our brain how are we going to um how are we going to fight that and I wanted to share knowing that we're uh coming to more to a close is one solution that my co-founder ASA uh came up with that I'd love to share with you please um so my co-founder ASA uh his father was Jeff Rasin I don't know if people here know who that is he started the Macintosh project at Apple so the Macintosh which everybody uses now the you know MacBooks Etc uh his father invented that with the idea of the Humane interface an interface that is ergonomic to how people's minds work so just like this chair is ergonomic to my back right uh if I sit in it for a long period of time a chair that's ergonomic you know is sustainable one that's not is not but ASA actually later in his career uh is the unfortunate inventor of infinite scroll infinite scroll is the design technique that when you're done scrolling through the first 10 Google results instead of making people click I want to see more Google results and loading the other page uh that instead would just keep scrolling more Google results he invented infinite scroll before there was social media so before there was any Doom scrolling he invented it for search result Pages or blog site so you read one article and instead of having to click back to the homepage it would scroll again and you could see the other articles so it sounds like a good invention um and because he invented infinite scroll and watched how it got sucked up by this engagement attention machine he's thought a lot about what would it take to reverse all that yeah so he came up with a really interesting idea I wanted to share with you which is Amazon famously found that for every 100 milliseconds that their website loads slower they lose 1% of their revenue wow so we're that impatient we're that impatient we're that much of the subtly one marshmallow oriented species um and so um and and designers know that and that's why they work on minimizing the latency so that's why when you scroll Tik Tok it's like boom it's right there the video is just playing because you don't want people to make decisions you want them to be sucked into the decision you're making for Netflix autop plays the next Netflix autop plays the next thing you know um it wasn't always like that but so how would you fix all this so what ASA actually did is he wrote himself software basically a VPN so when he he opens up Twitter or Tik Tok um what it does is after about 10 minutes it randomly adds between zero and like 400 milliseconds of latency so he's scrolling and the things still load but it gets just subtly slower and it's like you're on an airplane and you're trying to you know open up Twitter and it's like it's loading but it's not loading but it's loading but it's not loading and you just kind of get frustrated you do something else right so what that does is it's actually better than the screen time controls that are currently okay in in the phone because when you say hey you've been using it for 20 minutes but you're in this hot state where you just get out of my way I want to keep scrolling Instead This is actually ergonomically meeting the human in mind and how it actually works wow so this latency idea really works at at at getting you unaddicted in that moment but then now let's take this idea and say how would we do some maybe some laws or just an idea protot dictator yeah if you were the dictator for a day well let's say some people do want to be the dictator for a day but or I don't want to be dictator for for a day but if if you um imagine there was some kind of democratic body that said okay we now know because of the social dilemma and John heid's work and all these people who are working on this every day that there's all these harms inability to disconnect loneliness social comparison self harm suicides okay and then what we do is we say we're going to give each of these major bad apps a scorecard yeah how much is Tik Tok contributing to inability to disconnect versus how much is YouTube contributing to inability to disconnect you notice the difference YouTube doesn't try to um say oh you can't disconnect right now because your friends want to do all these things with you it doesn't do that but Snapchat with it streaks feature it does do that it makes it really hard to disconnect so Snapchat would get an F on the inability to disconnect and YouTube would get maybe an a now this Democratic panel would say guess what all these social media companies we're going to impose a latency tax So based on your a Toof rating yeah you're going to get a random slowdown between zero and 500 mill milliseconds and we're not even going to enact it now we're going to say it's coming in 6 months if you don't change your behavior and fix the inability to connect we're going to get T it's like a carbon tax it's like a carbon tax for social media and the cool thing about it is it directly attacks the moment of choice which is when your finger doing that yeah so what the cigarette tax was where there you are in the convenience store and the price of it is this yeah and it just makes it a little bit higher so now people do it less the latency tax you have to do it at this point in the it cost more time it costs more time but it's actually costs more like reptile it cost more marshmallows it's like it's it's more reptilian than that yeah but anyway I wanted to leave you with that because this is an example of a whole Suite of solutions that we believe are possible but we have to get cleare eyed about the nature of the problem we were talking backstage that um you know Charles karing famously said a problem well stated is a problem half solved and a problem that is not well stated is unsolvable if we allow ourselves to be confused by the Facebook's making the world more open and connected and Tik Tok is helping people share the express themselves and those are partial stories but it's not the underlying truth truth of how the machine is working yeah so if we don't fall for the stories and we all put on our x-ray vision and see the incentives first and then work to change those incentives I guarantee you we can live in a much better World beautiful wow I think that's a great place to end great um Triston Harris to find you Center for Humane technology yes do not follow you on social media or possibly on social media you have somebody on their team doing some things yeah you can you can check out our we have a podcast called your undivided attention uh we're a nonprofit uh we do a lot of great work in the world we have a course foundations of Humane technology you're welcome to uh to check out it's free uh and you know we're we're trying to tackle some big problems so we' love to to keep working with yeah and one just thing to say about Triston is I don't know of anyone as passionate as he is in terms of really taking on what we think is a really really important Challenge and so thank you so much for just holding that as a focus because I know it's not easy to carry the weight of a very complex problem and try to figure out paths through when there's big players involved and lots of money and lots of complexity and so just deep thank you for holding that for us than thank you thank you great thank you all