okay hello everyone well let's see today I wanted to tell you about a project that I've been doing recently I work on all kinds of uh unusual projects this one during its development was known as the cats project for reasons that you'll see but uh I recently posted something about it you can see here um the uh as I said I work on all sorts of different things um this one has an image of a cat and if I click on this this is the thing I'm going to be talking about today the topic is generative AI space and the mental imagery of alien Minds so so first sort of topic is AI is an alien Minds how do alien Minds perceive the world it's an old often debated question and philosophy and now turns out to be a question that rises to prominence and connection with the concept of the rouliad that's emerged from our orphan physics project and I I myself have wondered about alien mines for a long time and tried all sorts of ways to imagine what it might be like to see things from their point of view but in the past I've never really had a way to build my intuition about that that is until now so what's changed well it's AI because in AI we finally have an accessible form of alien mind I mean we typically go to a lot of trouble to train our AIS to produce results that are like we humans would do but what if we take a human aligned Ai and modify it well they get something that's in effect in Alien AI an AI align not with us humans but with an alien mind so how can we see what such an alien AI or alien mind is is thinking well a convenient way is to try to capture its mental imagery the image it forms in its Mind's Eye so let's say we use a typical generative AI to go from a description in human language like a cat and a party hat to a generated image this is why this is the cat's piece it's it's exactly the kind of image we'd expect which isn't surprising because it comes from a generative AI That's trained to do as we would but now let's imagine taking the neural net that implements that genitive Ai and modifying its inside Say by let's say by resetting weights that appear in its neural net by doing this when we're in effect going from a human aligned neural net to some kind of alien one and but this alien net will still produce some kind of image because that's what a neural net like this does but what will that image be well in effect it's showing us the mental imagery of the alien mind associated with a modified neural net what does it actually look like here's a sequence obtained by modifying the neural Nets that we're using before in effect making it progressively more alien and at the beginning still very recognizable as a picture of a cat and a party hat but it soon becomes more and more alien the mental image and effect diverges further from the human one until it no longer looks like a cat and the end looks at least to us basically completely random there are many details of how this works we'll talk about that later what's important is that by studying the effects of changing the neural net we now have a systematic kind of experimental platform for probing at least one kind of alien mind we can think of what we're doing as kind of artificial Neuroscience proving not actual human brains but neural net analogues of them and we'll see many analogs many parallels to Neuroscience experiments for example will often be knocking out particular parts of our neural net brain a little like how injuries like Strokes can knock out parts of a human brain but we know that when a human brain suffers a stroke this can lead to phenomena like hemispatial neglect in which stroke victim asks to draw a clock will end up destroying one side of the clock a little like the pictures of cats degrade when parts of the neural net brain are knocked out of course there are many differences between real brains and artificial neural Nets but most of the core phenomena that we'll be seeing seem robust and fundamental enough that we can expect them to span very different kinds of brains human artificial and alien and the result is that we can begin to build up intuition about what the worlds of different and alien Minds can be like okay so let's talk about this process of generating images with AIS how does an AI manage to create a picture say of a cat in a party hat well the AI has to be trained on what makes a reasonable picture and how to determine what a picture is of then in some sense what the AI does is to start generating reasonable pictures at random in effect continually checking what the picture it's generating seems to be of and then tweaking it to guide it towards being a picture of what one wants it to be a picture of so what counts as a reasonable picture if one looks at billions of pictures say on the web there are lots of regularities for example the pixels aren't random nearby ones are usually highly correlated if there's a face that's usually more or less symmetrical it's more common to have blue at the top of a picture green at the bottom and so on an important technological point is that it turns out to be possible to use a neural network to capture regularities in images and to Generate random images that exhibit them so for example here are examples of um uh of images that um are generated in that way and the idea is that these images while each is random in its specifics will in general follow the statistics of the billions of images from the web on which the neural net has been trained so we'll talk more about images like these later but for now suffice it to say that while some may look like abstract patterns others seem to contain things like Landscapes and human forms and so on and what's notable is that none of them just look like random arrays of pixels they all show some kind of structure and yes given that they've been trained on pictures from the web it's not too surprising that the structure sometimes includes things like human forms but okay let's say we specifically want a picture of a cat in a party hat from all of the almost infinitely large number of possible well-structured random images we might generate how do we get one that's a vocational party hat well a first question is how would we know if we've succeeded as humans we can just look and see what our images of but it turns out we can also train a neural net to do that and here are some examples it doesn't always get it exactly right how is the neural net train the basic idea is to take billions of images say from the web for which corresponding captions have been provided then one progressively tweaks the parameters of the neural net to make it reproduce these captions when it's fed the corresponding images but the critical point is that the neural net uh turns out to do more it also successfully produces reasonable captions for images it's never seen before what does reasonable mean operationally it means captions that are similar to what we humans might assign and yes it's far from obvious that a computationally constructed neural net will behave at all like us humans and the fact that it does so is presumably telling us fundamental things about how human brains work but for now what's important is that we can use this captioning capability to progressively guide images we produce towards what we want so we start from Pure Randomness then we try to structure the randomness to make a reasonable picture but at every step we see in effect what the caption would be and we try to go in a direction that leads towards a picture with the caption we want or in other words progressively try to get a picture that's of what we want so the way this is set up in practice one starts from an array of random pixels then iteratively forms the picture one wants different initial arrays lead to different final pictures though if everything works correctly the final pictures will all be of what one asked for in this case a cat and a party hat and uh here are some examples and yes there are a few glitches in all of this so we don't know how mental images are formed in human brains but it seems conceivable the process is not too different and that in effect we're trying to conjure up a reasonable image we can and as we do that we're continually checking if it's aligned with what we want so that for example if our checking process is impaired we can end up with a different image as in hemispatial neglect let me perhaps um just show you for a second here um what it looks like in practice to generate one of these images so let's let's go ahead and pull up a little notebook here and let me um just go and the way that my writings are always set up you can always click any image in there and you can and that will generate um open language computational language code that you can copy in here now this particular uh piece has the complexity that it uh to generate images is very computation intensive and you basically need a GPU in order to be able to do this well but let's try doing it for this particular case so this is uh saying generate uh use the stable diffusion synthesize resource function to generate a picture of a cat and a party hat and you see the picture uh sort of coming in there and baboon there is a cat so that that's that's roughly what it looks like to actually um do this in practice with woven language and uh what's important now is that because we're able to do it with Wolfman language we're able to do all sorts of experiments with it that sort of just wouldn't have been possible without that kind of capability well let's um let's come back and talk about uh the notion of what I'm calling inter-concept space so the fact that everything can ultimately be represented in terms of Digital Data is foundational to the whole computational paradigm but what the effectiveness of neural Nets relies on is a slightly different idea that it's useful to treat at least many kinds of things as being characterized by arrays of real numbers in the M1 might extract from a neural Nets that's giving captions to images the word cat but inside the neuralness it'll operate with arrays of numbers the correspond in some fairly abstract way to the image you've given and the textual caption it'll finally produce and in general neural Nets can typically be thought of as associating feature vectors with things whether those things are images text or anything else but whereas words like cat and dog are discreet the feature vectors associated with them just contain collections of real numbers and this means that we can think of a whole Space of possibilities with cat and dog just corresponding to two specific points so what's out there in that space of possibilities for the featured vectors we typically deal with in practice the space is many thousand dimensional but we can for example look at the sort of nominally straight line from the dog point to the cat point in the space and even generate images of what comes between and uh so we see there the sort of cat dog combo uh as as we go towards the cat Point here and yes if we want to we can even keep going Beyond cat and uh uh pretty soon things start becoming pretty weird well we can also do things like look at the line from a plane to a cat and uh yep there's pretty weird stuff that goes on in between it's kind of like a Wings goes to hat goes to ears kind of sequence so what about Elsewhere for example what happens around our standard cat in a party hat image with the particular setup we're using there's a 2 304 dimensional space of possibilities but as an example we can look at what we get on a particular two-dimensional plane through the standard cat point and our standard cat is right there in the middle but as we move away from the standard cat Point progressively weirder things happen for a while there are recognizable if perhaps somewhat demonic cats to be seen but soon there isn't much Katniss and evidence sometimes over here for example hats do remain we might characterize that as a kind of all hat no cat situation reminiscent of the kind of Texan all hat no cattle kind of story how about if we pick other planes through the standard cat point all sorts of images appear but the fundamental story is always the same there's a kind of cat Island Beyond which there are weird and only vaguely cat related images encircled by an ocean of what seem like purely abstract patterns with no obvious cat connection and in general the picture that emerges is that in the immense space of possible statistically reasonable images there are islands dotted around that correspond to linguistically describable Concepts like cats and party hats the islands normally seem to be roughly spherical in the sense that they extend about the same nominal distance in every direction but relative to the whole Space each island is absolutely tiny something like perhaps a fraction 2 to the minus 2000 or 10 to the minus 600 of the volume of the whole Space and between these islands the the LIE huge expanses of what we might call interconcept space and sort of analogy to Interstellar space so what's out there in inter-concept space it's full of images that are statistically reasonable based on images we humans have put on the web Etc but aren't of things we humans have come up with words for it's as if in developing our civilization in our human language we've colonized only certain small islands in the space of all possible Concepts leaving vast amounts of inter-concept space unexplored what's out there is pretty weird sometimes a bit disturbing here's what we see if we zoom in on the same kind of randomly chosen plane around Cat Island that we did before and uh let's see I have a a bunch more examples here of of what it looks like to zoom in around different cat islands and you see all sorts of strange as I say somewhat demonic looking cat-like images um more cats sometimes a bit troubling so what are all these things in a in a sense words fail us they're things kind of on the shores of inter-concept space where Human Experience has not yet taken us and for which human language has not been developed what if we venture further out into into concept space and for example just sample points in space at random it's just like we already saw above we'll get images that are somehow statistically typical of what we humans have put on the web and so on and on which our AI was trained and so here are a few more examples and yes we can pick out at least two basic classes of images ones that seem like sort of pure abstract textures and ones that seem representational and remind us of Real World scenes from Human Experience that sort of intermediate cases like textures with structures that seem like they might represent something and representational seeming images but we just can't place what they might be representing but when we do see recognizable real world inspired images they're a curious reflection of the concepts and general imagery that we humans find interesting enough to put on the web we're not dealing here with some kind of arbitrary interconcept space we're dealing with human aligned into concept space that's in a sense anchored to human Concepts but extends between and around them and yes viewed in these terms it becomes quite unsurprising that an inter-concept space the the in the concept space with sampling there are so many images that remind us of human forms and common human situations but just what were the images that they I saw from which it formed this model of interconcept space there are a few billion of them foraged from the web and like things on the web in general it's a very Motley collection here's a kind of random example of them some of them can be thought of as sort of capturing life as it is but many of them are more aspirational coming from stage not promotionally oriented photography and yes there are lots of kind of uh netaporte style clothing without heads images but also lots of kinds of of images of things like food and so on but somehow when we sample randomly and into concept space it's the human forms that most distinctly Stand Out conceivably because things are not particularly consistent in their structure but human forms always have a certain consistency of kind of head body arms and so on structure it's notable though that even the most real world images we find by randomly sampling into concept space seem to typically be painterly and artistic rather than photorealistic and photographic it's it's kind of a different story close to concept points like on Cat Island there are more there there are more photographic forms that are common though as we go away from the actual concept Point there's a tendency towards either a rather toy-like experience appearance or something more like an illustration by the way even the most photographic images the AI generates won't be anything that comes directly from the training set because as we'll talk about later the AI is not set up to directly store images instead its training process and effect grinds up images to extract their statistical properties and while statistical features of the original images will show up and what the AI generates any detailed arrangement of pixels in them is overwhelmingly unlikely to do so but okay what happens if we start not at a describable concept like a casting a party hat but just at a random point and inter-concept space here are some of the kinds of things we see and uh we can show a few more examples here and well let's let's um these images often seem to be a bit more diverse than the kinds of images around known concept points like our cat point and occasionally there'll be sort of a flash of something representationally familiar perhaps like a human form that'll show up but most of the time we won't be able to say what these images are of there are things that are somehow statistically like what we've seen but they're not things that are familiar enough that we've at least so far developed a way to describe them say with words well let's uh let's go in here let's talk a little bit more about these kind of images from interconcept space and there's something kind of strangely familiar yet unfamiliar to many of the images and into concept space it's fairly common to see pictures that for example seem like there are people but they're not quite right and for us humans being particularly attuned to faces it's the faces that tend to seem the most wrong even though the other parts are are wrong as well and perhaps in commentary on our nature as a social species or maybe it's because we're a social media species there's a great tendency to see pairs or larger groups of people there's also a strange preponderance of kind of torso only pictures uh presumably the result of kind of fashion shots in the training data and yes with some rather wild but interesting fashion statements maybe that's the shirt I need well people are by far the most common identifiable elements but one does sometimes see other kinds of things as well and uh there are also things like uh sort of landscape-like scenes and some of these look fairly photographically literal but others build up the impression of Landscapes from more abstract elements like here if you look in detail they really are not sort of photographically trees or anything like that occasionally there are also kind of city escape-like pictures and still more rarely uh kind of uh indoor-like scenes then there are pictures that look like they're kind of exteriors of some kind and um it's pretty common to see pictures that are built up from sort of lines or dots or otherwise kind of impressionistically formed and then there are lots of images that seem like they're trying to be of something but it's not at all clear what the thing is and whether indeed it's something we humans would recognize or whether it's instead something that somehow fundamentally alien here are a few examples of that it's also quite common to see what look more like pure patterns that don't really seem like they're trying to be things but more come across as kind of decorative textures but probably the single most common type of images are somewhat uniform textures formed by repeating various simple elements though usually with kind of dislocations of of various kinds so across Center concept space there's tremendous variety to the images we see many have a certain artistic quality to them and a feeling that they're some kind of mindful interpretation of a perhaps mundane thing in the world or a simple essentially mathematical pattern and to some extent the Mind involved is a collective version of our human one reflected in a neural net that has experienced some of the many images we humans have put on the web but in some ways the mind is also a more alien one formed from the computational structure of the neuron that with its particular features and no doubt in some ways computationally irreducible Behavior and indeed there are some motifs that show up repeatedly that are presumably reflections of the underlying structure of the neural net the kind of granulated appearance with alternation between light and dark for example is presumably a consequence of the uh um of the Dynamics of the convolutional parts of the neural net and analogous to the results of what amounts to iterated blurring and sharpening with a certain effective pixel scale reminiscent for example if people still remember that of video feedback of what happens when you uh point a video camera at a video screen and here's an example of of that kind of thing made with very simple repeated blurring and sharpening image processing we could we could actually do that and we could just run that just for the sake of showing how one runs something here let's just get that I did a click to copy there let's just copy it okay this is just showing oh wow this it's giving them there's the there's the key part the sharpener blur there and we can we can just go ahead and run this thing and um there we have our our uh Cat made with them with Progressive image processing okay well we can think of what we've done so far as exploring what a mind trained from human-like experiences can imagine by generalizing from those experiences but what might a different kind of mind imagine it's a very rough approximation we can think of just taking the trained mind we've created and explicitly modifying it then seeing what it now imagines or more specifically we can take the neural net we've been using and start making changes to it and seeing what effect that has on the images it produces so later on we'll discuss a bit the details of how the network is set up but suffice it to say here that it involves 391 distinct internal modules involving altogether nearly a billion numerical weights when the network is trained those numerical weights are carefully tuned to achieve the results we want but what if we just change them well still normally get a network that can generate images but in some sense it'll be thinking differently so potentially the images will be different so as a very coarse first experiment reminiscent of many that are done in biology let's just knock out each successive module in turn of those 391 modules setting all its weights to zero so if we ask the resulting Network to generate a picture of a cat in a party hat um here's what we'll now get well these are a bit small here let me see if I can get you a bigger version of that that we can see more easily uh let me think how to do that um maybe I have an idea here um let's see let's see let's see uh let me see um I might have an idea yeah let me see what I can make this work yeah this might work here are some bigger cats um maybe I can make them even a little bigger than that um okay these are a bit pixelated but you can kind of see get some idea here of what happens when we've kind of knocked out different uh elements of the um of the neural Nets here we're seeing different kinds of uh sort of alienly imagined cat-like things Okay so let's look at these images in a bit more detail uh Let's see we can look at oh wow some of these are missing from my collection here um well in quite a few cases kind of zeroing out a single model module doesn't make that much difference um for example it might basically only change kind of the facial expression of the cat let's see whether we can get this image here ah maybe we got that hold on yes there we go um and uh yes um or perhaps it can more fundamentally change the cat and its hat it can change the configuration and position of the cat and yes some of those cats are not anatomically correct zorring out other modules can change and affect the rendering of the cat but in other cases things get much more mixed up and difficult for us to parse sometimes there's clearly a cap there but its presentation is at best odd and sometimes we get images that have definite structure but don't seem to have anything to do with cats and then basically there are cases where we just get what amounts to noise albeit with things superimposed but much like a neurophysiology there are some modules like the very first and very last ones in our original list where zeroing them out basically makes the system not work at all and just generate pure random noise as we'll talk about later the whole neuron that we're using has a fairly complex internal structure for example with a few fundamentally different kinds of modules but we can make a picture that shows an example of of what happens when um uh 110 is out modules at different places in the network and uh here's that picture um and we see that for the most part there's no obvious correlation between where in the network the module is and what effect zeroing out will have the the data uh comes in at the at the left hand side here and that's kind of where the sort of noise is generated and the and the name of what we're trying to get is is put in and then things sort of percolate through this neural net until eventually the the final cat emerges on the right hand side here okay well so far we've looked at what happens if we just zero out a single module at a time um let's look at some examples of uh what happens if we randomly uh if one zeros out successively more modules we could kind of call this a Hal experiment remembering the fate of the fictional Hal AI in the movie 2001 Space Odyssey so we're starting off from sort of the um uh the full um the uh full Network at the beginning here and then we're progressively zeroing up more and more modules until we get to this blob of of almost nothing here in this particular case as we uh zero out more and more modules eventually we Fade to cyan so to speak basically once the Katniss of the images is lost things become more and more alien from there on out either descending into apparent Randomness or sometimes that kind of barren zerleness what about if rather than zeroing out modules we instead randomize the weights in them perhaps a little bit like the effect of a tumor rather than a stroke in a brain well the results we get are um at least qualitatively similar um these are you see here we are looking on our there we go those are those are the results from zeroing out um uh sorry from randomizing um successively more um elements in the um uh in the system these are different runs showing different uh different randomizations and ending with these kind of uh uh very hard to identify what's going on sort of pseudo-random results another thing we can do is just to progressively mix Randomness uniformly into every weight in the network it's kind of like globally drugging the brain and so um here are examples where um in each case we went from at the beginning here zero percent Randomness um to one percent two percent three percent Etc um and uh eventually things Fade Away typically in a very similar way um it uh each of these cases is a different sort of instance of the randomness that was added but we see the same same qualitative kind of behavior uh the other thing we can do is instead of adding in Randomness to kind of um uh to the to the neural net brain we can just progressively scale all the weights in the network down towards zero let's say here in one percent increments from 100 to 99 and so on and uh we can see things progressively sort of descending into randomness or we can progressively increase the numerical values of the weights just just scale them up numerically um in a sense sort of blowing the mind of the network and uh let's see where we have that um uh I think this is that all right ah there we go um and strangely going sort of a bit psychedelic in the process of blowing the Mind by basically just numerically uh turning up all the weights in the network okay well we can think of what we've seen so far as sort of exploring some of the natural history of what's out there in generative AI space or providing a small taste of at least one approximation to the kind of mental imagery one might encounter in Alien minds but how does this all fit in to a more General picture of alien minds and what they might be like with the concept of the rouliad we finally have kind of a principal way to talk about alien Minds at least at a theoretical level and the key point is that any alien mind or for that matter any mind can be thought of as observing or sampling the rouliad from its own particular point of view or in effect its own position in rural space so the rouliad is defined to be the entangled limit of all possible computations a unique object with an inevitable structure and the idea is that anything whether one interprets it interprets as a phenomenon or an observer must be part of the rouliad and the key to our physics project is then that observers like us have certain general characteristics we're computationally bounded with finite minds and limited sensory input and we have a certain coherence that comes from another our belief in our persistence in time and our consistent threat of experience and what we then discover in our physics project is the rather remarkable result that from these characteristics and the general properties of the ruliet alone it's essentially inevitable that we must perceive the universe to exhibit the fundamental physical laws it does in particular the three big theories of 20th century physics general relativity quantum mechanics and statistical mechanics but what about the more detailed aspects of what we perceive well that will depend on more detailed aspects of us as observers and of how our minds are set up and in a sense each different possible mind can be thought of as existing in a certain place in rural space different human minds are mostly close in real space animal Minds further away and more alien Minds still further but how can we characterize what these minds are thinking about or how these Minds perceive things from inside our own minds we can form a sense of what we perceive but we don't really have good ways to reliably probe what other Minds perceive but what um uh what about what another mind imagines well that's where what we've been doing here comes in because with generative AI we've got a mechanism for exposing the mental imagery of an AI mind we could consider doing this with words and texts say with another lamb but for us humans images have a certain fluidity that text does not our eyes and brains can perfectly well see and absorb images even if we don't understand them but it's very difficult for us to absorb text we don't understand it usually tends to just seem like a kind of word soup but okay so we generate mental imagery from Minds that have been made made alien by various modifications how come we humans can understand anything such Minds make well it's a bit like one person being able to understand the thoughts of another their brains and minds are built differently and their internal view of things will inevitably be different but the crucial idea that's for example Central to language is that it's possible to package up thoughts into something that can be transported to another mind the let's see so so whatever some particular internal thought might be by the time we can express it with words in a language it's possible to communicate it to another mind that will unpack it into different internal thoughts it's a non-trivial fact of physics that pure motion and physical space is possible in other words that an object can be moved without change from one place in physical space to another and now in a sense we're asking about pure emotion in rural space can we move something without change from one mind at one place in real space to another mind at another place in physical space things like particles as well as things like black holes are the fundamental evidence elements that are imagined to move without change so what's now the analog in rule space well it seems to be Concepts as often for example represented by words so what does that mean for our exploration of generative AI alien Minds we can ask whether when we move from one potentially alien mind to another concepts are preserved we don't have a perfect proxy for this that we can make a better one by appropriately training neural net classifiers but as a first approximation this is like asking whether we can whether we whether as we kind of change the mind or move in real space we can still recognize the concept the Mind produces or in other words if we start with a mind that's generating a cat in a party hat well we still recognize the concept of cat or hat in what a modified mind produces and what we've seen is that sometimes we do and sometimes we don't and for example when looked when we looked at Cat Island we saw a certain boundary Beyond which we could no longer recognize Katniss in the image that was produced and by studying things like cat Island and particularly its analogs were not just the prompt but also the underlying neuralness has changed it should be possible to map out how far Concepts extend across alien Minds it's also possible to think about a kind of uh inverse question just what is the extent of a mind in rural space or in other words what range of points of view ultimately about the rouliad can a mind hold will it be narrow-minded able to only think in particular ways with particular Concepts or will it be more broad-minded encompassing more ways of thinking with more Concepts in a sense the whole Arc of the developments intellectual development of our civilization can be thought of as corresponding to an expansion in rural space with us progressively being able to think in new ways about new things and as we expand in rural space we're in effect encompassing more of what previously would have had we would have had to consider the domain of an alien mind when we look at images produced by generative AI away from the specifics of Human Experience saying into concept space or with modified rules of generation we may at first be able to make little from them like inkbots or Arrangements of stars will often find ourselves wanting to say that what we see looks like this or that thing we know but the real question is whether we can derive devise some way of describing what we see that allows us to build thoughts on what we see or Reason about it and what's very typical is that we managed to do this when we come up with a general symbolic description of what we see say captured with words in natural language or Now computational language before we have those words or that symbolic description will tend just not to absorb what we see and so for example even though nested patterns have always existed in nature and were even explicitly created by Mosaic artisans in the early 1200s they seem to have never been systematically noticed or discussed at all until the latter part of the 20th century when finally the framework of fractals was developed for talking about them and so it may be with many of the forms we're seeing here as of today we have no name for them no systematic framework for thinking about them and no reason to view them as important but particularly if the things we do repeatedly show us such forms will eventually come up with names for them and start incorporating them into the domain that our minds cover in the sense that's what we've done here we can think of that as showing us a preview of what's out there in rural space and what's currently the domain of alien Minds in the general exploration of ruliology and the investigation of what arbitrary simple programs in the computational universe do were able to jump far across the rouliad but it's typical that what we see is not something we can connect to things we're familiar with and what we're doing here we're moving only much smaller distances in rural space we're starting from generative AI That's closely aligned with current human development having been trained on images that we humans have put on the web and so on but then we're making small changes to our AI mind and looking at what it now generates what we see is often surprising but it's still close enough to where we currently are in rural space that we can at least to some extent absorb and reason about what we're seeing still the images often don't make sense to us and yet and yes quite possibly the AI has invented something that has a rich and meaningful inner structure but it's just that we don't yet have a way to talk about it and if we did it would immediately make perfect sense to us so if we see something we don't understand can we just train a translator at some level the answer must be yes because the principle of computational equivalence implies that ultimately there's a fundamental uniformity to the rouliad but the problem is that the translator is likely to have to do an irreducible amount of computational work and so it won't be implementable by a mind like ours still even though we can't create a general translator we can expect that certain features of what we see will still be translatable in effect by exploiting certain pockets of computational reducibility that must necessarily exist even when the system as a whole is full of computational irreducibility and operationally what this means in our case is that the AI May in effect have found certain regularities or patterns that we don't happen to have noticed but that are useful in exploring further from our current human point in rural space so it's it's very challenging to get an intuitive understanding of what rule your space is like but the approach that we're taking here is for me a promising first effort in kind of humanizing rural space and seeing just how we might be able to relate to what is so far just the domain of alien Minds so let's talk a little bit that was kind of the main set of things that I wanted to say about kind of mental imagery of alien minds and its relationship to generative AI um let me just uh perhaps uh quite quickly go through a little talk a little bit more technically about how does generative AI work so let's see what I've been using here and what I'm talking about is a method called stable diffusion and its operation is in many ways both clever and surprising as it's implemented today it's steeped in Fairly complicated engineering details to what extent these will ultimately be necessary isn't clear but any case I'll talk here mostly about general principles and try and give it sort of a broad outline of how generative AI can be used to produce images so at the core of generative AI is the ability to produce things of some particular type that follow the pattern of knowing things of that type so for example large language models llms are intended to produce text that follows the patterns of text written by human say on the web and generative AI systems for images are similarly intended to produce images that follow the pattern of images put on the web but what kinds of patterns exist in typical images say on the web so here are some examples of typical images scaled down to 32 by 32 pixels and taken from a standard set of 60 000 images the very first thing we can kind of ask what colors show up in these images well they're not uniform in RGB space what about the positions of different colors adjusting to accentuate color differences the average image turns out to have a curious kind of Hal's eye type look presumably with blue for sky at the top and brown for Earth at the bottom but just picking pixels separately even with the color distribution inferred from actual images won't produce images that in any way look natural or realistic there are a few examples and the immediate issue is the pixels aren't really independent most pixels in most images are correlated in color with nearby pixels and the first approximation one can capture this for example by fitting the list of colors of all pixels to let's say a multivariate gaussian distribution with a covariance matrix that represents their correlation so sampling from this distribution gives images like like these that indeed look somehow statistically natural even if there isn't appropriate detailed structure in them so okay how can one do better the basic idea is to use neural Nets which can affecting code detailed long-range connections between pixels in some ways uh let's see typo there it's um similar to what's done in llms like chat GPT but one has to deal with long-range correlations the long-range connections between words and text but for images it's structurally a bit more difficult because in some sense one has to consistently fit together 2D patches rather than just progressively extending a 1D sequence and the typical way this is done at first seems a bit bizarre the basic idea is to start with a random array of pixels corresponding in effect to Pure Noise and then progressively to reduce the noise to end up with a reasonable image that follows the patterns of typical images all the while Guided by some prompt that says what one wants the reasonable image to be of so how does one go from Randomness to definite reasonable things the key is to use the notion of attractors in a very simple case we might have a system like this kind of mechanical example um where from any randomly chosen initial condition one always um um evolves to one of here two definite fixed point attractors the two Minima in this surface one has something similar in a neural net that's for example trained to recognize digits like here regardless of exactly how each digit is written or the noise that gets added to it the network will take this input and evolve to an attractor corresponding to a digit sometimes there can be lots of attractors like in this uh Class 2 cellular automaton here evolving down the page many different initial conditions can lead to the same attractor um but there are many possible attractors corresponding to different final patterns of stripes the same can be true for example in 2D cellular automaton where now the attractors can be thought of as being different images with structures uh determined by the cellular automaton rule but what if one wants to arrange to have particular images as attractors here's where the somewhat surprising idea of stable diffusion can be used imagine we start with two possible images an image of an a an image of a b and them in Progressive steps we add noise to them well here's the bizarre thing we now want to do we want to train a neural net to take the image we get at a particular step here and go backwards removing noise from it the neural net we'll use for this is somewhat complicated with convolutional pieces that basically operate on blocks of nearby pixels and Transformers that get applied to certain weights with certain weights to more distance pixels so in more from language the network kind of looks at a high level like this schematically like this uh a bunch of things that got a bit overlap there but anyway um and roughly what it's doing is to make kind of an informationally compressed version of each image and then to expand it again through what's usually called the unit neural net uh we start with an untrained version of this network say just randomly initialized then we feed it a couple of million examples of noisy pictures of a and a b and the denoised outputs we want in each case then if we take take the train neural net and successively apply it for example to a noised a the net will correctly determine that the denoised version is a pure a let me see if I can show you that there we go but what if we apply this network to Pure Noise the network has been set up to always eventually evolve either to the a attractor or the B attractor but which it chooses in a particular case will depend on the details of the initial noise so in effect the network will seem to be picking at random to fish either the A or B out of the noise so how does this apply to our original goal of generating images like those found for example on the web well instead of just training our denoising or inverse diffusion Network on a couple of Target images let's imagine we train it on billions of images from the web and let's also assume that our network isn't big enough to store all those images in any kind of explicit way in the abstract it's not clear what the network will do but the remarkable empirical fact is that it seems to manage to successfully generate from noise images that follow the general patterns of the images it was trained from there isn't any clear way to formally validate the success it's really just a matter of human perception to use the images to to us the images generally look right it could be that with a different say alien system of perception we'd immediately see something wrong with the images but for purposes of human perception the neural net seems to give reasonable looking images perhaps not least because the neural net operates at least approximately like our brains and our processes of perception seem to operate so what we've now described how a denoising neural net seems to be able to start from some configuration of random noise and generate a reasonable looking image and from any particular configuration of noise um a given neural net will always generate the same image but there's no way to tell what the image will be of it's just something to empirically explore as we did above but what if we want to guide the neural net to generate an image that we describe as being of a definite thing like a cat in a party hat we could imagine continually checking whether the image we're generating will be recognized by a neural net as being of what we wanted and conceptually that's what we want to do so that's that's that's what we can do but we also need a way to kind of redirect the image generation if it's not going in the right direction and a convenient way to do this is to mix a description of what we want right into the denoising training process in particular if we're training to recover an a mix a description of the a right alongside the image of the a and here we can make use of a key feature of neural Nets that ultimately they operate on arrays of real numbers so whether they're dealing with images composed of pixels or text composed words all these things eventually have to be ground up into arrays of real numbers and when a neural net is trained what it's ultimately learning is just how to appropriately transform these disembodied arrays of numbers there's a fairly natural way to generate an array of numbers from an image just take triples of red green and blue intensity values for each pixel we could take a different detail representation but it's not like a lumata because the neural net can always effectively learn a conversion but what about a textual description like a cat and a party hat we need to find a way to encode text as an array of numbers and actually llms face the same issue and we can solve it in basically the same way as llms do in the end what we want to is to derive from any piece of text a feature Vector consisting an array of numbers that provide some kind of representation of the effective meaning of the text or at least the effective meaning relevant to describing images let's say we train a neural net to reproduce associations between images and captions as found for example on the web if we feed this neural methylene image it'll try to generate a caption for the image if we feed the neural net a caption it's not realistic for it to generate a whole image but we can look at the innards of the neural Nets and see the array of numbers that derive from the caption then use this as our feature vector and the idea is that because captions that mean the same thing should be associated in the training set with the same kind of images they should have similar feature vectors so now let's say we want to generate a picture of a cat and a party hat first we find the feature Vector associated with the text a cat and a party hat then this is what we keep mixing in at each stage of denoising to guide the denoising process and end up with an image that the image captioning network will identify as a cat and a party hat so the most direct way to do denoising is to operate directly on the pixels and image but it turns out there's a considerably more efficient approach which operates not on the pixels but on features of the image or more specifically on a feature Vector which describes an image in a raw image presented in terms of pixels there's a lot of redundancy which is why for example image formats like jpeg or PNG managed to capture manage to compress raw images so much without even noticeably modifying them for purposes of typical human perception but with neural Nets it's possible to do much greater compression particularly if all we want to do is to preserve the meaning of an image without worrying about those precise details and in fact as part of the of training a neural net not to associate images with captions sorry to to train the enormous to associate images with captions we can derive a kind of latent representation of images or an effective feature Vector that captures the important features of the image and then we can do everything we've discussed so far directly on this latent representation decoding it only at the end into the actual pixel representation of the image so what does it look like to build up the latent representation of an image with a particular setup we're using here it turns out that the feature Vector in the latent representation still preserves the basic spatial arrangement of the image the latent pixels are much coarser than the visible ones and happen to be characterized by four numbers rather than the three for RGB but we can decode things to see the denoising kind of happening in terms of latent pixels and then we can take the latent representation we get and once again use the trained neural net to fill in a decoding of this in terms of actual pixels getting out our final generated image so that's basically the story of how the generative AI Works to produce images and it's perhaps as a last thing I'll talk a little bit about an analogy to all of this in simple programs where we can kind of see a little bit more the essence of what's going on so generative AI systems work by having attractors that are carefully constructed through training so they correspond to reasonable outputs and a large part of what we've done here is to study what happens to these attractors when we change the internal parameters of the system like neural net weights and so on and what we've seen has been complicated often quite alien looking but question is is there perhaps a simpler setup in which we can see similar core phenomena by the time we're thinking about creating attractors for realistic images and so on it's inevitable that things are going to be complicated but what if we look at systems with much simpler setups for example consider a dynamical system whose status characterized just by a single number like an iterated map on the interval like X goes to ax times 1 minus X well starting from a uniform uh array of possible X images we can kind of show down the page which values of X are achieved at successive iterations so for the parameter value a equals 2.9 the system evolves from any initial value to a single attractor which consists of a single fixed final value but if we change the internal parameter a to 3.1 we now get two distinct final values and at the bifurcation point a equals 3 there's a sudden change from one to two distinct values and indeed in our generative AI system it's fairly common to see similar discontinuous changes in Behavior even when an internal parameter is continuously changed so as another example slightly closer to image generation consider as we did actually above a one-dimensional cellular automaton that exhibits Class 2 behavior and evolves from any initial state to some fixed final state that one can think of as an attractor for the system so here's an example of that which attracted one reaches depends on the initial condition one starts from but an analogy to our generative AI system we can think of all the attractors as being reasonable outputs for the system but now what happens if we change the parameters of the system or in this case the cellular automaton rule in particular what will happen to the attractors it's like what we did above and changing weights in the neural net but it's a lot simpler the particular rule we're using here has four possible colors for each cell and is defined by just 64 discrete values from zero to three so let's say we randomly change one of those values at a time here are some examples of what we get always starting from the same initial condition as as we did before so with a couple of exceptions these seem to produce results that are at least roughly similar to what we got without changing the rule in analogy to what we did above the cat might have changed but it's still more or less a cat but let's now try Progressive randomization where we modify successively more values in the definition of a rule of the rule for a while we get roughly similar results but then much like in the cat examples above things eventually fall apart and we get much more random results so one important difference between stable diffusion and cellular automata is that while in cellular automata the evolution can lead to continued change forever in stable diffusion there's there's an annealing process used that always makes successively successive steps progressively smaller and essentially forces a fixed point to be reached but notwithstanding this week and try to get a closer analogy to image Generation by looking again as we did before at 2D cellular automata so here's a an example of a well not too exciting as as images uh final States reached from three different initial States in a particular rule and here's what happens if one progressively changes that rule at first one still gets some uh reasonable according to the original rule final States but if one changes the rule further things get more alien until they look to us quite random in changing the rule one is in effect moving in rule space and by looking at how this works in cellular automata one can get a certain amount of intuition changes to the rule in a cellular automaton seem a bit like changes to the genotype in biology with the behavior of the cellular automaton representing the corresponding phenotype but seeing how real emotion Works in a generative AI that's been trained on human style input gives a much more accessible and humanized picture of what's going on even if it still seems further Out Of Reach in terms of any kind of traditional explicit formalization so that's uh what I had to say in the piece that I just posted I see a number of questions that have come in and I can perhaps try and address these quickly and then I have to disappear to something else um let's see it's a question here from shelf how can we filter out the human bias towards Pattern recognition um in terms of the fact that when we generate kind of images and inter-concept space we keep on trying to move them and do what the neural net does and kind of move them to attractors that we know that are Concepts that we know that's the thing we do it's an interesting phenomenon um let's see um question from Pete here about um uh the embedding of words in in high dimensional space um let's see that and I was showing the the line between dogs and cats in through interconcept space the thing to understand is when you're in a very high dimensional space yes there is a line that goes through particular points but there are many many many possible lines so it's very confusing in a sense it's kind of like if you're if everybody is on a railroad track all the trains you know have to be careful not to run into each other but as soon as you're in in uh in three dimensions there's just an awful lot of different paths you can follow if you choose a particular path if you're flying between two particular points in in in in the air or something then yes the planes can crash into each other because there's just that one line you're restricting yourself to but in even three-dimensional space there's an awful lot of room to maneuver and by the time you get to these many thousand dimensional spaces million dimensional spaces it's a it's a bit unintuitive but there's just an awful lot of room to maneuver so between uh the dog point and the cat point you can Define kind of a straight line and a certain version of that high dimensional space and there are a limited number of points on that line but as soon as you go off that line there's kind of a lot of room to maneuver um let's see there's a question Here For What from what do um about signal to noise ratio I think probably referring to the way that denoising happens in stable diffusion algorithms uh what happens is you start from it's all noise and then what you've done is to make a system which has learned how to go from something which had just a little bit of noise to something without that noise and then you say well I want you to do even more than that go from something that's all noise and see what happens and that's kind of how one goes from this sort of Pure Noise initial condition to a quote's reasonable image at the end and uh that that happens that the kinds of things I was showing the images and into concept space happen by uh you you can make those by just sort of starting with noise and then and then generating an image from that the slightly more complicated thing when you have actual prompts where you're saying and I want a thing that conforms to this kind of verbal description or this description that kind of interpolates between verbal descriptions then you're mixing in some more stuff that kind of guides the way that that denoising will happen but it's a very weird process that one goes from something that's kind of all noise to something that is actually an image all right well if those are all the questions people had we should uh wrap up here thank you very much for for uh meeting these cats and um I I just want to remind everyone that um you can find the text of what I was talking about here uh on my website Stephen walton.com um and uh you can run uh any of the things any of the pictures that I showed in that piece and in the in what I've been talking about today you can run on your own computer though it won't be terribly fast unless you have a fairly fancy GPU um the GPU that I used for these things I think has 25 gigabytes of vram so kind of a mid-range GPU all right well thanks very much and uh bye for now