welcome to virtual wednesdays my name is francesca d'alessio and i'm so glad you could join us tonight tonight we welcome kate crawford to kick off the second iteration of our annual series thinking machines this year we will expand on themes and conversations presented in the exhibition uncanny valley being human in the age of ai tonight will be the first of our three-part series that explores the ethical questions and public discourse around ai i'd pass it over to claudia schmuckley the curator of uncanny valley being human in the age of ai she's here to welcome kate crawford to our virtual wednesday stage and launch the 2021 season of thinking machines please welcome claudia schmuckley thank you fran i am thrilled to welcome kate crawford tonight she is a leading scholar on the social and political implications of artificial intelligence subjects that are at the core of the exhibition uncanny valley being human in the age of ai she's a research professor at usc annenberg a senior principal researcher at microsoft research and the inaugural chair of ai and justice at the normale superior in paris she's the author of atlas of ai power politics and the planetary cost of artificial intelligence and the co-founder of the ai now institute at new york university the world's first university institute dedicated to researching the social implications of artificial intelligence and related technologies she's also a frequent collaborator with artists some of whom are in this exhibition so i couldn't think of a better person to kick off this series welcome kate thank you so much claudia and hello everyone it's a pleasure to be joining you today i wish we were doing this in person but as things are this is the best we have um and i'd like to begin with an enormous congratulations to everyone at deyoung for the incredible uncanny valley show for today i'm joining you from the traditional lands of the gadigal people of the urination and i'd like to recognize their continuing connection to these lands waters and culture now for those who aren't familiar with my work i'm a professor at ufc annenberg and a senior principal researcher at msr in new york and my work is centered on the social political and ecological implications of artificial intelligence and just a couple of weeks ago i published a new book called atlas of ai power politics and the planetary costs of artificial intelligence published with yale university press so for today's talk i'd like to tell you a little bit about why i wrote this book and then take you to some of the locations where ai is made so let's start with the deceptively simple question what is artificial intelligence well if you type ai into your google image search this is what you'll get blue grids floating numbers men in glasses staring thoughtfully into the middle distance etched circuit boards and lots of white robots yes they're almost always white i'd say this is a deeply problematic but very common framing of ai it's all very abstract ethereal immaterial it is the ultimate view from nowhere but if you ask somebody in the street what ai is they might mention apple siri or amazon's cloud service or tesla's cars if you ask experts in deep learning they might give you a technical response about how neural nets are organized into dozens of layers that receive labeled data are assigned weights and thresholds one of the most popular textbooks on the subject states that ai is an intelligent agent that makes the best possible action in a situation now i'd suggest that each one of these ways of defining artificial intelligence is doing a particular sort of work that is really setting a frame for how ai is going to be understood measured valued and governed if ai is defined by these consumer brands then ultimately marketing and advertising have predetermined the horizon if ai systems are seen as somehow more reliable or rational than human experts then i think it suggests that we should trust them to make high-stakes decisions in spaces like education and healthcare and criminal justice and when these specific algorithmic techniques are the sole focus that then suggests that only continual technical progress matters and that obviously is in a very narrow sense with little consideration given to the computational cost of these approaches or their far-reaching social and economic impacts but if we seek to account for the full materiality of ai away from its position in the clouds we see that ai is neither artificial nor intelligent rather ai requires vast amounts of natural resources energy and human labor a giant infrastructure project with logistical demands that span the planet and it's in contra distinction i think to this idea of a disembodied brain because ai is not akin to human intelligence in any direct way and neither is it autonomous rational or able to discern anything without computationally very intensive training with large data sets or predefined rules and rewards in fact ai as we know it depends entirely on a much wider set of political and social structures and due to the capital required to build ai at scale and the ways of seeing that it optimizes it is commonly designed to serve the existing dominant interests such as the military policing and the wealthiest companies on the planet in this sense artificial intelligence is a registry of power so for this book i wanted to explore how ai is made in the wider sense which is why i use the concept of an atlas now atlases of course are unusual sorts of books they allow us to engage with the world at very different scales you can look at a continent or you could zoom in to look at a particular city or a mountain range and for me i think this connects to this idea that we need to leave the nowhere of algorithmic abstraction to reach the specific somewheres the places where people and institutions are making choices perhaps my favorite account of how a cartographic approach can be useful comes from the physicist ursula franklin she has this fantastic line where she says that maps bridge the gap between the known and the as yet unknown they're testaments of collective knowledge and insight and the process of writing this book owes a great deal to the scholars the archivists the artists and the activists that i've worked with over the years who formed my views some of which i'll mention in this talk but there are many others who i see this project as generally being in conversation with including simone brown wendy chun benjamin bratton who of course was another speaker in this series alondra nelson and lucy suchman so maps at their best allow us to make new interconnections but there are also maps of domination those maps that show us the contested spaces and colonial paths of empires by invoking an atlas i'm suggesting that we need ways to account for the empires of artificial intelligence we need a theory of ai that looks to the states and corporations that drive and dominate it the extractive mining that leaves an imprint on the planet the mass capture of data and the profoundly unequal and increasingly exploitative labor practices that sustain it these are the shifting power tectonics of ai a topographical approach i think offers different perspectives and scales beyond just considering the latest machine learning models and there's another way that atlases i think are relevant here the field of ai is explicitly attempting to capture the planet in computationally legible form this is not a metaphor so much as the industry's direct stated ambition some ai scientists have in fact said that the aim of ai is to really map the planet and supersede other forms of knowing if we look at the imagenet project for example it is its aim is to map the entire world of objects and one of the very early founders of ai an early experimenter in facial recognition known as woody bledslow said in his words in the long run ai is the only science now this is a desire not to create an atlas of the world but to be the atlas the dominant way of seeing and this colonizing impulse centralizes power right back into the ai field itself where the world is being measured and defined while simultaneously denying that this is a political activity by its very nature i'm thinking here of the medieval mapamonde which illustrated religious and classical concepts as much as they did coordinates in some ways the maps made by the ai industry are just like this they are political interventions they're certainly not neutral reflections of the world so in contrast my aim here is to work against the grain of colonial mapping logics and actually move to different stories locations and knowledge bases than the ones we commonly hear in the shiny colonialist pioneer narratives of ai so a significant precursor uh to atlas of ai was this collaborative project that i did with the artist ladan jolo where we map to the entire life cycle of a single amazon echo those little beige nondescript cylinders that you may have in your living room or your bedroom depending how you feel about listening devices now this project ended up being i will confess a much bigger research endeavor than either of us expected because we started by looking at essentially the data pipelines in terms of how amazon harvests our voices but then we ended up going much further afield to if you will look at the entire nose-to-tail cycle of making ai that meant going into the supply chains going into the sort of the mining structures the pay scales the smelting practices and in container shipping and all the way through to the end of life where these devices are disposed in giant e-waste tips in places like ghana and pakistan when we completed this project i wanted to expand this analysis from looking at a single device to looking at the entire ai industry itself to create if you will an expanded view of ai as an extractive industry across natural resources data and labor so that was the motivation behind this five-year project of writing atlas of ai i structure the book around eight core chapters it's a stack analysis of ai in the wider sense it starts with earth and moves through labor data classification affect state power and space as the book begins at ground level i thought that might be a nice place to start today now when you fly into san francisco international airport you see this the aerial view of the empires of silicon valley we have the gigantic black circle of apples headquarters and then google's pretty nondescript head office you see the collection of squat buildings that are home to facebook which are ringed with massive parking locks which are set close to the sulphuric salt ponds of the ravenswood slough and from this vantage point the mid-rise skyline of palo alto betrays very little of its true wealth and power and centrality in the global economy but to learn about what ai is and how it's made we need to leave silicon valley all together and to travel to places like this this is the road to silver peak in nevada's clayton valley where about 125 people live depending how you count now this mining town is one of the oldest in nevada it was almost abandoned back in 1917 after the ground was stripped bare of silver and gold but in the 1950s people realized that silver peak is perched on the edge of a massive underground lake of lithium now the valuable lithium brine under the surface is being pumped out of the ground and left in these open iridescent green ponds to evaporate it's the only operating lithium mine in the u.s and it makes this site a place of extreme interest to people like elon musk and the other tycoons for one reason rechargeable batteries here in this remote pocket of nevada is a place where the stuff of ai is made lithium is also known as grey gold smartphones for example usually have around seven grams of this material the amazon echo has double that but each tesla model s car has around 62 kilograms of lithium which is required for its battery pack now these kinds of batteries were never intended to power something as power hungry as a car but lithium batteries are currently the only mass market option available now all of these batteries have a limited life span they can be recycled but it's quite difficult to do so and they're commonly discarded as waste a 2020 study by the university of augsburg in germany modeled 18 different scenarios of how we can actually treat lithium in such a way that we can keep using it and what they found on their most optimistic estimates and this of course assumes the best recycling practices is that lithium could be fully depleted just after 2100 but without best practices we could be seeing critical levels by 2040 and of course these imminent shortages are something which is now becoming an issue for the us more generally now claim valley is connected to silicon valley in much the same way that the 19th century gold fields were connected to early san francisco the history of mining like the devastation it produces is commonly overlooked in stories of technological process as the historical geographer great brecken points out san francisco was built on the gains of pulling gold and silver out of the lands of california and nevada in the 1800s when the land was stripped and the waterways were contaminated now since antiquity the business of mining has only been profitable because it does not have to account for its true costs in 1555 georgia's agricola known as the father of mineralogy observed that it's clear to all that there is a greater detriment from mining than the value of the metals that the mining produces in other words those who profit from mining do so only because the costs must be sustained by others if we only price the extracted minerals and not the negative externalities an easy calculus emerges extract everything as rapidly as possible that was if you will the move fast and break things of a different era now san francisco drew enormous wealth from the mines and and while that can be easy to forget there are these little reminders all around in the architecture of the city itself because the buildings have been constructed using the same technology that came from deep within the central valley these images come from the diagrams from the report of the geographical exploration of the 40th parallel in 1870. the square set timbering method was used to extract ore in nevada and the pulley system that carried miners down into the mine shafts were then turned upside down to transport people upwards into the elevators of the city's sky rises so bracken suggests that we should think of the skyscrapers of san francisco as inverted mindscapes the oars extracted from holes in the ground were then sold to create stories in the air and the deeper the extractions went the higher the great towers of office work stretched into the sky now of course san francisco is being enriched once more thanks to the extraction of substances like white lithium crystal vast amounts of data and human labor all along the supply chain just around 200 miles north of silver peak is this the tesla gigafactory this is the world's largest lithium battery plant right now tesla is estimated to use more than 28 000 tons of lithium hydroxide annually that is half of the planet's total consumption in fact we might think of tesla more accurately as a battery business rather than a car company so indeed as we know these sorts of sites are the ones that are imperiled if we start to think about what happens about the end of lifespan of these critical minerals like lithium but of course the mining that makes ai is both literal and metaphorical the theorists sandra mazadra and brett nielsen use this term extractivism to think about all of the different forms of extractive operations in contemporary capitalism i'm thinking here also of heart and negri the philosophers who think about this sort of dual relationship between extraction and abstraction you can think about all of those abstractions of ai and sort of numbers and images of white robots whereas in actual fact these are the extractions that are being abstracted away in many ways the cloud that we know the backbone of the artificial intelligence industry is made of rocks and lithium brine and crude oil in his book a geology of media the theorist yussi perika suggests that we think of media not from marshall mcluhan's point of view as extensions of the human senses but rather as extensions of earth itself computational media now participate in geological and climatological processes from the transformation of the earth's minerals into infrastructures and devices each object in the extended network of an ai system from routers to batteries to data centers is built using elements that required billions of years to form inside the earth so from the perspective of deep time we are extracting earth's geological history to serve a split second of contemporary technological time building devices like androids and iphones that have an average lifespan of around 4.7 years all of those devices ultimately end up buried in e-waste dumping grounds much of that waste used to go to china but when china banned e-waste because of its toxic legacy now it is sent to places like thailand pakistan and ghana one recent stat says that around 70 percent of all hazardous waste in landfills is now e-waste and i think this is why we need to traverse far beyond the united states to see the legacies of the tech industry there are so many such sites from basala in bolivia they're currently the richest side of lithium in the world and of course that's the site of ongoing political tension as well as places in the central congo mongolia indonesia and western australia these are the other birthplaces of ai in the greater geography of industrial computation now we can see these patterns across space but we can also see them across time at the end of the 19th century a southeast asian tree called the polyquium gutter became the center of a technological boom these trees which are found mainly in malaysia produce a milky white latex which is called gutta-percha after the english scientist michael faraday published a study in 1848 showing that this could be used as an electrical insulator gutta-percha rapidly became the darling of the engineering world it was seen as the solution of the problem of how to insulate telegraphic cables along the ocean floor now malay chinese and dayak workers were paid almost nothing for the dangerous work of felling the trees and slowly collecting that latex that latex was then processed and transformed to miles and miles of submarine cable sheaths in 1857 the first transatlantic cable required 250 tons of gutter percher but to make just one tonne of this material took over 900 000 tree trunks so the jungles of malaysia and singapore were rapidly stripped bare and by the early 1880s the palaiquim gutter tree had almost completely vanished the victorian environmental disaster of guru departure from the earliest origins of the global information society i think shows how these relationships between technology and its materiality are implicated just as victorians precipitated ecological disaster by undersea cables so do rare earth mining and global supply chains further imperil the delicate ecological balance of our own era so minerals are the backbone of ai but the lifeblood is still electrical energy now certainly the industry is trying to make efforts to make its data centers more energy efficient but already the carbon footprint of the world's computational infrastructure has overtaken that of the aviation industry at its height and since covert has accelerated at a much greater rate the energy demands of producing an ai model is still an emerging area of investigation but one of the early papers in the field was from an ai researcher by the name of emma strubel and her team at the university of massachusetts amherst back in 2019 they found that running just a single nlp model produced more than 660 000 pounds of carbon dioxide emissions or around 125 round trips from new york to beijing another paper published just back in march by emily bender tim nick gabriel margaret mitchell and angela mcmillan major pointed to the considerable environmental harm of the new large language models in machine learning which doubly punish marginalized communities because they're the least likely to benefit from the progress of these kinds of language models but most likely to be harmed by the negative ecological consequences now all of these researchers note that their modeling is just a baseline optimistic estimate and it doesn't reflect the true commercial scale at which companies like apple and amazon operate scraping these internet-wide data sets and feeding their own models but the exact amount of energy consumption produced by the tech sector is still unknown that information is kept as a highly guarded corporate secret just like mining at the mineralogical layer the data economy is premised on maintaining environmental ignorance so in some ways we might think of artificial intelligence as another kind of what the philosopher of technology lewis mumford called a mega machine that is these assemblages of technological technological approaches that depend on industrial infrastructure supply chains and vast amounts of dispersed human labor that stretch around the globe but are kept opaque we can see how ai is much more than databases and algorithms it is metamorphic fundamentally transforming the earth with manufacturing transportation cabling adding transmission signals through the air data sets produced by scraping the internet and continual computational cycles undergirding the entire process so my experience of traveling to the sites of ai's material production has really fundamentally changed the way i see and understand these systems and similarly i think it was really working with the technical substrates of ai that also changed my mind about how we do the work of sense making through our technical systems i was in part of a ultimately two-year collaborative project with the artist trevor paglin and of course you can see trevor paglin's work in the uncanny valley show at deyoung right now now trevor and i studied the large databases that are used to train ai systems to see the world and we then produced an exhibition on the history of training data for ai at the foundation prada museum in milan and it was called training humans now the research process behind the training humans exhibition revealed to us not just the deep problems with the underlying logics of training data from obvious biases and skews to the kinds of classificatory taxonomies that should really concern us but it also for me created this sort of mirroring effect where we can see how the extraction of data and the extraction of natural resources are each occurring because they do not have to be accountable for their full planetary costs over time and i think in some ways this is a reminder that the mines that drive ai are everywhere they are at physical sites scattered across the geography of the earth as well as in the devices and networks that we use every day i think understanding these deep material and human roots of ai systems is vital given that we are in a period of deepening inequality and of course anthropogenic climate change but that is easier said than done in part that's because these industries that make up the ai supply chain conceal the ongoing costs of what they do furthermore the scale required to build these systems is so complex obscured by intellectual property law mired in logistical and technical details that in many ways seeking full transparency will never be the answer instead if we're to work across and for greater justice i think we need to connect these ideas of the environment labor and data together to create what ashil and bembe calls a different politics of inhabiting the earth of repairing and sharing the planet or what the feminist political theorist jk gibson graham describes as finding ethical coordinates map-making again for a new kind of interdependence between humans non-humans and ecologies just before the pandemic hit i made my last trip to silver peak and then i walked up in the hills above the mine through these remnants of buildings which i discovered is a ghost town a town that used to be called blair in the early 1900s blair was a thriving town based around gold and silver mining and many hundreds of people came here for work and cheap housing but with so much mining activity the cyanide that was used for leaching the minerals began to poison the earth and ultimately the seams began to falter and dry up by 1918 blair was deserted and it was all over within 12 years silver peak may also be a ghost town soon the current draw on the lithium mine is very aggressive in response to the demand and nobody knows exactly how long it will last it might be 80 years or the end might come much sooner than that then the lithium pools underneath the clayton valley will be gone extracted for batteries that are destined for landfill and silver peak will return to its previous life as an empty and quiet place on the edge of an ancient salt lake now drained thank you very much we can move to questions now and invite francesca to join us i might just stop sharing right here so we can see each other hey perfect thank you all right hi thank you for that you are brilliant uh that was just wonderful um and unfortunately claudia wasn't able to join us live tonight but she sent a bunch of questions um and so i think let's just dive in and i encourage our audience too to drop some questions in the chat and uh kate and i will make sure to get to them too so if anyone's watching and has pressing questions please ask them um all right so our first question this one's from claudia uh your book atlas ai is very much a journey to multiple places around the world from factories to mines to even jeff bezos space launch pad tell us a little bit about your research methods and going to these locations and what you thought well yes uh i did indeed go to jeff bezos's uh space reusable locker reusable rocket base in west texas um in fact that's where i end the book uh and it's interesting because certainly for me part of this process of bringing ai back to earth and of seeing its full planetary consequences really meant sort of putting myself on the line going to those places seeing what it was like to be working in those mines being in an amazon fulfillment center going to the labs where large scale training sets are made and indeed you know visiting jeff's you know new space company blue origin and what i found in each one of these places is that even as someone who has been researching these topics for many years i mean i've been looking at ultimately artificial intelligence and related technologies for over 15 years now something really shifted for me by going to the places where it's made and and partly that's because you get to see the consequences differently i'm thinking here of when i visited amazon's fulfillment center in robinsville in new jersey of course we hear so much about these you know shiny environments where robots and humans interact in sort of hybrid workplaces but the reality is very different and and certainly just seeing the physical toll of working in these environments which you know are not just requiring lots of repetitive motions but also the sort of oppressive work of algorithmic management of trying to sort of meet what's called the picking rate of getting the right number of objects sort of packed away every hour i just saw so much stress physical stress you know people wearing sort of support bandages um many people who are sort of physically just feeling the strain of these spaces and and that affects you as a researcher it means the stakes are different the stakes become personal and they become in many ways sort of inhabited um these are spaces where people are working every day so to try and sort of move away from the stories of sort of silicon valley engineers sort of wearing hoodies and and hanging out and drinking lattes and actually seeing what these systems look like and all of the people that are being drawn on to make them work and all of those resources that was really sort of that you know the origins of atlas of ai wow and and thank you for sharing with us because a lot of us are unaware of those conditions as well um and so you know letting us know and letting us into these systems is incredibly powerful well and that's by design right i mean part of the way that these stories are told are precisely to keep us away from sort of seeing sort of the full impacts and costs of those supply chains and you know which is to say that in in so many ways by seeing it you start to think differently but it's not to suggest that this is somehow you know a consumer action problem and that you know we can choose more ethical or green ai i think it's it's really much more of a collective action problem it's you know what are we going to accept in terms of the conveniences that we get from from some of these systems like being able to speak to you know alexa and say hey alexa please order me some toilet rolls you know what does that actually cost in in the fullest sense i think means that we can have a different kind of calculus and we can think differently about how and where we use these systems yeah absolutely um so our chats are getting full um so this is from our youtube chat i'm concerned about the geopolitics on these environmental issues biden harris say they want to fight climate change but also want to secure in quotes rare earth supply chains can they do both i love this question uh and as people would know just last month the biden administration released an executive order saying that they have to secure these sort of critical supply chains and certainly rare earth minerals and lithium the things we've been talking about today are a core part of that because the vast majority of that material comes from places like china and western australian deserts so what we're seeing now is i think a bit of a global scramble both in terms of you know who controls and runs large-scale ai industrial power but also who owns these critical supply chains and can you do both i mean can you i mean certainly the us is trying to and and certainly as is china but what we're facing i think is a much deeper issue which is what is that environmental legacy looking at how rare earth minerals are produced is itself absolutely shocking i mean they're called rare earth they're actually quite common in the earth's crust but they're in quite sort of dispersed quantities so to produce them at scale and to enrich them actually requires a really toxic process that also sort of produces enormous amounts of waste and radioactivity so even here you know by creating these and securing these supply chains is a commitment to a type of environmental damage that i think we really have to question so rather than sort of assuming that these things are infinite and can continuously be giving us endless sort of mineral supplies i think we need to look much more closely at how we're actually engaging with these supplies how they're being produced and what these medium to long-term effects are because certainly in my research i mean i've just been really appalled at looking at where those legacies are produced and who who lives with them and again it's it's often the poorest the most marginalized communities who are experiencing those greatest downsides right wow um all right the chats are are really filling up here's another one uh you've collaborated with several artists over many years can you describe your interest in working in that format how would you describe the difference in methodology and resonance between a scholarly and artistic engagement with the social and political implications of ai so i mean it's i've been really lucky to collaborate with some fantastic artists over the years uh you know people like trevor paglin and vlad angelo who i mentioned the talk but but also many others um groups like deep lab which is a sort of feminist art collective and that was established by addie wagoneck and others several years ago and what i find in these sorts of collaborations is it's very different to what academics tend to do which is you know we write papers we speak at conferences and that is important work you know i will never denigrate that but it certainly does speak very much to an already informed group how do we actually have a bigger public conversation now that ai systems are affecting so many areas of our lives and simultaneously we're sort of seeing the sort of simultaneous shift into work life into education into healthcare into hiring into policing this requires a very different sort of moment and i think it requires a democratic conversation certainly a much more widespread conversation than is currently happening just within academia or just within industry itself and this is somewhere where i think artists are extremely well placed to sort of bring these ideas and debates into new spaces and also to give people a sense of being empowered to understand systems to have opinions on them and to sort of get a purchase on how they work we're going to need that particularly as these systems become more complex and are sort of presented to us in ways that only experts could possibly understand i think artists really brilliantly undercut that and say why let's let's look at these systems let's actually demystify them let's actually make them feel material so for me that that has really changed not just the way i produce research but also i think that the goals of what we're hoping to do here you know it's it's not just about sort of publishing more it's about changing practices and and that requires different modes right absolutely i look forward so much to meeting you in person and showing you uncanny valley i can't wait um okay so here's a good question you talked about the ecological implications of ai can you share what your timeline for where we are at now and what we can expect if things don't change well certainly the timelines are looking really stark um one of the studies that i shared today you know it was only published a couple of months ago and it really shocked me because it made me realize that there are so many scientists who have been sounding the alarm for a long time saying that the current rates of production for so many of these large-scale computational systems can't really be sustained without some really substantial shifts to the way that we recycle produce and use these systems so there seems to be a very profound disconnect between what we know about what the planet can sustain and what's actually happening industrially and and we see that disconnect of course across many industries and they you know we're dealing with this in terms of climate change itself you know how do we take knowledge that we have and actually put it into action so in terms of what i see in terms of the the horizon my hope is that more and more people will start to realize that even at the level of how we build technical systems they have to change but there's more than just that we cannot sustain a constant idea of limitless growth that idea of growth itself i think has become so deep in the sort of computational mindset and in the tech sector where we actually need to start questioning that quite profoundly one of the things that i found interesting and part of the reason i sort of end the book by going looking at the space industry is because you know so many of the sort of tech billionaires are now taking all that money that they made out of the tech sector and using it to build systems to leave the planet so what does that tell us about responsibility kind of to planet earth and where this came from more than that i think it's this idea that growth must be sustained so that must mean mining asteroids or you know reaching other planets rather than questioning that precept so certainly you know for me seeing that ideological trajectory is is part of this work is to say that is where we need to intervene why is that the vision of the future is to sort of abandon earth rather than to think differently out how to make this a sustainable home wow that gives me chills that's scary this is really scary stuff your work has also inspired simon denny whose work is in uncanny valley and spatializes the patent for the amazon work uh that is part of the anatomy of the ai project tell us about how these ideas are spreading into different modes i love simon denny's work and and you know i've been fortunate to sort of see that show which you know and particularly that piece um what he did is he looked at uh the amazon patent that vladimir and i write about in anatomy of an ai system and to tell you the back story on this uh we were sort of researching all of the production paths of the amazon echo and we found this patent for a cage that workers would be within uh inside fulfillment centers as a way of keeping them safe as they're collaborating with robots and it looks absolutely horrifying and again writing about patents you're always really writing about corporate imaginaries it doesn't mean that these things are built the cage doesn't currently exist but it was certainly something that amazon thought was important enough to patent so what simon denny did which i thought was was fantastic is he actually built one a super-sized scale cage that would be completely sort of along the this is the specs of amazon's patent and you know to see him sort of put that alongside the board game that he developed called extractor which is again thinking about these ideas of of mining that connect landscapes to data mining um for me it was just like a brilliant set of resonances that he took in a whole new direction to actually make these things visible so that you can see them you can walk around them you can imagine what sort of logics of work are being articulated in machines like that um and of course you know amazon has responded and said you know we have no intention of building cages you know we have we have vests that workers wear that alert them and buzz when they come into contact with a robot so it's a different type of cage i guess um but but certainly you know for me seeing this work sort of shift into different cultural modes is is part of the excitement of doing it uh and again it's that idea that these conversations have to travel for us all to be included in making decisions about whether these are the sorts of worlds that we want and and the cage is really a sight to be seen it sits in the exhibition definitely an anchor point of the exhibition have you gone up and touched it yet have you actually sort of felt the cage tactile it is i mean it has a presence i think i think everyone walks up and questions and touches it and and tries to make some sort of understanding around it right and it's it's so different when you see when you see that on a patent diagram and it sort of has this kind of cold clinical appearance of you know we've designed this cage because this is how humans can work with robots and then when you actually see it and you just see what what is the thinking here you know what is this vision of the contemporary workplace that we're working towards um you know that that's that's again part of the brilliance of what simon is doing there absolutely brilliant yeah okay so our last question your work over many years has focused on politics rather than ai ethics which we hear so much about tell us how political focus will help us in years to come this is a sort of a very live topic in the field at the moment um really sort of the ai ethics debate which has raised so many good questions you know in terms of how we think about the ethics of how these systems are constructed has also in many ways been captured and sort of turned into itself a new corporate discourse of you know essentially types of principle statements or you know ethical ideals which don't necessarily connect to the modes of production so i think one of the things in my work is that i've really focused on politics you know what are the forms of politics that are embedded in technical systems what kinds of politics do they promote you know how do they connect and produce particular forms of engagements with humans and environments and this gives us i think a different focus and in some ways a focus that i think is going to be very necessary in the next few years because i think we need to shift away just from you know ethics which is necessary but not sufficient to something which is going to be a much sort of stronger set of systems of accountability now regulation is obviously one of them um the calls for regulation are getting louder and louder and we have seen just in the last two weeks the eu release a draft set of principles for regulating ai and this was interesting because it's you know it's the first omnibus piece of suggested legislation uh to engage with all of these questions around how ai should be allowed to participate in social institutions and decision making as to you know how it will work it relies a lot on this this issue of transparency and notice of letting people know that you know systems like facial recognition or emotion detection are operating in many ways i think we need something stronger than that i think you know the way in which we're actually going to contain can tail rather curtail and contain both of them these systems is actually going to be something that regulators will be struggling with for some time but it's certainly exciting to see the beginning of that conversation happening in the eu and it's certainly streets ahead of where we are in the u.s so there's a lot of catch-up to be done but as i say in atlas you know these are global questions and it will be really important that what we see is not that you know people's rights are protected in places like the eu but yet we see in the global south that you know here are the ai client states where these systems are tested and people have very little by way of data protections let alone issues around climate justice and labor rights so this is where i think the big step needs to be taken politically is how do we connect these existing groups who work for things like climate change and labor rights and data protection and bring them together to see that these are in fact a shared set of concerns that are articulated in the way that technical systems are centralizing power right now absolutely thank you yeah and accountability is going to be key 100 yeah well thank you so much kate thank you for your time thank you for this beautiful presentation and thank you for all of your advocacy um it couldn't be more important so thank you so much and thank you everyone for joining us tonight thinking machines is made possible with support from app dynamics uh please join us on june 16th we welcome kathy o'neil our next rendition of thinking machines right here on virtual wednesdays um and thank you so much we hope to see you next week thanks everyone for joining and thank you so much francesca lovely to see you and hope to see you in person next time absolutely thank you so much you