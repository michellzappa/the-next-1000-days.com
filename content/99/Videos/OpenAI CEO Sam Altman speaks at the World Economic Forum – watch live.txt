[Music] [Music] [Music] [Music] [Music] [Applause] move all right this is the panel people have been waiting for um welcome all of you thank you so much for doing this uh if I can just ask you uh to turn your phones to silent I've realized in this day and age asking people to turn their phones off means they will not get a chance to record the event on video which means it didn't happen for you for you if you were not able to photograph it so keep keep the photo photography going if you want but please turn your the the sound off um we are going to try to solve the problem of AI in this panel we have 45 minutes so um Henry Kissinger used to say people who need no introduction crave it the most so I am going to uh I'm going to abandon that rule I think nobody here needs an introduction you know who they all are um and I'm going to assume none of them particularly care um let me start uh with you Sam I think most people are worried about two two kind of opposite things about AI one is it's going to end human humankind as we know it and the other is why why can't it drive my car um where do you think realistically we are with artificial intelligence uh right now what what is it for you what are the things it can do most effectively and what are the things we need to understand that it cannot cannot do you know I I think a very good sign about this new tool is that even with its very limited current capability and it's very deep flaws people are finding ways to use it and it for great productivity gains or other gains and understand the limitations so A system that is sometimes right sometimes creative often totally wrong you actually don't want that to drive your car um but you're you're happy for it to uh you know like help help you brainstorm what to write about or help you with code that you get to check and so we have been help us understand why can't it drive my car well there are I mean there are great self-driving car systems but uh like at this point you know way mes around San Francisco are there are a lot of them and people love them um what I meant is like the sort of opening eye style of model right is good at some things but not good at sort of like a life and death situation um but people under I think people understand tools and Tool limitations of tools more than we often give them credit for and people have found ways to make chat gbt super useful to them and understand like what not to use it for for the most part so I think it's a very good sign that even at these systems current extremely limited capability levels you know much worse than what we'll have this year to say nothing of what we'll have next year uh people lots of people have found ways to get value out of them and also to understand their limitations so you know I think it's AI has been somewhat demystified uh because people really use it now and uh that's I think always the best way to pull the world forward with a new technology the the thing that I think people worry about is the ability to trust AI you know what at what level can you say I'm really okay with the AI doing it you know whether it's driving the car writing the paper filling out the medical form and part of that trust I think always comes when you understand how it works and one of the problems uh AI researchers have ai Engineers have is figuring out why it does what it does um you know how the neural network operates what weights it assigns to very ious things um do you think that we will get there or is it getting so inherently complicated that we are at some level just going to have to trust the black box so on on the first part of your question um I think humans are pretty forgiving of other humans making mistakes but not really at all forgiving of computers making mistakes and so people who say things like well you know self-driving cars are already safer than human driven cars it probably has to be safer by a factor of I I would guess like between 10 and 100 before people will accept it maybe even more and I think the same thing is going to happen for other AI systems caveat by the fact that if people know if people are accustomed to using a tool and know it may be totally wrong um that's kind of okay I think you know in some sense the hardest part is when it's right 99.999% of the time and you let your guard down um I also think that what it means to to verify or understand what's going on is going to be a little bit different than people think right now uh I actually can't look in your brain and look at the 100 trillion synapses uh and try to understand what's happening to each one and say okay I really understand why he's thinking what he's thinking you're not a black box to me um but what I can ask you to do is explain to me your reasoning I can say you know you think this thing why and you can explain first this then this then there's this conclusion then that one and then there's this and I can decide if that sounds reasonable to me or not and I think our AI systems will also be able to do the same thing they'll be able to explain to us in natural language the steps from concl from A to B and we can decide whether we think those are good steps even if we're not looking into it and saying okay I see each connection here and you know I don't get to like I think we'll be able to do more to x-ray the brain of an AI then x-ray the brain of you and understand what those connections are but at the level that you or I will have to sort of decide do we agree with this conclusion we'll make that determination the same way we'd ask each other explain to me your reasoning um one of the things you and I have talked earlier and one of the things you've always um emphasized was that you thought AI can be very friendly very benign very empathetic and I want to hear from you what you think um what do you think is left for a human being to do if the AI can out analyze a human being can out calculate a human being a lot of people then say well that will th you know that means what we will be left with our core innate humanness will be our emotional intelligence our empathy our ability to care for others but do you think AI could do that better than us as well and if so what what's the core competence of human beings I think there will be a lot of things humans really care about what other humans think that seems very deeply uh wired into us so chess uh was one of the first like victims of AI right d blue could be casprov whenever that was a long time ago and all of the commentators said um this is the end of Chess now that a computer can beat the human there you know no one's going to no one's going to bother to watch chess again ever it's over or play chess again chess has I think never been more popular than it is right now um and if you like cheat with AI That's a big deal and no one or almost no one watches two AI play each other um very interested in what humans do when I read a book that I love the first thing I do when I finish is like I want to know everything about the author's life and I want to like feel some connection to that person that made this thing that resonated with me and uh you know like what same thing for like many other products that that humans know what other humans want very well humans are also very interested in other people I think humans are going to we're going to have better tools we've had better tools before but we're still like very focused on each other and I think we will do things with better tools and I admit it does feel different this time general purpose cognition Feels So Close To What We all treasure about Humanity that it does feel different so of course you know there will be kind of the human roles where you want another human but even without that I think like when I think about my job I'm certainly not a great AI researcher um my my my role is to like you know figure out what we're going to do think about that and then like work with other people to coordinate and make it happen and I think everyone's job will look a little bit more like that we will all operate at a little bit higher of a level of abstraction we will all have access to a lot more capability um and we'll still like make decisions they may Trend more towards curation over time but we'll make decisions about what should happen in the world Mark let me bring you in as the as the other technologist here what do you think of this question of what um so what what Sam seems to be saying is that you know it is those those emotional teamwork uh kinds of qualities uh that become very important you you you have this massive organization use massive amounts of Technology what do you think what what is what are human beings going to be best at in a world of AI well I don't know uh you know um when do you think we're going to have our first uh we uh panel moderator by an AI you know I've been on sitting on the stage for a lot of years I'm always looking down at someone got a great moderator right here with us and uh but maybe it's not that far away Along you know maybe pretty soon a couple years we're going to have a we digital moderator sitting in that chair moderating this panel and maybe doing a pretty good job because it's going to have access to a lot of the information that we have now I think it's going to evoke the question of are we going to trust it I I think that trust kind of comes up right up the hierarchy pretty darn quick you know we're going to have digital doctors digital people and these digital people are going to emerge and there's going to have to be a level of trust now today when we look at the AI and we look at the gorgeous work that Sam has done and so many of the companies that are here that we've met with like kohir and mrr and anthropic and all the other model companies are doing great things but we all know that there's still this issue out there called hallucinations and hallucinations is interesting because it's really about those models they're fun we're talking to them and then they lie and then you're like whoa that isn't exactly true I was at dinner last night and we were having this great dinner with some friends and I was we were asking the AI about you know one of my dinner guests and said the AI went well you know this person is on the board of this hospital and she turned to me she goes no I'm not and we've all had that experience haven't we we have to cross that bridge we have to cross the bridge of trust it's why we went to this UK safety Summit um we all kind of piled in there a couple months ago and it was really interesting because the first time the technology leaders kind of showed up and every government technology Minister from every country it was amazing actually it never really seen anything like it but everyone's there because we realize we are at this threshold moment but we're not totally there yet we're at a moment there's no question because we're all using you know Sam's product and other products and going wow we're having this incredible experience with an AI we really have not quite had this kind of interactivity before but we don't trust it quite yet so we have to cross trust we have to also turn to those regulators and hey if you look at social media over the last decade it's been kind of a show it's pretty bad we don't want that in our AI industry we want to have a good healthy partnership with these moderators and and with these Regulators I think that that begins the power of kind of where we're going and when I talk to our customers about what they want they don't really know exactly what they want I mean they know they want more margin you know Julie will tell you that they want more productivity they want better customer relationships you know is going to want that but at the end of the day you know they're going to turn to these AIS and are they going to replace their employees or are they going to augment their employees and today the AI is really not at a point where we're replacing human beings it's really at a point where we're augmenting them so I would probably not be surprised if you used AI to kind of get ready for this panel and asked you know chat PT some really good questions hey what's some good questions I could ask Sam Alman on the state of AI it made you a little better it augmented you you know my radiologist is using AI to help read my CT scan and to my MRI and this type of thing we're just about to get to that breakthrough where we're going to go wow it's almost like it's a digital person and when we get to that point we're going to ask ourself do we trust it all right for the record I did not use Chad GPT to prepare for this panel um but my is not quite there yet um Julie uh people talk about AI at a level of abstraction but I feel like people are trying to understand so how does it really improve productivity in exactly you know the question mark was posing so you run a vast organization I mean you just told me you employed 330,000 people in India alone what do you have any sense already of how you are implement menting Ai and what it's doing yeah yes so let me be practical for a moment I'm old enough that I remember when I was working at my Law Firm an email was introduced and I remember because I was a young lawyer who after five you had to stand by the fax machine yourself to fax anything to send to a client so email came and we were thought this is amazing and the heads of our Co of my Law Firm said well emails great great but you cannot attach a document and send it to a client because it's not safe now think about that a little bit of what's happening today when we have these abstract conversations our employees actually want in many cases to use this technology and they're going to start pulling for example if you do field sales in in consumer goods you spend most of your time trying to figure out what was the customer you know did we have a delivery issue because that's a different department and all that and today today with the technology today with all the appropriate caveats you can very accurately now on your phone be told which customer to go to whether they had a delivery problem generate something personalized and then spend most of your time talking to your customer which is how you really grow so when we think about AI of course there are different risks the technology is going to change as Sam said right and it's all about knowing what is it good for now how can you implement it with the right safeguards as a CEO I have someone I can call in my company they can tell me where AI is used what the risks are how we manage them and therefore we implement it and so we're implementing it broadly in the areas where it's ready now but I think we have to be careful that we don't you know you started this panel by seven saying we're going to solve the problem of AI and the immediate thing I said is I hope we're going to figure out how to use AI because it's a huge opportunity and I'm sure Albert's going to talk about what it's going to do for science but it's also doing a lot of great things for our people who don't want to spend their time reading and trying to figure out things and would love to spend their time with clients with customers so the single biggest difference between those who will use it successfully and not I believe our leaders educating themselves so they're not the ones that told me I couldn't email a document but you cannot do that if you do not spend the time to learn the technology and then apply it in a responsible way so if you were to try and improve productivity at Accenture um wouldn't one way be to use AI to have fewer people do what they do now in other words you know you have some large Department that fills out forms or things something like that the AI would much more efficiently be able to do it so you need half as many people is that likely fre so just remember gen is the latest AI I've been doing that for a decade I used to have thousands of people who manually tested computer systems that essentially went away in 2015 right so when my investor has asked me well you know when are you going to break the difference between people and Technology I'm saying I've been doing that every year I literally serve clients and promise that every year I'm going to find 10% more productivity before gen this is not new right this is more powerful than prior versions of Technology it's more accessible and you didn't hear things like responsible PC okay that wasn't a concept right right so because it's more powerful we have to think differently in 2019 we had 500,000 people we have 740,000 now we introduced technology training for everyone whether you worked in the mail room we still have one in HR or with our clients and they had to learn basic and past assessments AI cloud data you know today this in the next 6 months we'll train 250,000 people on gen and responsibility this is B basic digital literacy to run a company and to be good and by the way Public Service massively going to improve Social Services by bringing this powerful technology so it is first and foremost we have to learn what it is so we can talk about it in a balanced way and then absolutely there are capabilities that don't exist today in most companies like responsible AI where it's someone uses AI at Accenture it's automatically routed it's assessed for risk and then mitigations are pointed in and I can call someone and I know exactly where AI is used that will be ubiquitous in 12 to 24 months across responsible companies Albert the the other big revolution that we've been hearing about for the last few years was the revolution in biology the sequencing of the genome the ability to Gene edit what does AI do to to your field in general but particularly are those two revolutions now interacting in the AI Revolution and the biotech Revolution the tech Revolution is transforming right now what do we do what is our job is to make breakthroughs that change patients lives with AI I can do it faster and I can do it better and this is not only because of the advancements in biology as you spoke but also the advancements in technology and the collision between the two of them but they are creating tremendous synergistic effects that will allow us to do things that we're not able to do until now I truly believe that we are about to enter a scientific Renaissance in life sciences because of this coexistence of advancement in technology and biology give us some sense of give us a few examples or you know help us understand how these two technologies these two revolutions interact generative AI is something that we were all impressed and but we saw it now let's say basically last year right but AI in different forms exist for many many years and we are using it very very intensively in our labs the best example that I think people resonate it is the oral pill for kid it's called pclo was developed in the chemist part of it was developed in four months usually takes four years this is because the typical process is what we call drug Discovery you really synthesize millions of molecules and then you try to discover within them which one works with AI now we're moving to drug design instead of drug Discovery so instead of making Mak 3 million molecules we make 600 and we made by using tremendous computational power and algorithms that help us to design the most likely molecules to be successful and then we look to find the best among them for years to four months millions of lives were saved because of that W Mr Chancellor you're a politician um the issue that Sam raised about trust that that Mark benof raised about trust does seem Central how do you get people to trust AI should they trust Ai and should government regulate AI so that it is trustworthy I think we need to be light touch um because this is at such an emerging stage you can you can kill the the Golden Goose before it has a chance to grow um I remember the first time I went on chat GPT um I said is Jeremy Hunt a good Chancellor of the exer oh no and the answer came back Jeremy Hunt is not Chancellor of the exer so I said yes he is um and uh is he a good one and the reply came back I'm sorry we haven't lived up to your expectations but Jeremy Hunt is not Cher the exer so there's a kind of certainty about uh the responses you get which uh is often not justified but I think look we can all do tremendous ly well out of AI um the UK is already doing well London is uh the second largest hub for AI after San Francisco and the UK has just become the world's third largest tech economy trillion dollar Tech economy after the United States and China but um as a politician I look at the big problems that we face for example when we have the next pandemic we don't want to have to wait a year before we get the vaccine and and if AI can shrink the time it takes to get that vaccine to to a month then that is a massive step forward for Humanity at the moment in the UK and I think most of the developed World voters are very angry about their levels of tax if AI can transform the way our public services are delivered and lead to more productive public services with lower tax levels that is a very big win but I think we have to allow the technology to grow we have to have our eyes open to the guard rails that we're going to need um the UK also plays a very big role in global security we need to be sure as I was saying to Sam earlier this morning that a rogue actor isn't going to be able to use AI to build nuclear weapons so we need to have our eyes open which is why the AI safety Summit that rishy sunak organized at the end of last year was so important but we need to do it in a light touch way because we just got to be a bit humble there's so much that we don't know and we need to understand the potential where this is going to lead us at a stage where no one really can answer that question I feel Albert that this is an area where uh regulation is likely to be most people are going to be most worried about the issue of trust which is the combination of AI and medical and is this you know is it safe for me to listen to this doctor to take this drug this has all been developed in a computer somewhere um is there a way to alleviate that I think there is first of all we need to understand that AI is a very powerful tool so in the hands of bad people can do bad things for the world but in the hands of good people can do great things for the world and I'm certain right now that the benefits clearly outweighs the risks but I think we need regulations right now the there is a lot of debate how those regulations will set guard rails and there are some countries that they are more focused on how to protect against the bad players there are some countries that they are more focused on how to enable the scientist to do all the great things with this tool that we want the world to have as in the next pandemic I think we need to find the right balance that will protect at the same time enable the world to move on Sam when I look at technology my fear is often um What will bad people do with this technology but there are PE many people who fear this much larger issue of the technology ruling over us right you've always taken a benign view of of AI or relatively benign view but people like Elon Musk and sometimes Bill Gates and other very people very smart people who know a lot about the field are very very worried what what is it what do why is it that you think they're wrong what is it that they're not understanding about AI well I don't think they're guaranteed to be wrong I mean I think there's a spirit there's a part of it that's right which is this is this is a technology that clearly very powerful and that we we don't know we cannot say with certainty exactly what's going to happen and that's the case with you know all all new major technological revolutions but it's easy to imagine with this one um that it's going to have like massive effects on the world and that it could go very wrong um the the technological direction that we've been trying to push it in is one that we think we can make safe and that includes a lot of things it's um we believe in iterative deployment so we put this technology out into the world uh along the way so people get used to it so we have time as a society our institutions have time to have these discussions figure out how how to regulate this how to put some guard rails in place um can you technically kind of put guard rails in right a kind of constitution for an AI system would that work if you look at the progress from gpt3 to gp4 about how well it can align itself to a set of values um we've made massive progress there now there's a harder question than the technical one which is who gets to decide what those values are and what the defaults are what the bound are how does it work in this country versus that country what am I allowed to do with it versus not um so that's a big societal question you know one of the biggest but the from the from the technological approach there I think there's um there's room for optimism although the alignment Tech techniques we have now I don't think will scale all the way to much more powerful systems we're going to need to invent new things so I think it's good that people are afraid of the downsides of this technology uh I think it's good that we're talking about it I think it's good good that we and others are being held to a high standard and you know we can we can draw on a lot of lessons from the past about how technology has been made to be safe and also how the different stakeholders in society have handled their negotiations about what safe means and what safe enough is um but I I have a lot of empathy for the the general nervousness and discomfort of the world towards companies like us and you know are are the other people doing similar things which is like why is our future in their hands um and why why are why do they why are they doing this why do they get to do this and I think it is on us I mean I believe and I think the world now believes that the the benefit here is so tremendous that we should go do this but I think it is on us to figure out a way to get the input from society about how we're going to make these decisions not only about you know what what the values of the system are but what the safety thresholds are and what kind of global coordination we need to ensure that stuff that happens in one country does not super negatively impact another um to to show that picture so I think not having caution um not feeling the gravity of what the potential Stakes are would be very bad so I I like that people are nervous about it we have our own nervousness but we believe that we can manage through it and the only way to do that is to put the technology in the hands of people let Society the technology co-evolve and sort of step by step with a very tight feedback loop in course correction build these systems that deliver tremendous value while meeting the sort of safety requirements um Mark what do you think about this whole question well I think look we've all seen the movies you know we saw the movies we saw how and we saw her and we saw Minority Report and we saw war games and uh you our imaginations are filled with what happened happens when we uh have an AI That's going well and an AI That's going wrong and um you know we're moving into a Fantastical new world you know and I love it when Sam always says he has the sign above his desk and says I don't know what's going to happen next exactly because we don't completely know exactly what is going to happen next I think for our custom it says no one what does it say it says no one knows what happens next no Happ next so thank you for that correct so I will just say hopefully the spirit of what I was saying was correct so you know our customers are coming to us all the time and they're saying hey we want to use this and you know our customers what do our customers want they want more margin they want more productivity they they want better customer relationships and they want AI to give that to them and so I just got back from Milan and I was down with Gucci and they got 300 call center operators down there and they're like using our service cloud and they want to use Einstein which is our you know AI platform it'll do a trillion predictive and generative transactions this week we're partnered with Sam and it's very exciting it has a trust layer that lets our customers feel comfortable using their product and I said to them what do you really want and I'm not sure what they want are they looking to replace people are they looking to add people to get some kind of value you know it's an experimental time for a lot of Enterprises when it comes to AI so we put it in there it's it's a it's now a test that's been going on 6 n months it's amazing and something incredible happened this call center which was doing like you know you buy something a Gucci and then it's needs repair you know you got to have to it has to get fixed or replaced or whatever you call these folks and they're talking to you and and I walked in they said this is amazing what's happened I said what happened revenues up 30% revenues are up 30% yeah how did that happen well these were were all just service professionals but they now have this generative Ai and predictive as well they've all been augmented they've all been augmented the service professionals actually and this is what they told me are now also sales professionals and marketing professionals they're selling products not just servicing them they're they're adding value to the customers and it's a miraculous thing their morale went way up they can't believe what they've been able to achieve they didn't even know what they didn't know about the products it all was kind of being to tutored and mentored and inspired of them by the AI and that idea that Einstein could augment them and that then yes they got their revenue they got their margin that they so badly wanted even the we you know this app that you're all using is running on Einstein so those predictions that you're getting hey because you like this AI panel you should try that AI panel and you may look over here that is our Einstein platform giving you those ideas so this is really the power but for our customers and this is a little different between you know my good friend Sam and my company your data is not our product we're not going to take your data we're not going to use your data we do not train on your data we have a separation we have a trust layer we never take or use our customers data into our AI so your data is not our product that's very important that's core in our core value has is also trust trust and Custom success and Innovation and equality sustainability our core values have to be represented in how we're building these products for our customers that is really critical for our teams to understand but to back to your comment and Sam's comment you know look this is a big moment for ai ai took a huge leap forward in the last year two years like exactly what Sam said between one and two and three and then four and then I'm sure five six and seven are coming and here's the thing it could go really wrong and the thing we don't want we just want to make sure that people don't get hurt we don't want something to go really wrong that's why we're going to like that safety Summit that's why we're talking about trust we don't want to have a hirosima moment you know we've seen technology go really wrong and we saw a hirosima we don't want to see an AI Hiroshima we want to make sure that we we've got our head around this now and that's why I think these conversations and this governance and getting clear about what our core values are is so important and yes our customers are going to get more margin those cosos are going to be so happy but at the end of the day we have to do it with the right values Mark brought up the issue of data and dat data usage so Sam I have to ask you the New York Times uh is suing you um and claims that uh the gist of what the times is saying is that open AI other AI companies as well uses New York Times articles as a input that allows it to make the language predictions that it makes uh and it does so excessively and properly and without compensating the New York Times uh isn't it true that at the at the end of the day every AI model is using all this data that is in the public domain and shouldn't the people who wrote that data whether it's uh newspapers or comedians whove who've written jokes shouldn't they all get compensated many many thoughts about that uh I'll I'll start with the difference between training and what we display when a user sends a query um by the way with the New York Times as I had understood it we were in productive negotiations with them we wanted to to pay the New York Times a lot of moneyy to display their content we were as surprised as anybody else to read that they were suing Us in the New York Times um that was sort of a strange thing but we we would we we we are open to training on the New York Times but it's not our priority we actually don't need to train on their data I think this is something that people don't understand is any one particular training source that doesn't move the needle for us that much um what we want to do with content owners like the New York Times and like deals that we have done with many other Publishers and we'll do more over time is when a user says hey chbt what happened to Davos today we would like to display content uh link out uh show brands of places like the New York Times or the Wall Street Journal or any other great publication and say here's what happened um today here's this real-time information um that you're and then we'd like to pay for that we'd like to drive traffic for that um but it's displaying that information when the user queries not using it to train the model um now on we could also train the model on it but it's not our priority we're happy not to and and that I I think everyone happy not to with any specific one but if you don't train on any data you don't have any facts to train the data I was going to get there on to the next Point um one thing that I expect to start changing is these models will be able to take smaller amounts of higher quality data during their training process and think harder about it and learn more you don't need to read 2,000 biology textbooks to understand you know High School level biology maybe you need to read one maybe three but that 2000 and1st is certainly not going to help you much and as we as our models begin to work more that way we won't need the same massive amounts of training data but what we want in any case is to find New Economic models that work for the whole world including content owners and although I think it's clear that if you read a textbook about physics you get to go do physics later with what you learn learned and that's kind of considered okay um if we're going to teach someone else physics using your textbook and and and using your lesson plans we'd like to find a way for you to get paid for that if you teach our models if you help provide the human feedback um I'd love to find new models for you to get paid based off the success of that so I I think there's a great need for New Economic models I think the current conversation is focused a little bit at the wrong level and I think what it means to train these models is in is going to change a lot in in the next few years Jeremy you you said um in an interview that you thought it was very important that the United States and Britain and countries like that win the AI War uh versus China explain what you mean and why you think it's important I think uh that probably mischaracterizes the gist of what I was trying to say I think that when it comes to setting global AI standards it's very important that they reflect liberal Democratic Values um but I think it is really important that we talk to countries like China because in the end I mean I think one of the most interesting things um about this morning's discussion is Sam has a sign saying no one knows the future but we do have agency over the future and that is the tension between the two and I think that um you know we are incredibly lucky that people like Sam are helping to transform Humanity's prospects for the future I don't think anyone in this room thinks the world would be a better place if there wasn't AI but we have choices now uh and the choice we need to make is how to harness it so that it is a Force for good I actually think that means talking uh to countries like China because one of the ways it would be a force for bad is if it just became a tool in a new uh geostrategic superpower race um with much of the energy put into weapons rather than things that could actually transform our daily lives and those are choices we make and one of the ways that you avoid that happening is by having a dialogue with countries like China over common ground but I think we should whilst being humble about not being able to predict the future remember that we do have control over the laws the regulations uh we have the ability to shape this journey and I think we should also look at history and say you know look at the Industrial Revolution um the computer Revolution where those revolutions succeeded was where the benefits were spread evenly throughout society and not concentrated in small groups in the case of AI I would say the challenge is to make sure the benefits are spread throughout the world North and South developing world and developed world and not just concentrated in advanced economies because otherwise that will deepen some of the fractures that are already in my view taking in the wrong direction Julie what do you think about this cuz Accentra works all over the world do you think that this uh has the POS potential to create a kind of new arms race uh in in technology again being practical one would hope given we've all learned the lessons of having different regulations in data privacy that we would spend as much time thinking can we find common ground and use this to to to work with some of the places where we are having these around something that is objectively necessary if you want to have any kind of globalization to say let's have common standards so on The Optimist side of me says let's use this as a way of collaboration taking out some of the geopolitics of it because there is really good sense in it I'm reminded in this conversation we have a a leadership essential itic censure that I look at try to look at every day it says lead with Excellence confidence and humility and Jeremy you just talked about being humble I think one of the most important things we all have to do as leaders and countries is have a good sense of humility around this make sure we're talking to each other that's why Davos is so important um it's why the work we just did uh together with KPMG and PWC and the W on trust and digital trust and learning and reading you know I think there's a lot we have to do to educate ourselves and then try to start to think differently Albert for you when you look at uh you know how do you think uh uh China will regulate medicine in a different way or some of these issues we've had the issue come up with Gene editing where there was that famous case of a Chinese Doctor Who uh decided to try to do Gene editing to prevent AIDS and the Chinese Chinese government actually jailed him uh because of a a global convention could you imagine something like that happening with AI I don't know what can happen with AI as some said nobody knows and I don't know uh how China eventually will think about those things what I know it is that in life sciences China is making tremendous progress right now I think there are even more biotechs in China than exist in the US or in the UK or in Europe I think uh the Chinese government is committed to develop basic science in uh life science and I think in a few years we'll start seeing the First new molecular entities coming from China and not from the US W all right I'm going to close by asking aight let me put it this way not only from the US because us will continue to produ I'm going to close by asking a question slightly unrelated to all this but Sam you were involved in what is perhaps the most widely publicized boardroom scandal in uh in recent decades uh what lesson did you learn from that other than other than trust satiana Sam at least he's asking you when you only have 42 seconds left so you know you can take more I think people will wait to hear this answer um I mean a a lot of things uh trying to think what I can say be honest at some point at some point you just have to laugh like at some point it just gets uh it's so ridiculous but I think I mean I could point to all the obvious lessons that you don't want to leave important you don't know important but not urgent problems out there hanging and you know we had known that our board had gotten too small and we knew that we didn't have the level of experience we needed but last year was such a wild year for us in so many ways that we sort of just neglected it I think one more important thing though um is as the world gets closer to AGI um the stakes the stress the level of tension um that's all going to go up and for us this was a microcosm of it but probably not the most stressful experience we ever fa um and one thing that I've sort of observed for a while is every one step we take closer to very powerful AI um everybody's everybody's character gets like plus 10 crazy points it's a very stressful thing and it should be because we're trying to be responsible about very high stakes and so I think that as I think one lesson um is as we get we the whole world uh get closer to very powerful AI I expect expect more strange things and having a higher level of preparation more resilience um more time spent thinking about all of the strange ways things can go wrong um that's really important the the the best thing I learned uh throughout this by far was about the strength of our team um when the board first asked me like the day after firing me uh if I want to talk about coming back my immediate response was no cuz I was just very pissed by about a lot of things about it and then you know I quickly kind of like got to my senses and I realized I didn't want to see all the value get destroyed and all these wonderful people who put their lives into this and all of our customers but but I did also know uh and I had seen it from watching the executive team and really the whole company do do stuff in that period of time like the the company would be fine without me the team you know either the people that I hired or how I mentored them or whatever you want to call it like they were ready to do it and that was such a satisfying thing both personally about you know whatever I had done but like knowing that we had built we all of us the whole team had built this like unbelievably high functioning and tight organization um that was my best learning of the whole thing thank you all thank you thank you right well done Sam I [Music]