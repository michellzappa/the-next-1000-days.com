so this is just meant to be relatively casual I didn't really prefer this this is just a template that and threw to get a bunch of stuff um but a lot of it is just a lot of questions that I've been getting over the last couple of years um just about Ai and now about prompting and everything else because a lot of the the work that we now do with Gen kind of requires that you think about things differently right so this is just a collection of all of those things and as we go through and we'll see uh just tiny bit about me I run a company called gry wi here in Singapore you know we're focused on commercial shipping uh we do a ton of AI work we do a ton of data work uh when you know llms came up we started looking at them as NLP effectively on steroids because it was a suddenly all of the English language and people's you know messages emails were all accessible so we started working there um out of that work came you know that initial launch which was a comm's automation tool that's doing pretty well another one was an assistant of our own far before you know opening ey had tool usage or any of those things uh we would doing charts and a bunch of things then came sort of rag uh we do a ton of work with multimodal rag which is visual rag so being able to process sort of complex information how to visually index it and sort of how to use that to answer Mission critical questions so that is for example a dam data sheet from Samsung so they were testing the product uh and in shipping like all of these data sets are really important and the importance of the output is also very high so this is just to say you know like we've done quite a bit of work across different parts of AI and this is just everything we've learned uh also I'll put up like little QR codes uh just in Li of links uh the slides are going to be up later so if you see something and you're like oh I want to know a little bit more there's going to be a QR code so uh this is you know in the interest of hacking everything today is going to be about going from let's say 0o to 0.1 right where do you start how do you start so this is just an open source project that I recently released I'll put use that as an example later on how to go from like script to project to release uh this is effectively a tool to generate docs so we had a docs problem everybody's got a docs problem but what we did have is a ton of meetings we'd have tons of meetings repeated meetings about the same things explaining the same things so now we have whisper we have all of these things accessible can we just make docs out of things we've explained like 10 times before so this was launched like two days ago this has already had like I don't know what like 50 or 60 projects already makes make docs using it because it turns out people it's easy to talk it's very hard to write dos right right so that's just an example so the first kind of thing I want to talk about really and this is you know it took me a long time to discover and it made a huge difference is just the iterative loop right and when I say iterative loop I mean what is your process to build stuff right so long time ago you know if if you were coding that long ago we had write compile run right we basically would write code it would take a long time to compile people still working on xcode would have that same problem today we'd run it we go back write compile and run and then we we had sort of interpreted languages come along and then we now have like the repo which is effectively the readal print Loop right which is you write code runs instantly you keep changing it you keep changing it something happens and then you know bunch of guys came along I don't fully agree with these guys but you know they had a good point you know you have test driven development test build test that kind of thing but I think AI really because the way these models work is not deterministic and prompting can feel kind of cod likee and working with prompts can feel kind of code like but they're really the furthest thing so they really need new pattern so the pattern that you know me and my team and a lot of other people that I know fallen into is you know what I'm calling cpln so we'll we'll we'll see what that means so the first one's just chat right whatever your problem is whatever you're trying to do just chat with models make more and more and more examples and just keep changing prompts keep changing what you're doing right A lot of people and myself included get into this habit because we have that habit from coding and sort of building things of doing it once and it sort of works and then forever you're iterating on that particular prompt you make very small changes you keep fixing things and you keep fixing things but I think really where you should be spending most of your time really is just changing and finding new approaches to solve things because that makes a huge huge difference and that's unheard of in code right you wouldn't write something with the intention of rewriting it seven times before you got to the end right you'd write something something be broken you'd fix that broken thing you'd fix the next broken thing and then you just you be done so the most important thing is just chat and I'm still surprised and I still talk to the people on my team we included uh have this problem where we just don't play we don't chat enough really right once we get to a system that sort of gets to like 40% we're like okay we're now going to production we're just this is almost good and so that's a big problem right the next one is just you know take whatever you've learned go to the playground there's a lot of tools and some of them are really good but in most cases 90% of what you want is still just in the playgrounds everyone's got a playground all you're really looking for is the ability to retroactively edit prompts and conversation histories you know some people call it surfing the latent space and sort of make changes right so this is where you'd spend maybe 20% of your time once you've got that working right let's say you've got one of it working the next in most cases and this is just examples from like uh lentes is Loop Right add more data add more test cases a lot more see how solid your hypothesis were when you started right and always reset if it doesn't work once you're done with that right Nest right once you're done with that you've got a general sense of the approach you want to take 99.999% of the time and I I almost dared a few people to do it and I so far haven't seen a single prompt or a single approach where it couldn't be nested but and by by that I mean effectively break the prompt break the work you're doing into smaller and smaller and smaller Subs segments we'll go into it later right but if you're not going to accept like a 700 line code file as good you shouldn't accept a 100 line prompt as good right or a 50 line prompt is good it could always be made simpler it could always be broken down so really you just want to keep doing that right and once you've gotten this far and you know if luck would have it if you go to production and you've got users you've got subtask now and they can go through the exact same Loop right you run into a problem you've got a new customer with new kind of data new problems new things you want to go back to the original Loop so this is kind of where you want to be spending or where I found the the the best division of your time being right this entire blue segment is just try new approaches right because these models they've been around for about a year but they are so new and we are still finding new ways to use them that you might try something you might you might be the first person in the world to have tried it you might genuinely be the first person to have thought of that particular way of solving a problem with a model right so I really can't emphasize that enough and you probably want to spend about 20% in your time tuning the prompts almost everything usually is a prompt issue because I'm presuming that the people you work with and the things you're building that you guys are good at coding you know if you're not there's tons of ways to get better at it computers are really good at coding so in most cases it's your prompt right if it's not your prompt it's your input it's the data you're providing ideally see if you can change the size and shape of that data and in most cases that fixes your problem so couple of dos and don'ts so the first first one and I I I still have this problem although it's it's wonderful to know that someone in this room has solved my biggest problem which is diarization uh which is awesome um but really just use all modalities right I think everyone kind of a lot of people kind of forgot that when we got J GPT and in short order we we also got audio we got Vision right and we got speech detects and all of these different modalities and even just the input mod modality of text you can transform it into so many things right you can take text and transform that into code to get a more structured representation you can get structured data you can do language Transformations so use all of the tools that you've got right so let's yeah so speech for example here's where you'd use each one speech is verbos if you've got anything dealing with users we love to talk right this entire talk is probably going to be I don't know I'm hoping not uh like about 8,000 words right if you ask me to type out 8,000 words it would take me far longer I would be far less likely to do it and I'd probably tell you no right uh if you present the users with a text box they'll give you five words if you ask them to just press a button and talk they'll give you 200 words right and these models the things that we work with they love context the more context you can provide the better vision is insanely useful right there's a lot of relationships that you can capture with a picture that you can't with text like we know this right it's a th words anytime you write as a person you want to put pictures in for the same reason right so all all of that can be captured and now we're getting smarter and smarter and smarter models that can understand that information you can use it as really expensive OCR if you want to we do in some places uh but in but in lot of cases it's also far more dense right even if the the diagram on the top right top left that's an actual diagram that we use by the way uh were to be represented in text that would be far more token heavy than that picture right can and code code is awesome for structure both for input and output like you almost always want to be using structure both on the input and the output right use structured output whenever possible structure your input whenever possible right almost everything humans ever touch usually has some structure right like when I talk my talk has a structure when you write a paragraph there's a topic sentence everything humans ever do usually has structure and if you're leaving it out if you're not extracting it it's a lot harder to control yeah uh this is just stuff that we use right so we use typescript and Zod uh to build type specs and that makes it so much easier to steer these models we use SQL when we want to express something as a search query even if we never run that SQL it helps the model think it helps the system sort of better guide these things yeah same thing here you know use structured output as often as you can far easy to guide it's also far less prone to hallucinations because you've got a type speec on the inside and structured output usually constraints the output that's coming out of it that you see far fewer generation uh sorry far fewer hallucination ations with structured output right uh and I can talk about that more if we have time at the end but usually it has to do with token probabilities and the output set the same thing is again uh use as much as you can because you got this massive model for free right kind of right commoditized down and you got this massive model that had two trillion three trillion tokens thrown in about human information into it right use that as much as you can lean into it right uh there's a lot of libraries let's say project that you know I've either consulted or advised with where they're inventing their own dsls they're inventing their own languages to express what they want when ideally if they expressed it as a superet of something that existed say typescript python English you know Hindi whatever is in there you you'd get a lot more benefit out of that cool so this is a bunch of don'ts none of these are hard rules but they're general rules of thumb especially when you start out right in AI I mean this is this is a meme at this point but we are still very very early right this is not you know very early days of development or very early days of design like if you wanted to get into design and you wanted to be a good painter or a good designer you wouldn't use Dolly right you wouldn't add an abstraction between you and the thing you would learn how to paint right because you want that knowledge you actually want that harder knowledge of how these things work how they behave you know what the actual nature of these things are the more abstract actions and toolkits and libraries you put between yourself and the model when you're developing the less you learn right some of them honestly are really good but that's also a problem because they're really good and they have this little circle of things that they do really well uh and very quickly if you're lucky if you're lucky somewhat slower you'll want to step out of it and then you know it's just a wasteland right if you've ever built something with WordPress or Squarespace and then just wanted to do one thing that it didn't do you know what I'm talking about right that's impossible everything will fight you so ideally don't add abstractions I know it can be especially people with a coding background kind of sometimes I've seen want to distance themselves from prompting distance themselves from the non-deterministic nature of these things uh bad Instinct you know you know don't look away from it uh the next one is also I I know we've got credits to open AI but everyone wants to give you free money everyone wants to give you free credits these days if you're a provider it's too much investor money in this space the don't stick to one model right they're all very different they were all kind of similar when they came out because everyone was working with the same information set but things have diverged massively they're all practically different people right it's almost like if you you know if you gave some work to to someone on your team and they couldn't do it you wouldn't go oh this is undoable you probably give it to someone else right same thing work with different models they're all very very different differently trained there even different personalities in there this one is kind of easy to keep track of right uh basically have a general rule of thumb or that your outputs are not going to be that much bigger than your inputs in most cases again rule of thumb uh that's not going to end up well right if you're looking to generate let's say you know 20 paragraphs of an article from five words of input you're usually just going to get very generic not so good input right not not so good output so try and keep those ratios relatively the same if you can right cool um some smaller FAQ um because these questions get asked a lot right so agents uh a lot of people have asked me about agents uh the simple answer there is anything with looping and termination is usually considered an agent right so anytime you've got a system and it basically loops on the same prompt or some set of prompts and it basically has the ability to continue execution and then decide when it wants to stop that's usually an agent um this one is really helpful right when you run into problems or when you start working on a project or you're just looking for a project to work on it's useful to know what capabilities just got added to the tool set right with Gen these are four of the biggest ones right the first one is just plain NLP if you've done NLP or anything close to it it just got way better right we can classify documents we can classify information all sorts of ways we can label them um and we can do all sorts of things with them that previously NLP really couldn't do the second one's filtering an extraction right so you can pull information out right and the next one is sort of transformation so anytime you've got rag summarization that's a transformation right if you're doing code generation a lot of cases that's transformation if you're doing translation that's transformation right so often times it's useful to look at your problem right in an industry or your problem set in front of you or you're just looking for ideas if you look for one of these four things uh if you look for one of these four classes it's an easier way to structure maybe that's where you want to go instead of where to put things the final one and I think some people using for it but I've seen that use case sort of go down for some reason it's just general purpose generation right you want it to write things no one's ever written before you wanted to you know make things up so uh some resources I I'm not going to be talking about prompting not going to be talking about rag uh these are just some articles uh these are my articles if you don't like me the the the top of it has you know people that I respect that are far smarter than me so click the links and go there and read those oh cool um the the next one and this might be the final one is is debugging right I don't think I've I've heard that many people talk about I mean in you know among people who work with AI this this is a massive conversation right how do you debug because the the sort of curse and sort of the benefit that we got with modern AI things is that it's very easy to build a demo it's very easy to get to something that sort of works but it's very hard to debug things when they go wrong right that's almost again new paradigm so the what is happening to you right if nothing works right always go down to the prompt level and if you can't then get rid of your abstractions uh and work up from there right try a different model try going up a level of intelligence and see if it fixes it that should tell you where your problems are or try going down a level of intelligence and see what happens the next one is transform the input in most cases it's your input that's the issue either it's to verbose it's not the right transformation it's not structured the right way so any Transformations you can do on the input is going to make a massive difference right and finally if you're not doing this already add more structure to the out right more structure is going to help you point out where your problems are more structure is going to tell you sort of expose some of the big issues there okay so this is you know this doesn't usually happen to people this usually does right is it it's kind of working it's kind of working and I can spend another you know like two weeks on it and it'll get bit further down the line of kind of working uh but it's not working necessarily right so again I'm going to go back to data in most cases you want to find out what separate Ates your offensive data which is where it doesn't work to the stuff that does work right try all sorts of Transformations one of those is going to point to some sort of difference between the stuff that works and the stuff that doesn't right if you do that's a prompt right more validation is always going to help and then we saw the classification before right if you're trying to do more than one of those things inside the same system inside the same with the same model usually separate it out right and it makes a huge difference finally yeah just classify your errors most errors I've seen sort of fall into these three issues you've either got app level issues in terms of how that data is being fed in and fed out and how models are orchestrated once things get too large um or you get factuality issues right it's just making things up that don't exist or it's just giving you information that it really shouldn't or pulling out the wrong information it's a factuality issue um the third one is just instruction following is it just not listening to The Specific Instructions that you're giving it right and this is at theel level but it happens at the meta level as well even if you're working with say three models you know and 300 prompts all of these things still apply okay so what do you do right the first one is whatever you're doing right whatever you're doing as far as prompting and working with models go you're almost always two verbos because in most cases it's English and once we start adding things they kind of work so you get to this sort of Paro level of you know it works but it just doesn't doesn't it's almost how humans behave cut them down there's usually space to cut them down cut them again the lower your task complexity per prompt or per task or per function um the better right the easier it is playb the easier it is for you to have you know things with defined blast radiuses where something goes wrong you can swap it out and fix it um otherwise you know something goes wrong someday you're going to have a problem so um how much time have we got left okay 10 minutes perfect so this is just an example of that particular project that I mentioned at the beginning right so it started with just a specific issue you know like you know honestly wasn't even me it was was heie who's actually here who had a transcript for me and she was like okay can we make docks out of this right or I think it came partly from that so there was a lot of talking there was a lot of trying to figure out what we can pull out what it understood out of the transcript you're trying to look for understanding you're trying to see if this can even be done you're just testing very high level hypothesis right some of the things I tested were sort of trying to pull out structure directly some of the the ones were trying to classify that data before pulling out structure you learn just a lot about what it is you figure out where you want to put the transcript whether chunking is a is a valid strategy all of that you can learn from just talking right the next one is talk but then start changing things right now you start adding steps now you start adding structure you start getting information out and once you're done with that you know the the entire thing and this actually worked was just this one script right really I mean you don't have to read that it's actually in the repo uh it's just this one script right and really all it did was just Loop you know twice over everything and and then break it down intersections and use different models to write different things right so there's one model you know that's generating the structure there's another model that's actually doing the the long form writing and then the final one is just breaking it down into smaller and smaller and smaller functions so if you look in the repo still not that big right but there's a lot more State Management there's a lot more State Management there's a lot of self-healing there's a lot of Correction all of that stuff can go go in after like you've proven the thesis cool actually I'm I'm ahead of time I didn't think I would be so uh the final thing and I will say this is a lot of people I speak to are still very concerned about cost right I don't know how many of you guys watch the uh Nvidia keynote that that happened like a couple of days ago but long story short everything you're using now is going to get at least 10x if not 50x cheaper in very short order right it's going to get 10x if not 50x faster in very short order so what would you build if you were building for say 6 months from now or what would you make if you just presume that today right and it's a different way of working with these things you know if something costs 10 bucks that's a different system than if it costs 1 cent right if a if something takes an hour that's different from if it takes six minutes right so I would say this is a valid presumption to make right when you're building something is what more can you do if you just presume that about the future immediate future right right because we still haven't even gotten Hardware level optimizations that's what Nvidia is doing now you know that's a 10x memory level optimizations again still coming up that's a 10x quantization that's probably another 10x so all these things are almost being done now and they're very comparatively easy engineering Wise It's just incremental optimization to get there cool that's everything uh feel free to find me after or just reach out on Twitter I'm happy to help questions oh sure yeah question ask like what do you think about like long context window models and embedding models okay so long context is tough right because I might say something where I don't know what I'm talking about uh that said I this has been my question as well the problem with context Windows is our algorithm for attention is quadratic what I mean by that it scales by it scales exponentially to get twice as much context out of something you've got to spend four times the amount of memory in compute we still have that curse there's no way to we still don't know a good way to get around it right so what that what what that means effectively is to get really long context Windows you have to cheat you effectively have to say Okay I'm going to have something and before I run the model that's going to kind of figure out which part of the context to actually pay attention to so you don't actually get the full context window right you kind of do but if you take the full context window and you're trying to use every single token in it to compute an answer it's not going to work so that is still very much a problem that could be solved that's one of those open problems I think it's still open problem that could be solved tonight by someone that's that's working somewhere or 10 years from now we just don't know right you've mentioned a bunch about transforming the input um how do you go about doing that do you use AI to transform user in most cases yes you're going to be using AI to transform it but there's Al also just a ton of structured stuff you you can do right very easily like most documents let's say you know I've got a PDF or I've got let's say the the the the slides or I've got you know one of my document documents is in mark down there a ton of structure in there you can just GP for right because I could very quickly figure out what the sections are I can very easily separate by sentences that's all stuff that you can do today right so even just knowing that you know that's got 300 sentences in it that's a transformation of the input that is valuable super valuable right because we already have we can make assumptions already right if I give you a document that someone's written I can presume that the title is probably the highest compressed information in there right that is a good enough thing I can presume that the first section will have some sort of intro of what the thing is right those are all transformations but yes usually you use AI um I had a so how do you think about de uh I actually haven't used Evan I just have not had the time but I've had people tell me that it's it's good look coding is going to be where these models make just a massive massive difference right I already use a cursor which you know can can understand just a massive amount of context and sort of forth I I it has been 6 months since I wrote any code that wasn't at least partially a generated uh so it's just going to keep getting bigger and bigger and bigger that said I will say the time that you know most devs that I know and most companies that I know spend is in business logic you know maintenance and sort of really trying to transform customer uh input to really massive systems with a ton of Legacy code like we're a long way away from that right what I mean is it's getting easier and easier for you to spin up a more and more and more complex project from scratch right but the massive Dev work that sort of sits kind of sits past that right that still hasn't been touched uh the efforts to uh to to do something there because that's where the money is and ways cuz that's where most Enterprises are right if you look at sap or you look at most of these guys um have not so far borne active fruit like I know most of the companies in that space they're they're still having trouble getting it to work with very large code bases right like let's say anything above like a 50% company that's existed for more than three years that code base so far AI hasn't been able to touch right yeah I had a question so I recently read a not read I wouldn't say I read the paper I read thect right so where it was like uh I think from Amazon or from somewhere like or Netflix perhaps that getting coign similarities between embeddings uh it's not really a good measure for getting the meaning of things right and is a prevas from my question uh and also when we do like vector searches and just try to pull relevant information I don't know it feels like it doesn't work um trying to figure out like what am I doing wrong how to do it better I watched Jerry Le's talk like on from L index 18 minute talk or something it's very it's a very nice talk but it just kind of flew over so like what's your recommendation I think it's the I think the problem here is embeddings are sort of fuzzy search on steroids if you know if you're using them for anything more I think even today you have a problem right cuz the couple of things one these are really tiny mod model comparatively right big brain small brain tiny brain these are really tiny models in most cases they don't have a good understanding of the underlying text that's why long context edings never made sense right uh the longer the context it just doesn't really make sense um not to mention in most cases that's a transformation of the input right what he was saying that's a transformation of the input is you're transforming it but you're transforming it into a space where it's a lot harder for you to work with it right you're transforming it to a set of numbers and now the only thing you have is cosine similarity you can have a bias Matrix you can push that math a little bit more but because that model is unknown to you the model's workings are unknown to you those are forever going to be a bunch of numbers right in some insanely High dimensional space so there's not a lot to do there right what is becoming very possible now that I know I see a lot of companies switching to is just use the whole brain use the llm right like whatever you're using embeddings for you can use an llm right it's just more expensive right in most cases you can use an llm for that like let's say you're using you know I'll give you the most brute for Brute Force example of this let's say using embeddings to take you know 100,000 items and see which ones are similar or which one's closest to your query you can take an llm run it to every single one of those documents and ask hey is this close is this close is this close and you'll get an answer right that is not a good way to do it do not do it this way but but you see what I mean right so they are kind of you know you can substitute one for the other just a little bit I think embeddings have a place right but they should always be the last step in your pipeline you should cut down the search space as much as possible with structured search Transformations you say bm25 there's a bunch of stuff you can do right you should never be searching your search space with embeddings right you should always be searching some reduced search space where you know hey last 20 things you know and I know these are relevant because keywords I know these irrelevant because location I know these IR relevant because an llm told me after transformation whatever now I can that's fine right but if you embed at the beginning like in most case it just doesn't work at scale so it's more like to get the results and then sort it is that where embeding com uh more like to get the results and yes kind of to sort it but kind of also to identify like useful parts of those results let's say the results you got were pages but you want sentences right you want to know which part of it is you know heat map wise the most important you can use embeddings for that right all right uh thank you so [Applause] much