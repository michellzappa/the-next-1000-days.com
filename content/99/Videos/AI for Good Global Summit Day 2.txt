[Music] n [Music] n [Music] [Music] [Music] k [Music] [Music] w [Applause] [Music] w [Music] [Music] [Music] [Music] [Music] [Music] [Music] [Music] [Music] [Applause] you [Applause] you [Music] [Music] [Music] [Music] [Music] [Music] n [Applause] [Applause] go he [Music] my name is suan Chung I'm an artist and researcher and artistic director of silet a studio exploring human and non-human collaboration so my mother is a programmer and my father's a musician and I think this has me really interested in this idea of hybridity in particular hybridity through ART and technology and through some of these interests I found myself at the MIT media lab building my first collaborative robot in my practice in art and Technology I'm really engaged in the prises possibilities and paranoia U manifested by developments in art technology and science I believe these developments are changing what it means to be human and I'm really driven by curiosity about what that can mean for Generations that came before and generations to [Music] come in my practice I see art and Engineering practices as one and the same both Fields have the potential to uncover something real about The Human Condition and I think are grounded in an exploratory process of speculation and Discovery I work with robotics AI systems data and mixed reality as drawing performance sculpture and installation I'm really inspired by how we think about the idea of a human and of a machine and I'm really curious about where AI ends and we begin in the past few Decades of Technology development I designed I like to think of as sensory mixes of the future I've been working on a project called Drawing operations unit Generation 1 to 5 for like the past eight almost 9 years its focus has really been on the potential of human and machine collaboration in generation 2 we focused on exploring memory by training a machine learning model on two decades of my own drawing data in generation five design over the pandemic I thought about my own meditation practice as a kind of creative Catalyst and substrate I used my own bio feedback recorded through meditation to generate EEG data as drivers for robotic movement in my own painting process I like to think of it as waves of my mind to Lions on a canvas my most recent work is called Flora rearing agricultural Network Fran for short a project exploring human plant and machine connaturality the work speculates at what I like to think of as an interdependent ecosystem of human machine and Flora and explores the linkages between machine and ecology through the development of a networked robotic systems stewarding [Music] nature in my practice I work with and develop a range of Technologies I work with robotics as collaborative partners machine learning as drivers for painting movements and EEG to create systems of Bio feedback I'm interested in how research driven processes algorithmic systems and custom computer vision software offer new and speculative human and machine configurations using custom and existing research for artistic purposes means extending the possibilities of the research Beyond fixing a problem or asking a specific question into a more speculative playful Arena that engages new research prompts as well as new conditions for philosophical [Music] inquiry the drawing operations work as an intergenerational art and research project evolves conceptually technically and philosophically with the growing role of technology in our lives I like to frame it as a collaboration because it really foregrounds the relational Dynamics between human and machine and technology and Society I'm curious about this question of agency within systems and think of the practice and these projects as a microcosm to consider the wider implications of things like technological governance and its entangled relationship to the human subject [Music] it's so hard to make predictions about even 5 years down the road I think we've seen how quickly over the past few years life can really change in an instance but I hope that the field of human and machine collaboration is increasingly understood and grown as a sight of invention and of Promise one that extends A diversity of subjects and points of view I'm really hopeful about this because it means that we're working towards this transformation of the human and machine and our environment um and I think that as an interdisciplinary aim um is really powerful [Music] [Music] [Music] [Music] my name is Christian mclair and I'm an artist working mostly with digital fabric my background is Arts and Technology so as a dancer I learned about poetry and I learned about narration and on the other hand I'm a computer scientist and I studied human computer interaction which is about how we touch machines how machines see us how we see them my work today is mostly about the encounter the poetic Encounter of men and maing the friction and the beauty between the digital and the analog real so right at the Hybrid intersection of those synthetic and those natural Sensations and continuously Thrive to investigate how do we actually meet our mirror and how do we actually see ourselves through the lens of a machine my selected artwork is called Helen and it's an AI based scripture that means it its shapes its forms were defined through a process using deep learning and to me it basically discusses intention so an actual artwork normally is born within the artist and it's and his or her intention to create something and once this creation then starts building we can slowly see how this thought starts to manifest in the real world in the case of Helen however its shapes its lines were determined by a neural network and it was then shaped through a mechanical robot so basically it is an object that is now standing in the world that was not thought of by a human nor created through a natural process like stones at a cliff it just comes out of nowhere and to me it also feels like that it's a dark Cold Stone and it's quite beautiful however there is something missing and I think you see it when you you're standing right in front of it there's a certain emptiness and that Emptiness is something that interests me the artwork Helen is created through a custom algorithm that we invented at the studio Christian and it is basically an algorithm that is inspired by Deep fake technology so deep fake technology works like this it is basically analyzing a certain data set with a certain coherence for instance faces of humans and then is able to think of a completely new face that fits actually and that we expect to be a human and somehow this algorithm is able to kind of invent it we applied this technology of deep fake to art history and showed our algorithm 60,000 busts that were made in human history and then asked the machine could you create another one that wasn't done before but still fits to the to the style of what well humans do and did in the last 2 3,000 years then it came up with a new sculpture and that is called Helen [Music] [Music] [Applause] [Music] [Music] n [Music] [Music] [Music] [Music] [Applause] [Music] [Music] [Music] [Music] [Music] [Music] [Music] [Music] [Music] [Music] [Music] e [Music] [Music] [Music] [Music] [Music] [Music] [Music] [Music] [Music] [Music] down together forever [Music] together there [Music] [Applause] [Music] together [Music] [Applause] [Music] the [Music] [Music] [Music] [Music] [Music] [Music] sh [Music] [Music] [Music] what [Music] [Applause] [Music] [Music] [Music] [Applause] [Music] [Music] [Applause] [Music] [Applause] [Music] [Applause] that was amazing welcome everybody to day two of the 2024 itu AI for good Summit and what an incredible way to start the morning thank you to the amazing team of dancers musicians and data magicians today for it's an awesome performance and pepe thank you so much for um letting us into your world this morning it's it's amazing now I know this was more than a performance I know this was more than a performance it's an experiment as well you're collecting data so please tell us a little more that's right this is our 10th data collection this is a longitudinal study that has taken several months and we understanding de creative process in action outside the lab and it's amazing how long does it take to set up something like this oh we were here since 7 in the morning 7 in the morning and what were the challenges in getting this to work consistently every time we move to a new venue we need to adapt the choreography we need to make sure that the the wireless transmission is working and we need to adapt to to an environment you need to adapt to the environment and why would you do something like this and obviously the artistic element is a big part right I mean this is a great opportunity to understand the social brain interacting brain you can think about applications not only the art but Mentor Mente mother and child I see at work at home and how heavy are the packs that the dancers have to wear because did you see they had a kind of shoulder bag on and it looked quite strenuous well by by this time they are very used to that it's like wearing glasses but it's about 250 gram and what's in there oh it's a Wi-Fi transmitter that connects their brain activity to the computer so that's the brain to Computer Link so it's a Wi-Fi transmitter sensor and a bunch of data and then the generative AI visuals what what came first the visuals or the choreography the music oh wow I and the choreography we would like to you know integrate the music the dance and the visuals to make it very simple and intuitive to the public it's very important to engage the public including children wow brilliant well Pepe thank you very much to you and your team for opening AI for good 2024 thank you my pleasure wow well if you weren't awake before I expect you are now now and to those of you who were here yesterday lucky enough to get into the building because it was completely rammed uh warm welcome back to you and those of you arriving for the first time welcome to you as well I'm LJ Rich your host and Starship captain for the rest of today and I'm just going to do a few housekeeping slides just to make sure nobody's missing out on anything so as per yesterday we strongly encourage you to download the neural network app thousands of you already have and right now they're enjoying meeting and chatting with AI enabled conversation matching and a host of other things to play with so there's a lot of realtime benefits you can get from being here at the summit and using the app and then beyond there's a lot of chat functions too and we are still using the interpre app app even that's available for simultaneous audio or text translation into 75 languages and if you can speak 75 Lang languages then you really should have a job here at the itu okay what you need to do is simple scan the QR code to get started on this if you simply search for interprof On the App Store it will ask you for a code so you do need to do it this way around and please note our hashtags for the event you'll need these for the competition they are AI for good and itu AI Summit nice and easy there and the reason we've got AI for good is because it started in 2017 way before anyone thought AI was a thing apart from you all in this room you all knew it was and that's why you're here finally we've got newo create scan the QR code to crowdsource insights from the summit discussions and you're going to be co-creating a one-of-a-kind artwork so you can have your say and make an impact in the form of Art and words um this has been going incredibly well so we'd love you to add your thoughts to this I can see all of you with your phones up in the air this is brilliant interactivity for a time of just 9:30 in the morning brilliant work everybody I would like to thank you very much for being part of today and it's the perfect time for us to give a very warm early morning welcome to the director of the telecommunication standardization Bureau at the itu for some wonderful opening and welcome remarks please give a nice round of applause for SEO or noan [Music] thank you very [Music] much good morning everyone and very warm welcome to you all our discussions at this Summit highlight that AI will come to influence almost every aspect of our societies and economies that's also High uh highly evident in itu transation work we have published over 100 standards on AI around 120 are under development and this number always on R AI is now key to network oration multimedia coding and optimizing the energy and cost efficiency of networks and data centers it's also creating breakthrough in areas from climate action and agriculture to Disaster Response and health care and road safety that's why itu is so in uh invested in Building Bridges between different areas of XDS these breakthroughs are driven in large part by new connections among II specialist AI users data owners and and ex expert in domains where AI could contribute uh uh decisiv uh decisively to sustainable development it is stimulating these connections with the uh with support our AI for good in initiative our diverse membership partner un agencies and uh the over 30,000 professionals uh now part of the our AI for good neural network and with some of our standards appli as a part of our Global challenges they are already helping to build AI capacity around the world most of uh uh competitors uh students from developing countries we M we want safe and secure and trustworthy AI that lead to a better life for all the spirit of collaboration and consensus that powers sanation work to exactly the spirit needed to succeed standard represents brary commitment to new ways of work uh working uh working together they provide essential technical foundations for new new Industries to to grow and establish Industries to keep moving forward it's highly collabor collaborative process working together on standards we build Mutual trust and understanding we create the confidence to continue innovating and investing at new innovation uh Innovation ecosystem emerg uh emerge around AI standards uh will be uh essential in BR um bringing this ecosystem to global scale but to achieve this standard needs to be a result of process that is inclusive transparent and aligned with our Ambitions ambition for a better world I or this uh this assurance together with ISO and I I we offer a station platform where all participant voices are heard and every step for is determined by consensus position and as uh reading develop uh developers of international standards we are uniquely positioned to guide coordinated action from standards de opers and a growing range of stakeholders in standardization our coroporation helps to position everyone for success and that's exactly the aim of this collaboration we announced yesterday to provide a unified Frameworks for AI standards development standards to verify content authenticity and Providence are one of the top priorities and today's workshop on AI water marking will bring everyone together uh to ensure that we start out on the right foot AI is changing the world but we have deep experience to build on sers have helped us navigating Revolution after revolution with every breakthrough in science and technology we have come together to develop the standards required to thrive in New Frontiers that's uh that's what our station process are built for all of you whether in government industry Academia or Civil Society can drive our standardization work with their contributions and consensus decisions we need to decide together how AI should factor into our future this conviction anchors itu's leadership for uh of AI for good I thank you for your uh for your support thank you very much onisan please come and stand with me if that's okay whilst we reset the stage oh no please come here thank you so much it's just some brilliant insights oh I think we're going to invite the mayor up as well at the same time so come oh no we're all good no come back up why don't we do this at the same time what we're going to do is invite the mayor of Geneva to come up on stage so that you two can say hello it feels like the right thing to do doesn't it so um so let's do ladies and gentlemen and everybody distinguished guests please join me in inviting the mayor of Geneva Alonso Gomez there we go yeah just I thank you thank you thank you very [Music] much ladies and gentlemen as uh major of Geneva I have the great pleasure to welcome you most warmly to our city in the second day of the AI I pronounce well in English uh for good Global Summit it's a really a great honor uh for the municipal authorities to host such of an important event bringing together some of the world's leading AI Specialists we are fully aware of the scope the work being Carri out here and uh of course we hope that it will be uh fruitful since the public launch of the chat GPT in November 2022 generative artificial intelligence lies at the heart of every debate and from that moment on all kinds of scenarios concerning the impact of AA in on our lives were circulating ranging from the most irrational fears to the the wildest hopes however a general consensus seems to be emerging if you we use ethically responsibly and in a regulated way if it's put at the service of social good and Humanity AI can have extremely positive repercussions in many areas this applies for example in the case of health education and Disaster Response but also more generally in relation to the United Nations 70 sustainable development goals as you well know almost 10 years after the International Community adopted the 2030 agenda the sustainable development goals are unfortunately far from the being achieved only 50% of them are on track with many others are sleeping backwards poverty hunger inequality and discriminations are increasing at an alarming rate in many parts of the world and particularly in connection to the consequences the covid-19 pandemic at the same time we are facing a global crisis in terms of climate change and the decline of biodiversity which is gradually bringing Humanity to the brink of collapse we have little time little time left to change our Paradigm and in order to offer future Generations acceptable living conditions in our common Earth will the challenges arment how can we ensure that the use of AI benefits humanity is this essential question that is at the heart of the all for good Global Summit which brings us together today in Geneva and which throughout the year will constitute the largest multilateral platform in the unit Nations system for AI the city of Geneva is followed with the discussion taking place within this framework with the utmost attention strongly committed to the use of a responsible inclusive and Innovative digital technology that serves the all populations it has adopted the excellent guidelines laid down by the Swiss Confederation for the use of AI and in particular with a view to placing people at the center ensuring conditions conducive to the development and use of this technology and inuring security more generally International Geneva is heavily involved in discussions around the use of data and the governance of AA thanks to its Rich network of stakeholders in the field of new te Technologies and I believe nowhere else in the world is there such a concentration of cross disciplinary expertise I I hope that this environment will be beneficial to our work ladies and gentlemen today in view of the immense challenges we Face the world needs Collective actions it's not too late we can still succeed if we act now by combining our efforts at all levels and I have no doubt that this submit will make available contribution to this Collective edifice this is the strength of the multilateralism of the and of the DI dialogue together that for sure together we can go further thank you very much for your attention thank you very much that was absolutely excellent please continue that way we really appreciate you coming mayor that was fantastic and next up we're going to be confronting the digital Paradox that sounds kind of scary doesn't it well don't worry we don't have to do it alone we've got backup we've got someone helping us in the form of the rather excellent Abdullah Al Rashid let's hear about what he [Music] thinks okay have [Music] F all right um good morning so I uh I lead a busy life like many of you and uh a few weeks ago on my birthday uh my uh friends got me a coupon for a free service a domestic helper Civ where they send somebody to your house and uh they assist you in the house and it was honestly the first time that would I was going to try something like that um so I ring up the number they send uh a young woman to the house her name is Lucy she comes to the house and um we agree on what she's going to do she's going to help uh uh get some of the tedious tasks that occupy me out of the way you know things like I don't know doing the laundry the dishes cleaning the house doing these simple things out and uh I mean the idea is of course I would be a bit more free to be a bit more social do the things that really matter and really just even relax if I need to and things go out really well they turn out to be very good um the house is clean I can host more people and guests everything is organized it's all great but I don't actually end up going out that much I just end up slouching on the couch and watching and binge watching Netflix and other things a bit more but in the end still good you know like uh these tasks that I used to do I no longer have to do and then one day uh something weird happens I find out that she knows things that she shouldn't know so um I lost my watch at home and I go up to Lucy and ask her have you seen my watch and she tells me yeah it's in your locked jewelry box in your locked room um I know that it's there oh that's weird I don't remember ever giving her access to that room and then she leaves her phone on the table and I Snoop so I I touch the screen her wall paper is pictures of my children that's weird I again don't remember sharing that with her so I decide to confront Lucy and I go up to Lucy and I ask well I've seen X and I've seen why on your phone and I see my children photos and he said yeah well I have hundreds of them I have some of them when they were kids showering for the first time and they're on my phone but don't worry um I only share these photos with other domestic helpers in our company we don't they don't go out they're just between us this of course makes me extremely awkward so I go to the authorities um and I try to say well I I think I'm being robbed at home and my privacy is being invaded and they tell me what we have extreme laws against this right like if this happens anywhere it's not acceptable uh but oh this this domestic helper SL cleaning service that you have that doesn't really fall within our jurisdiction um that's in your private home what you do there you need to figure out yourself we're really sorry so I'm I'm faced with this really tough choice and it's not a conscious choice that I have to make it's a it's a tough choice I I have all of these amazing things that are happening you know like I I no longer have to do dishes or even order things from the grocery store cuz she knows what's missing and she orders it for me but then there are these concerns that I have and I honestly I decide just to live with it so now uh Lucy watches me when I sleep she monitors my height rate to make sure that I'm okay sometimes in the bathroom you know when I'm there she'll be in the room as well um just you know occupying me if I'm bored I mean this sounds funny um but that's the absurdity of our lives today and dystopian choices that we've made we seem not to be able to we don't hold Tech to the same standards that we hold anything else and we need these an anecdotal fictional settings to try and shed light on where we are today and this had like extreme ramifications on us really if I just I'm going to to pick out a focus on children just a few examples our research shows that 69% of geners skip sleep at least once a week because of their use of tech lack of sleep has been strongly correlated with increased risk of cancer we flash these devices in front of our children and 30 minutes of screen time has a 50% chance of speech delay for for young children you know for me if if you go to a store and you buy a u you buy a device or a toy sorry you'll see an age group restriction on it that says 3 plus or 6 Plus or whatever but we put these VR headsets and they have guidance on certain ages that you put in so a VR head should not we advise that it should not be used by people who are 12 years old or younger and then when you read the reasons the reasons are I Str neck stress and none of it is about what a VR headset and being connected to a virtual world does to your brain our research shows that 40% of people particularly Jers are have a completely different personality online than they do offline and any other time in history I think that would be like cause for concern for schizophrenia but not today not with us and then as parents we look at like the benefits right so we Outsource parenting a third of parents use deck devices to occupy their children on a daily basis I mean I'm going to throw an example that I think everyone is guilty of right you're on a zoom call your kid comes up into the room he's shouting you throw an iPad in his face just let him occupy himself you're in an airplane they start shouting or Screaming or crying you're embarrassed so you turn on the screen and this stat was particularly around non-g governed like non-parental controlled content right so a third of parents are giving their children ad devices they don't even know what they're watching or they're doing it's just Outsourcing parenting to Tech what does that mean in an AI World I'll leave that to you guys to figure out and what does all of the result in probably maybe the most alarming statistic from our research that I've for me is that 53% of Jen's years would rather live without a close friend than their phone can you imagine right and if when our researchers meet and do these qualitative interviews it makes sense I mean I I love a quote that one U one of the uh interviewers said uh it's not a cell phone it's a self phone it's me it's everything it's all my life like that's where Tech is basically reality and reality is the is the is the virtual is my virtual life it's where I study it's where my friends are it's how I connect it's how I'm cool it's how I create social status it's everything and so we've given Tech this opportunity to dominate and intervene we're really more comfortable with our kids being performers than they are being social beings so you see the children across the world happy to go in front of a screen thousands of people followers going and acting and portraying a certain image and then put him in a room with three other kids and they won't be able to interact this is happening now this is not a a doomsday scenario this is children today we even have research on gen Alpha that we do in across the world kids who are under 12 years old and how their parents talk about what's happening with them and I want to give another example on the adult side for us Humanity has always uh had this right to forget and I'm going to share a video of something that maybe a few of you have seen but um a woman uh tragically lost her child who was 8 years old at the time in in the past when something as tragic happens what we would do usually is as Humanity you know like we'd uh we'd consult console create support groups and eventually slowly maybe we'll be able to move on our reaction today is very different we allow the woman and the parent to create a full digital construct of her Lost Child she puts on a VR headset and is now interacting with a virtually created um uh manifestation of her child both voice visual everything what happens to humanity when you can't forget when we lose the right to forget I think the with as with all Technologies the the premise of this idea is wonderful it's great it's amazing benefits you know a a a losing mother being able to connect to connect with her Lost Child but have really studied what the consequences of that are I cut the video cuz I I was told maybe it's best not to share the entire video it could be uh a bit um disconcerning but you can find that online and our response to that is that the industry will collect itself you know like yeah this okay fine we've heard this many times before every uh every new technology every development there's always this concern it will correct our but I don't recall an industry or a time where people who are working on it are shouting out to be regulated they're not able to work uh to CH to instill the change in uh internally and so they're raising their hands please save us I I was thinking of an analogy of this and it's not the right analogy um and I'll just mention why but it's like an alcoholic coming in and really fed up with their lives and they're coming in for a support group to help them and our response is like you know no don't worry about it you'll figure it out but that example is not really great because the alcoholic is the user it's actually the Brewer coming in and saying you know what I don't want to create alcohol anymore and we're saying no no don't worry figure it out it's okay and so when we look at the response of the world to this it seems to be split in half um we see a leniency towards control um in the East um uh where China is pioneering or maybe leading um uh elements of time constraints on uh technology um age restrictions on technology even content restrictions on what goes on and then on the western side a more open uh response and I'm I'm not here to say which one is right I I don't know which one is right but the reason why this is a really important conversation now is that we've been doing our research for 3 years now and the following stat is really the greatest indication that we're at Tipping Point 50% of people say that they'd love to embrace Ai and then 50% say that fear it we're really at the Nexus and the Tipping Point of this decision and the time is now to try and be purposeful about our way forward so I want to talk a bit more about what we do and then maybe conclude with a few ideas going forward so ifra and sink are a nonprofit cultural institution in Saudi we realize this problem and you might ask why would a cultural institution get into this topic of tech and consumption but really we're all technologists now whether you're a pediatrician a lawyer a parent um uh an artist whatever you're a technologist either by usage or creation and we need to be involved in that conversation and so we launched This Global program a few years ago with many partners and we try to do three things the first is that we try to do some groundbreaking research in the space um both um across the globe but also on our region we convene we hold large Gatherings and Summits last week we had the digital well-being Summit 40 countries 20,000 people came and then we tried to also educate and the question I got on education is like what do you educate on and what are you trying to uh to instill and I know that the answers are not there but at least we need to educate on awareness and the conversation I want to leave you with an example of the kind of things that we produce um to try and raise awareness on these topics this was more on screen time in social media [Music] so again there might not be clear answers but I think the problem is very very clear I'd say that this is very different to anything else we face because of three things number one it's exponential and we've heard Keynotes yesterday about how exponential it is two it's unforeseeable we don't know the results of it and maybe that's true of a lot of Technologies but really the concerns around this are much bigger because of how intertwined it is into our Humanity psyche psychology social behavior even our biology and then the third is that it's irreversible I'll leave you with a stat during Co our screen time went up by 2 hours that's two hours more screen time during Co than we've had in the last 10 15 years so when covid stopped you'd think that after 15 years of experience or 15 years of practicing something and only a few months of screen exposure we'd go back to where we are now our screen time now is 1 hour above so although we were able to draw back a little bit we can't really fully reverse uh once we Embrace this technology so I want to leave you everybody here whether you're a user a Creator a developer an enabler a politici and advocacy with this question the real Drive behind this uh uh uh speed race for technology is utility that it's going to be benefit for Humanity that it's going to make our lives better and my question is is it Humanity or utility that should be the priority I mean so what if my autonomous car comes in 5 years later so what if I end up going to the grocery store and shopping on my own rather than my fridge ordering for the next 3 years if that improves our chances of mental well-being of Health even by 5% that's a bet I'm willing to take I'm fine and so for me it's not Humanity or utility it's Humanity over utility it's not to say that technology is bad it's just that Humanity should Suede and be above that thank [Applause] you thank you very much to Abdullah there excellent It's what just about 10:00 and we've already had quite a lot of thought-provoking content about the use of Technology with children I've got a smallish child he's sort of seven and a bit and there's always that conflict between do we occupy him with technology or do I have to occupy him with my time and it's a real balance and with the 50% fear and 50% Embrace that's a really interesting statistic I wonder if I'm I'm both of those at the same time but I'm generally optimistic watching what all of the amazing things that you're doing are achieving so that's brilliant listen this is a pleasure to keep going with a panel you may get a clue it's a panel because there are a few chairs being set right there so it's tempting to presume that large corporate organizations are slow moving by Nature actually not all of them are there are some incredible Innovations taking place all over and some very well recognized Brands so the next panel is going to talk about how these incredibly large organizations are using Ai and it's always this conundrum I think a lot of organizations will fail if they are simply using it to cut costs or or drop headcount actually what you can do is improve quality of life and add extra abilities to people who are already working there this is what I'm a big fan of but then how does society work if you have to pay somebody instead of paying for someone's time you might end up paying for their expertise which is kind of interesting I think I can see some water bottles coming as well does that mean there are tables also no they are set excellent well we're going to have a fantastic moderator for this panel we'll be introducing them shortly and then they're going to introduce everybody else and I think after that we might be going off to a few more panels then a no we've got a coffee break straight after that no we haven't oh we've got a really cool talk straight after this one it's a mindblowing lots and lots of thought-provoking things happening so I recommend that if you do wish to kind of continue right up to the break I would very much think you would enjoy all of the talks after this one as well I think we're all set with is excellent so let's hear more about AI for good in a corporate environment with our moderator for the next session please help me welcome a partner at D Piper it's Danny [Music] Toby thank you LJ it is a pleasure to be here with everyone today my name is Danny Toby I am a medical doctor by training and a lawyer and I've spent my entire career working with companies adopting technology including Ai and trying to position it to do good so I'm thrilled to be here today um for those of you who don't know da Piper is a truly Global Law Firm we are in 90 offices in over 40 countries in the world so we are very proud of our partnership with the UN and helping work towards the sustainability goals I'm delighted to introduce our panel to you today these are some of the top leaders at some of the top companies in the world truly global companies who are working to adopt this revolutionary new technology but to do so in a responsible way and to position it for the good of their customers and the world and I'm delighted to introduce them now first please welcome suji Co suji is the senior vice president and Chief privacy officer of 3M [Applause] hello suji good morning next please join me in welcoming Rob beard Rob is the chief legal officer general counsel and Global head of Affair of policy Affairs for Master Guard and last but not least we have Andrea AEL Andrea is the Chief Information and security officer of the global pharmaceutical company Eli Lily welcome [Music] [Music] Andrea so thank you all for joining us um I'm really excited about this panel because we all know your companies um known around the world and each of you represents really a different Focus within the company we've got privacy security legal and policy and then we also have three companies working in very different sectors towards very uh different goals and so I think we're going to learn a lot hearing about how you at your companies are adopting AI where you see the Promise and where you're putting safeguards in place so let me start with Andrea Andrea tell us a little bit about how Eli Lily is adopting AI for good Eli Lily's mission is to create medicines that make people's lives better and so when you think about AI we have this tremendous ability to shorten the time it takes to develop medicines across the entire life cycle it goes from uh even looking at things like what you know how quickly we're going to be able to get through the research and development to the interactive nature that we may be able to have with health care providers and patients I'll give you three quick examples the first is back to the scientists if you think about research and development we get a large data pool that we're trying to identify which molecules will best work for a specific therapy and today it takes us weeks even with machine learning and models that we have what we've seen is that time compress where we're now able to identify 10 to 12 molecules that are best worth the scientist's time to research uh because of AI and we're measuring that in minutes instead of days and weeks a second use case is probably more generally applicable to the audience which is translation so at Lily we have to take all of our clinical documentation regulatory filings we have to get it into the native language of those Regulators that can take up to 20 weeks sometimes and so what we're able to do now is within minutes get a quick rough draft uh in the hands of a human who can then refine and find tune and get that submissions to the regulators and that means we can get our medicines globally to patients a lot faster and then the last use case that I'm actually most excited about is this idea of interactive um ability to educate and help with medical adherence for healthc care providers and patients and so we're actually going to start all the way back at the clinical trial phase we have the magnol AI sensor that's going to allow us to start decentralized trials that will allow a more diverse population with a more robust data set that we can start to use to train models so then as you think about educating healthc care providers and patients we can really bring them along their journey to have a really effective experience and that's something we're starting with Lily direct and we really see it as being an unparalleled opportunity now at the core of all of these Innovations is the a of digital trust and that's where cyber security comes in every use case we have to ask two questions one is for all this good what's the potential harm and then secondly for all of those potential harms what can we do to prevent that's always our goal right or to monitor detect and respond so that we can identify those harmful situations and if there are not controls there aren't ways we can do that that's where we have to have the transparent conversation with the business so that we can really make sure that digital trust is at the Forefront of all of these except AI use cases thank you Andrea let me turn to you rob next how is Mastercard looking at AI sure and well thanks a lot for inviting me to have this conversation with the Danny I really appreciate it and and I was actually um you know thinking about a something I heard as we were walking in which was really interesting to me and is something I think a out a lot with AI um you know people are out outside the this room maybe people who are less familiar with AI and what's it's capable of are are tend to be a little bit afraid of what AI could do and um one of the things I thought was really interesting and I think about all the time is AI is tremendously powerful in enabling us to have better information to make decisions to exercise our own judgment and to understand what information is out there so that we can make better judgments it's not that we're you know and and I think people are afraid that that the computers are going to make those judgments for us and and I think it's really interesting as we think about the principles that underly AI the principles that we're all trying to put in place in terms of the Frameworks around the world we think about how do we how do we set those Frameworks so that we're getting better information to help us exercise our judgments better make better decisions better judgments not to turn those judgments over to machines machines making the calls on things um at MasterCard we're deploying Ai and we and we've been deploying I AI for many years with one real core sole purpose which is to make transactions safer and more efficient and to make the user experience better so the the whole core of our activity in this space is looking across billions of transactions so MasterCard sees about 125 billion transactions this year as we see those 125 billion transactions each of those transactions generates data and it's it's not for us it's not data about the individual or or their credit rating or or anything personal about them but it's it's that transaction activity and that transaction activity then going into our models can tell us a lot about which transactions are good and which transactions are bad and that has a lot of potential implications whether it's starting from very thing basic things like anti-money laundering terrorist financing but all the way down to like how do we keep our parents from getting ripped off online and mastercard's been deploying AI in this technology since since about 2019 really in in terms of establishing and creating a framework for being able to use information to make our Network safer but it's more than just making our Network safer right it's it's anti- fraud for example is is something that can be done on a very sort of blunt level right many of you who've used credit cards in the past and and and all of you probably traveled as you travel and you use your credit card you think back 10 years 10 years ago if you wanted to leave the country and say you wanted to go to another continent you had to call your credit card company and say hey I'm going to travel I'm going to be gone for 10 days please don't decline these transactions they're not my usual transactions today with the power of AI and our models you don't have to call your bank anymore we have the ability to look over billions of transactions and determine in an instant when you go present your card that that transaction is okay so it's not just about fraud prevention but it's also about decreasing the friction in transaction making those transactions more trustworthy for you and for the counterparty and then ultimately it's about introducing two people to each other who who've never met each other before and telling them it's okay to transact thank you Rob and suji let me turn to you what's your experience at 3M using AI for good thank you so much Jenny for the opportunity to share 3m's AI for good journey at 3M is a material science company and we believe the Vance in AI to design train and run at Large Scale can benefit various Industries and we've just heard from finance and from the pharmaceutical how it could benefit society around the world in fact AI is not new at 3M we have been using it for many years in our manufacturing process more recently we have um embraced AI as part of our innovation and a really good example of how 3M and AI come together is our physics informed machine learning accelerated design AI platform that's um mouthful just to say it as fast as I just did and what it does it helps our scientists chemists and Engineers predict at an accelerated Pace new possibilities for personal safe safety or climate technology solution that really empowers Modern Life and so at 3:00 a.m. we are really committed to leveraging AI for good throughout the company um to advance human progress and of course um Drive 3M Innovation thank you suji I I'll give a perspective um it's amazing to hear about how large companies are rolling out this technology there are also a number of great startups that are using this technology for good and I'll just give a shout out I I couldn't name them all but I'm lucky to work with one called created by humans and their focus is ethically sourced data so everybody's seen in the newspapers about lawsuits and and who owns what and the idea with created by humans is let's build a technology Pipeline and let's build a legal structure so that artists and creators can have an easy platform to license their material to the llm creative and the AI deployers and at the same time and this is the fun part for me as a lawyer to define a whole new category of content rights that we call AI rights so that you're not just selling all or nothing but you can as an artist have control over which aspects of character plot whatever the case may be and then how those can be used by the models so there's just a lot of exciting thinking from security to law to privacy on how to deploy these tools but I do want to turn now we've heard great talks in the last couple days about the risks of AI and on the one hand you guys have been working with AI for decades AI is a constantly evolving category but with all the new generative Ai and new powerful tools how are your companies adopting AI in a trustworthy responsible reliable matter and as a corporation how do you put up those safeguards and suji I'll start with you it's a great it's a brilliant question and as you've heard from Andrea and Rob AI is being adopted across various Industries to drive positive change however equally important is strong AI governance and human oversight and at 3M we actively promote trustworthy AI by leveraging strong AI governance that prioritize trans transparency privacy ethics and accountability throughout the development and deployment of AI specifically 3m's multifaceted AI governance measures focuses on three things firstly people secondly process and technology and I'll just quickly zip through them for technology our employees use a secure internal AI platform to advance innovation for AI governance we've established an AI Center of Excellence Council consisting of leaders across various organizations such as legal it cyber security human resources and our research and development Who oversee how um employees adhere to our responsible AI use policy and for process pulling through the threat that Andrea just mentioned we make maintain strong data privacy and security protections consistent to 3m's high standard and and relation to people it's super important that you share knowledge you train and upskill your employees so that they can understand and be accountable for using AI responsibly and if I can just land with this one thought it's super important with organizations that AI governance and oversight particularly human oversight is at every stage of whether you're developing AI or deploying or even a combination you've got to make sure there's human oversight as well thank you seri Rob let's go to your next well I I'll just pick up on the thread because I think maybe start with the human oversight I think that's a really important part is it it's um responsible AI needs human intervention right we we need human checkpoints along the way as we design these things and as we as we operate them and and it comes back to that principle of AI is a tremendous ability to give us information and and that information can help us make better decisions uh in in all facets of our organization so I'll give you an example MasterCard we have this really cool thing called check your bias and I love check your bias because you know in in the world of lending over time there have been in you know sort inherent biases biases people aren't even aware of that make that in sort of creep into their lending decisions right we can help people when they think about issuing cards for example we can give them information about their previous decisions that they've made and help them understand what what where we where we interacting with people how does that interaction look like where are we where do we have blind spots where are we making mistakes where are we excluding people because for us we're trying to power connect and power an inclusive economy right inclusive digital economy and the AI has the power to give us more information that to help us guide us on that journey and help our customers on that Journey but it's it's not about it it still involves it's not about excluding the humans from that process we still need to be involved we still have to be there to take and ingest the data and make decisions on it create the Frameworks that help us understand these are the guard rails for the for the use cases of this particular technology here's here's how we're going to use the data we we're going to keep it confined to ensure that it's it what we're doing remains safe and secure for people um and I think that's a really important element of strong design in AI today is that we don't you know and I think we need to talk about it in in various ways we're not looking to take humans out of the equation what we're trying to do is give the hum give humans more information to make better decisions about what they do um at MasterCard that's something that really informs our responsible AI principles in in 2019 as we started using AI more and more and more we developed a framework for responsible use of this type of technology and for companies like Mastercard or 3M or others it's up to us not only to use the to develop the frameware to use it responsibly ourselves but to promote that framew work around the world um you know before Danny and I were talking before he came on stage one of my big concerns with AI and government's getting interested in this space is that we're going to end up in a fragmented world where where countries around the world will decide this is what AI government looks like over here and this is what it looks like over here and this is what it looks like over here and the result will be that we will have a we won't be able to leverage ai's power in the way that we otherwise would be able to so it's up to it's up to us it's up to companies who have adoped opted responsible principles to advance those principles into the world take those principles out and so I think that's that's another way that large companies can use their experience with AI for good which is to help inform the policy debate and take that policy debate out and and reduce fragmentation in the world um coming around with with one standard maybe particular to certain use cases um so that we're able to deploy AI responsibly and efficiently thank you Rob Adria well you're can hear a lot of common themes here uh going across but uh very much like 3M and MasterCard uh Eli Lily has been using machine learning and AI for years but last year we really started to recognize the gamechanging potential and stood up an AI governance framework and we started with the principles so you know things that I think you've heard echoed throughout the conference transparency fairness safety security oversight and privacy and then we established a strategic governance committee where really all of the final decisions escalated decisions are made and we have a risk subcommittee and a technology subcommittee um and then those groups are asking their teams to come up with things like uh inventories and the design principles reference architectures but as you all know the technology is evolving and the use cases are coming so rapidly that we often don't have time to get a reference architecture out uh before the use case is ready so that's where these committees are coming into play and we pull all of the stakeholders together so privacy legal technology clinicians the business ethics HR security are all at the table and our decisions have varied from hey that's not the risk to take right now to how do we descope or how do we we baby step into this to better understand the risk and benefit to hey we need to accelerate this faster it's a low risk proposition that can really benefit the patients um from a security perspective you know it is really all about the transparency about our ability to have controls in place and very often I find myself having discussions with the business about I'm not sure this is this is ready but can we go pilot it can we go descope something so we can get smarter and look for opportunities to build controls to make this a really safe experience um and and really I think even if we didn't have these amazing opportunities to bring medicines to patients faster if you're in the cyber world you have to be interested you have to get involved with AI because the thread actors are using Ai and we've seen it uh fishing is gotten way more effective and efficient better targeting uh there are a lot of use cases where we're seeing where thread actors get into an environment they go out to use a public uh large language model to refine their code base for that environment so they can exploit it more quickly so we have to take the knowledge not just of the controls that we're trying for the business but how we're going to respond to the threat actors and the threat Landscapes bring those together in the discussion and all of that brings back to that idea of how do we make sure we have the right digital trust in every one of our use cases thank you Andrea a couple things I just want to press on because you guys raised them and they're so so important what one is I think it's extraordinary and and I want the audience to to just reflect on this for second there are no comprehensive AI laws being enforced right now I mean Europe has a has a legislation that will be rolling out the US is talking about it many countries are talking about it but these are companies taking proactive steps to voluntarily adopt responsible Ai and and I think that is a really important lesson and and I'll say I've had the pleasure of working not just with folks here but but lots of companies and and it's a similar story people are taking this opportunity and challenge very seriously uh the second thing I heard that I loved is human in the loop and and even where things can be automated companies are asking the question should they be and and I think we're hearing to a tea that this is not a replacement for human judgment and I love hearing that across Industries and someone even asked me yesterday is AI going to replace lawyers and I said I'm afraid you're stuck with us so so I think I think humans have an incredible important role to play as The Gatekeepers of this technology and and I really love hearing you say that the the third point I heard is you know we're at the UN and the consistency among what you you have been doing is really remarkable because we have groups like the UN and others who are setting principles and standards and you know fairness and trust and and non-discrimination non-bias but someone has to take those principles and operationalize them and you guys are doing that and sometimes as a lawyer I feel like middleware because I got someone says be fair and then we've got companies making medicine and finance and Material Science he said okay we'll be fair what does that mean and you guys are really doing that and the multi-stakeholder way you are every one of you drawing in across disciplines um this is the most horizontal technology in history and you guys are rising to the challenge by pulling from Le business finance privacy security and it does take a village but you guys are making that happen um so thank you for sharing those insights today um I hope for those companies that aren't thinking about this yet this this really serves as a a really good role model to to to think about what one before we close one announcement um since the world is stuck with lawyers uh I do want to say d Piper is extremely proud of its collaboration with the United Nations and I want to announce that we are the founding law firm of the United Nations AI for good law track and what that means in in reality is we're going to be founding a nonprofit called the AI Law And Justice Institute and we're going to be having lots of companies and thought leaders and academics and Civil Society organizations joining us to really think about what are the UN sustainability principles and how do we create legal structures of the future that are fair and accessible and just and how can AI help expand access to justice for everyone in the world in different countries different regions so AI for good law track uh the AI Law And Justice Institute please keep your eyes open and if you or your companies or yourm would like to be involved to reach out U it's going to take all of us to get this right but we very much appreciate you having us here today and please join me in thanking the panelists for taking time with us [Applause] LJ back to you thank you very much panelists that was an absolutely well win tour of the corporate world there and I'm very sure that all of them will be open to networking of all kinds within reason of course so please do go stop them and have a nice chat with them now we're going from the very real corporate world to something slightly more unreal and as I work a lot with generative AI when it comes to music I'm quite fascinated to see what you think of this next presentation that contains a lot of generative imagery a lot of interesting things and also I should probably mention that the next presentation contains a few swear words as well so it won't be suitable for younger viewers unless they obviously know the words already so uh please open or close your eyes accordingly as we get going on that one you may also be interested to know that some of the music that you're hearing in between the sessions in the break areas uh is AI generated by me so you may hear the odd yeah yeah yeah yeah AI song that one was made over an evening and it's really fun and I've now got it stuck in my head so it's my own fault I've done this to myself I can no longer think clearly that's fine though we've got somebody else to talk who is going to be quite a lot more articulate than I am before my fourth couple of coffee so please help me welcome to the stage the Fantastic co-founder and associate professor at pinscreen it's how Le have [Music] fun all right thank you so much for the introduction my name is Holly I'm CEO and co-founder of pinscreen I'm also associate professor at the the new AI university called the Muhammad B Zed University of artificial intelligence uh today I'm going to speak about distorting and enhancing realities using generative AI so 30 years ago um there was one particular movie that actually made a huge impact on my entire career I'm pretty sure you guys remember T1000 from Terminator 2 uh where the first time I would see like a liquid metal morph morphing into different shapes um basically what was telling me is that c gii or visual effects was able to do anything that is possible right so things that are not possible in physical realities we can do it using computer Graphics so a couple of years later um we would actually see a ton of movies that would use that would make heavy use of visual effects right so one great example here is Avatar in Avatar there were over 3,000 shots that were have using visual effects or CGI and only two shots in the entire movie um didn't have any CGI so what it means is that CGI is a transformative technology that would change storytelling so you might think that you know everything is possible Now using these kind of Technologies but one thing that we were seeing back then is that human faces were very difficult to achieve right so um one of the reasons was that we as humans social animals are very sensitive to the human like likess right so CGI faces were pretty often very creepy and people would avoid them in movies so the phenomenon that we're seeing here is what we call The Uncanny Valley effect right so intuitively you might think that if we add more realism to you know computer generated imagery then you might find it to have more empathy right so on one axis we have realism on the one other axis we have likability if you start with something abstract like futureama characters or Simpsons characters and then you go to Pixar characters you might find them more likable however when you get closer to photo realism one thing that you will see is that because we get more sensitive to it uh we might notice everything that appears very bizarre right so this is where we have um the feeling that something feels like zombies right and of course the ultimate realism is a real picture of someone so how do we solve this problem initially one of the technologies that still right now is highly adopted in the industry is to use data capture or computer vision right so the idea is that we would scan actors uh using for example a multiv stereo technology or in this case a multi view photometric stereo system one thing that uh was used heavily in our Labs back then when I was a professor at USC uh we would do highrisk scans uh so we can get down to poor level details using control lighting uh captur so a technology that was initially developed by Dr Paul deic and uh we would use this technology to scan actors and also capture physical appearance properties of the phase so we could simulate these faces inside um virtual environments so the main issue with these kind of Technologies is that you need a very complex system right you need it's a million doll system it's hard to deploy and not to mention the amount of heavy post-process that happens afterwards so 15 years ago when I started my uh PhD at uh eth Zurich in switzland um used to have the same haircut and um one thing that we were doing was we were trying to think about can we make facial tracking more Deployable right so this was way before there were commercial depth sensors um here's a system with a projector and Machine Vision cameras and what you can see is that we were demonstrating that realtime face tracking was possible and highly automatable right so initially this technology was developed to uh facilitate visual effects and make it easier for artists to use but uh something I didn't really expect but we commercialized this technology and was acquired by Apple and uh the end solution was actually uh the enoji technology that you have in your iPhone so I continued to push the envelope of facial tracking uh a couple of years later um I was in involved at wether digital uh one of the projects that we're working on is basically how can we reenact a photo person right so this was a use case where Paul Walker who unfortunately died in an actual car accident um we were trying to recreate reenact his phase in the uh film fear 7 and basically the idea was we were capturing we were tracking the faces of his brother and trying to recreate a digital uh face of Paul Walker so this technology actually required a lot of human labor right so it basically cost like millions of dollars just to do a couple of um you know shots in the movie so one thing that's really important is that um with the you know the the Breakthrough of deep neuron Network we could basically make these things uh a lot more robust right so I'm going to give a quick introduction of deep neuron networks so initially U deep neur net networks uh were modeled using artificial neuron networks so basically uh multi-layer perceptrons but one of the big breakthroughs here is to have what we call neuron Network 2.0 which is convolutional Neuron networks convolutional neuron networks U basically consist of multiple layers of linear and nonlinear functions and what it allows you to do is actually analyze an image that's basically what we use nowadays for face recognition for um self-driving cars and and the principle is very simple right so you basically have multiple layers of these um um these uh neuron networks and given an input image what it allows you to do is to basically classify into multiple um properties right for example given a uh photograph of you know one of my dogs um you can basically say is that a beagle is that a toy pool and you give basically provide probabilities for each of these um items now we're going to simplify this uh concept and basically just put this as a deep new network so the first thing that we can do is instead of using a deep near Network as a classifier we can actually use it as a regression into um different what we call facial blend shapes right so different uh properties of the face when people are doing different facial expressions so given a video so this was an early work with uh our company and Nvidia and we're basically showing that it's possible to build a very robust system to track the human face now one thing that is even more remarkable is that if you just track a phas you still have to render the face using a traditional computer Graphics pipeline so what we wanted to do is to think about maybe we can turn this deep near Network around and instead of just analyzing it we can actually use it as a generator to generate images this is B basically um the basic concept of generative AI right so the idea here is for example I want to create a toy portal and you can actually generate an image of a toy portal now if you think about it one thing that's interesting here is that well what kind of toyle is it generating it can be anything right so that's actually one of the principal problems of generative AI which is how do you control it anyway let's do a quick tour of generative AI so in generative AI one of the crown jewels as many of you have heard is generative adversary networks right so this is a um early work um that was um pioneered by Ian uh Goodfellow um and the idea is basically to combine two deep NE networks one that is there to generate and the other one that is enhancing the training of the generator by using a discriminator right basically telling it if it's good or if it's bad and if you train this network with sufficient data you can basically have a deep near Network where you can always generate something in this specific domain of faces a realistic face right so this is something that Nvidia has been pushing the limits um multiple research papers were came out of this and you know one of the state-of-the-art methods nowadays are style Gan 1 2 and three and what it does is that if you train this network with sufficient data you can actually generate realistic images of things that that never existed right so this is really the crown jeel of generative AI here and this is something you can actually try out right so I'm pretty sure you've seen that before you go on the website this person does not exist and you can just constantly generate a new face by way a technology that people use a lot uh for creating fake identities so what we did now is we're interested in you know manipulating faces and also um generate new facial expressions not just new identities so one of the technologies that we've developed a couple of years ago is um what we call Pagan photorealistic Avatar Gan and the idea is that instead of generating a new face we would actually generate new Expressions so in this example you can see on the upper right so here we basically have just an ex you know simple input image and on the left you have a driving video so we're conditioning the generation of new facial expressions based on a video so what you can do is you can actually generate plausible facial expressions from a simple person this technology is just using forward propagation so it means it works in real time so here is a live demonstration of how we can use a single single camera single photograph and we can overlay another person's face onto a video so this basically is one of the first real-time deake Technologies right so at the same time um there was the whole you know concept of deep fakes that emerged that was back in 2017 um it was anonymously developed and um of course um the code became open source so a lot of you know you could basically see a lot of viral videos um this is a prominent one um um created by Chris um right so it's basically the Tom Cruz uh deep and in addition to all these entertaining videos um unfortunately we would also see a lot of you know use cases where you know deakes were used in UNC consensual uh nonconsensual pornography right so a lot of aless celebrities were targeted and um there was also a study by uh sensity AI where 96% of all the um the fake contents were actually uh porn related at the same time they were also a lot of you know concerns about what if people would weaponize these Technologies and there were actually a couple of cases recently where you know defs were used in the context of disinformation campaigns for influencing politics geopolitics uh Etc right and of course everyone is aware that there are also privacy and copyright problems so another uh problem is in scamming right so obviously these Technologies are highly accessible they can generate things that appear extremely convincing um here's an example of a high-profile case that happened earlier this year so a finance worker actually got tricked uh by someone who actually pretended to be the CFO of a company so there was a 25 million transaction that was actually done and to my knowledge this was one of the first where AIO visual defects were actually used in a live conversation and of course there's also other types of uh deep fakes uh that were used um for example in the Taylor Swift case um this is a different kind of uh D which I'll will talk about later this is using the fusion models where people would actually generate completely fake images of her and in this case um you know related to uh porn images that were spreading virally on Twitter right so 47 million views that were reached in just a few days so the main problem here is that we now have a technology as opposed to in the past that were only accessible to visual visual effects and Production Studios it's accessible to everyone right so everyone can generate these content um they're very easy to produce and you can also generate things that are extremely convincing so what can we do about it well one of the things is to enhance and to protect ourself using deep fake detection Technologies right so we've actually published one of the first work on how do we detect deep fakes right so the early Technologies were based on um you know biometric um type of approaches so the idea is that we would um for example record you know a lengthy video of someone who is known and basically try to match if certain features are you know appear in a new video and to see if that you know the movements are consistent with um what is known about the person um a more approachable solution these days is basically to um you know train deep new networks with real and fake data and you can actually you know pretty pretty well um detect if something is a defect and of course there's a lot of commercial Solutions out there here are two examples one from Intel and one from Microsoft um but you know based on our experience it's actually better to uh look at the research community so there's a lot of advancement there as well um the other important thing is that we also need to raise awareness of you know the potential of deep F so together with the world economic Forum uh we've actually developed the first real-time deep fake technology basically to Showcase that was back in 2020 that it is possible to actually um you know have life conversations with a fake person so this was demonstrated back then and but at the same time you know this was this was the idea wasn't really to um have a company that actually creates deep figes but our initial goal was actually to enhance digital avatars and make them more real right so originally the whole development was to create a better technology for building digital humans on the left what you can actually see this is a standard output of a state-of-the-art game engine uh in this case the unreal game engine but just using a couple of minutes of additional training data we can actually enhance the likeness of the person so we actually moved on to a you know positive use case of uh these kind of Technologies so what our company is doing is basically we're using generative AI for visual effects I'm going to show you a couple of interesting use cases um this is a use case for um the movie Slumberland um so the movie you basically have a scene where toddler is actually starting to speak so we have one of the actors uh who basic basically puppeteering the baby and make the baby speak so I'm going to show you how this looks like babies obviously here's another example for a production with Netflix so this is uh the TV show the Manifest it went over four seasons and one of the main characters actually grew up uh over the different seasons but in the final season they actually go back in time and they wanted to see how the actor actually looked like uh how he was as in the first season so what we did is we use the film material from the first season and trained the model so that we can turn a digital double that you can see here on the left into the likeness of the double uh of the original actor on the right right um here's another use case this is uh Rafael Nadal Rafel Nadal was recently injured and uh we he wanted to shoot an advertisement so we created his current age and also deaged him in five different uh ages for an advertisement with infosis so um here you can see um none of these people are Rafel Nadal it's a different person and what we did is we actually used generative AI to actually recreate his likeness and um if you're aware so this is the latest show uh fallout um on uh Amazon Prime um in in in Fallout there is like a flashback uh scene where Kyle mclan the you know the actor from the original Dune movie um had to look much younger right and uh this is also what we did in terms of like daging so the process is we would take um young film materials of the actor train the model and basically use the model to actually face replace and Dage his current age so there is another very interesting use case and that's actually you know the SK scalable market and the bread and butter for our company which is can we use this technology to augment actors and make actors speak any language they want right so imagine you had a foreign movie The Only You Know The Only Solution right now is you have to read subtitles if you don't understand the the movie or you have to um you know deal with really bad dubbing um so the idea is can we actually can we use these uh puppeteering Technologies facial Reena in order to AI lip sync the mouth movement so that's actually what we did uh we're actually the only company out there that has been able to um AI lip sync entire movies using this technology so this was back in 2022 uh there's a movie called uh the champion um it's a holocaust movie and it's in um German polish and what we did is basically we uh changed the language into English R Happ B I've read that boxing is like playing chess Rudy off to bed I've read that boxing is like play chest Rudy off to bed right and here's a recent uh work that we've done um we're actually doing a lot of like Netflix movies uh this is a French action movie um called AKA and here you can see how we translate from French to English [Music] [Music] what's the problem okay peew I'll tell you what's a problem I owed these guys one huge debt I had to give them the scoop these things Happ your dad is not my problem Size Matters wouldn't you say huh I'm not leaving without those plans I told you then you won't be leaving at all so one thing I'm going to uh we're going to release also very soon is a new product called pinup Ai and what it'll allow you to do is basically just upload your own video and uh through our service you'll be able to translate into any language you can upload an audio track and AI lips sync uh your video as well or you can also type in any text words and then make the person say um you know new content so here's an example of uh myself like it's an old video um and I you know don't speak Spanish so I wanted to see how I look like when I speak Spanish so this is so the idea is that you would use these kind of technologies that we deploy in Hollywood and can use it for your own videos okay so a lot of these examples actually focus on manipulating or generating the human face um but then there's a question of what if we wanted to generate anything we want right so this is the real power of generative Ai and one of the breakthroughs recently that enables this to happen are diffusion models right so you've probably heard a lot about stable diffusion so the idea is that you would break down the general problem of generating content into multiple smaller problems so the idea is that we would add noise into an image signal and the generator become the D noising problem which uses a deep neur Network right so the idea so one thing that is really practical here is that you can actually facilitate the use of a text prompt using a text embedding so that you can can actually generate any content you want right so a couple of examples here uh for example you know DOL 2 your prompt is a teddy bear cut toy poodle eating a bagel in Dubai we generate these images that was shown a couple of years ago mid Journey right another text image generation Solution that's very popular and of course Runway ml which for the first time showed kind of creepy uh videos that were generated from text back then I thought it would take a couple of years to to uh generate you know any videos but about this technology and I think we should all Embrace artificial intelligence thank you so much thank you for your attention thank you thank you so much to Howe their incredible work yes Tom Hanks has deaged himself with the aid of metaphysic a company so in about a hundred years there'll be yet another Tom Hanks movie to enjoy now as we head to the break let's recommend a few fun things to do whilst you're packing up uh the social media competition is running all you need to do is actually post your best picture thoughts about the summit things that you like ideally things that you like um and the funniest or best social media posts on LinkedIn with our hashtags will in fact win an expensive smartphone excellent so that's rather nice next up buy Sip and win you can win uh an actual phone if you simply buy a collapsible coffee cup which is in my bag normally I show it and I I kind of demonstrate what you do with a coffee cup but I think you get the idea you're an intelligent audience so buy a cup and that acts as a raffle ticket and then you can win a Samsung smartphone worth over $1,000 I think it's $1,300 something like that also you can buy a t-shirt from the itu shop yes you can look like you know about the future of AI and actually people might come up to you and ask you more about it or not who knows and if you're stuck you need some help why don't you ask our friendly volunteers they are in a different t-shirt which is not purchasable if you want to become a volunteer though at the next event please let them know and they'll try and help you too all right there's lots and lots of things for you to visit and I'm going to leave you to say so that you get a little bit of chance to stretch your legs and get a nice uh refreshing beverage so we'll see you here for 11:30 thank you bye [Music] you and me you and me you and me [Music] for for [Music] the all [Music] [Music] [Music] [Music] [Music] [Music] [Music] [Music] [Music] [Music] [Music] [Music] [Music] [Music] [Music] e [Music] [Music] [Music] [Music] [Music] [Music] [Music] [Music] [Music] [Music] [Music] [Music] [Music] [Music] [Music] [Music] n [Music] [Music] [Music] [Music] get [Music] n e [Music] [Music] [Music] [Music] [Music] [Music] w [Music] [Music] [Music] [Music] [Music] [Music] [Music] [Music] [Music] [Music] [Music] [Music] [Music] [Music] [Music] [Music] n [Music] a [Music] [Music] [Music] [Music] [Music] [Music] [Music] [Music] [Music] [Applause] [Music] [Music] [Music] [Music] together [Music] together [Music] [Music] down together [Music] [Applause] [Music] your [Music] [Music] me me you I'm do you welcome back everybody it's a pleasure to be back in the room with you I missed you I missed you all it's lovely to see you again and I'm really glad that you're here uh we're going to continue with our programming shortly but first just a little bit of help for those of you who might be having difficulty working out how the Wi-Fi works it's uh actually both simple and complicated at the same time you have your username and password on your badge so you select itu Wi-Fi and then on the right hand side of your badge you will see two numbers the first one is your username and the second one is your password actually that's an alpha numeric it's not just numbers there's some letters there as well feel free to use your phone to magnify the letters as well if like me you were trying to log on in the dark and it was quite a challenge but we managed all right so I've left that up there just enough time for you to understand that brilliant next let's talk a little about interprof which is is a translation service I incorrectly said this morning that it translates to 75 languages it is in fact six languages I typed the wrong numbers into my script and then just read it out so that's apologies for that one it is six languages they're all un languages though all you have to do is scan that and then you can access real time translation it's brilliant we also of course have subtitles powered by AI on the screens either side and finally we are so happy that more and more of you are contributing to the neuro create this is the word tag Cloud that we've all been waiting for in the world of AI simply scan that QR code and you can crowdsource insights from Summit discussions that's brilliant isn't it so you know the drill by now this is day two and I would like to invite you to enjoy some fantastic amazing research all about making AI accessible to all please help me welcome Dr hakeim HED [Music] good morning good morning everyone so uh I'm here to talk on a pretty interesting topic uh just sharing some thoughts on the accessibility uh maybe it's interesting to set the context first so there are different definitions of this accessibility so we have people who are working uh rightfully on how to make AI accessible for people with disabilities for example there is a huge work that is done there we should do and we should Explore More uh but I will not touch Bas on that today I will be touching base more from the accessibility in terms of counties and institutions to this uh to this AI that we are having uh nowadays so this is hakeim so I'm coming from tii executive director acting Chief researcher of the AI Research Center uh just quickly brief introduction of tii so we're based in the UAE in Abu Dhabi so we are a government entity and the research arm the research and development arm of the atrc that is the Abu Dhabi technology research uh Council so we're doing applied research AI is not the only uh sort of topic technological topic that we are handling but we do much more things uh we have we are 10 research centers uh exploring different uh facets of the technology probably we are known with the Falcon and the new uh large language models but we have other model other colleagues also working on uh several exciting topics like uh space robotics cryptography biotech uh directed energy so on and so forth but the talk of today is more related to the uh AI accessibility and I usually start with this slide because it gives us a sort of an interesting uh perspective on the importance of AI so we can see uh it's just depicting actually the uh number of days or the time that it took for different Technologies to reach 1 million users so we started at some point with Netflix that took actually 3.5 years to reach the 1 million users and the accessibility let's say was was pretty slow and then going through different Technologies Twitter Facebook we got into chat GPT a few few years back like a couple of years back that took everybody in the store so it needed actually only 5 days to reach uh a million user so that's an interesting statistic actually so it shows the importance of the AI it shows also the uh the need for the users to get such Technologies so but if we dig deeper into the the statistics actually we can see at some point that these people and the people who can access and use this AI are in a specific place of the of the globe right so I would say the usual space like the northern uh hemisphere of the of of the planet so this technology needs probably four pillars to to to exist so the first one is the data to build these models you need a lot of data and this data is mainly coming from the internet so most of it is is available publicly but the issue that you have is that you need a lot of compute to get the data and you need a lot of compute to also uh sort of clean the data and build the model so this is these are the first the first two pillars and then you have the algorithmic part we work nowadays with the Transformers maybe tomorrow we we will work with some something else but that's something uh important also to have in the equation then we have the important thing that is the talents uh that's a key thing we don't talk a lot about the talents but that's a very important thing to have so the countries the institutions that will be able to master these four or to control these four let's say dimensions of pillars are the ones who will be able to provide the AI of tomorrow and to be able actually to access this AI tomorrow so this AI came actually it's not it's not a new thing right like seven eight years back we have different countries that have started defining their AI strategies right so you have very very sort of small uh timeline here so things have started in the US and South Korea back in 2016 defining the AI strategies then we have different other countries that that followed and then we had for example on our case in 2017 the UAE has defined the AI strategy 20 203 AI strategy and they appointed the minister that was specifically dedicated for AI to actually amplify and coordinate all the work that is done around uh the the AI few years later in 2013 you can see that most of the countries of the world have started actually working on uh their strategy setting up an AI strategy to make sure that they can contribute to the uh to to the definition of AI and this shows also again the importance of the AI for the economy for the society and for the humanity uh in general the issue is that there are two two things here so there is the definition of the strategy and then there is the followup when it comes to the implementation of the strategy right so most of the countries as of today they have a strategy for AI or they are in the process of defining the strategy but most of the countries also they don't have enough resources to implement this AI so if we go back to the pillars that we have before and I was hearing this since I since the first day uh of the AI for good the computing power for example is a huge issue for everyone including many countries so we not everyone has the necessary resources to actually enable this so this could be one of the reason the slides that you have here is basically showing the cost that we need the increasing cost that we are getting when we are building these models so we have started with a few thousands of of dollars and now we are getting to a few hundreds of millions of dollars to get only one model so it's a very complex process and we believe that not although the strategies are there not everyone can afford to have these amounts want to build a model so having $100 million to build one model and with the pace and the speed things are going so we may need few hundred millions of dollars if not billions of dollars to build this kind of thing so this makes uh clearly things complicated for several countries and then I I looked into a little bit more from the research perspective and from where the research is coming when it comes to the to the AI so we see again certain tendency to have the classical actors the classical uh players who are contributing to that but I would like you just to look into this this picture and or this this this map and think for a second right so if we see the state of today when it comes to AI models and we question ourselves where are they coming from mainly right so I would think clearly that these models are coming mainly either from the us or the raising China as as as as main sources right so we still have in Europe for example we have a lot of Publications that are coming but Europe clearly is lagging behind right so there is this polar polarization between the US and China where the AI is growing extremely fast new models are coming uh Europe is lagging and then probably we have Africa and the South America that are extremely lagging behind so this is creating in my opinion another divide that that I would call the the AI divide as we call it today so in addition to the divide the industrial divide that was created with uh because of the Industrial Revolution this AI is also creating another divide and not everyone will probably be able to access this AI tomorrow if we continue in this way so the ecosystem the AI is not just a model is not just using maximum compute to to build your model it it needs much more than that so of course you need you need the money you need the budget for that but you need the whole ecosystem and the countries they should work into having uh the right ecosystem the right actors who are involved there to make sure that we get some something interesting so we have the data the data is the core and is is is at the is a Cornerstone for this AI so we need regul ations indeed but I believe what we do not to be excessive in the regulations to be able to explore and exploit AI to the maximum so we have the hardware uh providers uh we see the situation nowadays the hardware again the hardware providers are localized in specific locations of the world we have the scientists and the developers we this is this goes back to the talents again it's very important to create an environment where the talents they can work they can uh work together the governments we see more and more uh involvements of the governments in the AI it's an interesting thing but again we need to see what's the right way of doing uh these kind of things then we need the deployment and the business so if we are just on the scientific side we are not paying attention on how to deploy how to get value uh let's say economical value from this AI things will be complicated and then we have the community and we have have the end users that need to be considered uh in the loop the challenges to get uh a good strategy for accessible AI is the compute the first one is the compute so we need once we have the data we need to look in the compute and the compute nowadays again I was hearing this during these three days the compute is is is is is a blocking point for many of the actors and we need to think uh let's say as a community on how to solve that so building AI needs a lot of budget it needs a lot of resources like Financial Resources this is a blocking thing it's good to have an strategy that is that is on the paper but to be able to implement it we need a lot of resources the quality of the outcomes uh we have the IP issue so we see more and more uh work that is closed sours I would say uh everybody wants to keep the IP because there may be something interesting in that I believe that we can find something more open or at least more hybrid uh sharing things that are slightly open or things that are slightly uh closed I think the other thing is the is the politics it's it's an important thing we are actually at at at a time where we are almost on the edge right in in between having the opportunity to explore AI to make it more accessible for everyone or we close everything or even we we even stop some uh innovations that may come uh from there how to make AI accessible the first thing we often I believe forget this is the digitalization or the uh digital transformation so most of the countries that we have today it's nice we are talking about big models intelligent models so on and so forth but we have a lot of countries today which do not have access to the internet for example right they don't have power powerful Mach machines they are still working on paper right so the digital world is still lagging from from on on those countries so we still need to keep that in mind before jumping to the AI there is a need to to help those countries also to to come to a point where they can exploit their digital content the second thing is the model training model training is extremely hard uh but we cannot ask everyone to build a model to train a model from scr so we have different actors including us who are open sourcing the models that we have so not everyone needs to start from scratch taking the models that are there and then building on top of them doing some continuous uh training will be useful uh for everyone the inference again it's the same story so you need a lot of Hardware a lot of resources to be able to run the inference not everyone can access that so we need to think of ways to run or to be able to EXP exploit and access these models on the inference time on smaller devices for example smaller devices either computers uh either uh phones or these kind of things we cannot uh just consider that to run an inference you need a big cluster of of of gpus that not everyone uh can afford and then the talents is a critical uh thing we need to do training we need to organize a community that is able to train people and to form the talents uh of tomorrow just to link it to that so A couple of contributions from ours side from tii the first one is the Fon foundation so what we are doing is that we are providing all our models as open source the Falon Foundation was set up with a $300 million budget to help all the community all the developers who cannot access for compute for example to build things on top of Falcon so we provide the model we provide budget compute budget for developers and researchers and then they just need to put everything they need to build uh on top of Falcon the only condition that we we we we ask for is that whatever is built has to go back to the Falcon Foundation to be open source for the community again so we are very supportive in that and we're trying to coordinate all those efforts around around Fon the uh second thing that we have and this should be my last slide so is that we have launched to help the countries that are not able to access this AI to build either to move forward when it comes to the digital transformation or to be able to exploit AI so AI either at the generative models uh sense meaning or AI in terms of machine learning and related technology so we have a program or a fund that is specifically dedicated for that with the $200 million and we are supporting those countries to get a little bit more modernized uh when it comes to to Ai and the digital world just few concluding remarks here so the AI is getting less accessible mainly because of the cost mainly because of the resources that it needs to be run so we should actually look look into how to make it more accessible work together and bring the the necessary talents uh to work on that so the AI device if it continues this way definitely will have an impact will change or will reshape actually the world and then the economy the politics probably will be impacted one thing that we need to think about is probably are we doing or exploiting or exploring the right AI is it the right path that we are doing so the way we are doing it we are doing it today probably is costy and may create some issues down the road so we are very excited with what's happening but we should proba keep in mind that there may be other options that we need to think about in in the future so we are working to support the communities and different uh countries in in in in getting a little bit to lift them up and get them to use the AI and exploit the AI and as I showed before so we have two main initiatives the Faron foundation and the atrc fund for the developing uh countries Thank you very very much thank you ever so much hakee an absolutely excellent presentation and my goodness audience have we got some treats in store for you over the next few sessions you are going to absolutely love this so what I'm going to do is talk about the potential of AI to empower and include people with disabilities and what I'd like to do is welcome to the stage Cho asakawa [Music] um good morning and good afternoon it is a great honor to be here and I thank you very much for asking me here I'm excited to share a few SS on empowering people with disabilities through technology I will focus on the AI suitcase a navigation robot for the visual imp perod followed by the challenge of social acceptance to implement new technologies into society um let me give you some background when I was born I was excited and by the time I was in junior high school I grew to love sports people around me thought I could become an Olympic athlete in the future studying was not my interest and I never imagined that one day I might become an IBM fellow when I was 11 years old I hit my eye on the side of the swimming pool by the age of 14 I became totally blind one of the challenges I faced as a blind person was Mobility I couldn't go to school by myself I couldn't go shopping by myself I couldn't go anywhere by myself I really wanted to be free from relying on someone I wanted to be independent that became my strong need that pushed me and ignited me towards invention and Innovation after many twists and turns I joined IBM research in 1985 and started working on accessibility I then happily discovered that IBM has a long history of accessibility back in 1914 IBM hired its first employee with a disability there was a remarkably early long before Society began paying s uh paying attention to such issues I first focused on information accessibility by developing bra digitalization Technologies and IBM homepage leader in the N uh in the '90s from 2010 from around 2010 to today I started working on the mobility challenge this video shows uh my exact goal please [Music] watch that is the flying eyeball CH do you know what it is it can't be identified maybe a kind of monster beware of it it's too dangerous it is a very very old uh Japanese TV program I liked it when I was a child and could still watch it the little B on the boy's shoulder is a robot named cha cha helps the boy by Whispering about everything around him from the weather to approaching enemies it was science fiction in those days but now we have ai Robotics and a variety of sensors I decided that time had come to bring this science fiction to life technology like this could notify me of traffic lights stairs escalators elevators any information that allows me to walk independently even more it could help me navigate and avoid collisions Wai in the line at the coffee shop describe scenes and people's behavior in the real world we are currently developing an AI suitcase please watch that video we arrived at divers City Tokyo plaza where should we go I'm thirsty please take me to a place for a drink there is a smoothie shop would you like to head there yes please there is a Starbucks on your right the seasonal recommendation is the strawberry Frappuccino for 680 Yen we have arrived at the smoothie shop I like to explore around here do you have any recommendation there is a life-sized statue of unicorn Gundam Outdoors it is one of the symbols of diversity sounds good take me there there is a Hello Kitty shop on your left here they sell sweets shaped like hellow Kitty dolls they are priced at 600 Yen for 10 pieces avoiding people entering the Festival Plaza we have arrived the Gundam statue is on your right the height of the Statue is 19.7 M and I'm sure such information should be useful for everyone okay it is real I really wanted to bring the AI suitcase here but logistic as this time are still being worked out as you just saw in the video the suitcase moves one step ahead of the user a guide do does the same a white cane enables the user to confirm safety one step ahead so it is a very safe for the suitcase to also be one step ahead now uh let me show you the hardware the suitcase robot is equipped with several sensors a lighter sensor on top of the suitcase measure the distance to the surrounding wall and obstacles three RGB depth sensors under the lighter on the left right and front are used for detecting pedestrians now inside the suitcase a GPU computer on the left does image analysis a computer on the right does localization controls maps and manages the user interface via a smartphone in the middle there is a battery it runs the suitcase for about 3 hours the selected model and gear configuration allows for manual pushing through doors similar to a regular suitcase our handle is very special when I grip it it starts when I release it it stops when turning right the right side of the handle vibrates when turning left the left side vibrates before developing the AI suitcase we studied how guide dogs navigates a blind user good as you saw a guide dog avoids collisions with static obstacles avoiding a person just like a guok the AI suitcase can move avoiding a static obstacles in this case is a standing person okay there are many similarities and differences between a guide do and the suitcase robot the AI suitcase navigate to a user to a destination a guide do cannot the AI suitcase and the user can interact with each other in the case of a guide do it is limited however a guide do can go anywhere humans can go the AI suitcase cannot thanks to the recent AI the suitcase can describe what's around a user I took a photo and got this description by using an AI app for the visually impaired this image shows the entrance of bror a traditional beer garden in Munich the entrance feature signs for lenro and Franciscan Weis beer with the street name beer steerer 78 visible the exterior has yellow walls and a cobblestone path decorated with flowers Brun wart offers local beers and Bavarian cuisine in a relaxed setting surrounded by trees it's a popular spot for both locals and tourists to enjoy traditional German food and drink in a picturesque Garden atmosphere I presented the ultimate goal of my research when I joined IBM it was substitute vision for the blind using technology it was in those days a kind of dream but now it's almost a reality as you just heard if we can use AI for good our world will become more inclusive and accessible uh so far we have conducted trial sessions for the AI suitcase and received many comments such as I feel Independence that I've never experienced after I became blind I want to bring this robot back to my home I really like this one I want to give the robot a name like my gu dog and another Memorial comment was I feel comfortable working seamlessly and naturally in City areas without being recognized as a blind person I don't feel like people are watching me because I work confidently however some users commented it might be a bit scary because people passing by do not notice we are blind and so we should not expect the necessary help from surrounding people they questioned um should we carry a white can even if we don't need it just to be recognized when visually imped people walk with a white cane they often risk going the wrong way or hitting an obstacle so they sometimes need help from surrounding people unlike working with the white G the AI suitcase will not go the wrong way or will not collide with an obstacle it can navigate a user to a destination so the visually impaired do not have to carry a white can for help or to be visible they will be able to walk around public spaces without drawing a necessary attention from people but Japanese Road uh traffic lad requires a person in a person alone in a public space to carry a way together or to be with a guide do and similar laws exist in many other countries when new technologies become uh closer to availability we need to review current laws invention and implementation are a pair of whe for concept a great invention cannot improve quality of life if real users do not use them or if they are not implemented into society we need to change common awareness for social acceptance and implementation for example smart glasses uh would be very useful for visually imperi because those glasses can help them understand the surrounding world but sometimes some people don't like them uh due to privacy concern safety is also another important topic that requires societal understanding take the case of the autonomous driving vehicle even if autonomous vehicles become completely autonomous level five will people accept if a visually impaired person or a child neither is the driver's license drive the car large languaging models like AI chart are rapidly advancing and providing many services like scene captioning but there are many challenges like inaccurate information we always must explain the progress of Technology we need to explain how uh safe and trustworthy the technology is we need to continue communicating with Society for a mutual understanding when we look back at the history of Technology we see a wide range of cases where the specialist of people with disabilities motivate Engineers to invent new technologies the telephone is an example in the 1800s Alexander Graham B invented the telephone why his mother had hearing impairments so he became interested in acoustic engineering taught himself and invented various Technologies and he also established a school for people with hearing impairments um through these experiences he invented the telephone in 1876 the first opportunity to to show The Invention was the Philadelphia Expo in that year he wanted to show it after refinement but his wife with hearing impairments forced him to put it on display the demo was placed by the judges and awarded the gold medal and it led to the uh rapid spread of the telone the very next year in 1877 the very telephone company was founded that later became the AT&T Corporation very quickly other telephone companies were founded all over the country this is not a one-time phenomenon we have seen this repeatedly in the history of Technology B sta designed the internet basic protocol in the 1970s he has hearing impairment and became interested in the computer networking system to communicate with others more smoothly that led to this invention the latest AI Technologies such as image description have also be motivated by accessibility needs accessibility could be a flagship case for cutting H Ai and Robotics and accelerate social implementation by clearly showing how such uh innovation has a power to change uh our quality of life I strongly believe it will lead us to the next generation of breakthrough invention in spite of the advancement of the Technologies and efforts to make our society inclusive many black Lind and visually impaired people have difficulty with education and employment using GDP the estimated annual cost of potential uh productivity losses from the visual period was 410 billion US do in 2018 there is 0.3% of the world's GDP in other words if visually impaired people uh participate in society more actively um and improve their productivity our world can grow and expect to become better and such a world will be eventually inclusive and accessible technology like Ai and Robotics play important roles to achieve such goals and turn a dream to reality we need to implement new technologies into society however as mentioned earlier gaining social acceptance is key for implementation and therefore success we have a major opportunity at the Expo 2025 Osaka in the C area of Japan one of the goals of the export is the uh future Society showcase the export aims to give a realistic uh picture of a future Society by applying Advanced Technologies in 1876 the export accelerated the implementation of the telephone I hope that 2025 EXO Expo will accelerate the implementation of the AI suitcase I believe Expo is a great opportunity for gaining social uh acceptance we have been working on um interactive AI suitcase daily event uh for the Osaka C Expo and I'm happy to announce that the AI suitcase will be at the Osaka canai Expo please join us and experience the AI suitcase for yourself uh we hope to work together with each and every one of you thank you very much thank you thank you so much for your thoughts cheero I'm right here I'm going to turn you around so we can walk back I want a suitcase that tells me how high things are I should bring I could I I ideally wanted to bring the suitcase there I could go back to the backstage with a suitcase it's a great idea I'm just passing you on to Julian there thank you so much oh my goodness me imagine something like oh yes a massive Round of Applause Cho so if you want to see the AI suitcase in person looks like you might have to book your tickets to Osaka for the Expo 2025 what an amazing demonstration and it's a great example of how diverse teams can make for better quality output for everyone there are so many compromises that those with disabilities have to make in order to take part in a society designed without everyone in mind so I'm really glad to see Amazing Ideas like the AI suitcase getting the oxygen of publicity because it's in everyone's interest to bend the world to our wishes for an accessible and inclusive future so with that in mind we have an incredible event coming up next I'm going to introduce a demonstration from the founder and president of wondercraft Nicola simol uh founder and president are you going to head up at the same time or are we going to yes let's invite you up first shall we Happ you come [Applause] hi like to introduce Charlotte or shall I okay um and also please indulge me in welcoming to the stage the professional wheelchair tennis player and exoskeleton user Charlotte Fairbank so hello everyone I'm Nicola I'm the found of wondercraft and this is Charlotte she will be demoing the our personal exoskeleton uh later uh so when she's striping into the device I will be talking about the company I founded 12 years ago so uh I graduated from echal poly technique which is a French enging school and Imperial College uh with a specialization in artificial intelligence so 12 years ago it was already uh a train and um I also have a a family with a genetic disease which is called shakar so my grandmother had the DS and she had 10 childrens and seven of the 10 children have the dees so uh including my father who gave it to my brother and my sister so people in my family lose the ability to work uh as they grew old and they end up using a wheelchair so just after graduating from uh my engineering school uh I looked at what existed at that time in robotics and it was the time where we had the First videos of Boston Dynamics with a robot walking on a frozen lake and it was pushed and at that time it was reacting to keep its balance very fast and what struck me at that time is that it was really reacting like a animal would do and I told myself okay so now we have the science to reproduce the inner workings of a brain animal brain and what I want to do with technology is to build a new device to help people in wheelchair uh walk again and uh go around in the street or in the streets or in their home uh with this device um so what we did is we buil like a humanid robot so it's really like the legs of a human robots 12 degrees of freedom 12 Motors uh a lot of sensors so we have first sensors in the ground Inner Cell sensors a bit everywhere in the structures position sensors and we take all this information uh at 1,000 H by seconds we compute the optimal motion uh to keep the stability and it's a very hard problem because even for a child it takes one year to learn how to work as as much as long as to learn how to talk so we do it without thinking about it but the brand is working all the time to adjust your position to keep your balance and it's particularly hard uh for be bipedal uh so that's why robots started with quadri Peds uh because beds it's harder uh so we we worked 12 years of R&D we are now 100 uh people we've rised 70 million doar and we invested in developing uh this product uh we started by releasing a third generation of our product in 2019 so it's a rehabitation product it's called at talant uh it helps people uh learn how to to work again after a stroke for example in a rehabilitation institute uh we have helped more than 2,000 patients um relearn to walk after a stroke but the end goal was always to build the device for people to be able to take take them home to use it in their home environment or in the streets uh to go into a park with their friends and uh after 12 years of work uh we appr to PR on choose this personal Exon and uh yeah now Charlotte will do the demo thanks Nicola um hi everyone I'm happy to be here my name is Charlotte Fairbank and I have been a full-time wheelchair user for the last 16 years almost um so in 2007 I had an accident uh where a bale of hay um was quite an original accident um a bell of hay crushed me um it wa it was very heavy and it crushed my back it rendered me paraplegic um so when you're paraplegic you can no longer feel your legs or move your legs at all so I've got complete paraplegia I can't move um my legs at all wondercraft has um enabled me to to walk again um so the first time I worked with wondercraft was uh just under two years ago in August 202 2 I was initially using or walking uh with the rehabilitation device um and I really think that um there is a massive future for um the exoskeleton so you're now going to see me uh for the first time in 16 years uh walk across a main stage here we go we ready for [Applause] [Applause] so I'm now in speed number two um I'm going to switch in speed number three um there are different speeds and I'm going to try and go and pick up this bad B um so they different uh modes so there's the walking mode that you just seen there's also a free mode uh which allows you to kind of have more um of an active uh side to the exoskeleton um I'm going to quickly going to switch so this allows me to move around a little bit more and go and grab the [Applause] bag um I can now turn around a little bit more um there's also in order to um so move around with this ex exoskeleton as you can see I'm using a remote control it's easy to hold um I can also clip it here if I want um to go and reach something and I don't want the ex the uh remote in my hand um all I have to do is push on this uh joystick at the end of the remote control to move sideways forwards backwards um move around and this also works with a motion sensor uh which is behind my back so this motion sensor detects kind of my initial movements so my intentions really um so when I'm for example standing up or sitting back down the light kind of inclination that I have with my back that will be sensed by the sensor and it will enable enable me to stand up and and sit back down again um so I'll just turn around um and then I'll let uh Nico speak again and talk about the future of wondercraft for [Applause] okay so that was our first live demo stage so it went well no demo effects um so I'm really happy to have done that because uh you see the smile of Charlotte and that's really why we're working for that uh we're giving smile to people and to my family to we all have people uh you know uh knowledge that have Mobility impairments and you saw that what AI is able to do it's quite complex machine it took us 12 years of hard works we have a lot of top engineering guy in our company uh that are working very hard to solve the problem every day and what we're seeing now is that it's really accelerating really fast with AI and the latest technique in uh machine learning uh we've seen incredible progress in our Labs because the new techniques really when you use it it's like you're able to reproduce the performance of the brain of the human brain so what whatever you are able to do with your body the machine is able to do it so for example we have new algorithm that are able to un pushing slops uh stairs uh we're also adding Vision sensors on the device and everything is possible thanks to AI so for for us AI is really about empowering people uh so the science the technology I'm I'm a True Believer in progress and Science and this is a a good example of what we can do uh if you use the technology well and another good news uh is that Medicare because technology is beautiful but access to the technology is more important um so that's quite a complex uh machine and it has a cost but uh Medicare decided uh in April 20 uh 2024 so this year very recently to cover personal exoskeleton so it means that in the US uh 70% of the people with seci will have access to such a device so it's really big news and now we are Hing because we are a French company but France we follow uh the US example and as we are scaling production because we're preparing to produce it uh at Large Scale uh we really hope to get the cost down because in the end it's only like 12 electric motors so it's mostly like uh 12 electric B cycle so there's no reason that the cost cannot go down and there is millions of people needing such a device for example in the US there is 2 million people uh that use a wheelchair being uh spinal cord injury stru patient that were not able to work again after stroke multiple sclerosis delative disease like in my family shakar so it's really millions of people and if we produce it at scale it can goes down a lot and for example it's 10 times less weight than a core 10 times less component so there's no reason if we produce hundreds of thousands of millions of them that it doesn't cost 10 times less than a car thank you B wow thank you so much and uh do you know I tried this out in 2019 I visited your offices and I filmed with the BBC so I have stood where you've been you're standing now and back then it was really big it was clunky I had to buy High shoes so that I could fit and it's just amazing to see how how far you've come so what's next so as I said we are working every generation to get thinner lighter uh more able to address uh an event ground adverse environment even going uh into cow navigating complex spaces and really it's going really fast with the development so this is the version today but tomorrow we'll have even better one oh I wish you all the best of luck what a powerful demonstration thank you very much to the wondercraft team and Charlotte thank you as well well done my goodness thank you right I think we're going to gently casually walk off stage because you can I love how we've normalize this by the way isn't that amazing just walk off with your exoskeleton and I'll tell you what's going to be in store for after lunch okay so as we leave wondercraft we have many more things for you to enjoy uh we are running our social media competition as well which is here all you have to do is uh you can scan this for the contest and if you are to tweet on I I don't think you can tweet anymore can you okay you can X I guess but I believe we're going to be monitoring LinkedIn because that's the new Twitter I believe uh if you want to have a look on LinkedIn put your thoughts and some pictures possibly of the Fantastic exoskeleton and uh and the winners will receive a new smartphone lovely okay you can also win an expensive Samsung smartphone another way if you head over to our um our shop and you can do a buy Sip and win this is kind of like a raffle contest with a difference all you need to do is by a lovely collapsible cup to keep your hot and cold drinks in and that will act as your ticket and the winner of our prize draw will also receive a fabulous Samsung smartphone excellent now we can also look the part with our t-shirts yes you can buy a very very snazzy looking multicolored t-shirt and that also shows your support for AI for good and shows that you were here when thousands of people weren't able to get into the building yesterday so thank you very much for being here again on day two and if you do need any help please do not hesitate to go and contact our fantastic AI for good volunteers they're brilliant they're friendly they're clever they're everything we hope an AI assistant should be except they're actually human assistants not AI assistants probably a few more years before we replace them with AI okay well thank you very much for being so attentive we're going to say goodbye and I would like to see you all here back at the main stage at 155 for a lovely 2 p.m. start thank you we love we care we it's how we should be let's play Thinking together St stay stay in world we love we we [Music] it rain today tell mepe you [Music] [Music] got find out together stay stay in a place we love care we sh it's how should be let thinking [Music] [Music] [Music] plan good for each other sustainable us all [Music] [Applause] [Music] [Applause] [Music] [Applause] [Applause] [Music] [Applause] [Music] okay [Music] [Applause] okay [Music] [Music] [Music] [Music] [Music] [Music] [Music] n [Music] n [Music] [Music] [Music] a [Music] [Applause] [Music] he [Music] [Applause] [Music] [Music] [Music] [Music] [Music] [Music] [Music] [Music] oh you [Music] [Music] my [Music] [Music] [Music] [Music] he [Music] [Applause] what he [Applause] he [Music] my name is suken Chung I'm an artist and researcher and artistic director of silet a studio exploring human and non-human collaboration so my mother's a programmer and my father is a musician and I think this has me really interested in this idea of hybridity in particular hybridity through ART and technology and through some of these interests I found myself at the MIT media lab building my first collaborative robot in my practice in art and Technology I'm really engaged in the promises possibilities and paranoia um manifested by developments and art technology and science I believe these developments are changing what it means to be human and I'm really driven by curiosity about what that can mean for Generations that came before and generations to [Music] come in my practice I see art and Engineering practices as one and the same both Fields have the potential to uncover something real about the human condition and I think are grounded in an exploratory process of speculation and Discovery I work with robotics AI systems data and mixed reality as drawing performance sculpture and installation I'm really inspired by how we think about the idea of a human and of a machine and I'm really curious about where AI ends and we begin in the past few Decades of Technology development I design what I like to think of as sensory mixes of the future I've been working on a project called Drawing operations unit Generation 1 to 5 for like the past eight almost 9 years its focus has really been on the potential of human and machine collaboration in generation 2 we focused on exploring memory by training a machine learning model on two decades of my own drawing data in generation 5 designed over the pandemic I thought about my own medit meditation practice as a kind of creative Catalyst and substrate I used my own bio feedback recorded through meditation to generate EEG data as drivers for robotic movement in my own painting process I like to think of it as waves of my mind to lines on a canvas my most recent work is called Flora rearing agricultural Network Fran for short a project exploring human plant and machine connaturality the work speculates at what I like to think of as an interdependent ecosystem of human machine and Flora and explores the linkages between machine and ecology through the development of a networked robotic systems stewarding [Music] nature in my practice I work with and develop a range of Technologies I work with robotics as collaborative Partners machine learning as drivers for painting movements and EG to create systems of Bio feedback I'm interested in how research driven processes algorithmic systems and custom computer vision software offer new and speculative human and machine configurations using custom and existing research for artistic purposes means extending the possibilities of the research Beyond fixing a problem or asking a spefic specific question into a more speculative playful Arena that engages new research prompts as well as new conditions for philosophical [Music] inquiry the drawing operations work as an intergenerational art and research project evolves conceptually technically and philosophically with the growing role of technology in our lives I like to frame it as a collaboration because it really foregrounds the relational Dynamics between human and machine and technology and Society I'm curious about this question of agency within systems and think of the practice and these projects as a microcosm to consider the wider implications of things like technological governance and its entangled relationship to the human subject [Music] it's so hard to make predictions about even 5 years down the road I think we've seen how quickly over the past few years life can really change in an instance but I hope that the field of human and machine collaboration is increasingly understood and grown as a site of invention and of Promise one that extends A diversity of subjects and points of view I'm really hopeful about this this because it means that we're working towards this transformation of the human and machine and our environment um and I think that as an interdisciplinary aim um is really powerful [Music] [Music] my name is Christian mclair and I'm an artist working most ly with digital fabric my background is Arts and Technology so as a dancer I learned about poetry and I learned about narration and on the other hand I'm a computer scientist and I studied human computer interaction which is about how we touch machines how machines see us how we see them my work today is mostly about the encounter the poetic encounter of man machine the friction and the beauty between the digital and the analog realm so right at the Hybrid intersection of those synthetic and those natural Sensations and continuously Thrive to investigate how do we actually meet our mirror and how do we actually see ourselves through the lens of a miss [Music] my selected artwork is called Helen and it's an AI based sculpture that means it its shapes its forms were defined through a process using deep learning and to me it basically discusses intention so an actual artwork normally is born within the artist and it's and his or her intention to create something and once this creation then starts building we can slowly see how this thought starts to manifest in the real world in the case of Helen however its shapes its lines were determined by a neuron Network and it was then shaped through a mechanical robot so basically it is an object that is now standing in the world that was not thought of by a human nor created through a natural process like stones at a cliff it just comes out of nowhere and to me it also feels like that it's a dark Cold Stone and it's quite beautiful however there is something missing and I think you see it when you're standing right in front of it there's a certain emptiness and that emptiness is something that interests [Music] me the artwork Helen is created through a custom algorithm that we invented at the studio Christian M and it is basically an algorithm that is inspired by Deep fake technology so deep fake technology works like this it is basically analyzing a certain data set with a certain coherence for instance faces of humans and then is able to think of a completely new face that fits actually and that we expect to be a human and somehow this algorithm is able to kind of invent it we applied this technology of deep fake to art history and showed our algorithm 60,000 busts that were made in human history and then ask the machine could you create another one that wasn't done before but still fits to the to the style of what well humans do and did in the last 2 3,000 years then it came up with a new sculpture and that is called Helen the aspect of Helen that brings insights into our possible future is actually the way it was created if you think of Institutions as well as brains what they try to do is to analyze what serves Us best and then feedback this to us by pred predicting what could be done Brands try to increase Revenue through this continuous interaction with a population and institutions try to serve and help humans to improve um the way they live now that is exactly how machines work they analyze data and predict imagine that there's in the future an emptiness an emptiness inside of Institutions and brands that contain continuously analyze with machines how we feel and what we do and accelerate exactly this but without opinions made by [Music] humans my prediction for the next 20 years is that we will see and witness how we continue to separate from scientific reality as the population today's artists are not standing stable looking into the future as they completely comprehend today's reality the most Forward Thinking artists of our time are standing shaky insecure and trying to grasp what they saw in science in the last 15 to 20 years trying to find balance [Music] hello my name is Sophia Crespo I'm a generative artist and I work primarily with AI Tools around the topic of Nature and artificial life forms I'm also the co-founder of a small artistic studio called entangled others where I work together with felican mccormic an artist from Norway and together we collaborate on various projects that aim to create narratives or story lines about nature and um also reframing new technologies I am very fascinated by the idea of evolution and organic life using artificial mechanisms to evolve and through my work I try to explore how we humans create algorithms to replicate or to create something that to us seems like a replica of a biological process my practice focuses on imagining artificial life forms and every project that we worked on somehow touches on that aims to do that hybrid ecosystems is a series about the boundary of Nature and technology and where that boundary actually lays and a future where that boundary could be very blurry so one uh struggles to tell where a technological artifact ends and where a nature begins another series that is very dear to my heart is neural Zoo which is um series of speculative life forms that aim to recreate textures that look natural but are actually species that don't exist in my work I use a wide range of different neural networks and very often that depends on the concept of the project so it usually begins with an idea that I want to produce and the neuron networks can take a lot of different shapes they can be text or text to image models or audio Gans 3D Gans 3D style transfer Etc this means that to me machine learning isn't an end in itself it's a tool that I have available right now but to me it feels part of a larger project that in the future could take a completely different shape I like a lot the idea that technology becomes naturalized over time and that given enough time and enough use we take the technology for granted and it stops feeling like a completely separate object to us but this also implies that for this to happen our own relationship with nature changes as well so nature becomes part of the same thing that we are and I think that's a very important shift to do as humans to stop uh seeing ourselves as a very separate entity from the rest of nature [Music] I don't like making predictions of what's going to happen in the future because I prefer approaching the present as it comes and finding ways to adapt to it but I do really enjoy the place of dreaming speculative Futures and trying to think what are potential ways that we can collaborate and come together as humans to to change our way of uh connecting with with the world so I can only hope that we will use Technologies in ways that help us do that [Music] [Music] hi I'm portra XO I am an independent artist and researcher I have been heavily sonically obsessed with space and time specifically over the last couple years I've been researching and collaborating with data scientists such as data Bots and open-source culture and coders from pollinations doai community and have also been doing my own personal experiments with open-source resources and I'm forever curious about what all of this means to us living in a a datadriven society the impact on me as an individual as well as collective impact um the impact on society and our environment and I am searching for the humanity between art music Science and Technology through exploration and experimentation of how far I can take sounds and storytelling through Lan space my AI audio visual piece plastic skin is the result of two artist residencies and one part of my AI audio visual album wire in 2020 I finished my artist residency at factory Berlin and collaborated with CJ Carr from datab Bots where we trained 1 hour of My Singing vocals into their custom sample RNN model that generated 10 hours of new audio over 2 and 1 half days and it gave birth to a process we like to call neur voal duet that I fallen in love with that basically allowed me to co-create lyrics and Melodies with this AI version of my voice that was creepy eerie and also fascinating the second residency was at BBA Gallery where I was able to have different types of performance captured in the gallery space and this video shows me performing in the gallery and then using that video as input for a textto video clip guided vgan open source model provided on pollinations doai and that allowed me to further tell the story of the meaning behind this song through text prompts and there were two different experiments that were basically blended into one that you see in this video there were several types of technology used to produce this work first step was to gather one hour of my vocals which I took from over 200 songs that I wrote in a year and took the best from that and for that to happen I used Ableton which is my go-to recording software the second was custom sample RNN model by datab Bots which was the way we got this raw audio AI generation of my voice and the second piece of technology was provided by pollinations AI which is the text to video clip guided VQ Gan model [Music] the aspect of this piece that maybe gives insight into our possible future relationship with technology is in the storytelling the song itself is written in the perspective of the robot singing to its human Creator who created the Robot to try and fulfill all its desires and needs including love and the Rob B basically is trying to point out to the human that based on the data and analytics the result is inconclusive because human behavior with love is far too erratic and I genuinely think that AI will not become sentient AI is not sentient but AI can possibly make humans more sentient and I do think that human machine collaboration used with AI in this way can offer a whole new level of intimacy in the way we work as [Music] creatives I think the next 20 years of human machine collaboration is going to get really fascinating full of surprises at the same time I think that there will be some aspects that will naturally get faster and better like audio visual fidelity and I think it's really crucial and important for More Humans to get into The Narrative of AI and understand its impact on us because humans can save humans machines cannot save humans but humans working with machines in particular ways can maybe save humans [Applause] [Applause] [Music] [Applause] [Applause] [Music] [Applause] [Music] okay [Music] [Applause] okay [Music] [Music] [Music] [Music] [Music] [Music] [Music] e [Music] n [Music] [Music] [Music] he [Music] he [Music] [Applause] [Music] [Applause] [Music] [Applause] he [Music] [Music] [Music] [Music] [Music] [Music] [Music] [Applause] [Music] you out [Music] [Music] B [Music] [Music] [Music] [Music] he n [Music] [Applause] what [Applause] go [Music] my name is suan Chung I'm an artist and researcher and artist director of solet a studio exploring human and non-human collaboration so my mother's a programmer and my father's a musician and I think this has me really interested in this idea of hybridity in particular hybridity through ART and technology and through some of these interests I found myself at the MIT media lab building my first collaborative robot in my practice in art and Technology I'm really engaged in the promises possibilities and paranoia of manifested by developments in art technology and science I believe these developments are changing what it means to be human and I'm really driven by curiosity about what that could mean for Generations that came before and generations to [Music] come in my practice I see art and Engineering practices as one and the same both Fields have the potential to uncover something real about the human condition and I think are grounded in an exploratory process of speculation and Discovery I work with robotics AI systems data and mixed reality as drawing performance sculpture and installation I'm really inspired by how we think about the idea of a human and of a machine and I'm really curious about where AI ends and we begin in the past few Decades of Technology development I design what I like to think of as sensory mixes of the future I've been working on a project called Drawing operations unit Generation 1 to 5 for like the past eight almost 9 years its focus is really been on the potential of human and machine collaboration in generation 2 we focused on exploring memory by training machine learning model on two decades of my own drawing data in generation 5 designed over the pandemic I thought about my own meditation practice as a kind of creative Catalyst and substrate I used my own bio feedback recorded through meditation to generate EEG data as drivers for robotic movement in my own painting process I like to think of it as waves of my mind to lines on a canvas my most recent work is called Flora rearing agricultural Network Fran for short a project exploring human plan and machine Co naturality the work speculates at what I like to think of as an interdependent ecosystem of human machine and Flora and explores the linkages between machine and ecology through the development of a networked robotic systems during [Music] nature in my practice I work with and develop a range of Technologies I work with robotics as collaborative Partners machine learning as drivers for painting movements and EG to create systems of Bio feedback I'm interested in how research driven processes algorithmic systems and custom computer vision software offer new and speculative human and machine configurations using custom and existing research for artistic purposes means extending the possibilities of the research Beyond fixing a problem or asking a specific question into a more speculative playful Arena that engages new research prompts as well as new conditions for philosophical [Music] inquiry the drawing operations work as an intergenerational art and research project evolves conceptually technically and philosophically with the growing role of technology in our lives I like to frame it as a collaboration because it really foregrounds the relational Dynamics between human and machine and technology in society I'm curious about this question of agency within systems and think of the practice and these projects as a microcosm to consider the wider implications of things like technological governance and its entangled relationship to the human subject [Music] it's so hard to make predictions about even 5 years down the road I think we've seen how quickly over the past few years life can really change in an instance but I hope that the field of human and machine collaboration is increasingly understood and grown as a sight of invention and of Promise one that extends A diversity of subjects and points of view I'm really hopeful about this because it means that we're working towards this transformation of the human and machine and our environment um and I think that as an interdisciplinary aim um is really powerful [Music] [Music] my name is chrisan mclair and I'm in artist working mostly with digital fabric my background is Arts and Technology so as a dancer I learned about poetry and I learned about narration and on the other hand I'm a computer scientist and I studied human computer interaction which is about how we touch machines how machines see us how we see them my work today is mostly about the en encounter the poetic Encounter of man and machine the friction and the beauty between the digital and the analog realm so right at the Hybrid intersection of those synthetic and those natural Sensations and continuously Thrive to investigate how do we actually meet our mirror and how do we actually see ourselves through through the lens of a machine my selected artwork is called Helen and it's an AI based sculpture that means it its shapes its forms were defined through a process using deep learning and to me it basically discusses intention so an actual artwork normally is born within the artist and it's and his or her intention to create something and once this creation then starts building we can slowly see how this thought starts to manifest in the real world in the case of Helen however its shapes its lines were determined by a neural network and it was then shaped through a mechanical robot so basically it is an object that is now standing in the world that was not thought of by a human nor created through a natural process like stones at a cliff it just comes out of nowhere and to me it also feels like that it's a dark Cold Stone and it's quite beautiful however there is some something missing and I think you see it when you're standing right in front of it there's a certain emptiness and that Emptiness is something that interests [Music] me the artwork Helen is created through a custom algorithm that we invented at the studio Christian and this basic Al an algorithm that is inspired by Deep fake technology so deep fake technology works like this it is basically analyzing a certain data set with a certain coherence for instance faces of humans and then is able to think of a completely new face that fits actually and that we expect to be a human and somehow this algorithm is able to kind of invented we applied this technology of deep fake to art history and showed our algorithm 60,000 busts that were made in human history and then ask the machine could you create another one that wasn't done before but still fits to the to the style of what well humans do and did in the last 2 3,000 years then it came up with a new new scure and that is called Helen the aspect of Helen that brings insights into our possible future is actually the way it was created if you think of Institutions as well as Brands what they try to do is to analyze what serves Us best and then feedback this to us by predicting what could be done Brands trying to increase Revenue through this continuous interaction with a population and institutions try to serve and help humans to improve um the way they live now that is exactly how machines work they analyze data and predict imagine that there's in the future an emptiness an emptiness inside of institut ions and brands that continuously analyze with machines how we feel and what we do and accelerate exactly this but without opinions made by humans my prediction for the next 20 years is that we will see and witness how we continue to separate from scientific reality as a population today's artists are not standing stable looking into the future as they completely comprehend today's reality the most Forward Thinking artists of our time are standing shaky insecure and trying to grasp what they saw in science in the last 15 to 20 years trying to find balance [Music] hello my name is Sophia crispo I'm a generative artist and I work primarily with AI Tools around the topic of Nature and artificial life forms I'm also the co-founder of a small artistic studio called in Tangled others where I work together with felican mccormic an artist from Norway and together we collaborate on various projects that aim to create narratives or storylines about nature and um also reframing new technologies I am very fascinated by the idea of evolution and organic life using artificial mechanisms to evolve and through my work I try to explore how we humans create algorithms to replicate or to create something that to us seems like a replica of a biological process my practice focuses on imagining artificial life forms and every project that we worked on somehow touches on that aims to do that hybrid ecosystems is a series about the boundary of Nature and technology and where that boundary actually lace and a future where that boundary could be very very blurry so one uh struggles to tell where a technological artifact ends and where a nature begins another series that is very dear to my heart is neural Zoo which is um series of speculative life forms that aim to recreate textures that look natural but are actually species that don't exist in my work I use a wide range of different neuron networks and very often that depends on the concept of the project so it usually begins with an idea that I want to produce and the neuron networks can take a lot of different shapes they can be text or text to image models or audio Gans 3D Gans 3D style transfer Etc this means that to me machine learning isn't an end in itself it's a tool that I have available right now but to me it feels part of a larger project that in the future could take a completely different shape I like a lot the idea that technology becomes naturalized over time and that given enough time and enough use we take the technology for granted and it stops feeling like a completely separate object to us but this also implies that for this to happen our own relationship with nature changes as well so nature becomes part of the same thing that we are and I think that's a very important shift to do as humans to stop uh seeing ourselves as a very separate entity from the rest of nature [Music] I don't like making predictions of what's going to happen in the future because I prefer approaching the present as it comes and finding ways to adapt to it but I do really enjoy the place of dreaming speculative Futures and trying to think what are potential ways that we can collaborate and come together as humans to to change our way of uh connecting with with the world so I can only hope that we will use Technologies in ways that help us do that [Music] [Music] hi I'm portra XO I am an independent artist and researcher I have been heavily sonically obsessed with space and time specifically over the last couple years I've been researching and collaborating with data scientists such as data Bots and open-source culture and coders from pollinations doai community and have also been doing my own personal experiments with open source resources and I'm forever curious about what all of this means to us living in a datadriven society the impact on me as an individual as well as collective impact um the impact on society and our environment and I am searching for the humanity between art music Science and Technology through exploration and experimentation of how far I can take sounds and storytelling through lame space my AI audio visual piece plastic skin is the result of two artist residencies and one part of my AI audio visual album wire in 2020 I finished my artist residency at factory Berlin and collaborated with CJ Carr from datab Bots where we trained one hour of My Singing vocals into their custom sample RNN model that generated 10 hours of new audio over 2 and 1/2 days and process we like to call new vocal duet that I fallen in love with that basically allowed me to co-create lyrics and Melodies with this AI version of my voice that was creepy eerie and also fascinating the second residency was at BBA Gallery where I was able to have different types of performance captur capured in the gallery space and this video shows me performing in the gallery and then using that video as input for a textto video clip guided vuan open source model provided on pollinations doai and that allowed me to further tell the story of the meaning behind this song through text prompts and there were two different experiments that that were basically blended into one that you see in this video there were several types of technology used to produce this work first step was to gather one hour of my vocals which I took from over 200 songs that I wrote in a year and took the best from that and for that to happen I used Ableton which is my go-to recording software the second was custom sample RNN model by datab Bots which was the way we got this raw audio AI generation of my voice and the second piece of technology was provided by pollinations aai which is the text to video clip guided VQ Gan model [Music] the aspect of this piece that maybe gives insight into our possible future relationship with technology is in the storytelling the song itself is written in the perspective of the robot singing to its human Creator who created the Robot to try and fulfill all its desires and needs including love and the robot basically is trying to point out to the human that based on the data and analytics the result is inconclusive because human behavior with love is far too erratic and I genuinely think that AI will not become sentient AI is not sentient but AI can possibly make humans more sentient and I do think that human machine collaboration used with AI in this way can offer a whole new level of intimacy in the way we work as [Music] creatives I think the next 20 years of human machine collaboration is going to get really fascinating full of surprises at the same time I think that there will be some aspects that will naturally get faster and better like audio visual fidelity and I think it's really crucial and important for More Humans to get into The Narrative of AI and understand its impact on us because humans can save humans machines cannot save humans but humans working with machines and particular ways can maybe save humans [Applause] [Music] [Applause] [Music] [Applause] [Music] [Applause] [Music] [Applause] [Music] okay [Music] [Applause] okay [Music] [Music] [Music] [Music] [Music] [Music] [Music] let's play play find out together stay stay stay in a place where we love we care we it's how it should be let's play Thinking together and stay stay stay in a world that we love we can will sh it's how it should be [Music] eally the recipe you got me can you cook for me can you see [Music] [Music] meay stay in place we love we the way we sh it's how should be eally play playing together and stay stay in a world that we love we can Wonder sh be [Music] [Music] he I for [Music] good good for me good for the good for [Music] [Music] he I for good [Music] hey I for good n [Music] good for me good for me good for the planet good for each [Music] night [Music] that's [Music] [Music] see us as friends the way we reach for them the we reach [Music] [Applause] [Applause] [Music] for there you we go to l tell us we [Music] dreams only ch [Music] [Music] Dre [Music] I Want I Want I Want I Want I use AI for good yeah use AI for good I I I I I use AI for good yeah use AI for good let's use AI for good for good let's use AI for good good let's use AI for good a i [Music] for yeah yeah yeah yeah s g yeah yeah yeah yeah you and me yeah yeah yeah yeah s g yeah yeah yeah yeah you and me yeah yeah yeah yeah s yeah yeah yeah yeah you and me you me you you me you me you and me you me you and me [Music] everybody yeah yeah yeah yeah yeah yeah yeah yeah AF you [Music] you me me you me me you me you me me [Music] everybody St St [Music] the plan stay all we have [Music] you st [Music] sustainable [Music] [Music] all e [Music] [Music] good afternoon everyone now um I'm not sure if you'll have noticed but there's a few things on stage behind me this evening yes well there's going to be more on that I'm so excited for you to see these demonstrations and welcome back everybody to the main stage here at AI for good we've got a lot in store for you if you were wearing a Brain Cap like those dancers this morning it would register a huge increase in activity over this afternoon session so ahead of some super impressive demonstrations it's a pleasure to introduce to the stage the super impressive Deputy Secretary General of the international telecommun uh telecommunication Union even please welcome an afternoon Round of Applause for Thomas laan ascus [Music] our planet is on fire and flooded by water every month breaks new records the wrong kind of Records April 2024 was 11 months in a row with a record high global temperatures actually the month was 1. 158° C is warmer than the estimated April average before Global industrialization the consequences include super cyclon forest fires a severe drought in Amazon rainforest and severe floods from Afghanistan to Kenya often the most vulnerable communities are the ones hit hardest Rising levels put small island developing States in severe Peril when it comes to the climate crisis is AI part of the problem or will it help us find a solution ladies and gentlemen good afternoon actually I was debating whether to say good afternoon at this moment after all this introduction but here we go so for now our AI use makes a large and growing carbon footprint these Technologies are hungry for electricity more than they can get from Renewable Power Supply the International Energy agency or iea tells us that two years from now dead centrus could consume twice as much energy as Japan does today according to a study by and the World Bank in the two years up to 2022 electricity use for data centers increased by 57% emissions from data centers are skyrocketed they accounted for 32 million tons of emissions in 2022 up 45% from 2 years earlier we as AI developers and users need to bring this under control to limit global warming we must cut Tech related emissions to Net Zero by 2050 rather than unleash exponential emissions growth the necessary path is actually captured in a Kyu standard and it says that we need to start with a crucial 45% cut between 2020 and 2030 AI is thirst to two researchers found that 10% 10 prompts can consume as much as half a liter of water and then there is also a risk of intensifying resource competition as competing AI hubs Scramble for energy supplies Rare Minerals and scarce microprocessor chips well AI can also B EOS solutions that help protect biodiversity though for example AI Technologies can detect and analyze subtle ecosystem changes and help plan conservation efforts AI Solutions boost Energy Efficiency and cut waste em waste and Emissions across other sectors Recent research actually suggests that AI can help mitigate between 5 and 10% of global greenhouse gas emissions by 2030 equivalent to the total annual emissions of the European Union the potential for AI based climate Solutions is crystal clear but it won't be realized until we tackle the risks to our planet presented by rapid AI growth head on the good news is that digital companies are leaders in renewable energy uptake accounting for 60% of global purchases by 2021 this has helped keep Tech related emissions constant despite the surge of generative AI itu standards have also helped address Tech related emissions and E-Waste for several years we have standards helping big data and AI support Smart Energy control for Telecom sites and data centers especially by prioritizing renewable and low carbon power sources our green standards package is expanding to ensure we reign in our industry energy and carbon footprint importantly the tech industry recognizes its responsibility as well green digital action track that we launched at the last C climate conference c28 green digital action in that track mobilized over 40 Partners including governments businesses and civil society as well as un agencies and International Development Bank through green digital action we aim to put digital Solutions at the Forefront of the climate action Partners have also committed to report their climate data a crucial step to get Tech on the right side of the history we need far better data to Green the additional economy itu and partners are working to ensure that the emissions of digal products or services are measured and reported similarly itu and our world standard cooperation Partners have pledged to deliver technical standards that make both business and environment sense we are encouraging the entire Global Tech industry to get on board encourage all of you to support green digital action and make AI part of the solution so ladies and gentlemen I'm confident AI will help us respond to the climate crisis but we need to work hard to make that happen it is a vital aspect of using AI for good and an urgent challenge for command today let's work together to make sure that AI helps us save our planet not thinkink it further thank you very [Applause] much thank you very much to Thomas there for a very powerful call to action and this isn't the first time I've shared the stage with a robot but what I'm going to do is briefly explain what's going on behind us the clue is robotic auton in the wild I'm sure you're as intrigued as I am I have seen the rehearsal for this it's quite remarkable but to help make some sense of this display we have from the wonderful Norwegian University of Science and Technology alongside his robotic owl yes you did hear that correctly please welcome cost us [Music] Alexis hi my te and I are here today to present you progress about using autonomous robots at any time and in any environment however strenous and demanding this might be we call this as from the title robot autonomy in the wild we believe that such robots can be used to probe and explore extreme natural habitats such as underground caves or glassiers where we are actually located in Norway and likewise also be used to monitor inspect and maintain critical infrastructure and Industrial facilities at the best possible standing therefore also reducing their potential environmental impact but we ask ourselves scientifically what is a common way that can allow diverse robotic configurations walking systems flying systems or even swimming systems that you will not see today because making a pool will be very difficult to operate with resilience in any environment under extreme conditions before we go ahead to discuss technology for the same we are going to do a small demonstration here on stage you're going to see two robots a legged robot and a drone but they're going to be working together in a marsupial fashion so the Drone is sitting on the back of the quadraped and they will be tasked to explore this area we have built here on stage which involves two compartments one you can see through and it has a net and one you cannot see through the two compartments are connected through a small aess Hutch and the key is that the quadraped does not fit to go through this access hatch right so it has to rely on the Drone so with that the word is on my team which are ready to do the demo for you so now the quadraped enters inside and as I told you there's a small access hatch possibly you see it from the video and it cannot go through on its own so it will depend on the drone to explore the remaining of the environment of course we are doing a demo here on public stage so everything is enclosed with Nets we're going to close the door some safety precautions because you are here and we don't want to create accidentally any issue having said that now the robots to operate in their mission they rely on their onboard sensors so the onboard sensors involve a set of different modalities laser scanners could be Radars accelerometers gyroscopes Vision system sys and so on so forth and uh as you already saw the quadraped now has opened its extra structure on top to allow the Drone to be released give us now some time because sensors uh take some time to you know wake up and get ready for operation yep so next step [Music] once it enters you will see the data can you show Arvis yeah and now you see the 3D model of the system as it reconstruct environment and the path from its [Music] navigation so this demo is small because this is a small environment we have built but we haven't stopped yet what we want to show so now M here will be moving the screen of the 3D data from the robot and you see the small compartment it has built but also here if you can please show further away for the overall room and know yeah so we will increase a little bit the size for you to have something a bit more visible yeah so I don't know how visible it is from there but this is actually the room we are all sitting so it's important to highlight some few things in this small demonstration here on stage that we did have a safety pilot but the safety pilot was not there to intervene with a robot unless necessary nothing happened bad so the safety pilot was only there just for the sake of you know being around and uh the second important thing is that we indeed build this facility but we do not provide information to the machines about the environment they are T to explore so let me now come and ask the question what it takes not to do this demonstration here on stage for the sake of presenting to you the capabilities of robotic systems in principle what does it take to use robots in extreme conditions seamlessly without any worry without a team behind the robots to make a demonstration to understand the challenges we can look at a well-known Paradox in the field both of Robotics and AI more X Paradox which states elegantly that typically what is hard for humans for example doing complex mathematical calculations is very easy for AI or tends to be very easy for robots and likewise on the other way around what is very easy for humans maneuvering around any complex environment using your hands in a dexterous manner tends to be still very difficult for robotic systems and this a paradox that is known for decades not something new and we can only relate to some examples for example we can see a toddler and the daughter one day learns to walk and seamlessly afterwards very soon Maneuvers any place in the world with robustness they may fall but they can still manage to continue or a baby one day learns to understand that this is a cut and then the next day you show a sketch that you just draw yourself a terrible sketch and the baby still understands that this is still a cut so we generalize very well and later in life not when babies we understand very well the notion of risk so when we are going around something we can actually not do safely we don't do it we remain safe so we have a good understanding of the model of what we can do in the world and what we cannot do unfortunately or good for us as researchers Robotics are not there yet and we have to find a way to get the same capabilities so we humans and other natural beings are very resourceful we have redundancies we deal with disturbances we handle uncertainty we generalize from previous experiences to new experiences and we find our way to do what we want to do even in the presence of adversity robots are not there yet and we question ourselves how we can actually bring them to this level of resilience such that robots are not there in a demonstration but everywhere around us and they can execute something useful for the society my team and I we are working to instill resilience across the robot stack so from how a robot sees with camera sensors laser scanners Radars different sensing modalities how the robot fuses the data that it sees to understand the world and reason about the world about what it can do in this world or what is inside this environment and then how a robot can plan its actions to execute something useful save for itself safe for its surroundings and of high utility for the humanity and last of course how a robot can actually deliver its actions can it actually move and execute what it needs to be and it's important to highlight because this is Robotics and it's not only a software system it's not only about the intelligence as we think of it as humans that we take for granted most of the times our body body is very important for robotics so for example you see some vide that the Drone collides and sustains it's a soft system and by being soft much like insects can Collide and can get more damage without it actually having to stop so I don't like hype and I don't want to say that robots are there yet and they are not but we can pull already several fits that I hope you can find impressive so these are some results from the group for example a drone that navigates inside dense smoke and Maneuvers the world with infusion of lighter and radar sensors and goes in areas we could even be challenged to navigate or a quadraped that operates completely autonomously for several kilometers of navigation to explore an underground mine and come up back with a map without the need for a human to enter this dangerous and difficult environment a soft drone as mentioned before that can sustain trouble and damage and can fit through cross-sections more narrow than itself there is a very good video from BBC with a bird that does something like this way better of course and we motivated from what we see in nature and robots that have no prior information for the scene much like this little demo but not only in this little small stage and enter unknown areas and come back with high detailed 3D models not only geometrically but also we reason what we see in the world and this is for free robots can do this in a very efficient manner for free I don't mean cost-wise I mean without the humans being there or the humans having to teleoperate we are talking for systems without any need for teleoperation or commanding purely autonomous machines and uh having said that subject to the fact that we slowly instill these capabilities to robotic systems we can go ahead and do useful missions so I will just organize over two types of activities natural environments and Industrial environments so we have been in extreme natural habitats in the moan CS in California mapping the cave system or in the darker Subterranean challenge together with other partners in a team we LED we had the opportunity to explore simultaneously caves mines Subway infrastructure and so on so forth or for example fly Under The Canopy of forest and observe the differences that are impacted from processes in the climate and the nature in general or on the industrial front we can monitor critical infrastructure what you see in the videos on the bottom level is ballast tanks of a ship or a nuclear power plant in the United States or an underground mine so we have some progress and I think we can continue this direction and not necessarily tomorrow but soon robots will be able to operate in the wild and we also have identified We Believe two critical directions that we can put our efforts the first is that the same robots are used pretty much all the time they either look like miniature M Aviation systems or M systems in general or mimicking nature but actually we can do not only mimicking we can do the idea of nature of specializing robots to a certain ecological niche meaning robots that are evolved and trained to be best in a certain environment so for example a class of environments forest and so on so forth we call this computational code design of the robot body and the brain and we have some progress in this field and second Beyond core research we can also do right now robots that are useful for the society either to inspect infrastructure or for example even more bold goals using autonomous systems that can help suppressing wildfires with their own capacities so with that I want to actually give you this final message that resilience is key resilient autonomy is very hard to achieve but also an exciting and Endeavor for us to manage and second thing I want to say I want to credit our sponsors the public sector that is there to support this fundamental research before it actually puns out as an excellent result we can see in a video my team that we're here to do the demonstration for you so Marvin Jorgen m mikar m Carney that spent a lot of time shipping robots from Norway coming to Switzerland just to do the demonstration for you and of course some credit to our robots the Drone built at the lab and the animal Leed robot that was from a company here in Switzerland and btics modified to carry our drone so with that I want to thank you and give the stage thanks a lot thank you thank you very much to costus and his amazing team I love that he thanks the robots as well that's lovely and today I learned there's a classification called marsupial robots brilliant I wish you the best of luck with your continued work and next it's a privilege to briefly pass the torch of moderation to a trusted guide who will give you a whirlwind tour of some of the more incredible projects for good I'll be back soon but meanwhile you get to enjoy being in the very capable hands of Professor of atmospheric physics at University of Oxford please welcome Phillip [Music] Sher all right uh it's a Friday afternoon and we having session on environmental topics so it's almost last but certainly not least I should just mention if you want to dig deeper we also convene a AI for good Discovery session on AI for climate science and then you can dig much deeper in the same topics that you will hear today but we have a really exciting session for you today and we'll kick off right away so our first speaker is Sage L and she's an activist working to build an educational system to train the next generation of uh leaders uh who will ultimately tackle the climate Solutions and she started really ground up uh by teaching her own program as a student at UC Berkeley she broke record for all the attendants uh in a student Le classroom and she was uh named as a Time Magazine uh 2023 Next Generation leader and today she will call us to action and we'll ask we'll uh pose the question we can't let AI accelerate environmental destruction I'm looking very much forward to hear this [Music] hi everyone thank you my name is sage lir and I'm a climate activist I initially approached this conversation with no formal involvement with AI specifically or honestly even Tech more broadly my interest is wholly environmental and my concern is singular our economy has us on track for three degrees of warming by the end of the century which in no uncertain terms guarantees that large sectors of our society and economy will collapse and billions of people will suffer I still can't quite understand why preventing this from happening is not the first priorities of Industries and governments but that's a conversation for another time my engagement with the tech industry stemmed from a desire to understand who exactly are the culprits for climate change the climate movement has very firmly latched onto fossil fuel companies but in my mind they only hold a respon a portion of the responsibility the burning of fossil fuels explains how climate change is happening not why what I want to know is why why we're consuming so much energy why are emissions still increasing every year and who is making it profitable one of the grimmest facts I will share with you today is that none of the renewable energy we're building is helping to solve climate change we are not replacing fossil fuels with Renewables every year our Global demand for energy increases so much that the renewable capacity we build is only offsetting that additional growth and every year demand for an extraction of fossil fuels goes up it is a proven fact that we cannot stay under 2° C by building Renewables alone which means we need to be decreasing energy demand and yet it keeps increasing in 2022 data centers consumed 2% of global energy demand which is equivalent to the entire country of Columbia that was before the AI boom started in November of that year with chat GPT now because of AI data center electricity consumption is expected to Triple by 2030 this massive surgeon energy demand is threatening our ability to lower emissions and in more ways than one because it comes at the same time that demand for electricity was already surging for fossil fuel free infrastructure like for electric vehicles when we take the gasoline out of cars and plug them into the walls we obviously have to find a way to increase the amount of energy supplied to the power grid but in the last 2 years grid planners have been slammed with a long list of requests for massive amounts of power for new data centers utility are telling us that as of right now they're incapable of meeting these demands unless someone governments or the tech industry makes a massive investment in new power supply data centers for AI have set off such a large increase in American power consumption that some coal plants previously scheduled to be closed down are being delayed these areas built enough solar and wind to replace their coal plants and they can't now demand has has surged so much that the Renewables are just acting as a supplement to fossil fuels utility shortages in the face of these de data center demands are happening in almost every US market global grid infrastructure has been eroding for years and many communities around the world are already experiencing increased blackouts when energy demand increases the utility's ability to provide during extreme cold or extreme heat which is now made more extreme and more frequent by climate change in the age of AI utilities will have to decide who gets energy for air conditioning during a heat wave a few thousand homes or a single data center that cannot go offline if governments and the tech industry do not put guard rails in place building AI is going to blow a hole in our power grid and make climate change worse ecological econ economists have been shouting for years about extra alities like this that are never included in corporations accounting when they're deciding what is possible they just assume that they can consume an unlimited amount of resources like energy without factoring in the cost to Society of their consumption we do need governments to come together to work on International oversight for the development and use of AI and specifically for its energy consumption short of that we need to pressure tech companies to commit to adding as much renewable energy capacity to the grid as they demand operating completely grid independent wherever possible this is the bare minimum we should expect from an industry that has the resources and influence like Tech the other day was talking to an AI climate researcher at MIT and he had never heard of this company that I read off called Shen that was a good piece of context for me because I otherwise wouldn't have thought to explain this given how popular this company is amongst my generation Shen is a relatively new fast- fashion company and it belongs in a category of its own to give you a frame of reference Zara has been under Fire for years for their gross overproduction of of clothing inhumane factory conditions and massive carbon Improvement Zara adds 2,000 new items to their website each month Sheen adds 60,000 they're young and they're growing at a very scary speed in 2023 Shen generated an estimated $32.5 billion in Revenue which was a 43% increase in just one year and now they're set to be dwarfed by a brand called Teemu Teemu was created in September of 2022 and in 2023 managed to bring in 27 billion in Revenue we have never seen something like this company it is is the fastest retail rise in history a June 2023 Congressional report on forced labor found that one third of the packages entering the United States were from timu and shien and that percentage has probably increased because timu has not slowed down its exponential growth in the last 12 months shien and timu are what happens when we allow AI to be applied to industries that are already destroying the planet and exploiting the people in their supply chains AI enabled these companies to rapidly analyze fashion trends and consumer preferences create hyper-personalized marketing strategies and optimize for Accelerated production Cycles these companies could not produce at such fast-pace and low cost without labor exploitation which usually includes child labor and people who live in modern slavery the AI driven pressure exacerbates these exploitation conditions an expose on Shen recently found Factory workers forced to pull 17 hour shifts in one Factory they made a daily base salary of $20 which could be docked $14 if they made any mistakes so this growing crisis already goes beyond ai's own energy demand we have clear evidence that the usage of artificial intelligence in the private sector is accelerating environmental degradation and human rights violations when we do the reporting the data centers for AI get counted in the tech industry's carbon footprint and Teemu gets counted in the fashion Industries but where should accountability start and end most of you are here because you're excited about Ai and you think it can do amazing things if it's not already obvious I'm not very enthusiastic but this room was one of the only places where I'm in the minority being faced with data like this with stories like this might be uncomfortable but it would be a disservice to my generation and the movement I represent if I didn't bring these concerns to your attention so as much as I and much of the general public wish there was a way we could slow down this AI mad grab we don't have the power to do that so many like a lot of you here are turning to how we can harness these Technologies to create social good and I I think that's the right thing to do given the situation the climate movement can't afford to let AI leave us behind and there are some environmental problems that can only be solved with machine learning like smart grids whether or not the applications of AI for good can make a difference or even outweigh ai's own carbon footprint is not something we have data on yet but we do have the ability to track investments into Ai and right now the vast majority of money is being being put to use making our current exploitative system more efficient if this industry was truly committed to using AI for good we would see significant Investments directed towards solving real problems like climate change thank you thank you very much and this obviously raised many many important concerns now we're shifting gears slightly and we will focus more on the biodiversity and our next speaker is Marcus Rin marccus is a director at the max Blan Institute for Bio geochemistry uh and he's also professor at the University of Y and his research interests are really how climate variability affects ecosystems and how this responds also to climate change so today Marcus will pick up this topic with a talk called breathing nature and he will unveil the biosphere Secrets through Ai and Earth observations over to you Marcus [Music] hello yes I would like to welcome you to this talk where I want to tell you why what breathing nature is and why it's important for sustainable development goals and what science and a can AI can do to better understand it first of all let me start with a slide that you all know or with knowledge that you all know climate is changing it's happening now and we are realizing experiencing the effects of climate change almost every day somewhere on Earth it is these impacts that matter and these impacts are actually mostly not directly related to temperature directly but to the water cycle to too much water to less water droughts and they emerge through Domino effects and cascading effects which I will try to explain to you in the next slide let's look at at a heat wave as an example it has such a heat wave has hit Canada recently India Australia Europe and in 2010 there was kind of a prototypical heat wve uh in Western Russia uh which is pretty well studied so there's a blocking High system nice weather in principle blue sky but no rain on top of climate change which then leads to a heatwave and drought stressing the ecosystems they are disecting this makes them fire prone so there's a lot of forest fires that that are developing from that which affect the air chemistry with pollution with fine particles with nitrous oxides and it's very important to note that then only this kind of indirect effect of the air pollution together with the heat wve actually put the strain on the health systems and mortality of more than 10,000 people this is this was a case in 2010 but we have similar results for example for California uh heat wve and and fires and so on and then if such a event happens in a bread basket then the crop failure that is inevitable will then also lead to socioeconomic repercussions like high volatility in wheat prices and Studies have really clearly shown that this kind of economic volatility then causes uh not caus but at least adds to the causes of social unrest something that we now know as as the Arab Spring so what really important that if you if you talk about that and think about that that the different sustainable development goals are actually connected and we should not look at them each each one after the other but together and climate change is not the only issue but it's an important triggering triggering issue so we need to have systemic viewer we had experienced something similar in Germany where we had these devastating floods in Western Germany and reinland where more than 100 people died economic damages of more than 10 billion Euro triggered by a weather event by very strong downpours of rain but what less people know is that a very similar weather event happened a couple of months uh before in mbor Pomeranian easn Germany and almost nothing happened so we have the same weather but different impact why is that the Landscapes look very different we have lomy soils dense soils hilly terrain and in Western Germany in that area and very gentle terrain and Sandy soils in in Eastern Germany in that area and so they do something very different with with the same weather and Eastern Germany basically the sand could refill could be refilled with the water which was actually good for the groundwater while we had these devastating FL NS uh in in Western Germany so it's really important how ecosystems look like how how Landscapes look like and we need to model that we need to have a system view on climate impacts we need to integrate atmosphere biosphere and anthroposphere look at the interactions look also at the feedbacks and it's very difficult to model that from first principles how we can do it with weather so that's why data is very important that we exploit the data to understand those relationships that we cannot just describe with physical laws so fortunately we do have a lot of data for example from space from remote sensing here this beautiful image of lake Lake Geneva where we are very close to where you can see the edies the currents and also the complex landscape um around we can also look actually deeper with radar remote sensing where we can interrogate vegetation and get a kind of tomographic scan and get the 3D structure globally um of of vegetation and so get even a better Insight these remote sensing observations also provide temporal information for example here from the isas uh Sentinel 3 in 2018 from from green to Brown in one month basically showing how the vegetation response to such a drought and heat wave as we experienced in 2018 or longer time scales thanks so the legacy of uh of lanat we can basically observe what we humans are doing to vegetation here the deforestation of forest in in in Madagascar just as one one example but with this remote sensing observation we don't really see the breathing of the BIOS we don't see what ecosystems really do we only see how they look like but we don't see um what they do and ecosystems do a lot it's called ecosystem services or nature contributions to people many are mentioned here many of them are related to climate like related to carbon uptake related to cooling the environment others are related very importantly to water Purity and and to food to Timber production um and it's hard to estimate really the value but more and more studies do that and end up with values that under the range of 100 to2 200 trillion us do annual value that they generate which is more than the global GDP so we really need to understand what the ecosystems do how how can we do that our point is that we need to look closer we need to do it like in an intensive care station that you can see here where the pulse is measured the respiration the blood uh oxygen content where basically three parameters are continuously and 30 parameters every second day so we need to do that for the ecosystems and we have been doing that and continue to do that by putting a sensor on top of the ecosystems that measure the CO2 water and heat exchange between ecosystems and the atmosphere looking what the ecosystems are doing we're using the turbulent flow in the atmosphere to do that and we can generate every half hour over decades now estimates of what the e systems are doing here how much carbon dioxide are they actually taking up here ploted as a so-called fingerprint of the ecosystem x-axis as time of the day and then time of the year as you can see and we see for example a tropical rainforest taking up carbon during lunchtime every single day in the year while for example European beach Forest is dormant and winter doesn't do much and so on and so forth so we have this information for many many stations because it has been such a successful and um appealing method this network has been growing it still needs to grow for example in in Africa um and it still of course doesn't cover the whole globe we have maybe 1,000 Towers covering 1,000 kilomet square kilometers that is not one one million or 100 million square kilometers which the air surface is so we need to somehow go from from these observations what the ecosystems do to the global scale what they are doing and for that we need to build AI powered models we basically use the drivers the metrological conditions and try to build machine learning based models new networks for example that predict what the ecosystems are doing given the weather and other conditions and then we of course we need to compare that with the real observations to improve the model and that is basically exactly the machine learning approach and then we apply those drivers these statistical predictors apply that model globally with all the observations that we have have globally and we can come up with with a global picture of what the ecosystems are doing here we see dial uh activity with um how basically the sun moves through and the ecosystems can do photosynthesis and we do that can do that basically every day I should add one thing we should from a scientific point of view amend the AI method and the Machine learning method with still our scientific knowledge with causality with physical laws bring that together with hybrid in a hybrid modeling approach so that we get more consistent and robust predictions and can also predict unobserved variables if we do that all together we can get actually a mostly datadriven picture of breathing nature here the CO2 uptake and released by ecosystems it's an uptake if it's green and going in we call it also carbon sync and release when it's when it's uh more reddish so this is a First Data driven AI based estimate we can since the method measures not only carbon dioxide but also water we can get actually a very holistic picture of what's going on for example how the water is moving up and down North and South across the globe how much heat is injected from the ecosystem into the atmosphere causing for contributing to heat waves and we can link that also to the atmosphere and basically describe how the E how the CO2 concentrations in the atmosphere change and how it's influenced actually by by by the ecosystems and also how the groundwater resources change over time and if we put that all together also with other data then we can also understand where is the system getting weird where where it's getting um anomalous so we can detect extreme events we use these data cubes many many different variables that are in Space in Time organized and we asked basically where are the constellations of those variables strange and with AI methods then we can basically find these spots that are here indicated in this space and time on the right inside when the E when the ecosystem do something very very strange or when the overall Earth system is strange regionally very strange and in this case we detect for instance this kind of blob that you see here and this is just derived from the obervations that we have the Russian heat wve with all the consequences that I had mentioned before but the challenge is of course also to go deeper because this is kind of on on a quite on a large and Continental scale and we do have deep observations more precise observations with 10 m resolution where you can watch your own backyard for example here fire development on the left hand side or the drying of of a lake um on the on the on the right hand side but is actually currently happening so we ask basically are Landscapes predictable from AI from with AI from climate geographers would say yes should be possible climate human and Geo factors cause Landscapes but I'm not aware of any physical model that can actually predict that because it's just too complex so we thought let's adopt a method that has been developed in in machine learning that can where that has been used also in the fashion industry to create photo realistic images for example of handbags here and instead of having the input to Output mapping that is seen shown here we have an input to Output mapping where climate and other Geo factors are mapped onto Landscapes as they are seen from space um with for example from those satellites that I just that I just showed and it works actually very very well so you probably don't cannot say which of these images are are a generated and which of them are really observed I also forgot it but okay here it is the upper one is the predicted one the lower one The observed and the next challenge is basically not only to predict like static Landscapes based on average climate but to understand how Landscapes evolve over time given a drought giving another extreme event and this is work work in progress so this challenge to predict dynamically evolving Landscapes from from climate here an example from uh from from Greece you see here this part of the landscape where we have a North facing and south facing slope and here just an experiment what the AI method says with different climate input so on the bottom it's hotter and on the right hand it's wetter uh how that actually affects the development of the landscape over over growing season and you see it clearly the large scale climate effects but we see also fine scale effects like North facing slopes still stay green for for longer time or The Ridges you see the ridges on top um are red they are desiccating very quickly and so the vegetation Browns first so and this is very important for for local prediction of climate effects and for for early warning and I we really believe we need to adapt to climate change we need to mitigate but we also need to adapt and a I can help with adaptation by embracing the whole early warning chain from observation and weather forecast to Hazard and impact forecast but also for the warning for the communication itself and and for the for the decision- making so we have basically prediction task for AI and information or communication task and just few examples of course weather forecast is a very essential one and we have seen a lot of breakthroughs in the last years on that we need to predict what are the impacts for example here can we really say which areas are inundated so we know who's endangered who's vulnerable who is not and then we can even go for with generative Ai and generate images of property so that people can more intuitively understand if they are endangered by a certain climate extreme or not instead of having this abstract numbers 200 mm of rain or 8 MERS of of water or something this will probably lead to a better response to those um to those disasters so let me let me end with with this one we have a complex system we need to understand that the breathing biosphere plays a very important role uh in this whole earth system and AI will do the best job if it connects to the different Sciences so that we can have a better understanding what's going on on Earth I would like to acknowledge quickly the max Blan Society for funding the research also the Alis Network and the European research funding is also very very fundamental for what we are doing we are really grateful that we are living here and have such a good support for science in Europe uh and if you want more info there's a lot of information the max plank for Max plank research both in English and German and write an email or text me if you want thank you it was a fantastic overview and so many exciting applications of AI for the environment in a broader sense so really one question we wonder is how do we scale this up how do we make the community bigger and so it's really good to learn from the experts uh so this is a good time to introduce our next speaker CL Monon who is a uh research director at INR in Paris and a professor at the University of Colorado in Boulder and cla's probably thought about AI for climate science before most people actually knew what this might actually be uh and so she started 13 years ago a very very foundational conference International Conference on climate informatics that brought together a lot of the community working in the space and today Claire calls us for action and she will speak on catalyzing a community on AI for climate change over to you [Music] thanks so I'm going to tell a story and it's a story hopefully relevant for a lot of us here trying to bring AI to bear on topics for good about bringing AI to bear on addressing climate change I like to be inspired by this photo from Aspen Colorado I took a couple summers ago where we have nature wildlife and human infrastructure all sort of living in harmony it's a happy picture from Colorado a not so happy picture from Colorado um is the the results of this fire that we had a few years ago um and I was actually glad to follow Marcus's uh motivation of of how you can get this sort of event in our case the region is used to PL plentiful snow in fall and winter it got no snow so the vegetation was extremely dry finally on New Year's Eve Eve a snowstorm was going to come in it was preceded by extremely high winds so then all it took was a single ignition and we got basically a firestorm that jumped over our major highways in multiple places on burning embers and in a day completely leveled these Suburban neighborhoods around Boulder and Denver um we also heard a little bit before about other cascading hazards such as when you have drought followed by wildfire and this happened in Santa Barbara County right above a very R residential area by the coast that an intense rainfall happened on the burn scar producing a debris flow so a landslide this is very scary Boulders coming into your living room a horrible loss of life and damage your critical infrastructure So based on these extreme events that we can observe and just general global warming that has been established for 16 years I've been pushing the idea a that um AI can be used to shed light on and address climate change and working in this field called climate informatics which was recognized by the world economic Forum in 2018 when they also put a call to action and said that climate informatics was an important research priority as we see what benefits AI can have um for the Earth um so here's a bit of a timeline as I was was finishing graduate school I was really excited by the launch of bioinformatics which was revolutionizing biology along with some advances in genomic data using machine learning algorithms I was aware of some methods in the past and I wanted to form a community on climate informatics that would make the same kind of advances in addressing climate change so I started working with a climate scientist and also the national Science Foundation in the US was starting to fund research like this such as $10 million each investments in understanding climate change using Data Mining and in computational sustainability so we launched this event a workshop which eventually turned conference um 14 years ago but one year we had to skip due to covid um we also went to our top conferences in Ai and machine learning and so for example in narps in 2014 we really made a call to action to get people to work on climate change and we found that hackathons were a really good way to bring individual teams together so you have students early career folks anyone that is good at programming or has taken some machine learning or data science class together with a domain expert giving us an important data set for a challenge problem things really ramped up around uh 2019 uh so we took climate informatics International um climate change AI was also launched which which provides a nice Network to get people involved um and NSF started making a major funding so a $20 million AI Institute in trustworthy um weather climate and Coastal oceanography and we launched a journal because one of the other things about building a new field is having places where you can publish in a transdisciplinary forum instead of only publishing core a advances or core climate change um domain advances um now we're seeing much even larger investments from the NSF and also I've seen it from French governments there's other Investments on addressing climate change using a primarily AI driven or AI enabled approach we've also seen in the past couple years a revolution in AI driven weather forecasting um so this is a really exciting time to be in the field we launched the publication site in the very last days of 2020 and we've seen a doubling in submissions every year um in environmental data science so let me summarize what I think of as where AI has had an impact and can have an impact going forward um on climate change and environmental sustainability so those extreme events those cascading hazards we ideally needed you know AI informed prediction systems to help save lives and infrastructure and we needed Solutions yesterday now actually Google and Huawei and other tech companies that have shown the revolution in AI for weather are able to predict the tracks of hurricanes with um better forecast skill up to a week in advance versus conventional physics driven models can we take that benefit to things like wildfires now wildfires can spread in multiple directions simultaneously and also we have to consider interfacing with Society anytime we do this climate change adaptation work I worked for many years in the US where um there's a known Legacy of climate Injustice meaning certain communities have been subject to polluters incinerators and in the fire in the Wildfire example if there's a community that is more vulnerable to lung disease given a history of environmental Injustice then when we make these Warning Systems we should warn those communities certainly in in the track of the fire but also vulnerable communities that might be farther a field so what can we do in the near to medium term to mitigate climate change um in the US we showed that um we can use deep sequence learning to better predict at week ahead lead times when it's going to be sunny this can reduce costs reduce uncertainty for grid operators considering incorporating renewable sources we're also working with EDF in France um to try to Envision the new wind turbine and where it should should be placed and similarly for the new PV winds are changing that has been established the patterns have been changing and the wind turbines of today may not be future proof their operating uh statistics conditions need to be Revisited and they potentially need to be put in more optimal positions and then where I actually got into this because my first work was with the climate modeler was trying to improve the long-term future projections that we get out of the physics driven climate models that inform the ipcc for example where we showed that while there's a lot of disagreement in future um projections even for a single scenario across ipcc models we harnessed Ai and present day data to basically adaptively combine The Ensemble and robustify our predictions and then we're now use doing this for you know individual requests such as uh sea level rise around certain island nations and Etc um I just wanted to give you one Taste of a an idea of what would enable what has enabled progress on all three of these areas and that is this idea of downscaling so consider this plot um from a paper in science advances by another group where on the the xaxis is the spatial scale at which the SIM ulation is being run and the Y AIS is the temporal scale so ipcc is informed by General circulation models which are in the upper right hand side of the box now none of us expected that ipcc models were actually simulating individual snowflakes that we have at the bottom left but you might be surprised that these Mega storms and even clouds which are going to be the key to understanding climate change do not make it into those General models so take for example the adaptation task asked for by EDF tell us future wind patterns and intensities so we can redesign wind turbines and put them in places that will be more futureproof well we actually then need predictions of wind fields at the scale of an individual Wind Farm which is not what we're getting out of the global climate models so this idea of downscaling taking a geospatial data field at course resolution and generating one at fine resolution um is one where we have shown that probabilistic generative AI not trained on text like an llm but trained on wind and other meteorological Fields um Can can do so and it can also do so in a self-supervised way um what do I see as the long-term goal posts you know these cascading hazards you know we have skill at say I in the track of a hurricane but what about when these multiple extreme events combine and we know we have outside societal impacts also climate Justice any Tech intervention should of course Do no harm but I would like to aim a lot higher what can we do to build Tech that actually helps undo the legacy of climate Injustice trigger warning so in the US um a meteorologist Jack sillin put together this graph which simply in grayscale plots percentage of uh Black Americans living in the regions indicated and the radius of weather radar sensors so we don't have weather weather radar everywhere but we have it in those green circles blowing up what's in the legend he wrote many majority black parts of the southeast USA are relatively far from weather radar our sites meaning that it's hard to gather information or data about storms impacting these areas so there's a the real challenge even at the level of the data availability um that is highly skewed due to a legacy of climate Injustice first let's take a pause AI is not the Panacea we need to call on governments and we need to implement incentives and economic Le levers so this sort of thing is fixed and does not happen again okay but I would like to also call for using AI as a driver towards climate data Equity just like we showed that we can take um the future projections of climate and translate them to um to future projections at local scales that we care about for example in energy that's going from the data the the sparse data future or the no data future and augmenting it with AI trained at the present time we can also take the benefit of AI from high data regions to low data regions in a variety of ways just technically speaking in the previous example we could have had a remote sensing Pro product learn relationships between the remote sensing data and the radar data where we have it and then apply that trained AI model in some sense as a virtual sensor to create radar weather radar measurements where we don't have it alternatively you can consider learning High data uh models in the high data region and then applying them um and even fine-tuning them to do to have them better transfer to the low data regions my example was from the US but this is also true when we think about climate change where the guilty ones are generally um into indes in the global North but North America and Europe have really quite a lot of data um and so can we take models trained in low data regions and apply them um in high data regions and apply them in low data regions to um to address climate change thank you so as you seen there are a huge amount of opportunities to engage so in case you work in Ai and the Chance is probably quite high if you're here if you want to engage there's lots of communities like climate informatics like climate change Ai and many other institutions and institutes so just reach out to people just in case you don't want to do advertising or so as much you can do something for climate and for good so we're moving on uh to our next speaker uh next speaker is BJ Stevens uh from the max Blan Institute for meteorology uh where he's the director and he's also professor at the University of hurg b is really interested in what what CLA exactly highlighted as the unresolved parts and traditional climate models clouds and clouds are key uncertainty in our climate system and so this is something that B has been working on for a long time but more recently he's been really at the Forefront of pushing for a new generation of climate models that can explicitly simulate some of these Cloud features and therefore really allow us to quantify climate risk maybe at the scale that mats and the mats is the scale of the impacts and just in that theme B will be speaking today on Earth virtualization engines exposing New Frontiers and climate science through AI over to you [Music] B we um understand global warming most of us know why it's happening and roughly that it means that the Earth is a hole is getting warmer but we really have no idea what it means and in a practical sense what to do about it some of you might have seen this it was last week in um Southern Iowa it was a tornado that ripped through a wind energy installation it's pretty impressive you'll see after a little while I'll I'll go on one of the wind turbines interacting with the Nature's turbine and it gets ripped apart is this climate change who knows does it matter when we think about climate change tremendously if we're developing infrastructure like this do we want that to happen if we have back out and we look at infrastructure like on the bottom of Gena revealed how destructive these floods truly were do we want this to happen fire flood wind the assault of waves on affluent communities in Massachusetts fire seem to be burning across that's the face the violent face of climate change or not but if we want to be able to manage a prosperous planet in the future we have to be able to anticipate those sorts of things and what it means for our efforts to adapt and adjust and mitigate but there's also a slow Bur to climate change does any do people recognize what that is on the left is there anybody from the Caribbean here you know over the last years the Caribbeans really been assaulted by waves and waves of sarcasm in many small communities that depend on tour tourism you have the Sea of seagrass coming up and washing on the beaches it rots in a noxious poisonous stink it you know communities depend on the livelihood of their be es for their vitality and it's threatened by invasions of seaweed that we don't understand I don't know if you follow the uses last week when all the you know the howler monkeys were falling off the trees in the Yucatan they had temperatures above 50° um so it's not just humans that we care about but the natural environment so somebody was saving the baby monkey there not so far from here Brian in eastern Switzerland the permafrost receding permafrost in the mountains sets the Rocks loose and the rockfalls are endangering communities here this community was evacuated because the mountain behind it was crumbling and so all through the Alps we see this happening accelerated by the force of climate change we can think about Renewables but if we don't know where to deploy them um in in ways that make them most effective we're throwing money into the wind another aspect of climate change last summers in in central western Europe the waterways that fuel the Commerce of this continent um are fueled by rainfall and when the rain goes away the waterways go down and the ships don't travel and so how do we develop an infrastructure in Europe um in the presence of a changing climate land through the Dual problem of of more intensive water use and less replenishing through natural water flows um all across the world we're seeing places where the north yakarta the land is subsiding faster than the sea level is rising so if we're talking about the built infrastructure if we think about adapting to climate change we need to deal with problems that happen on this scale it turns out that technology is pretty useful for some of these problems you guys know this picture right you're not good at raising your hands but you know this picture it's the Blue Marble it was taken 51 and a half years ago December 7th 1972 um and it was taken by the last crude Mission going to the moon and they looked back and they took a picture of the Earth and people say this image did more to change humans consciousness of their self and their place in the world than any other picture ever made the power of a picture is pretty profound but when you think about that it's not just a picture that's the Pinnacle of a huge technological achievement you know of the of the of the mission to the Moon to commemorate this what we asked was if the same technology Revolution that's fueling AI if if you look at what it did to AI models that many of us knew in the 80s right all of us Everyone likes to say oh you know back in the 90s I was programming neural networks when I was in graduate school and I was and many of you were but they bear nothing in common with the neural networks that we use today with their millions and billions and tens of billions of parameters just that same technology can fuel transformation and climate models to make them look like nothing like the ones we've dealt with before and here's an example this is the same Earth with the very sparse data that's in it ingested in a modern climate model simulating the Earth at 1 kilometer globally and it allows us to look not just what the NASA astronauts saw but how it moved we can turn the Earth around and look around the corner where they couldn't see here at the mon soon over South America we can zoom in and look at aspects that were hidden in a picture for instance this is the sea surface height and you see the through flow across um the southern African um part of the continent you can see the salinity with the freshening near the the the the the Bay of guine the the the temperature of the waters in Reds and blues the cloud superimposed the very large scale structure of small scale fronts how they interact with the cloud Fields this is the power of Technology it's the power of physics there's no AI anywhere here but it shows you how we can harness the power of computing and our understanding of physics to give us a wholly new view of at least parts of the world but there's lots of the world that don't fit in that picture you heard Marcus rin's talk there's there's things we can't simulate the things we don't know the laws for but here we can observe them this is two days ago 5 4 3 [Music] 2 St first stage by the stage separation the first [Music] Earth care separation confirmed an amazing view there on your screen successful deployment of the earth care payload and with that confirmation we'll be bring this is Earth car it was launched by the European Space Agency two days ago it's the most complex set of instrumentation we've ever put in space but it's not alone there's 80 other satellites measuring anything you can imagine so we have this we have this enormous problem we don't know what climate change means with the the at the level of local detail that we need to act on it we have this tremendous capacity to simulate with local granularity globally and the things that we can't simulate we can observe so what's the problem the problem is we just have no way to put this all together ask yourself climate change is the biggest problem that the Earth seems to be facing and name one single institution whose task primarily is to deal with climate change we don't have one we have NASA for space we have jaxa for space we have Isa for space we have Noah for the environment we don't have a world climate organization which brings these things together in a way that allows people to use them and we have an enormous opportunity because if you look at it we can compute from physical laws this thing called the the physical world we can observe the things we can't compute and we can inform ourselves about the impacts but the intersection of those three circles is where climate science is right now a very very very small place which involves the intersection of modeling observations and impacts what AI can do is expand all of those spheres so we can use the fullness of the observations the fullness of the laws and the fullness of the information to aform societies going forward and this is the the power of AI before without AI we had to look at where those these intersected so you might know ipcc you might know CIP it lives in that little tiny space where those three circles come together the task we have before us is to expand that space and the tool that we have to do that is AI um we take the laws we can move forward if we know through inference how the laws relate to the things that we can't model we can we we can see how that could look like in the future and we can see how the impacts change in the future so we have this capability not just for one future but also for many futures um to put this all together and this is something that we call Eve so the idea with Eve Earth virtualization engines is how do we tap this enormous capacity to observe this new capacity to simulate and this incredible need to inform people about it what it means and the way we do it is we put AI in the middle it's the it's the facilitator that animates the physics and the facts for people many of us came together last summer in Berlin 200 leading climate scientists some ecologists computational experts um uh climate service providers to ask how we would do this and the proposal at the time was that we need an International Federation a global Federation of AI um learning resources to do four things we need to create these Futures with physical laws and high performance Computing so recreate and refresh the best possible counterfactual landscape of law-based Futures that was that blue circle we need to provide high bandwidth access to the data there's about an exobyte of Earth observation data that's scattered around the earth how do we put that at the fingertips of of of of machines that want to learn from it from it and how do we allow users from around the world if this is a public resource a public space in the Digital Universe how do we allow users to bring their own data if you're looking at sarasam in Barbados where I do some of my work how do you bring your information about sarasa and Barbados to a place like this to learn also from your information and then how can we embed that in better decision-making it's not Eve it's not a it's not a research project it's about global industrial policy for making our our our planet um sustainable for the future it's drawn the attention of Industry um you see many Industries willing to line up but what's lacking is initiative to create this in the public sphere as a public private partnership where the world world can meet to solve the problems of climate change and here are the seven powers of of AI that I think are vital for this effort I list them up here if if we want this to work we need AI to manage data compression so we make a exobyte or exobytes of of data manageable we need AI for data Centric programming so we understand how we can map the computer models that we use onto modern machines to make them run most efficiently we need to how to understand how to make the component of those simulations run faster AI is doing all of these things and the names are listed up there along with many others how to do automodel inference we don't have sargassum in our model but if we understand how sargassum relates to the the the the things we do have in our model we can we can build that in in the hybrid modeling that Marcus reichstein was talking about how can we look at many more scenarios how can we look at ensembles of natural variability these are all tasks that AI could be very good at but most importantly how can we use AI to enhance the user experience to make that information something tangible that they can touch that they can feel that they can interact with these are the superpowers of AI and funny enough if you want to remember something about this conference I kind of think where AI can really help is actually doing what I call the stupid things faster with more energy this is this is a sign from our coffee room and it says drink coffee do stupid things faster with more energy and all of these things that I list they're not rocket science they're things we know that AI is good at but what we lack is an Institutional setting where we can do these things together to generate the sort of information that we all can use and trust and so what we need with AI is we need to do let's say what we know how to do we need to do those necessary things faster and we need to do them if not with more energy but with more emphasis so I would say this is how to do AI for good is to embed it in an infrastructure in an international effort that brings together the best Minds in AI the best Minds in climate modeling the best Minds in observational science and AI for good is AI for Eve and with that I'd encourage you all to um look at the efor climate.org website and and and see how you can play a part in this really exciting initiative thank [Applause] you that was a truly fascinating overview thank you very much ban um and you raised an important question how we might know the path that we have to take but how do we do it and how do it in institutionally we've heard this morning about the cost of training large language models and these only deal with language and they available text not an exabyte of Earth observations so the cost is prohibitive for many activities and how do we do this in a way that includes everyone in particular also the global South that at the moment has no access to some of this so we might need institutions to actually achieve some of this so the last part of this session we we switch a bit gears but to something also equally important and that's again biodiversity so the last speaker is AAR Raskin and it's a talk about understanding biodiversity in a slightly more fundamental way so AA is a co-founder of the earth species project it's an international nonprofit dedicated to use AI to decode animal communication he's also the co-funder of the center for Humane technology working to Align Technology with human Humanity's best interest but to today I I will be speaking on understanding biodiversity AI to decode non-human communication and over to [Music] you wow hi everyone um we heard yesterday that Nick Thompson's son thought that there wasn't enough NE animals in AI so really this is just uh fulfilling that request um so I'm here to talk about Earth species uh you saw my co-founder Triston Harris yesterday speak and this will be a different kind of talk but at the core I just want to start with this thought like what is the common thread between all of the major problems that we as Humanity face whether it's climate change or opioid epidemic or loneliness epidemic or runaway inequality the connecting thread is that they all stem from a narrow optimization of a narrow goal at the expense of the whole right which is to say a form of disconnection and I will return to that as the sort of the why what we're trying to do but Earth species is a NGO uh International we um work with uh 40 plus uh universities biologists um and our goal is to discover non-human language and decode it um and so we'll we'll we'll start with this um who can guess what animal makes this sound any guesses whale's a good guess but wrong other guess see not polar Bale I like that seals yes that's exactly right well done this is the bearded seal um by the way that was their mating call so if you got excited now you know where to go um and it turns out the reason why I want to start this way is that when we think about animal communication we only think of a very small slice of how animals actually communicate um there is a lot that's already known so for example it turns out parrots parrot parents spend the first week and a half or so of their chick's life leaned over Whispering into their ear until they can repeat back a unique name that those parrots will use for the rest of their life um it turns out dolphins do the same thing um and then we'll even refer to each other in the third person that is they will talk about another dolphin by name that is not here so one of the major Hallmarks of language a lot is already known and although I'm mostly here to talk about animal communication I also want to talk just a little bit about plants um so do you think plants can hear like well sort of by the nature of me asking this question here the answer has to be yes um but the University of Tel Aviv in 2019 did this very interesting study where they played audio to Primrose flowers and they played like high pitch noises like bats low pitch noises like traffic but only when they played the sound of an approaching bee approaching polidor did the flowers respond and they responded by producing more and sweeter nectar in around 3 seconds so quite literally the flowers hear the bees coming and get excited our ability to understand is limited by our AB ability to perceive and what AI does is that it throws open the aperture of that which we can perceive which means of course that we are about to understand a huge amount more and to give a sense of this um this is uh this is my favorite humble graph it's humble because it only includes all of time and all of space uh but you can see The Human Experience is this tiny little portion which means we are about to be able to start expanding what we can perceive and the history of science teaches us that that means we're about to realize how much smaller we really are than we know another way of saying it is that the world is way more magic than we think okay but I'm here to talk about animal language is there even really a there there yes maybe names but do they have some kind of representational language um well we don't know yet but here's a very intriguing study from University of Hawaii 1994 and here they taught Dolphins two gestures the first gesture was do something you have never done before if you think about that that's already a very complex thing able to communicate the idea of innovate but the Dolphins can do it they'll remember everything they've done before understand the concept of negation not one of those things and then be able to invent whole cloth some new thing pretty cool then they teach the Dolphins a second gesture do something together and they'll say to Dolphin pairs do something you've never done before together and the Dolphins go down exchange Sonic information and come up and they do the very same thing at the same time that they have never done before and while that doesn't prove representational language I sort of think it puts the burden of proof on the other foot it's like how else would they be doing this okay I come find me at some point in the conference and I can just tell you an infinite more of these kinds of things um it's uh it's a lot of fun but the next question then becomes all right but let's assume for a second that yes maybe there really is language something rich and symbolic but how would you translate something without a rosetone yeah maybe I can see how you might do simple things that where there's a behavior but a lot of what humans communicate about is abstract how would you possibly figure that out well the reason why we started Earth species in 2017 is that that was the year that AI gained the ability to translate between any two human languages without the need for any examples or any Rosetta Stones it sort of slipped by but it was a profound moment um and to understand how that works I actually want to AR arm all of you with a little bit of how to think about Ai and why every demo you see ends up being sort of the same demo but it's it's not obvious the thing to know about AI is that it turns relationships into distance and Direction turns semantic relationships into geometry so that's a little abstract now let me give a more specific example this is uh English this is the top 10,000 most spoken words um if you're technical you know that this is an embedding and what's cool about this kind of shape which represents a language is that every Star here is a word words that mean similar things are near each other and then words that share a relationship share a distance and Direction so you know King is to man as woman is to queen so King is the same distance and direction in the shape as woman is to queen which means it's the same distance direction as boy equals is to Prince or girl into is to princess and if you think about it let's take a look at the point which is Dog the word which is dog well it has a set of relationships you know friend to Guardian to how to Yelp to fur and if you think about all the different relationships it fixes that star on a point in space and then if you think about solving the massive multi-dimensional Sudoku puzzle of every concept to every other concept out pops a rigid structure that represents a language now the computer doesn't know what anything means but it knows how they relate so this is the shape that represents the internal relationships of a language and here was the Insight in 2017 researchers said well if we build the shape for English and we build the shape for Spanish they can't possibly be similar shapes right and anthropologists said of course not they have different cosmologies different ways of viewing the world langu said they have different declensions and yet the machine learn's like whatever let's try um and it turns out it works you can take the shape for English and the shape for Spanish and you rotate one shape on top of each other and even though there are words in one that don't exist in the other the overall shapes are roughly the same and the point which is dog ends up in the same spot in both and then you could say well okay but English and Spanish are super related but it works for Japanese and erdu and Finnish which is apparently a weird language although I'm not sure if I'm allowed to say that here um every human language seems to fit in a kind of universal human meaning shape I still get Shivers when I think about that because in a time of such deep division there is a hidden structure that unites us all okay so obviously the question is well can we build the shape for Animals the shape for humans overlap them see what gets translated but I think a very reasonable response to that would be like yeah but the reason why as profound it is that all human uh languages fit in the same shape is because we have the same Hardware we have the same umelt we have the same senses so maybe that's why it fits you shouldn't expected to work at all with animals and I just want to sort of like reveal just a little bit deeper um some of the way that AI Works which is you guys have seen Dolly right and like all of the image generation bid Journey things how do those things work I sort of want to like answer that for you now because this goes deeper than just aligning shapes to translate between languages this can work across every modality so you can also build a shape that represents human faces um where every Star is now a face and faces that share a relationship share a distance and Direction same thing so here we have a dude and uh a version of his face which is smiling so in the shape there's a distance and Direction between those two if you subtract you get the distance and direction that represents smiling this you add that to say this face and you get the smiling version of this face this is how all of these image generation things work is that they've discovered the internal relationships of uh faces or images and then you can move semantically around them okay so then how does Dolly work well works like this you say generate me the shape for language generate me the shape for images we've got that now look at image caption pairs from the internet and that aligns the shapes it's no longer just a hard rotation it's now a linear transform but roughly speaking it's just like a a relationship and then you say okay portrait of Chile as a person is this spot in language space translated over over to image space and show me what image goes there that's how it works so there's actually something even deeper going on here because deep learning is starting to show us the analogic relationship of the world and then lets us map them together this was my face when I first like realized how this all worked um and you end up with this Maxim that actually everything that can be translated will be translated and in fact when you see demos of like you type in text and you get out code or you type in text and you get out DNA or translation from brain imagery into images brain scans into images it's all the same thing behind the scenes it's actually sort of all one demo um and it explains this sort of deep question which is why is it that the very best brain reading technology is essentially mid journey and it's now you start to understand why that is okay so I think that means we will be able to get translations because it's deeper than just human language to human language um but why should we expect there to be any kind of overlap um between humans and animals well I just want to give two examples um of shared experience these are dolphins looking into a mirror um and there's a there's definitely a universal experience of looking to mirrors and checking out your abs uh but there's a thing thing called the mirror test where you paint a DOT on an animal they look into the mirror they weren't aware of the dot before they see the dot in the mirror and they start looking at it trying to get it off what does that show that shows that thing in the mirror that image is me Consciousness self-awareness exactly and it turns out a number of animals pass this um elephants for instance although scientists thought for the longest time that elephants didn't pass but it turned out that that was because they were using a small mirror um how very human right so if animals are communicating they may well be communicating about a rich interiority self-awareness the most profound thing that we have here's another example these are lemurs um biting on centipedes to get High um they bite on them they enter these trans-like states they get very cuddly um it's almost like a a Proto birning man I'm I'm sure uh and it turns out a lot of species will intentionally alter their states of Consciousness Dolphins will intentionally inflate puffer fish and pass them around in a circle to get high off of their venom in probably the original puff puff pass um chimps will spin uh to get dizzy um if animals are communicating they may well be communicating about Transcendent states of being again one of the most profound things that we have but of course there's a huge amount that may not be shared between us and animals sperm Wells spend 80% of their life a kilometer deep in complete darkness and see via sound that's very different and so we'd expect some part of the shape to overlap and some part of the shape not to overlap and I still don't know which part is going to be more fascinating the thing that we can do direct translation for or the thing that we can see richness and complexity in but do not know what it means and when I think about like what it is that is the solution to Humanity's problems I'd argue it's not in our imagination because if it was in our imagination we'd be doing it so the thing we're looking for is things that are outside the sphere of human imagination whales and dolphins have cultures you can trace them back languages that they pass down that break apart to go dialects to mutually unintelligible languages that Trace back 34 million years can you imagine the wisdom encoded in a wisdom tradition that is 34 million year old years old let's get to some of the the challenges of this another guessing game what animal makes this sound any guesses yeah this is a harder one these are belugas and surprisingly all of that digital sounding stuff that's what they sound like that's not added later it appears that they speak in more modem like packets um Dr valer vagaro Who did the original research um showed that they say both their name and include their Clan identity in their hell um what I find amazing about this is even though well this is by the way what um belugas look like in the wild you can see why this is such a challenging data problem is that even though scientists have uh tags on on these whales that record audio and video they can't tell who is speaking or they're all overlapping it was three in the last uh example which means they have to throw away 97% of their data and this is where you should pause because this means for the most vocal underwater species with the greatest vocabulary Western Sciences only ever touched 3% of their communication right this is kind of next Frontiers and actually our very first uh paper and piece of work was listening to multiple animals speaking at the same time and separating them out into their own individual tracks we can do it for humans ai's been able to do it for humans for a couple of years now we're just starting to be able to do it um for animals in non-lab likee settings and I should just name there's one other way that we think about going around translation and this is our partner Dr Ari friedlander down in Antarctica putting seually suction cup tags on whales think of them as whbl um that includes their uh audio visual um and motion and the way that we're thinking about using this and we were part of um we helped lead a uh a a thing a words collaboration uh on using multimodal sensor data and the ability to translate to and from all those different kinds of uh modalities in science uh late last year and the idea here is that you can say Okay given say this motion of an animal complete this sound so whale strikes are one of the leading causes of whale death what happens if you just say okay what does one whale say to cause another whale to dive now that might mean there's food down there or there's danger up here but you can see as you start building models where you can sort of pass a Turing test for an animal you can say okay well what sound does one wh make that cause of another whale to dive and start engaging in a feeding Behavior versus dive and then leave the area and even though we obviously should be listening for whales and moving out of their way in the cases that can't happen imagine how useful it would be to be able to ask gently for them to to get out of the way so that's the kind of thing like application that you can get to but I think it's deeper than that because this is another way of getting from vocalizations to behavior Behavior to vocalizations and there's really just one more thing to to speak about then which is we've talked mostly about listening and the goal for Earth species project really is to listen not to speak because we do not change when we speak we change when we listen but we also need to be able to test whether our hypotheses are right so this is um from one of our partners Dr uh Michelle for in uh her documentary fathom and sort of talks about like where we are towards communication the oldest cultures are not [Music] human they're from the ocean 40 million years ago before we walked upright before we sparked fire whales evolved to build relationships in the dark I'm trying to start a conversation is the most basic way you can say it I'm trying to put a speaker in the ocean and talk to a whale and hope it talks back starting playback if this work is successful it will be the first experiment where we have engaged in a dialogue with the humpback whale the punch line is is that it worked um and she's doing the very simplest thing instead of like the hello world this is the hello whale experiment um and she's saying hello to humpback whale with a pre-recorded message and they respond back so sort of like speak and spell level technology do you guys want to know how to say hello in humpback whale yeah okay I use my hand you don't have to I just think it helps limber me up um it sounds a little bit like you going to do it yes possibly my favorite moment um it turns out they can also include their name in that hello but I haven't figured out how to do that yet um and what she discovered is that she says hello they say hello back and actually a couple years ago um my team went up with some scientists that were recreating her experiment but they're doing something a little different they were recording one day and then playing back the next day and it was a day I took this picture uh the morning of the experiment super Vivid Sun but also foggy so everything was Vivid white birds are flying from nowhere going to Nowhere you could hear the humpback breathing but you couldn't see them because of the fog and humpback sound a little bit like Darth Vader doing yoga and when they breathe they're like it's very meditative um the experiment starts and almost instantly a humpback lunges at the boat from around 30 m away H mouth half open we'd never seen Behavior like that before and for the next 10 minutes it was moving from one side looking investigating lunging experiment stops and it and it beelines away and we went down and asked the scientist what happened and after we identified the whale it turned out that the scientist had played the hump back's own hello back to itself so this is a kind of mirror test the speaker as you saw sort of small whales are big so in the recording you can hear the whales name was Twain you can hear our speaker go I'm Twain and then the humpback respond I'm Twain and then we just went back and forth like that um so communication is possible but I think this gets to a really important point which is that I'm actually not sure whether that experiment should have been done in the wild because we don't fully know yet what we are saying one of the deep um plot twists that I was not expecting is that because of the nature of large language models and AI we will be able to communicate fluently before we fully understand what we're saying and humpback whales their song can go viral so for whatever reason humpback whales off the coast of Australia are K-Pop singers um and there's a channel called the sofar Channel in the ocean which acts sort of like a fiber optic cable and hump and sperm well are known to go down to this Channel and have communication that goes up to like 5,000 km back and forth um so to the original whale Wide Web sorry um so because that their song goes viral and is sung by much of the world population sometimes within a season or two and we don't know why if we are not careful we may create and we just go out there with the synthetic whale that sings We may create some kind of you know whale cult we just don't know and it's really important to show up to this new responsibility before it actually the techn technology is actually there right because this will be used by uh ecotourism it will be used by poachers and we need to put in the safeguards beforehand which means a kind of you know prime directive Geneva Convention for cross species communication the whole point of Earth species is we need to transform our relationship with the rest of Nature and this showing up to that responsibility is absolutely a part of it and I should say like so I used to run design for Firefox um in Firefox 1 through 4 days so like I very much believe in open source and we started Earth species with the idea that everything was going to be open source this is about broadscale accelerating science and conservation but the realization is that has costs so we're no longer taking the largest models and releasing them open because we are aware of the harms that this might cause if you just proliferate it and so it takes a more nuanced approach for how and when it's let out um it should say we are starting our first experiments we did uh two months ago to do full two-way realtime communication we're starting with a little song bird called a zebra fining that does vocal and social learning so you can sort of hear the first half of this is um a real song bird the zebra finch second half is generated so really we are on the cusp in the next 6 years we will have the technical capacity to have full two-way realtime communication with the other species of Earth okay we're in the very final home stretch here you know there's this moment um I think it was 1995 December 18th where Hubble Telescope was pointed at an empty patch and sky and what was discovered was not nothing what was discovered was everything the greatest number of galaxies that we had ever seen in one spot and this is the general principle of new scientific tools you point it or Humanity pointed at a place where we thought there was nothing and what we discover is everything you know I think when we wake up to the idea that other beings on this planet have sentients are conscious it changes the basis of law who has personhood changes the basis of religion who has souls it changes the you know alternative meat uh industry it it changes a lot in fact we don't know everything that it changes but when we think about it it's to return to that idea of disconnection as the fundamental problem in most indigenous myths humans start out speaking with nature speaking with animals and that point of disconnection is represented by our inability to communicate with nature how powerful will it be to change the fundamental myths that we tell ourselves where we reconnect and realize actually the world is way more magic than we think and maybe the highest form of what AI can do for us is just like with the telescope we learned as we pointed out at the universe that Earth was not the center that this time we'll Point our new tools out at the universe and what we'll discover is that humanity is not the center and it's that Breakin human ego that I think we need so thank you thank you very much to Azar Rasin I am looking forward to saying to you when I come off the stage all right well all of our speakers were brilliant weren't they this afternoon and there's more to come I should also thank phillipia as well a professor of atmospheric physics who also knows how to create a great atmosphere for discussion thank you very much all right it's time for the break now so as you pack up and enjoy your coffee break I can just briefly tell you that uh the open and I'll start again I can briefly tell you the social media competition remains open simply scan this and share your views on LinkedIn and if you do add the hashtags AI forg good or itu AI Summit you will be in with a chance to win a wonderful $1,300 smartphone from Samsung and if you want to uh win another way then you can also buy Sip and win with this collapsible Cup this reminds me of the days when I used to work on QVC The Shopping Channel as a technology expert like yes here we are for the very low low price of not entirely sure you too can have your very own Great Value cup which you can then put in your pocket when you're not at an amazing International AI Summit okay and stand out from the crowd with this incredibly stylish t-shirt as well I believe it comes in three sizes I've suggested that uh maybe next year we can get some Childs siiz ones cuz that would be really cute having these tiny little AI children running around but yes you can do that and if you still need help you don't need to ask me you can just come and say hello though and uh we've got some wonderful volunteers who are absolutely excited at the concept of helping everyone there in the yellow t-shirts all right I think that's it we're going to start hopefully on the dot for Jeffrey Hinton at 4:15 thank you very much see you soon [Music] [Music] is [Music] [Music] [Music] [Music] [Music] [Music] [Music] [Music] [Music] [Music] [Music] [Music] [Music] [Music] he [Music] [Music] [Music] [Music] [Music] [Music] [Applause] [Music] [Music] [Music] [Music] [Music] [Music] [Music] [Applause] [Music] I e [Music] n [Music] [Music] [Music] [Music] [Music] [Music] oh [Music] [Music] [Music] [Music] a [Music] [Music] [Music] [Music] [Music] the [Music] together [Music] in [Music] your together [Music] [Applause] [Music] together [Music] [Applause] [Music] the [Music] what did you tell me will it rain today tell me recipe you got me can you cook me me tell you I'm do you understand there I you [Music] hold play find out together and stay stay stay in a place where we We Care go it's how it should be let's play think together and stay stay stay in a world that we love we care one we share it's how it should be [Music] what is it you tell me will it rain Tope you [Music] got do there when I need you can you hold my let's play find out together stay stay stay in a place where we love we care the way that we should it's how should be eally let's playing together and stay stay stay in world we wonder sh be e [Music] [Music] hey I for good [Music] good for me good for the good for each other [Music] [Music] hey I for [Music] good me [Music] hey I for good [Music] [Music] good for me good for the planet good for each other most sustainable un might all [Music] [Music] good [Music] for Mach help us help each other help us be better there for one another [Music] back everybody I've just had a couple of sips of possibly the strongest coffee on the planet so I am now hyperthreading like the sort of graphics card that you wish that you had in your machine welcome back everybody um I may have got hold of one of these AI t-shirts this is the medium size if anybody is interested in in purchasing one and uh I also would love to just direct you briefly to neuro create it's your opportunity to scan this QR code and you can be part of the giant kind of art version of the word cloud if that makes any sense for the AI for good Global Summit 2024 um there's not that much left to this uh Summit so I'm really glad to tell you that we've got some incredible things lined up and then we have the Afterparty over at the frontier stage which you're all invited to and this this afternoon we are incredibly lucky to have a very special guest joining us remotely and once again I'm very lucky to invite the one and only CEO of the Atlantic up onto the stage so it's Nicholas Thompson is coming onto the stage an advisor for Learning and machine and brains Jeffrey Hinton will be on the screen amazing take it away thank you so much thank you delighted to be back here again and I'm delighted to get to share the stage with Je Hinton who is one of the smartest most wonderful most capable and kindest people in this entire field how are you Jeffrey Hinton I'm fine thank you for the over the top introduction all right well Jeff I want to start with a little conversation that you and I had almost exactly a year ago and we were in Toronto and we were about to go on a stage and two of my children were with me they were then uh 14 and 12 and you looked at the older one and you said are you going to go into media like your father and he responded no and you said good and then I said well if he's not going to go into media what should he do and you said he should be a plumber and so that son has just applied for the school paper and I'm curious if you think he's making a grievous mistake and I should actually send them downstairs to fix the Ducks no I was being somewhat humorous but I do think that plumbing is going to last longer than most professions I think currently um we're AI the thing it's worst at is physical manipulation it's getting better quickly but that's where it's worst compared with people all right wonderful all right so what I want to do with this interview I want to start a little bit with Dr hinton's background ground this then I want to go into a section where I ask him some of the most interesting technical questions some of the ones we talked about on stage we'll talk a little AI for good then a little AI for bad and then we'll talk a little bit about regulatory Frameworks sound good Jeff okay great all right so I first want to start 40 years ago where you are a lonely scientist and you have what turns out to be one of the most important insights of this field maybe of the L latter 20th century where you realize that to make an extremely powerful computer you should pursue that by modeling it on the architecture of the human brain and it sounds somewhat obvious now but it wasn't then so tell me about that moment of insight that really gets this field going um this is a nice myth but there were a bunch of different people thought that in particular in the 1950s both for nyman and shuring thought that it was very unfortunate that they both died young otherwise the history of our field might have been very different but it seemed to me just obvious that if you want to understand intelligence you need to understand the most intelligent thing we know about and that's us and our intelligence doesn't come from people programming in a lot of propositions and then it's using logic to reason with those propositions it's it emerges from a brain that was designed mainly for vision and motor control and things like that and it's clearly that the connection strengths in that brain change as you learn and we just have to figure out how that happens all right so that makes good sense you're grounded in history so now let's go very quickly you work on this people say you're heading down the wrong path you pursue it other people join you eventually it becomes clear you're on a good path it's not clear where it will go you win a turing prize you join Google you sell a company to Google you then about a year and a half ago you leave Google tell me about the moment when you leave which is a few months after the release of chat GPT tell me what the last thing you worked on was and that moment of departure first let me get something straight I left for several reasons one being that I was 75 and I decided I should retire then anyway I didn't just great for 75 yes thank you I didn't just leave in order to talk about the dangers of AI but that was another reason and I became acutely aware of the dangers of AI the existential threat at the beginning of 2023 in around March 2023 and I started talking to other people who were scared about the existential threat like Roger gross for example and they encouraged me to go public and then I made a decision to leave Google so that I could speak freely um the reason I became scared was I was working on trying to figure out how analog computers could do these large language models for 30 Watts instead of megawatts um and while doing that I became convinced that there's something about digital computation that just makes it much better than what the brain does up until that point I'd spent 50 years thinking that if we could only make it more like the brain it will be better and I finally realized at the beginning of 2023 that it has something the brain can never have because it's digital you can make many copies of the same model uh that work in exactly the same way and each copy can look at a different part of the data set and get a gradient and they can combine those gradients and that allows them to learn much much more that's why gp4 can know so much more than a person it was multiple different copies running on multiple different Hardware that looked at all of the internet um that's something we can never have so basically what they've got and we haven't got is they can share very efficiently we we can share very inefficiently that's what's going on now I produce sentences you try and figure out how to change the synapses in your brain so you might have said that that's a very slow and inefficient way of sharing digital intelligences if they're different copies of the same model can share with a bandwidth of trillions of bits and so you have this moment this realization that suddenly these systems can be massively more powerful than you thought it must have been a moment both of great excitement why was the great fear so prevalent too well um it made me think they're going to become more intelligent than us sooner than I thought and it made me think they're just a better form of intelligence okay let me ask you about two of the other Godfathers of AI so you won the Turing prize with three people Yan laon who now runs uh AI at meta yosua benil I was trying to figure out the differences between you and let me know if this works you're all Godfathers Yan kind of thinks of AI as Fredo corleon not very capable easy to control yua maybe thinks of it as Sunny you know potentially quite dangerous and you view it as Michael Michael Corone potentially extremely dangerous is that more or less correct I don't think so I think Yoshua and I have very similar views about the dangers but your difference with Yan is essentially you view this as a much more powerful system than he does and that's why you are more concerned than he is that's one difference yeah that's that's a main difference so I think it really is intelligent already and Yan thinks a cat's more intelligent right well let's let's get into that intelligence which I think is one of the most interesting questions do you think that there is anything in the human mind that cannot be replicated by these machines and by AI systems is there anything that our brains can do that can't be replicated in a machine no and does that mean that there's nothing that we can do that cannot be surpassed by these intelligent machines can for example one could say that they will eventually be able to produce more beautiful music they will be able to do all the things that we do better than us that involve simple cognition that's what I believe yes and you don't believe there's anything spiritual or outside side or anything that is beyond what can be captured in a set of neural networks I think what we mean by spiritual could be captured by these alien intelligences I agree with Sam Alman that it's an alien intelligence it's not quite like us it has some differences from us but if you look at um things like religion I don't see why you shouldn't get religious ones yeah yesterday when I asked Alman this question he said that well there might be one difference which is subjective experience a bot a system can't experience the world do you believe that AI systems can have subjective experience um yes I do I think they already do all right let's go into that a little bit more explain that that is a controversial proposition Jeff you can't get away with a one- sentence answer please follow up Dr Hinton okay I was trying to give nice sharp answer an to your question it's lovely I I have in the way that Altman didn't but um yeah we need to follow up on that one I so my view is that um almost everybody has a completely wrong model of what the mind is um this is a difficult thing to sell I'm now in a position where I have this belief that's kind of out of sync with what most people firmly believe um I'm always very happy in that position um so most people have a view of the Mind as a kind of internal theat in fact people are sort of sort of so convinced this view is right that they don't even think it's a view they don't even think it's a model they have they think it's just obvious in much the same way as people thought it was just obvious that the Sun goes around the earth I mean you just look at it and it goes around the earth eventually people realized that the sun doesn't go around the earth the Earth rotates on its axis um that was a little technical error Sam made and since I'm pedantic I like to pick him up on it it's not that the they thought this the initially they thought the Sun goes around the earth and then they realize the earth goes around the Sun that's not the right contrast they thought the sun went around the earth and then they realized the Earth rotates on its axis the earth going around the Sun is to do with years not with days but anyway it was obvious the sun went around the Earth and we were wrong we had a model it was a straightforward model it was obviously right you could just see it happening and we were wrong about that model and I think the same is true of what most people think about the Mind most people think about an inner theater and they're just wrong about that they haven't understood how the language of mental States works but explain how that applies to an AI system explain the way if a okay if I say if I say to gp4 I say you've just experienced a loud sound and something has collided with you it isn't feeling pain or hurt and its ear Stone ache to what to what sense has it had a subjective experience okay so let's take a nice simple example um I don't pretend to have the full answer to what Consciousness is although I I think I've made a little bit of progress um in fact the progress was made by philosophers in the last Century um so if I say to you I see little pink elephants floating in front of me one way of thinking about that is there's an inner theater and in my inner theater there are a little pink elephants and I can sort of directly see those little pink elephants and if you ask what they're made of they're made of stuff called qualia maybe some pink qualia and some elephant qualia and some right way up qualia and some moving qualia all somehow can join together that's one theory of what's going on it's an inner theater with funny spooky stuff in it a completely different theory is I'm trying to tell you what my perceptual system is telling me and my perceptual is telling me my perceptual system is telling me there's a little pink elephants out there floating in the air and I know that's wrong so the way I tell you what my perceptual system is telling me is by saying what would have to be the case for my perceptual system to be working correctly so really we can get when I say I have the subjective experience of little pink elephants floating in front of me I can say exactly the same thing without using the word subjective experience I can say what my per perceptual system is telling me would be correct if the world contained little pink elephants floating in front of me in other words what's funny about these little pink elephants is not that they in an inner theat made of funny stuff called qualia they're hypothetical states of the world and it's just a sort of indirect reference trick I can't directly describe what my perceptual system is telling me but I can say what would have to be in the world for it to be correct so a m so so a machine can more or less do the same thing with its perception yes and so let me give you an example of that so I want to give you an example of a chatbot that's obviously having a subjective experience suppose I have a multimodal chatbot and it's got a camera and a robot arm and I train it up and it can talk and it can see things and I put an object in front of it and say point at the object It'll point at the object now I put a prism in front of its lens and without it knowing and now I put an object in front of it and say point at the object and it points off to one side and I say no that's not where the object is the object is straight in front of you but I put a prism in front of your lens and the chat bot says oh I see the prison bent the light rays so the object's actually straight in front of me but I had the subjective experience that it was off to one side and if the chatbot said that I think it would be using the phrase subjective experience in exactly the way we use it it's not referring to Spooky inner stuff that chatbots couldn't have it's referring to a hypothetical state of the world such that the perception of the chatot would have been correct wow all right this is the you are the first person to have argued to me about this but that is a fascinating fascinating case to make let's talk about interpretability which was something I asked Alman about because to him understanding the inner core of an AI system would be the thing that would most protect us from catastrophic outcomes you help design these systems why is it so hard to look inside of them and understand what they're doing okay let's take an exe case let's suppose we had a big data set and we're trying to answer a yes no question and in this data set there's lots of weak regularities maybe there's 300,000 regular weak regularities that suggest the answer should be no and there 600,000 weak regularities that suggest the answer should be yes and that the regularities are about equal strength so the answer is very clearly yes there's overwhelming evidence the answer should be yes but this evidence is in all these weak regularities mares it's just in the combined effect of them all this is an extreme case of course um if you then ask someone okay explain why it said yes the only way to explain why it said yes is to go into these 600,000 weak regularities so when you when you're in a domain where there's lots and lots of weak regularities and there's so many of them that they're actually significant they combined effect is significant there's no reason to expect you should be able to get simple explanations of things and and so in that conversation yesterday Alman pointed out a paper from anthropic which I thought was incredibly interesting and the paper talks about analyzing the inner workings of Claude anthropics model and finding all the connections the sort of the neural connections to the concept of the Golden Gate Bridge and you add weight to all those connections and you create Golden Gate claw and then you go into that chat bout and you say tell me a love story and it's a love story that happens on the Golden Gate Bridge and you ask you know what it is and it describes the Golden Gate Bridge given that why can we not go in a large language model and adjust the weights not for the Golden Gate Bridge but for say the concept of empathy the concept of compassion and then create a large language model that is much more likely to do good for the world I think you can make an empathetic model but not by directly adjusting the weights you just train it on data that exhibits empathy then you get the same result yes should we be doing that I don't there's been lots of examples in the past of people trying to understand what individual neurons are doing and I've been doing that for like 50 years and if the neurons connected directly to the inputs or connected directly to the outputs you stand a chance of understanding what the individual neurons are doing but once you have multiple layers it's very very hard to to understand what a neuron deep inside the system is really doing because it's its marginal effect that counts and its marginal effect is very different depending on what the other neurons are doing depending on the input so as the inputs change the marginal effects of all these neurons change and it's just extremely hard to get a good theory of what they're doing so I could take my neural network that I've been building backstage and try to adjust the weights for compassion and I actually come up with some kind of horrible animal killing machine because I don't know exact what I've done and how everything connects uh yeah I may be one of the few people who's actually tried doing this so in the very early days of neural networks when the learning algorithms weren't working very well I had a list machine and the mouse had three buttons and I figured out a way of displaying all the weights in a small neural network and I made it so if you press the left button the weight got a little bit smaller and if you press the right button the weight got a little bit bigger and if you press the middle button you could see what the value Val of the weight was would print out the value of the weight and I tried fiddling around with neuronet adjusting the weights it's really difficult um back propop is much better well we'll have to have to wait for a Next Level AI that is even smarter than Jeffrey Hinton to figure out how to do this um let's talk a little bit about some AI for good you've often talked about the benefits that will come to the medical field and when you go through the sdgs it seems like good health and Medicine in a scenario where you feel that AI will have a lot of benefits is that fair and tell me why um yeah I'm a bit stumped it's just obvious why um it's going to be much better at interpreting medical images in 2016 I said that by 2021 it will be much better than clinicians at interpreting medical images and I was wrong it's going to take another 5 to 10 years partly because medicine's very slow to take up new things um but also I I overes estimated the rate of short-term progress um so that's a wrong prediction I made um but it's clearly is getting better now it's comparable with um quite good medical experts at many kinds of medical images not all of them but many of them and it's getting better all the time and it can see much more data than any clinician so it's just obvious in the end it's going to get better I just thought it would happen a bit sooner but it's also much better at things like combining lots and lots of data about a patient combining data about the genome the results of all the medical tests I mean I would really love it if my family doctor had seen a 100 million patients and could remember stuff about the mall or had Incorporated information from the mall and so when I go in with some strange weird symptoms the doctor can immediately say what it is cuz she's seen like 500 patients who are quite similar already in the 100 million that she seen um that's coming and that's going to be amazing and so the future of the medical benefits then are a doctors who have seen many more patients un trained on them be specific tasks like analyzing images and what about scientific breakthroughs like the stuff that your old colleagues are working for on Alpha fold 3 Alpha fold 2 of course there's going to be lots of those it's going to be wonderful for doing things like understanding what goes on and as well as designing new drugs obviously it's going to help with designing new drugs um I think deis is a big believer in that now uh but it's going to help us understand basic science and in many cases there's large amounts of data that are not of the kind that we evolved to deal with so it's not visual data it's not acoustic data it's data in genomes and things um and I think these a systems are going to be much much better at dealing with large volumes of data and seeing patterns in it at understanding it it and that gets at one of my main critiques of the field of AI that I'm I'm curious if you share I understand why so many researchers and some of your former students many people who are pioneers field are working so hard to make machines that are just like humans and are indistinguishable from humans but they're also all these other people who are trying to build very specific things like Alpha fold 3 or try to figure out how to use AI to push forward cancer research do you think I'm wrong to feel like there's too much weight and too much focus on the AGI side and not enough wait and focus on the specific scientific benefit side I think you may well be right about that for a long time I thought that AGI isn't going to be there's not going to be a moment when suddenly these things get smarter than us they're going to get better than us at different things at different times so if you play chess or go it's clearly um there's no way a human ever going to be as good as things like Alpha go or Alpha zero um they way surpassed us um we can learn a lot from the way they play those games and people are learning that but they're way ahead of us there and probably en coding they're already way ahead of me um I'm not a very good coder so I think the idea that all of a sudden they're going to be better at everything is silly they're going to get better at different things at different times and physical manipulation is going to going to be one of the later things I believe and so when your former students are asking for projects to pursue do you often Point them in the direction of say we'll do more basic scientific research push for more discoveries as opposed to continuing to go for human-like intelligence um my former students are now all so old that they don't ask me anymore his former students run basically every AI company in the world so that was like kind of a subtle way to get at that question but we'll let that be so back to AI for good looking at the SGS looking at the Ambitions of the people in the room do you feel like AI will transform education in a way that helps Equity particularly as these systems become fluent in every language on Earth yes so let me give you a little story when I was at school my father insisted I learned German cuz he thought that was going to be the language of science um that was CU in chemistry German sort of was the language of science I believe in the middle part of the last century or the early part um and I wasn't very good at German I I didn't do very well in it and so my parents got me a private tutor and pretty soon I was top of the class in German um private tutors are just much more efficient than sitting in a class listening to broadcasts by the teacher because the private tutor can see exactly what it is you misunderstand and give you just that little bit of information you need to understand it correctly and so I think everybody's going to get private tutors and until now private tutors were the domain of the rich or the middle class and ambitious um so in that sense it's going to help a whole lot and I think the K Academy believes that too well that's a huge thing I mean if everyone has these incredibly capable private tutors they can speak their languages which we'll get at some point God willing soon it's been a big big topic here don't you see the world becoming more equal in in that sense yes in terms of educational opportunities I think it will become more equal the the elite universities aren't going to like this but I think it will become more equal yeah we're not we're not here we're more interested in the future of humanity this is not you know AI for elite universities it's AI for good so I think we can take this as a win on the stage absolutely but but there was a gap there in your answer suggesting that you feel like AI overall won't be a net force for equality May in fact be net net a force for inequality was I wrong to read that into your answer well we live in a capitalist system and the capitalist systems have delivered a lot for us but we know some things about capitalist systems if you look at things like big oil oil or big tobacco or asbestos or all sorts of other things we know that um in capitalist systems people are trying to make profits and you need strong regulation so that in their attempts to make profits they don't screw up the environment for example um we clearly need that for AI and we're not getting it nearly fast enough so if you look at what Sam Alman said yesterday um he sort of gave the impression that yeah they're very concerned about safety and so on but we've now had an experiment on that we've seen the results of an experiment where you pit safety against um profits now the experiment was done in rather bad conditions it was done when all of the employees of open AI were about to be able to turn their paper money into real money because there was a big funding round coming and they were going to be allowed to sell their shares so it wasn't an experiment done in ideal circumstances but it's clear who won out of profits and safety and it's clear now that um what open AI has got it's got a new safety group um it's employed some economists or at least one Economist I think of economists as The High Priestess of capitalism and um I don't think it's going to worry about the existential threat nearly as much as Ilia and um the people working with him did I also I also think um the problem is that capitalism is about making profits which I'm I'm not totally against I mean that's done wonderful things for us that drive but it needs to be regulated so it doesn't also cause bad things um it's going [Music] to create a lot of wealth I think it's clear to almost everybody that AI is going to increase productivity the question is where is that additional wealth going to go and I don't think it's going to go to poor people I think it's going to go to rich people so I think it's going to increase the gap between rich and poor that's what I believe do you not have hope seems like you're saying AI it's Powers the fact that will probably be a small number of Corporations because of the resources needed to train these large language models that AI is kind of incompatible with capitalism inequality do you not have hope that some of what we were just talking about equity and education the ability of everybody to have access to extremely powerful machines if not entirely as powerful as the most expensive machines do you not have hope that that will counterbalance it um there is some hope of that but sort of for most of my life I thought that as people got more educated um they get more sensible and it hasn't really happened if you look at the Republican party now they're just spewing lives and just crazy lies um this is uh let's I actually this is a good moment let's go into the question I want to get into the question of how to do regulation and your ideas for that but I also want to get through some of your other fears about where AI is taking us why don't you here lay out maybe the one or two things not that you're worried about kind of the existential fears that you're worried about for the economy but your fears for the next 12 months okay so I'm worried about something I know very little about which is cyber crime um I Heard Dawn song Speak recently and she said that fishing attacks went up 1200% last year um and of course they're getting much much better because you can't recognize them anymore by spelling mistakes or funny foreign syntax um because they're all done by chatot now um or a lot of them are so I'm worried about that that but I don't know much about that another thing I'm worried about a lot is um fake videos corrupting elections I think it's fairly obvious that just before each election there's going to be lots of fake videos when there isn't time to refute them and I actually think it would be a good idea to inoculate the public against fake videos so treat them like a disease and the way you inoculate against a disease is you give a kind of attenuated version of it and so I think there's a bunch of philanthropic billionaires out there I think they should spend their money or some of it um putting on the airwaves a month or so before these elections lots of fake videos that are very convincing at the end they say but this is fake that wasn't Trump speaking and Trump never said anything like that um or that wasn't Biden speaking and Biden never said anything like that this was a fake video um then you'll make people suspicious of more or less everything that's a a good idea if there's a lot of fake videos around but then you need a way for people to check whether video is real um that's an easier problem than checking whether it's fake if they're willing to put in like 30 seconds of work so Yan Talon suggested for example you could have a QR code at the beginning of each video you could use the QR code to get to a website um if the same videoos on the website you know that website claims this video is real and now you've reduced the problem with saying the videoos real to the problem where that website's real and websites are unique so if you're sure it's it really is the Trump campaign website um then you know the Trump campaign really put out that video so could just pause for a second this is why I love interviewing Jeffrey Hinton we've gone from like new theories of Consciousness an incredibly controversial theory about subjective feelings to an idea that we should inoculate the public against fake news by pumping out low dosages of fake videos let's go to the first part because your solution there had I think if I heard correctly two parts so the first is inoculate the public against fake videos so you mean specifically someone should create millions of short fake but not very damaging videos and put them on Twitter threads they could be M they could be mely damaging they're not going to be convincing unless they look like real political advertisements um but at the end of the advertisement there's short advertisements so you hope people watch to the end at the end of the advertisement it says this was fake that's the attenuation that allows you to deal with it I see so you watch it and you're like ah this proves my point wait that was fake and then you're more distrusting I like this okay exactly then the second part is that every video should have a QR code and so you see something now you're aware of it and so you scan the little QR code you go to the website ah it's real it's on a real website that's the idea well it's not not sufficient just to go that it takes you to a real website cuz fake videos could take you to the same real website it the video has to be there the same video has to be there on that website fair enough all right let's talk about biases and how to prevent them so one of the risks that people talk about is that AI systems trained on biased data will have biased results right let's go back to Medicine where you've made the compelling case that net net AI will be hugely beneficial you can imagine a doctor who has just been trained on the medical records of people in the United States not giving the Right medical advice to somebody from Zambia because they're different medical concerns different DNA Etc how worried are you about this problem and what does one do to fix it okay so I'm less worried about the bias and discrimination problems than I am about the other problems and I am aware that I'm an old white maale so that might have something to do with it it hasn't happened to me much um but I think if you make the goal replace biased systems or biased people with systems that are less biased not systems that are unbiased but systems that are less biased that seems eminently doable so if I have data of old white men deciding whether young black women should get mortgages um I'm going to expect there to be some bias there once I've trained an AI system on that data I can actually freeze the weights and I can go and examine the bias in a way that I can't with people with people if you try and examine their biases you get the kind of Volkswagen effect that they realize you're examining them and they behave in a quite different way um I just invented the name of the Volkswagen effect but there you go um with AI systems if you freeze the weights you can measure the bias much better and do things to overcome it ameliorate it you'll never get rid of it completely it's too difficult I think um but suppose you make the Target make the new system considerably less biased than the system it's replacing I think that's eminently doable remarkable and do you feel as though the focus in the industry on biases which has been a major topic has underappreciated the fact that actually these systems could end up being more just and that really we should just instead of saying we've got to wipe out all the biases we should just say let's make them less biased than humans and go from there um I think that would be rational I don't think politically I'm not sure whether it's politically acceptable I mean suppose you said we're going to introduce self-driving cars um they kill lots of people on the road but only half as many as ordinary cars I don't think you get away with that they have to kill almost nobody for you to get away with it um so I think there a political problem there to do with accepting new technology in a rational way um but I think we should aim for systems significantly less biased and be content with that all right let's go to um what you've described in uh interviews as the biggest risk with AI which is that they would get sub goals right and that they would get a goal beyond the initial goal given to them by their creators and by their users explain a what you think a sub goal is B why that's so bad and C what we can do about it so an innocuous kind of sub goal is if I want an AI agent to plan a trip for me I say um you've got to get me to North America suppose I'm in Europe I say you have to get me to North America so it will have a subgoal of figuring out how to get me to the airport um that's just a classic kind of sub call and if you want to make intelligent agents they have to have sub goals like that they have to be able to focus on one little part of the problem and solve that without worrying about everything now as soon as you have a system that can create its own sub goals there's a particular sub goal that's um very helpful and that sub goal is get more control if I get more control I can be better at doing all sorts of things that the user wants me to do so it just makes sense to get more control and the worry is that um eventually an a system will figure out look if I could control everything I could give these silly humans what they want without them having any control at all um and that's probably true um but then the worry is suppose the a system ever decided that it was a little bit more interested in itself than it was in the humans we'd be done for and in fact even before we're done for as you were describing that I got quite worried right so you have an AI and the goal is get Nick to the airport on time the AI is in some future State all powerful well the best way to get Nick to the airport is probably immobilize Nick put his hands behind his back just throw him in a car it's much more efficient because then he doesn't talk to anybody on the way out so you can see these sub goals going terribly wrong right um yeah but remember it's a very intelligent system by by then it should be able to not go wrong in ways that are obviously against human interest it it should be trained in such a way that it is interested in human interests all right excellent cuz I don't really want that to happen to me um all right let's go through I want to go through some regulatory Frameworks I have a question for you that I think you may be able to answer you better than than most anybody which is one of the things that holds back the big AI companies and the AI researchers from working on safety or slow going down it isn't just power it isn't just money it's the dream of like doing something great or as coders say like finding something sweet tell me about a moment so Regulators can understand this where you as a developer on the close you know in the cusp of a breakthrough what that feels like and how Regulators should think about that as they think about policy um I'm not sure I can not sure I can give you good insight into that um for a for a researcher for a research who's driven by curiosity um working on how to make something more capable to introduce some dramatic new capability like a previous speaker talked about the idea that you learn a model for one language you learn a model for a different language and then you can take the internal representations and rotate them onto each other um that's kind of amazing you get a lot of joy out of seeing something like that and I'm not sure you get the same level of joy out of um working on safety um so I sort of agree with you there however working on safety is very important um and there are some very good researchers who are Keen to spend their careers working on safety and I think we should do everything we can to make that career path be a rewarding career path so you would say to the young Enterprise encoders in this room this is God's work work on safety if it or that would be a good thing to do perhaps better than even better than being a plumber oh yes better than if you could if you could make progress on safety that would be amazing yes all right excellent I'll talk to my kids um let's talk about the regulatory Frameworks you want one thing you've talked about is I believe you went to 10 Downing Street and said that the UK should have Universal basic income will you explain why and then explain the other regulations that you recommended there yes it was I got invited to ATT diing Street and there were a whole bunch of sunak advisers his chief of staff and a whole bunch of other people who advised him on AI and I talked to them for quite a while um at that point I wasn't sitting down so I walked into this room and there was this big group of advisers and I spent a while talking to them including saying I thought that um I wasn't confident a would create as many jobs he got rid of and so they'd need something like Universal basic income um when the meeting came to an end I started to go out the door and realized I've been standing directly in front of a huge picture of Margaret Thatcher and explaining to people they should have socialism I'm in front of a big picture of which is quite funny all right so Universal basic income what else is in the Jeffrey Hinton regulatory plan for a world with I I think a very straightforward thing which Sam Alton won't like um is this idea that comparable resources should be devoted to safety um if you look at the statements made by at least one of the people who left open AI because it wasn't serious enough about safety it was to do with resources um I think the government if it can should insist that um more resources put be put put into safety it's a bit like with an oil company you can insist they put significant resources into cleaning up waste dumps and cleaning up um the stuff they spew out and governments can do that and if governments don't do that they just keep spewing stuff out that's clearly the role of government to make capitalism work without destroying everything um and that's what they should be doing um but but there's a simpler way to do that right I mean government can regul these big companies and say you have to work on safety and we need to audit and make sure you're doing that but the government could also just fund a lot of Safety Research and take a lot of government data and make it available to safety researchers and fund a bunch of compute and give that to safety researchers so should the government officials here all be setting up AI should the UN set up an AI safety Institute I think the UN is rather strapped for funds and the UN has to do things like feeding people in Gaza um I'd rather spent the money feeding people in Gaza I don't think the UN has resources maybe it maybe it should have the resources but it doesn't um Canada I don't think has the resources Canada's made a serious effort to put money into funding um compute for universities and startups so they recently put $2 billion into that which is a lot of money especially for Canada but it's nothing compared with what the big companies can do um maybe countries like Saudi Arabia can put in comparable money um but I'm not so sure they're interested in safety so Jeff we have one minute left and I have 14 more questions even though you gave wonderful wonderful brisk answers so I'm going to ask one big one at the end from all of this AI research you've been studying how the brain works you have incredible theories about why we sleep if you get a chance to talk to Dr Hinton I advise you ask about that what have we learned about the brain in the last year and a half in this explosion of AI that has surprised you oh that's surprised me um I'd rather go back a few years and say what's really surprised me is how good these big language models are um I think I made the first language model in 1985 that used back propagation to try and predict the next word in a sequence of words the sequence is only three words long so it was and the whole system only had a few thousand weights but it was it was the first of that kind of model and at that time I was very excited about the fact that it seemed to be able to unify two different theories of the meaning of a word one theory is that it's to do with its relations with other words that's the sort of deure theory and the other theory that comes from psychologist is that it's a big set of semantic features and what we've done now is by learning embeddings and having interactions between the features of embeddings of different words or word fragments we've managed to unify um these two different theories of meaning and we now I believe have big language models that really understand what they're saying in pretty much the same way as people do so one final point I want to make is that the origin of these um language models use backprop to predict the next word was not to make a good technology it was to try and understand how people do it so I think the way in which people understand language the best model we have of that is these big AI models so people who say no they don't really understand that's nonsense they understand in the same way as we understand all right well we'll have to end on that note it makes me somewhat heartened to know that Jeff hinton's incredible mind is in some way behind all the AI models that we use today thank you so much Dr Hinton thank you for joining us today thank you oh thank you very much to Jeffrey and Nicholas what a fantastic session just going to move over here because we're going to set the stage for an incredible panel and I want to have a word a little bit about responsible AI whilst they're resetting the stage in 2020 I made the Beatles sing Call Me Maybe using generative Ai and supervising every 3 to four seconds a few few months after that that I was invited to voice clone a senior official at an internal organization when I started doing it I realized very quickly that the result was so good it was audio cloning that I stopped and had to ask myself should I be doing this just because I can should I be doing this and so this next panel is going to be absolutely fascinating we're looking at the nuts and bolts of why AI can work for us and we need to help it do exactly that I can see a lot of you nodding your head here so that's excellent that we're in the right place and this is an upcoming panel on the next wave of AI for good and after that we have a few more interesting things including a K-pop video where you will be able to join in with the top half of your body I'm not sure if that's something that sounds exciting at this point because you're ready to move again after a lot of sitting down or whether you think you know what I'm going to watch everybody do it well don't worry because nobody will be looking behind to see if you're doing it but I I will see you all moving your arms and legs so that's going to be coming up as well as some more incredibly useful panels right then it looks like we're all set so please can you give a late afternoon day two round of applause for the absolutely fantastic moderator in the program chair AI for goods former deputy director tsv at the it it is the unique and amazing Reinhard Sha [Applause] [Music] are you coming okay okay [Music] I think we maybe this is a little it's a somewhat unscripted it's pretty unscripted the panel discussion so we have five panelists right next to me is ran shaari and she's the CE of human Humane Humane intelligence then we have Virginia dignum Professor for ethics at the University at umia in Sweden we have steuart Russell Professor Berkeley University and Stuart I think you have been to all our inperson Summits and this is fantastic I think we should have given him an Applause here and then we have Amir Ben fatimi with without Amir we wouldn't be here today because Amir is a co-founder of the AF Global Summit and uh I think we all I'm we owe your big thank you uh for actually putting bringing this bringing us together also and then we have uh Ana kaspersen she is a former colleague colleague in the sense we both worked at the United Nations and she she has an incredible background in security and uh diplomacy and uh you are extremely well spoken and uh I'm not quite well you're representing you're also working for itle e and you're representing the uh Carnegie foundation so this is somewhat unscripted I'm going to throw out some questions and then whoever would like to take the uh the floor please uh please go ahead so we're talking about the U how to move from the AI framework principles to uh implementation so governments and companies and universities Civil Society have been spending quite a number of years trying to figure out what kind of rules what kind of policies would we need in the realm of AI and over the last you know months or a couple of years uh quite a number of framework are being put into put into law the European AI act which seems to be now dandal has been in the works I think for five years and uh the United States put out its executive order China's been working a lot on it and there are many other efforts that are taking place around AI governance so I would like to emphasize our discussion on how we could actually measure how could we actually implement the Frameworks so how would we actually know that what the policy makers have been uh deciding that this is working who would like to uh step in on this Virginia I can start we I don't think we know necessarily what whether the the Frameworks and the regulations that are putting forward are right but we also don't know that AI we we get it wrong all the time with AI so we also cannot expect that the Frameworks and the regulations that we put out will be perfect the first time and I think that it's much more important to to try and to test the different types of approaches they are already first thing is also that it is not true that AI is not regulated already now without whatever regulations AI for falls under uh sector uh Healthcare uh regulations uh uh industrial regulations product liability so there is already a lot there which makes that the AI that we use is H as safe and as trustworthy as possible in terms of the AI regulations and AI principles that we can put forward we can we cannot know what is the best approach if we don't really in the same way that we try with AI systems we don't try and we don't put them forward we we don't have to wait until the law is perfect if we wait until the law is perfect we will be waiting forever I think when we we have a scientific mindset or maybe most of us you just run an experiment and if it doesn't work you run another experiment so I think yeah we should just try it out yeah I I can let me build on Virginia's point a little bit um you know like I come from industry and what I haven't heard is anybody ever sit the CEOs of the companies and say is your product ready to be rolled out into the world what what if what if it's not working 100% we are thrilled to see new products launch right and I think we can have the same safe iterative approach to policy and I completely agree with Virginia one thing that I'm you know heartened to see here one thing I want to note I feel like there have been two conferences happening over the last few days and there is one conference that is this room with the neon lights and the glitz and the Glamour and the big screen and Nick Thompson from the Atlantic interviewing people about their opinions there's another conference happening it's mostly on the third floor I believe and it's in different satellite offices and those are people you will see and there's no Neon Lights there's no applause at the end of it but they're putting their heads down and they're working together and they're solving problems I'm really heartened to see that happening and that's the room of people you should aspire to be in you should be in aspire to be in the room of problem solvers CU I will say we know that policy won't be good perfect but we're going to make it as good as we possibly can okay uh Stuart um yeah so I want I want to agree with what's been said but I think we we are at a stage now where most of the policy that's been enunciated is at too high a level okay to actually um tell you know is my system in compliance or not um and so there's still a lot of work to do um you know for example if you take an analogy to another area like food safety you could have a high level principle saying you know food should be safe uh people shouldn't get ill from eating the food but then a huge amount of work was done to turn that into specific rules like what temperature should uh you know cooked meats be stored at how long can they be stored before they have to be thrown away exactly what has to be on the label uh how often should we inspect restaurants um you know there are rules about how many rat hairs there are allowed to be in a can of beans right and the answer is I think it's one right so one is okay uh I think you can have maybe one rat dropping for each uh so so many kilograms of of product and so on uh so those have been worked out and then you can tell someone can come along and look at the can of beans and count the red hairs right we are nowhere close to that with AI systems so we talk about fairness um there are dozens of definitions of fairness the nist risk management framework has basically uh an IOU it says look there's all these definitions of fairness and we still need to work out uh you know which ones should be applied to which kinds of decisions uh and what degree of compliance uh has to be achieved and so on so um so as Roman says there should be people working on nailing down all of those details um and it's it's interesting actually one of the questions so Reinhardt sent us some questions to think about uh one of them was uh you know is Alpha fold safe that's a really difficult question to answer uh we think of alfold as being very beneficial uh to science uh I have lots of biology colleagues who love it they're like kids in a candy store um but there are ways of misusing alphafold um and we've seen uh for example uh an analogous case where a chemists were able to use uh one of these molecular design programs to actually uh synthesize new toxic weapon chemicals uh by the thousand in the space of a few hours so Alpha fold is not safe in the sense that uh if someone says Okay I want to use Alpha fold or some some variant of of of this kind of analysis program to uh yeah you can let me finish my sentence um uh Alpha fold is not set up to actually prevent that from happening and so uh one one then the question is what do you do about that okay well I want to dig into this Alpha fold example because you yourself have touted the FDA as a great example of you know how drugs are made safe so I want to emphasize that making AI safe is not about just inspecting the model and beating up the model until we've created the appropriate safeguards only in the bottle we have never done science that way when we have made science safe it's because we have created the appropriate infrastructure in the real world so if we talk about let's say someone's ability to make um you know some sort of toxic chemical a bioweapon they would actually have to have the ability to physically synthesize those chemicals which actually in many cases is restricted they would have to figure out how to distribute it and get it out there into the world world right so there are many steps many of which are human to getting that to happen right so you know I just want to make sure that you know like theoretically one could say that about pharmaceutical companies and getting drugs out there right they could cut Corners Etc but this is why we have these institutions of governance set up to insureance safe I I so I don't want to get people overly worked up about oh my God we have to make sure these AI models can't create chemical bioweapons because to be clear clear the AI models themselves if they are spitting out a formula or a way to do it is not the end of creating a biological weapon you can find the recipe for malicious weapon like you know biological weapons like Anthrax right online um that doesn't mean we're all at a risk of being poisoned with an I just want to clarify that there's more than just governing a model if I just can go go go back to Stuart uh just just to finish the the uh the alpha fault discussion I mean you're you're known to say AI models need to be provably safe how would you put a provably safe uh stamp on on a model like Alpha fault so um actually the the point of my example is precisely that uh at the moment uh deciding safe or unsafe is too difficult uh and that we could you know if we just if we have a high level principle model should be safe we can't turn that into a specific regulation we can excuse me what we can do um is say these here are completely unacceptable behaviors by models and uh require that developers show that their systems will not exhibit those unacceptable behaviors and those unacceptable behaviors are only you know small subsets of the totality of unsafe things that could happen um but for example a model that replicates itself that you know breaks into other computer systems and takes them over and makes copies of itself uh we would consider that to be unacceptable and um and therefore it would be reasonable that regulation should require uh a demonstration that the system will not do that I see that Virginia is super eager to jump in but let me try to get Amir and Ana in would one of you like to talk about the uh Alpha fold discussion here no or you would uh you know okay you don't okay fine so Amir do you think we are on the right way with respect to implementing or or what is it that we have to do to implement the the AI governance Frameworks uh well my opinion goes back to the observation the past 8 years of AI for good deployment in general where we have witnessed that uh machine learning and AI models and recently llms based approaches have demonstrated significant progress on identifying patterns prediction um and ways to to mitigate risk the the issue is governance I think is on a multiple level if you look at the the UN system and the stakeholders aligned here we talk about inclusivity democratization safety access privacy and we look at the industrial part we look at productivity efficiency uh safety from a different matter but not necess risk so there is not necess alignment in terms of language and how we look at this and the uh the support for uh for uh deployment of of AI for good or or governance of it is critical Junction is scaling having a pilot or demonstration of of a model is one thing deploying it within an application in a specific use case another one where there is engineering involved there is probably uh under series of set of uh Public Safety privacy uh awareness transparency that has to be involved it goes beyond the model so the governance I'm not sure today we are still aware of all the layers that have to be worked out to perspective when you think about product there is a very clear guidelines about product deployment when you think about research we're still observing and researchers are now fearing but probably rightfully so that there is huge risk ahead if we don't control those models but probably we're not at the place where we can actually deploy them from an enging perspective wide enough so the question about governance is that who's the who's in the governance perspect who's in the governance room and how these governance discussion should be taken care of and uh what type of methodology or vocabulary are we using but definitely to paraphrase what Virginia is is also saying is that governance should be focusing on good Ai and I'm let her this amplify that that that that concept which we all arrived at is that we're talking about AI for good and the governance of AI for good should start with good Ai and what is good Ai and what is safe AI what is AI that can be deployed not everything needs to be deployed necessarily and that conversation about governance has should I should continue with probably a line on vocabulary and concept that is measurable uh and I'm I'm emphasizing that scaling is the issue we need to be able to think about how to scale for the public good at a large level and this is where the governance I should be emphasized first Anya I think we sometimes get caught up in making these binary propositions good bad safe unsafe risk benefits uh ruman made a comment about this on our first day on the AI governance day and it's kind of leading us down a path which is not helping with putting governance efforts so systems and it's interesting because I've been involved in this with rard and never all the great people that I you from the outset and there has been a big transformation with this conference because initially when it was first organized it was even a poor comprehension about what are the societal impacts does it really affect us I'm just a small I'm just a small company why would I have to care about this things I see now we see a completely different comprehension about the societal impacts but we also moving further away because there more and more push I mean narratives matter so there's a greater push to try to take control of those narratives and put forward those binary propositions I see another thing which is quite interesting one is the more the mechanical side of AI I feel that that's sometimes lacking we had a lot of U you know really deep dives into technical Insight sometimes maybe a bit isolated or insular you know from each other but to understanding issues like systems Integrity you know once you embed any form of AI into system you actually change entire Integrity of what you're trying to do and that's not often understood on the policy side and this is critical when you're trying to think about putting governance in place the other thing I see where we still struggling is that of a shared language you talked about language the nomenclature and we know how difficult it is to do within our own Fields when it comes to actually putting effective governance Frameworks in place to even have a clear and shared idea what are we trying to govern at what state of the process like for example in the ethic you know kind of embedding ethics and safety by Design you know in the early conference St that was seen more as a slogan airing now I think it's understood that it has to be that way but even that looks different from who you are in that equation are you a company develops these systems in which case the ethics stars at a conceptual development stage but if you're a public sector or you a un organization that ethical kind of Hardcore work that needs to happen actually starts at a procurement stage you know you have to know what you what you buying and you have to know that you even have the right problem you're trying to apply to I mean I'm sure Stuart had the same thing the amount of conversations that we go to where the problem that is being described is not an AI problem it's not even a governance problem it's a human problem that needs to have completely different vectors inside so my point is that narratives matter more than ever who gets to Define these Technologies what they are what they're used for the words that are being used towards it and the questions are being asked so always when I come here and when I speak I always say like I hope I leave you with good questions because this is the one feedback I get from so many people so interesting I learned so much really interesting insights I still don't know what questions to askh Virginia thank you Anya Virginia you sure wanted to get back to stward or many things I could anyway uh I think the I fully agree narratives matter and the first narrative that we need to get straight is that AI is not a technology AI as we are regulating it as we are using it as it is impacting us is a social technical system and as such we need to regulate it from the perspective of the technology but we cannot forget those that develop deploy manage govern use and whatever else so when we talk about making the the models safe or unsafe we can make them completely safe like we can probably make a scissors the model of the scissors is completely safe and provable and whatever and still someone can use the scissors for doing all kinds of whatever they want even regulations that come from your microwave which probably also can be provable provable correct I don't know come with regular come with instructions don't don't dry your cat inside the microwave so we really need to take Ai and the regulations and the use of it from a perspective of um social technical effort and as such we also need all of us and we are here because we believe in AI for good and we believe that AI can make a big contribution for achieving the sustainable development goals to really make the world a a better place otherwise probably we would not be here but we really need to start asking ourselves all of us that are building these systems for good how good are we really committed and building these systems are we willing un able to be accountable for whenever these systems fail or don't do what we expect are we doing using the data do we know which data are we using where we are training the systems to the systems that we are building do we believe that are we uh really taking all the steps that we know even without the regulations or without the the the laws there are we doing it good because this whole issue of Regulation starts with us not with the models it's with us and if we don't trust the model then the first thing and only thing we can do is don't put it out there ran I have a question for you and then you can maybe answer my question and also respond to uh Virginia you have been um involved in model evaluation uh are we at a point where we could think about standardizing model evaluation even though the basic signs of model evaluation I guess is still in flux uh um you have asked my favorite question um I think it's because the science of model evaluations are in flux we need to have the conversation about standardization so there's two parts of this Virginia is 100% correct in saying that this is a soot technical problem um steuart had mentioned the nist RMF and I agree and that was like some of the feedback that nist had received it's like okay well it seems like a blueprint but what's the implementation and I know folks here have been probably flying in or busy or getting their hotel but on Tuesday nist announced something called Arya it is a soot technical testing platform this involves model evaluations red teaming and field testing so this involves engaging real humans in interacting with AI systems and testing specific use cases to understand how these models will act in the real world in both malicious and natural use situations um so one effort that I am spearheading and leading as Humane intelligence is creating a global community of practice around the science of evaluations I think it is very needed um to to Think Through best practices and methods for how evaluations work for example if we say red teaming I think folks in the room who are familiar with me and what I work on know I work on red teaming in particular but we don't actually have a science of how red teaming should work how many people is a sufficient number of people to red team who qualifies as an expert how do you know you're done red teaming you know how can you test the robustness of your red teaming responses none of these are answered questions that doesn't mean we don't go do them that means we have to go and do them to get this information but it's helpful to have different evaluation bodies safety institutes globally engaged on the conversation because we do want to make sure that whatever these approaches are are interoperable agreed upon why is that important because let's say you know the Malaysian government does their evaluation of an AI system they should be able to hand that over to the Singapore government the US government the UK government and everyone starts off knowing exactly what the best practices were this is how science works right scientists engage in a common shared language of science absent that we need to create that language for AI generative AI evaluation so we can have a shared conversation steart I'm like to turn uh to you again we organized an AI governance day uh on on Wednesday and uh you know one way maybe to to structure the field of a governance is uh AI needs uh data Ani needs algorithms and AI needs a computing power so you could think uh that you need data governance you you look at whether the data are uh that people have access to data that the data are good uh you can think of algorithm governance how do you ensure that uh they okay that's related to to data governance that you don't get biased byas results and then you could also think of compute governance and so I think that was a term that for maybe many of the participants was new so you're a professor of computer science and it seems uh that compute governance is actually the area where it might be easiest to measure something because if someone is training a model you know you need compute power a lot if you if you train a large language model so you know you need water to cool things so this is something you can actually measure and this might be easier than to measure whether your data are in integer or whether the algorithms are are biased or the data are biased so can you talk give a little bit of maybe background on on compute governance what it is that could be measured is that a useful thing um yeah so there is a number of proposals uh and uh you can see numbers in the European AI act in the uh the US executive order um where they'll say you know a system that uses above this amount of compute uh in the training process uh is subject to additional uh restrictions and Reporting requirements and so on I think the number is 10 to the 25 operations um but you know the details of exactly what is an operation you know it is it a bit operation is it a bite operation blah blah blah it doesn't matter that much um so you can measure those things quite precisely but um it's not clear that to me that they actually mean anything um there is constant ongoing research to achieve the same level of capabilities from much less compute partly because it's very very expensive uh to to run 10 to the 27 or 10 the 20 28 operations um and so I think any such uh hard threshold is is going to be uh outdated very quickly um and if you think about it right humans learn from far less data typically than the systems that we're training I mean their their text intake is made maybe 100,000 times more than any human has ever read um so if we actually can improve the algorithms uh we will find that we don't need anything like as much training data uh as we're currently using and we don't need anything like as much compute to produce something that might be superhuman so I'm not actually in favor of this idea that as long as we know where the big compute is we're we're good but there is an aspect uh of this overall problem where compute governance could be very important and that's in uh the complementary side of so we got regulations that might eventually say here's what AI models have to do here's what we mean by safe uh here are the tests and requirements and all the rest and and all of the um the uh the Bonafide actors in the space will comply we hope but then what we call the Dr Evil problem is that there will be actors who have no interest in complying with any kind of safety regulations and how do you prevent the proliferation of extremely dangerous uh AI systems systems that can replicate themselves that can break into other computer systems that can destabilize markets uh or or Hoodwink entire populations into misunderstanding the situation that they're in um and that's going to be I think uh controllable not through the kind of policing that we're currently trying to do with malware which is a complete and total failure uh but it's going to have to be at the level of the hardware itself because software is produced by typing um and can be copied and transmitted at speed of light it's very hard to police but Hardware is produced only by a very small number of Manufacturers if Dr Evil wants to bypass the existing Hardware ecosystem Dr Evil has to build uh their own tsmc which requires hundreds of billions of dollars tens of thousands of Engineers and Decades of work and so um if you can get the hardware itself to check that the software objects that they're about to run are compliant and refuse to run non Cent software then you have a chance of preventing this uh this problem uh and you would also as a byproduct uh be able to get rid of malware as well so um there's there's a huge amount of technical work that needs to be done to make this possible but the ideas the technical ideas go back to the 1990s with a a technology called proof carrying code where the software object comes with a proof that the software actually complies uh and and that's something that we could then Implement in Hardware uh and get somewhere yeah an I'd like to ask you a question and then you can think about how to answer or how to comment on on steuart's response are we on the the right way towards uh coming up with good rules policies for a governance would it take we talked a little bit before would it take perhaps a major catastrophe and quite sure how to define a major catastrophe with 100 people left to die with 100,000 people left to die or something similar or would it be rather maybe a slow creeping process AI taking somehow control more and more control over our lives uh like with uh Regina said like with climate change would it take a disaster or would it be a creeping process and uh then it might be too late you like with climate change maybe we were're too late maybe we could have reacted earlier but earlier scientists didn't really know how this all worked so what what what's your assessment so I need to say I'm strictly taking my all my official hats off when I answer that question um because this is my purely my personal statement um I think we might be a we might see both you know when you look at the history of Technology specie especially when you're look at from an International Security perspective there are unfortunately trends when you have big transformative Technologies to sense the urgency around regulation around coming together often it is it does follow something that is undesirable happening first but then you also have this creeping effect you know the where it sort of penetrates more and more what we do is making us almost Spectators to ourselves so it also changing Society at a very kind of granular level where we may not have the resilience in place both at the human level at the society level now uh I just wanted to follow up on some things that ask the question to you kind of bigger you know bigger issue um but I do think Stuart is making a really entral point which is often seen as a bit more un seexy side of AI which is all the people that need to work on the systems in the background that people required to maintain them to upkeep them I remember the first time I met steuart you know he was lecturing and he was saying for everyone in the room read Machine Stop do you remember this it's a novel from 1905 1904 19059 1909 and essentially how we become over reliant on this big computational system and we stopped checking in with ourselves and there is a real risk of that at at a at a human level now going to the governance side is going to make it his point so one thing I do worry about to the second part of your question is that we seeing an extreme level of fragmentation this go back to my issue of of narratives you know how we speak about it how we govern it you know regulatory Frameworks that actually might be pushing us into very granular approaches to it rather than coming together there's another component to it which is we actually have a lot in inter International governance instruments today including itu that can be brought together to create this framework you know anyone who works in computer science would no this concept of middleware you know the the the the mid the the the the mechanisms you use to bring things together so if we can emulate on some of the really critical experiences that we made internationally you know on issues of nuclear safeguards Etc the atomic energy agency is also here at the conference which was really hard one difficult things to negotiate but we have done it in the past where you found that balance between promote and protect so we need to be a little more unafraid to tap into what we know to the experience that actually exists in the National Space and that's where standards come in and the secret General spoke about it I think twice during this conference the importance of standards and of course my organization is also involved in this space especially the social technical space um and I see because I come more from the policy side I actually see standards standards does a very important job in building confidence between people that work in technical Fields but it has this onap potential to also help building confidence or doing confidence building between policy makers it offers that sense of you know the the clarity on nomenclature it offers guidelines or insights into the limitations of a system to the opportunities to the maturity of a system so actually looking at standards as a baseline of bringing greater convergence where we find ourself very divided I think is an onta potential in in that space as well Amir have the last word uh what is your you know assessment with respect to AI governance are we are we on the right track what would you like to see over the next year or so uh that should take place well after after everything we said um I think we agreed on a number of topics about language and Clarity and and testing I think the the the focus on air governance should be on moting what I said earlier is is defining good Ai and trying to implement as much as possible good AI in different all the lines layers of sdgs to understand and gather data from the ground up of course standard organizations have to work to create standards they have to have ground through data to work on the standards we have to have measure and methodology we have to be able to characterize those those issues if we don't experiment more uh we're going to be staying at the level of conversation which is pretty much a banner native as was suggested by Annie as well um the concept of good AI has to be defined we're going from AI for good we need to probably put an adjective of good AI in front of it but I say we need to work on good AI for good and good AI is a safe transport human Centric uh beneficial that provides value and make sure that researchers scientists those who are implementing and monitoring systems also aligned with this concept and try to implement and that case governance should also provide a framework about how should we push more good AI into our society there is an issue of literacy as well we usually drive cars and use knives and scissors and many object that could be dangerous and lle but we have learned to understand their limits and their boundaries and what to do with them and not uh bringing up literacy at the at the global level I think should be an act of governance to make sure that everybody understand the limits and the limitations and find a way to make sense of what we're talking about I think we still have a two speed Society going on right now okay that's a good closing word uh Amir good AI for good so thanks a lot to the participants including Virginia who needed to catch a plane otherwise she will be stuck here thanks a lot thank you thank you very much to all our panelists as you make your way off of the stage we really appreciate you all making time to join us here on stage and the same goes for our next panel we are so so grateful for people adding their involvement to this evening and making time for this next session which is all about a sustainable and Equitable future for all this is a power panel so it will be short but incredibly informative a bit like me actually okay so let's invite every body to the stage it's uh Thomas lamascus from the itu his Excellency Ambassador laber Gabriella Ramos from UNESCO and Rob opam undp my goodness hello how are you hello thank you [Music] LG all right we have everyone so we're nearing the conclusion of yet another remarkable Summit congratulations all of you and we are very very privileged to have representatives from three un agencies and the co-host of the AI for good Summit on stage and I'm going to just say a central theme throughout both the AI for good Summit and wises has been collaboration and over the last 3 days we've seen outstanding examples of collaboration amid the UN system entities and the UN activities report released by The itu on Wednesday highlighted impressive initi initiatives from more than 45 agencies and we've also learned about the close partnership between UNESCO and itu in facilitating coordination and coherence within the UN system on AI so Thomas I'm going to start with you what are your plans to further strengthen this collaborate effort amid un agencies as well as other stakeholders so thank you thank you very much El great to be here with you as we are coming to a close of this very very intense but very productive week and I think when we talk about Partnerships we see we need to see and this week has showed us what we're building upon I think anyone who walked there these holes here and even outside the building when you saw there a lot of people trying to get in you saw how many people want to partner how many people in these different meeting rooms in the hall sit down and discuss how they will do and what they will do together and we have a lot to build on so of course in this already in this uh Summit we already launched quite a few things that we'll be building upon so we launched that open wallet Forum with the with the lenux foundation and others as well where we'll be bringing digital adids and digital wallets inter operable wallets to everyone we launch Global initiative on AI and disaster management the again which will harness AI in this very important climate adaptation Challenge and that builds up on all other similar Global initiatives so last year's launch Global initiative on AI and health together with who and wo as well so we also discussed here in in these Halls collaboration with World sers Corporation together with I and ISO how we'll work together and bring others along or to coordinate AI standards and also specific track on water markeing and content authenticity we of course have a broader platforms to build in this gain Forum we launched another annual report of un projects and initiatives on eii with more than 400 projects highlighted showcasing how un is already working on AI and that chose how we use AI for school connectivity mapping we use AI for flood predictions we use AI for water uh water quality as well predictions so we're already doing that and this coordination with the UN system is super important and that's that brings me to a coordination and I'm sure Gabriel also agree with me she's our my partner in crime and we today this week we felt like always like twins and most of this I think every time I was on the stage except for one it was always with Gabriella because indeed that also shows how we as un are working together more than 40 agencies and it's very really pleasure together with UNESCO to co-lead that coordination already coordinating to make sure that we are there together we've been asked by our colleagues to come back now and say how we can do it even stronger now exactly this we working on working on we learned a lot this week again we brought those un agencies here we actually asked them to mix with the member states as well we had a great mixer there thank you very much for Swiss Confederation to facilitating that as well and there a lot to build on so stay tuned they'll be thinking a little bit more few announcements maybe still to today but also stay tuned for this great collaboration going forward so thank you much brilliant thank you very much Thomas let's chat with Gabriel Ros I noticed it is actually quite difficult to tell the two of you apart but I'm going to continue and thank you for joining us on the stage um unesco's ethical recommendations on AI represent a pioneering effort to ensure that ethics are Central to AI development and you've actively participated in governance day and engaged with countries across the development Spectrum so what are your key takeaways from these conversations and and what are your thoughts on enhancing even more collaboration across the system well first and foremost what do I take away from here the Fantastic leadership of itu dorine Thomas amazing and I think they deserve a big Applause because they are amazing I feel that when we when we say that to understand the Technologies to govern the Technologies the conversation on governance really went very uh solid in these days uh you bring the private sector you bring the academics you bring the stakeholders you bring the international institutions you did it so leading by example thank you so much I I'm I'm I'm I'm very encouraged by the conversations because it seems that we are converging in terms of what needs to be done in terms of governing not only about the question of regulating or just controlling the downside risks but how do you create incent incentives and this is the main message that I take from this fantastic Gathering how do we create incentives in the private public everywhere to ensure that we invest more in the good Ai and that we address the problems that Thomas was mentioning because at the end we want AI to solve our problems and then in terms of Partnerships uh remember the uh Summit of the future is coming the global digital compact we spoke about with our members because our members are happy that we are cooperating uh we deliver this impressive document and with Thomas uh co-chairing and of course with the support undp many of the institutions that are there to show that the UN system and you can be proud that the UN system is really taking this seriously and is making very concrete contributions in all the areas of work that we have therefore that what paper and the inter agency working group was signaled and this is something that I take with me very seriously as one of the platforms that can be used to advance the summit of the future conclusions and I hope that we our members will take that with them and then there's nothing that like like Partnerships and uh in our global forum on the ethics of AI because we we have 194 countries implementing the recommendation on the ethics of AI so we have the global forum we launched the observatory on the ethics of AI with Alan Turing and with the itu uh we have a Readiness assessment then suddenly we realize that of course the undp this fantastic development institution has also the Readiness assessment and we were asked by your countries where are you doing Readiness assessment B of you so we're joining forces and we are collaborating to see how we can go together in in delivering these assessments uh the landscape the AI landscape of undp and the Readiness assessment and then of course we cannot do it without the itu because the itu we also help us with the Deep Dives in terms of the sectoral assessment that they're doing so I feel that we not only come I would say I'm not being arrogant but I will say a little bit more wise not only because of the panels not only because of these fantastic exchanges that we have but also because we got this sense of purpose confirmed that we can steer the development of these Technologies in a positive manner so we are uh really looking forward I I I actually considering with Thomas and and with dorine and with the teams with pretam how do we also build the linkages between the global forum on the ethics of artificial intelligence with where all of the Rams are presented and the AI for good and whs's going forward so thank you so much watch this space oh thank you so much Gabriella let's go on to Rob op from the undp next thank you also for joining us as the undp with its core mission of development and assistance to countries what did you find most resonant about AI capacity building during the summit and with itu and UNESCO on stage both heavily focused on AI as we've heard from Thomas and Gabriella what are your plans for future collaboration well what I found most resonant about capacity building is that there needs to be a lot more of it and that's also as the UN system what we're committed to doing uh at the moment if you look across subsaharan Africa only 3.3% of of Journal articles and journal citations on AI are actually coming from that part of the continent and the an au report released on the African continent said that only 36 out of 54 African countries actually have data privacy and protection policies in place so if you don't have some of the fundamentals and you don't have the capacity to put the fundamentals in place how are we going to ensure that the digital divide doesn't actually get wider because of the introduction of AI where part of the world is able to zoom ahead and there are others lagging behind and that's as a un system what we're committed to doing because we stand for leaving no one behind it is a core part of our Charter it is a core part of the agenda 2030 and the sustainable development goals that we all subscribe to and so that would resonated with me it's a reminder that we need to act with urgency and with our collaboration and that brings me to the collaboration point which is that um an important part of capacity building is understanding where you are and as Gabriella mentioned we're looking at the Readiness of digital ecosystems to embrace Ai and we're going to work together as UNESCO and and undp to really be able to support countries in that way to look at that as a diagnostic and then identify priorities where we're going to work together and with itu we have ongoing capacity building initiatives already many different initiatives when it comes to thinking through where we're headed around cyber security and many other things that contribute to the AI and the effective use of AI for good so I'm really encouraged and I Come Away knowing that we have major challenges in front of us but feeling very comforted that we have such a strong Spirit of collaboration as we move forward with great Partners oh brilliant thank you very much and now we're going to hear from his Excellency Mr y laber um hello thank you for being very patient um Geneva already has a thriving AI ecosystem it's only going to expand isn't it so as we move into this intense phase of discussions on the summit of the future the global digital Compact and the wies plus 20 review based on what you've heard over the past week where do you see Geneva fitting into the future AI landscape thank you so much I'm I'm stoked I'm really super excited about what I saw this week and about the future role that Geneva will play so I maybe have three messages the first one is a big thank you Thomas Gabriela Robert to you your colleagues your agencies this was a fantastic event I mean last year was already really great this year was next level I've never seen so many people such an energy around the center the fact that you're all here on a Friday afternoon late afternoon uh tells you tells you something really really really done AI for good is the flagship event within the UN system and beyond second um I firmly believe that we can make AI for good Prevail over AI for bad if we continue to be uh smart and I like what you said I I'd like to I think we've become wiser all of us collectively individually uh also help thanks to events uh like this week I think we understand better uh the substance and we also understand better individually in the different agencies in the missions in the countries what AI means as a challenge but also as an opportunity and how uh to deal with that and that leads me to the the third point the structures are here and that's a message uh maybe I want to give to our colleagues in New York the summit for the future the global digital compact is a great opportunity these are great opportunities to reaffirm some of the basics the values we need to protect and promote in the facee of technological advance but then how to go about this what it means in specific areas these structures these organizations are there and many of them are in Geneva that's why I'm so stoked about how this can happen in Geneva so um structures are here don't invent new things but and this brings me to the last Point part Partnerships cooperation I think we need to we can there's still room for improvement more discussions amongst ourselves learning from each other uh looking at the specificities more collaboration more more more Partnerships uh that's I think the challenge or the task we have for the next year thank you very much oh thank you very much um well I think we're sadly out of time for this but I can safely say how much encouragement your collaboration has generated and I hope Switzerland and Geneva continue to be part of making core un values like peace security and human rights and we want all of that to be part of the future of AI thank you all very very much thank you thank you thank you so much oh that's lovely thank you oh that was lovely I'm going to keep I'm going to stay on stage yes absolutely I'm not allowed off yet thank you very much well it was absolutely amazing to hear everybody's thoughts and I think we're at a really interesting moment in Ai and having the chance to be responsible and do AI for good and I say this as a generative AI artist very shortly we're going to have some K-pop coming up and we have closing remarks from our very own Dorene bogon Martin as well and then we're going to reset the stage for a few more bits and pieces I think we're nearly there yes it's a very busy stage for the last part of this event and not surprised really because we did have quite a few people who want to come on and it's a pleasure to invite everybody forward okay W let's invite back the director of itu say Onan and the additional Secretary of the Department of Telecom India his Excellency Mr Naraj Verma for let's invite them [Music] um okay thank you very much um onor San I would like to invite you for remarks first please thank you and good evening everyone uh in October this year uh we will meet in New Delhi uh at at the governance conference for it standardization work the world telecommunication standardization assembly wtsa India is bringing wtsa in NAIA for the very first time it's a momentum occasion and I thank India once again for your great hospitality wtsa is our guardian of the itu standardization platform it ensures what we remain well positioned to meet emerging sanation demands it's a key opportunity for itu members to highlight their priorities for our work India is world renowned for the focus on the future and Innovations for greater digital inclusion this will be on show at AI for good impact India the first event of our new impact series as well as Indian mobile Congress both we run alongside wtsa creating an excellent opportunity for a global it Community to meet with Indian innovators and to tell us more it's my great pleasure to welcome sh Nash BMA to share a few words with us thank you thank you good evening excellencies ladies and gentlemen it is my privilege and honor to stand before you today we are here to announce the upcoming world telecommunication standardization assembly or wtsa 2024 which will be hosted in our vibrant country India in October this year India with its Rich Heritage and a rapidly growing digital economy becons you all esteemed dignitaries I extend a warm welcome and invitation to you all present here and your country delegates to come to India to participate in meaningful dialogue and enjoy our Hospitality I express my gratitude to the itu for providing this platform and extend our invitation thank you and we eagerly await your participation in the world telecommunication standardization assembly at New Delhi from 15 to 24th October 2024 and in India mobile Congress during the same time from 15 to 18th October 2024 thank you thank you thank you both um thank you so much and uh I think we have a video to watch now so let's watch the video [Music] information and communication Technologies touch the lives of individuals and facilitate businesses and governance India's robust development in the ICT sector as the world's second largest Telecom Market of 1.17 billion subscribers with 931 million smartphone users an indigenous 4G and 5G stack have helped in delivering state-of-the-art Telecom services to its citizens countries come together under Under the Umbrella of the international telecommunication Union to decide on policies regulations and standards for Telecom and ICT itu helps in providing the universal and meaningful connectivity Bridging the digital divide and connecting the unconnected standards play a critical role in the development of Telecom products and services these standards are developed by member states and other it members India has been a founding member of the itu and has contributed to the development of Telecom standards India has a vibrant standardization ecosystem Little Wonder that India stands at an important position in international standardization organizations by virtue of its contribution for Innovative well- researched Solutions and standards India is proud to be instrumental in developing 5gi standards of the it U India believes in the philosophy of vasuda kutumbakam a Sanskrit adage meaning that the whole world is one family this makes India a natural partner in realizing the vision of the itu as a connected society and accomplishing the sustainable development goals 2030 using Telecom and icts in this endeavor India is privileged to host the World telecommunication standardization assembly 20 24 from the 15th to the 24th of October 2024 preceded by the global standards Symposium on the 14th of October 2024 at pragati Medan in New Delhi Delhi from being the historic capital city has evolved into a vibrant Cosmopolitan modern city today Delhi is a beautiful collidoscope of modern society with Rich Heritage and culture in the heart of the capital c City a sprawling 128 Acres International Exhibition Center called pragati Medan hosts a majestic modern Convention Center latest and largest in India which is the venue for the forthcoming prestigious G20 Summit the convention center is designed like an elevated Podium with five levels to make seating for 13,500 guests best suited to host the coveted WTS a this convention center at pragati Medan has been selected to host the wtsa 2024 India and the itu proudly invite the global Community to assemble in New Delhi for the highly evated wtsa 2024 to contribute towards the goal of a better connected secure and sustainable World wow thank you very much so thank you to India and the itu as they leave the stage what an incredible and extraordinary video and I wish you all the very best for October all right so it's going to be time for a final panel on something I'm fascinated by which is watermarking because uh when I make art it's really important to me to signify that something is generative AI inclusive and I would like very much next to invite on stage the deputy to the director of itut who will be moderating a fascinating panel on watermarking please welcome Dr Bell Jimi so fast he's already there off you go thank you thank you LJ and good afternoon everyone I'd like to invite a list of colleagues for a big announcement that we'd like to make today um Alesandra Salah from Shutterstock please join us she shared a wonderful Workshop all day since 9:00 a.m. this morning Sylvio uh from the deputy Secretary General of iso Jill ton the deputy Secretary General of IEC uh Thomas vant study group 16 Andrew jenss director of media Providence at Microsoft Leonard I'm not sure if Leonard still with us from Adobe uh John greeter Sam Gregory uh Taj uh jpeg please join us professor at epfl um Peter iser Mr  uh Mr Brown Gupta uh leeway from cic Mr Woo H Mr Wang and uh my our colleague from wpo Tobias if you're still around I think we have everyone please come on both sides so we can make half of us on the left and half on the right um Alexandra please stay next to me there we go okay very good so uh ladies and gentlemen on Wednesday during the AI governance day 45 ministers 25 Regulators 100 private sector un Partners Academia Civil Society debated and discussed the AI governance and certainly deep fakes of audio video text speech uh was one of the issues that was discussed in terms of needing governance and that topic cannot be governed without International standards so um on the stage on Wednesday afternoon we had the CEOs the Secretary General of iso of IEC and the TSB director and as you remember remember I moderated that se uh that that session and the three Executives committed to coordinating AI standards as the world standards cooperation yesterday we had a 2hour round table on AI standards that was inclusive of other standards organizations like the itle E we also had un Partners like unep um unido and others we also had government Representatives ambassador of the United States States our colleagues from China the Ambassador from Switzerland the private sector Nokia Erikson uh Google and other companies were huawe uh in that uh in that panel and we all agreed at the end of two hours that we will continue the Journey of Standards collaboration and coordination for all of the AI standards so we heard from the world standards cooperation we had heard through the round table that the um the that SE session was very useful and we need to continue it and today we had a deep dive on the first topic that we need to tackle which is deep fakes and all of the colleagues around me um shared what they are doing individually in their organizations the companies and the speakers uh we had 21 speakers some of them had to fly out but those who are still here are around and uh we all shared the difficulties the problems the ex in Solutions what's missing and one one of the elements of what was missing is a collaboration on deep fake standards on water marking and multimedia authenticity so we're very pleased that at the end of the day we issued a communic if you scan the QR code on the screen you'll find the communic already posted on the world standards cooperation website and this is an indication of the agility of the standard Community to address what the policy makers and The Regulators need so we had the discussion on Wednesday we're declaring and communicating on a new collaboration on multimedia water marketing and authenticity uh and also this is to show that the AI for good platform has been allinclusive uh and is is really working on concrete deliverables and announcements at the end of the work that we had this week thank you very much and I would like a big round of applause for my colleagues who made this happen thank you we're going to take a quick photo to Comm commemorate this moment please thank you thank you thank you T thank you thank you very much for a breathtaking selection of announcements and a flawlessly executed group photo afterwards as well well later we have the CEO of pulse 9 the amazing company behind the K-pop virtual human sensation eternity but first we are going to invite some close in remarks from the remarkable amazing incredible person it is Secretary General Dorene fton [Music] [Applause] [Music] Maron what an incredible three days let me start ladies and Gentlemen by thanking all of those that made it possible really this has been uh a kind of whole of whole of system effort with more than 40 un Partners the government of Switzerland our sponsors and of course all the amazing speakers panelists exhibitors it's been incredible we've heard powerful stories we've also made lasting connections and we've had some very meaningful conversations some that we will never forget there were actually people lining up outside this building lining up for more than a block to get in and see the action inside and I'm told we've actually reached historic record levels of of participants which is actually tremendous we even had what they call a viral moment we had a viral moment this morning when the French President macron he retweeted the first tweet ever written and published using only the power of thought history was made right here on our Frontier stage children took over the youth zone to build their own robots they're tomorrow's AI innovators and leaders what what princess batri said yesterday really resonated with me as a mom when she urged us to figure out how best to use these incredible Technologies for our children and then of course a moment I think no one will forget we met extraordinary people like Louise I hope you were in the room yesterday when he joined us remotely from Lisbon and ALS took away Louis's ability to speak but not his voice thanks to AI connecting with him was moving it was inspiring and that's what AI for good is all about AI for good is where leaders from the UN from government from industry from International organizations Academia and the technical community and of course Civil Society came together sat side by side over the last three days and they called for all voices to be included in AI Global governance processes I share the concerns of ministers and many others who felt that their countries were being excluded from critical AI conversations let me say we heard you and we took action here over the past few days to move us in the right direction and I thought I would just highlight three actions three actions that we've taken and the first action is about giving developing countries an equal seat at the table both at the summit and at our first AI governance day inclusion is at the part of everything that we do at the itu as the UN Agency for digital Technologies by bringing both the whs's community and the AI for good Community together we've actually shown the importance of building a digital Society with and for everyone I'm also pleased to see organizations step up their digital inclusion efforts around the world we had seven organizations from government from the UN from industry NOS as well they answered the call to our pledging campaign that we launched earlier this year by partner to connect and the AI for good Community together they've committed over 1.7 billion US do to use AI to advance digital inclusion especially for persons with disabilities for young girls for women and that campaign will continue and ladies and gentlemen I encourage you to get engaged take that example and make your pledge you can even make it now the second action is strengthening standards cooperation and collaboration and that's something that we've heard repeatedly from the unsg from hlb we need to strengthen that standard collaboration and that is the real Essence it goes to the core of the landmark collaboration that was just announced by the world standards cooperation to provide a unified framework for AI standards we've heard repeatedly from participants about the importance of interoperability and security as being a necessity for responsible AI they are a necessity if AI is to turbocharge sustainable development as the UN Secretary General has called for one that's based on Trust on security one that's affordable and of course we need to be advancing inclusivity especially in developing countries driven by itu by ISO by IEC This Global initiative will ensure the effective translation of AI governance principles into practical actionable standards ultimately our goal is to fill existing gaps in AI standardization so that we can tackle our most pressing Global challenges and advance and achieve the SGS over the last three days we've also heard about the urgency to stop the spread of Aid driven misinformation and deep fakes we cannot sit idle as misinformation and deep fakes erode trust in our elections in our institutions and the Very foundations of our societies the problem with watermarking techniques right now is not that they don't exist it's that they don't work across different Technologies and that's why I'm pleased that we have formed this multi-stakeholder collaboration on technical standards for AI watermarking for multimedia authenticity and deep fake detection Technologies by improving current standards and identifying the need for new ones this collaborative effort will help to provide copyrights and recognize AI created content on large scale so the third action is about building AI capacity around the world and that's where the AI for good impact initiative that was launched yesterday comes into play this this initiative is going to link AI innovators with problem owners to scale Aid driven Solutions equally across the sdgs and every region of the world and we need big capacity building efforts like this one if we're going to address and meet the scale of the challenge yesterday we heard some early significant financial commitments to this new initiative on this very stage and I think ladies and gentlemen that's a great start I'm calling on all of you to join us and help us to scale to fund the most promising AI Solutions so that we can achieve Maximum Impact over the past three days we've come face Toof face with three dimensions of artificial intelligence and AI that captures our imagination and Promises great opportunities an AI that concerns us and Taps into our greatest fears and an AI that challenges us to reimagine our relationship with technology and with each other all three dimensions demand urgent action because if not now then when and if not for the SGS then what cause ladies and gentlemen the UN Secretary General reminded us about the need to build safe and inclusive AI that is accessible to all and as I said yesterday the AI Genie is out of the bottle and there's no putting it back but I think there is hope you have sent a strong message to the world that the future of AI is not yet ridden and as we look to 2030 and Milestones like the summit of the future and September and next year's wises plus 20 review I think now is the time now is the time that we have to redouble our efforts let's redouble our effort efforts let's make AI Innovation inclusive let's build safe secure trustworthy AI systems and let's scale AI Solutions so that we can rescue the SGS because I firmly believe we can do it we can do it together because we are the AI generation thank you very much thank you thank you oh my goodness thank you so much once again to Secretary General Dorene Bogden Martin for once again inspiring us with your closing remarks it's incredible and my goodness our final talk is a musical one it's a good warmup for the drinks reception and the AI art competition that will be coming up shortly afterwards but what a pleasure to round up this evening's event by introducing the CEO of pulse 9 it's Jan pack to the stage please come on [Music] up all right so uh thank you for promising to get us into a dancing mood for this evening's celebrations please can you tell me a little bit about what the audience is going to see uh hello everyone I'm so glad to be here my name is Chan Park I'm the CEO of person9 a techment startup which present the world first K-pop AI Idol band with 11 virtual GS I'd like to say a special thanks to the Korean government agencies and starbank so many people helped eternity Reach This distance Place Geneva it is great honor thank you now I heard that this Kpop virtual human group is preparing for the closing performance can you explain the theme of the closing performance yeah sure uh there's a special closing performance featuring uh 11 AI do cars this event introduced a new era with AI created songs and voices and virtual humans onver vering witness the fusion of advanced AI Tac and K-pop Artistry Imagining the entertainers of the future now I've seen some of this in advance and it's absolutely remarkable and I understand that AI technology was behind uh the group eternity a lot of Technology was behind this can you tell us a little bit about how the AI technology was applied how it was developed and which areas is it being utilized yeah eternity the 11 girls are advancing pH sness is technology in collaboration with Atri a leading Research Institute in Korea and also we are Focus focused not not only uh beautiful faces but also developing AI to link the world for social with starbank for example some of the eternity project will develop AI compan companions for social isolation and loneliness of teenagers with starbank as a cobal Investment Bank while there are concern that AI technology could be used for bad such as defect crimes it is crucial to continue developing advanced technology for good purpose as the as with the main theme of the AI for good Global Summit AI Idol are also constantly striving to use technology positively and ethically oh brilliant thank you so much and what do you think we can focus on to better enjoy the closing ceremony performance together uh after the greeting a new song will be unveiled uh the second song that follows is a popular track with over 6 million view on YouTube it will be a more enjoyable performance if you follow along with the key choreography of the second song okay brilliant so what we're going to see is we're going to see the new unveiled performance and after that we're going to see a wildly popular video and uh do you know I think it's a good idea perhaps to learn some of these key dance moves together and we're going to teach you there'll be a video it's going to be repeated three times and I'm just going to put this down here and I'm going to attempt to learn the choreography now because what better way to end the day than with some more physical exercise so um how do we do it we can do yeah or on Fe it yeah one two one two and okay and double double double purle okay all right so shall we watch the video and then learn it why not everyone today I will try the point choreography of eternity's DT GM GN at this place trip Tri can we say [Music] again okay that looks easy doesn't it everybody one more [Laughter] time show trip Tri show trip this may possibly be the hardest thing I've done over the entire two days of the summit but I'm ready to try it should we audience should we try this just the upper half if you're sitting down so it goes show me your best double triple double this bits easy double double double triple and your hands are three because it's triple although technically that's six so just you know all right so I guess the next thing is to say thank you very much and we watch the video is that right right yeah yes okay let's do it shall we hear from [Applause] eternity hi all I'm Jane a member of the world's first 11 member K-pop AI Idol girl group eternity which is the abbreviation for Eternal Stars nice to meet you I am very happy to participate in the AI for good Global Summit it was a meaningful time where we could think together about how AI technology which innovates daily can have a positive impact on society our eternity members are contemplating innovating various aspects of the future such as education welfare finance and policies with AI technology while actively working as K-pop artists I am particularly interested in young friends from all over the world who are trying to escape social isolation and economic difficulties so today we have prepared two exciting performances with the meaning of coming together as one no matter what difficulties we face this performance specifically includes the unreleased new song from our eternity album showcasing its uniqueness and anticipation and it is composed of AI Technology based songs and voices forming virtual Idols that do not actually exist allowing us to see the future culture being created by the latest technology do not miss the chance to meet the future performers where state-of-the-art generative AI technology and K-pop art are brought together would you like to be a part of The Incredible Journey with eternity members if so please enjoy the mesmerizing performance together thank you and goodbye thank you [Music] okay oh exciting don't waste your Don't Waste Your Love don't wish your T cuz it's the best time you know don't wish your hype don't Your Love Don't Tak just yourself my no [Music] she's trying to stop playing game you can see me tell me we right we are when I your see [Music] [Applause] me we are we [Music] Bo hat my I'm and it's the best time be my friend you ever know I'm get [Music] Ro come on all new [Music] want to us baby like trip they could be touching highlight could be a show me your triple trip show me your best triple [Music] Jo us baby now let's go more do away and [Music] a show me your trip trip hell show me your best double triple double double triple triple brilliant thank you so much an an absolutely Flawless performance there by myself um I also like the fact that I failed to dance properly and uh 11 AI generated virtual people that don't exist completely slayed me on the Dance Floor along with the CEO of pulse 9 ladies and gentlemen and everyone thank you very very much okay now I would like to uh how can you follow that you might ask well I have an idea and that is the fact that everyone's invited to the Afterparty and there's one thing remaining and that is to acknowledge the absolutely outstanding incredible team behind the AI for good Global Summit 2024 so let's invite the one the only the inimitable the incredibly Musical and skill Fred Werner to the stage yes we got there we got to the [Applause] end wow so I paid her to say that what an incredible introduction thank you LJ and look at all the people here tonight it's almost 7 o' and you're still here so we must be doing something right and for our free drinks too so it might be that um no first of all I I would like to send a word of appreciation to the amazing LJ rich I don't know how you're still standing oh thank you yeah I have publicly publicly stated that I will not and cannot do a summit without AJ uh sorry LJ so you're your employment is guaranteed at least until 2030 and then we'll see if we do another 10 or 20 years after that who knows so thank you so much LJ um there are drinks coming I know it's late it's Friday night uh is anyone thirsty ready for a party okay so we have an art competition that's happening it's been happening all year long hundreds of artists from around the world using AI to basically increase their creativity and Human Performance to create these amazing art pieces with a positive message of sustainability we're going to be revealing the winners on the frontier stage with a nice drink in your hand in just a few minutes and of course there's also going to be music AI music surprise surprise and uh we're going to do a little experiment for those of you that don't know LJ is an amazing pianist and vocalist she can actually play a two different songs at the same time with her left hand and right hand I'm going to modestly try and uh play drums along with her and we're also going to have an AI DJ his name is CJ oh and z and Zach and there might be some robots on stage trying to jam with us what could go wrong it's probably going to be better than the dancing I just displayed let's be honest that was amazing okay last but not least I know you're all thirsty so I want to thank the AI for good superheroes so all of the itu staff who helped with AI for good I'd like to invite you all up on stage for a group photo Daren anois Selena belel Sena there's too many to name please come up here Fred would you like to display the slide is there a slide is there a slide that you want to display okay oh yeah oh yes yeah all right as the team as the team come on to the stage um I'm just going to extend a huge thank you to the speakers sponsors the organizing team at the itu they're still coming the phenomenal production AV and backstage my goodness you're amazing our lovely volunteers exhibitors and you the audience for your generosity your time and your attention and I'd like to to invite you all back to the 2025 AI for good Summit next year we think it's in July but we'll keep an eye out and uh let you know the exact date so are we all ready for the oh my goodness it's quite it's getting bigger we need a bigger stage that's a good thing wow I didn't know we had such a big team this is amazing okay we need a few rows can the short people come out to the front please Thomas it's definitely me all right I'm going to come down here come down so pictures we could have some music thumbs up everyone stand up a b all right and uh can I encourage you to make your most expansive gestures Ready Steady oh oh hang on we've missed some people come on up our extra people maybe yes this is most of the audience no this we might have to do a sensible one everyone before the silly one so that everyone's in the sensible one and the silly one Gabriella has been part of the AI for good family since the very beginning so you and we need to get you a t-shirt yeah and thank you audience for indulging us we've done this every year for quite some time can I also say what the farewell reception we're all going to be there it will be a pleasure to meet you all I can't wait and now a live change the action hero great work wow you know oh I'm sorry about that all right so I think we're clear all right crazy picture okay all right so free drinks and we'll see you next year in June byebye thank you very much oh congratulations no well done thanks so much dorine thank you so much [Music] n [Music] [Music] I [Music] [Music] [Music] h [Music] [Music] [Music] [Music] [Music] [Music] [Music] [Music] [Music] down together [Music] [Music] together forever [Music] [Music] together [Music] the [Music] [Music] [Music] recipe you got me but you cook for me [Music] find out together and stay stay stay in a place where we love we care we sh it's how it should be eally let's play play Thinking together and St stay stay in a world that we love we one we share it's how [Music] [Music] [Music] [Music] stay in a place where we love we care the way that we sh should be let together stay [Music] [Music] [Music] plan [Music] [Music] night [Music] [Music] of e e e e for spe spe e e e you