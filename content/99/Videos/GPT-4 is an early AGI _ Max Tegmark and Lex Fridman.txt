it's not gpt4 that's terrifying it's the gpt4 is a baby technology you know at Microsoft even had a paper recently out with the title something like sparkles of AGI whatever basically saying this is baby AI like these little Neanderthal babies and it's gonna grow up there's going to be other systems from from the same company from other companies they'll be way more powerful and but they're going to take all the things ideas from these babies and before we know it we're gonna be like those last neanderthals who were pretty disappointed and when they realized that they were getting replaced well this interesting point you make which is the programming is it's entirely possible that GPT 4 is already the kind of system that can change everything by writing programs yeah it's because it's Life 2.0 the systems I'm afraid of are going to look nothing like a large language model and they're not but once it gets once it or other people figure out a way of using this Tech to make much better Tech right it's just constantly replacing its software and from everything we've seen about how how these work under the hood they're like the minimum viable intelligence they do everything you know the dumbest way that still works sort of yeah and um so they were life 3.0 except when they replace their software it's a lot faster than when you when when you decide to learn Swedish and moreover they think a lot faster than us too so when uh you know we don't think uh have one logical step every nanosecond or a few or so the way they do and we can't also just suddenly scale up our Hardware massively in the cloud because we're so limited right so they are in it they are also life have consumed become a little bit more like life 3.0 and that if they need more Hardware hey just rent it in the cloud you know how do you pay for it well with all the services you provide yeah and what we haven't seen yet which could change a lot is uh entire Software System so right now programming is done sort of in bits and pieces uh as as an assistant tool to humans but I do a lot of programming and with the kind of stuff that gbt4 is able to do I mean it's replacing a lot what I'm able to do but I you still need a human in the loop to kind of manage the design of things manage like what are the prompts that generate the kind of stuff to do some basic adjustment of the codes let's do some debugging but if it's possible to add on top of GPT for kind of uh feedback loop of of uh self-debugging improving the code and then you launch that system out into the wild on the internet because everything is connected and have it do things have it interact with humans and then get that feedback now you have this giant ecosystem yeah of humans that's one of the things that uh yeah Elon Musk recently sort of tweeted as a case why everyone needs to pay Seven dollars or whatever for Twitter to make sure they're real they're make sure they're real we're now going to be living in a world where the the Bots are getting smarter and smarter and smarter to a degree where you can't uh you can't tell the difference between a human and a bot that's right and now you can have uh Bots outnumber humans by yeah one million to one which is why he's making the case why you have to pay yeah to prove you're human which is one of the only mechanisms which is depressing and I yeah I feel we have to remember as individuals we should from time to time ask ourselves why are we doing what we're doing right then as a species we need to do that too so if we're building as as you say machines that are outnumbering us and more and more outsmarting us and and replacing us on the job market not just for the dangerous and and boring tasks but also for writing poems and doing art and things that a lot of people find really meaningful you've got to ask yourself why why are we doing this uh we are the answer is moloch is tricking us into doing it and it's such a clever trick that even though we see the trick we still have no choice but to fall for it right come also the thing you said about you using uh co-pilot AI tools to program faster out how many times what factor faster would you say you code now does it go twice as fast or I don't really uh because it's such a new tool yeah it's I don't know if speed is significantly improved um but it feels like I'm a year away from being uh five to ten times faster so if that's typical for programmers then uh you're already seeing another kind of stuff recursive self-improvement right because previously uh one like a major generation of improvement of the codes would happen on the human r d time scale and now if that's five times shorter then it's going to take five times less time than it otherwise would to develop the next level of these tools and so on so this these These are the this is exactly the sort of beginning of an of an intelligence explosion they can be humans in the loop a lot in the early stages and then eventually humans are needed less and less and the machines can more kind of go along but you what you said there is just an exact example of these sort of things another thing which which um I was kind of lying on my psychiatrist imagining I'm on a psychiatrist's couch here saying what are my fears that people would do with um AI systems another so I mentioned three that I had fears about many years ago that they would do namely uh teacher the code uh connected to the internet then teach it to manipulate humans a fourth one is building an API where code can control all the super powerful thing right that is very unfortunate because one thing that systems like gpt4 have going for them is that they are an Oracle in the sense that they just answer questions there's no robot connected to the gpt4 gpt4 can't go and do stock trading based on its thinking yeah it is not an agent an intelligent agent is something that takes in information from the world processes it to figure out what action to take based on its goals that it has and then does something back on the world but once you have an API for example gpd4 Nothing Stops Joe schmoe and all and a lot of other people from building real agents which just keep making calls somewhere in some inner Loops somewhere to these powerful Oracle systems and which makes them themselves much more powerful that's another kind of um unfortunate development which I think we would have been better off uh delaying I don't want to pick on any particular companies I think they're all under a lot of pressure to make money yeah and um again the reason we're calling for this pause is to give them all cover to do what they know is the right thing to slow down a little bit at this point but everything we've talked about I hope we'll can we'll make it clear to people watching this you know why these sort of human level tools can cause a gradual acceleration you keep using yesterday's technology to build tomorrow's technology yeah and when you do that over and over again you naturally get an explosion you know that's the definition of an explosion in science right like if you have two people um they fall in love now you have four people and then they can make more babies and now you have eight people and then then you have 16 32 64 Etc that's we call that a population explosion where it's just that each if it's instead free neutrons in a nuclear reaction that if H1 can make more than one then you get an exponential growth in that we call it a nuclear explosion all explosions are like that and an intelligence explosion it's just exactly the same principle that some quantity some amount of intelligence can make more intelligence than that and then repeat you always get exponentials what's your intuition why does you mentioned there's some technical reasons why it doesn't stop at a certain point what's your intuition and uh do you have any intuition why it might stop it's obviously going to stop when it bumps up against the laws of physics there are some things you just can't do no matter how smart you are right allegedly um laws of physics yeah yeah right Seth Lloyd wrote a really cool paper on the physical limits on uh computation for example if you make it put too much energy into it and finite space it'll turn into a black hole you can't move information around Fashion the speed of light stuff like that but uh it's hard to store way more than than a modest number of bits per atom Etc but you know those limits are just astronomically above like 30 orders of magnitude above where we are now so no bigger different bigger jump in intelligence than if you go from uh from an ant to a human I think of course what we want to do is have have a controlled thing the nuclear reactor you put moderators in to make sure exactly it doesn't blow up out of control right when we do um experiments with Biology and cells and so on you know we also try to make sure it doesn't get out of control um we can do this with ai2 the thing is we haven't succeeded yet and Morlock is exactly doing the opposite just fueling just egging everybody on faster faster faster or the other company is going to catch up with you or the other country is going to catch up with you we do this we have to want this stuff we have and and I don't believe in this just asking people to look into their hearts and do the right thing it's easier for others to say that but like if if you're in a situation where your company is going to get screwed if you by other companies that are not stopping you know you're putting people in a very hard situation the the right thing to do is change the whole incentive structure instead and and this is not an old I I maybe I should say one more thing about this because molok has been around as Humanity's number one or number two enemy since the beginning of civilization and we came up with some really cool counter measures like first of all already over a hundred thousand years ago Evolution realized that it was very unhelpful that people kept killing each other all the time yeah so it genetically gave us compassion and made it so that it like if you get two drunk dudes getting into a pointless bar fight they might give each other black eyes but and they have a lot of inhibition towards towards just killing each other that's it and similarly if you find a baby lying on the street when you go out for your morning jog tomorrow you're gonna stop and pick it up right even though maybe it make you late for your next podcast so Evolution gave us these genes that make our own egoistic incentives more aligned with what's good for the greater group or part of right and then uh as we got a bit more sophisticated and developed language we invented gossip which is also a fantastic anti-malark right because now it it really discourages Liars Moochers cheaters because it their own incentive now is not to do this because word quickly gets around and then suddenly people aren't going to invite them to their dinners anymore or trust them and then when we got still more sophisticated and bigger societies you know invented the legal system where even strangers who didn't couldn't rely on gossip and and things like this would treat each other would have an incentive now those guys in the bar fight even if they someone is so drunk that he actually wants to kill the other guy he also has a little thought on the back of his head that you know do I really want to spend the next 10 years eating like really crappy food in a small room uh I'm just gonna I'm just gonna chill out you know so and we similarly have tried to give these incentives to our corporations by having having regulation and all sorts of oversight so that their incentives are aligned with the greater good we've tried really hard um and um the the big problem that we're failing now is not that we haven't tried before but it's just that the tech is growing much is developing much faster than the regulator has been able to keep up right so Regulators it's kind of comical the European Union right now is doing this AI Act Right which and in the beginning they had a little opt-out exception that gpt4 would be completely excluded from regulation brilliant idea what's the logic behind that some lobbyists pushed successfully for this so we were actually quite involved with the future Life Institute um Mark Bracco Mr ook Anthony Geary and others you know we're quite involved with um talking to very educating various people involved in this process about these general purpose AI models coming and pointing out that they would become the laughing stock if they didn't put it in so it the French started pushing for it it got put in to the draft and it looked like all was good and then there was a huge counter push from lobbyists yeah there were more lobbyists in Brussels from tech companies and from oil companies for example and it looked like it might it's going to maybe get taken out again and now gpt4 happened and I think it's going to stay in but this just shows you know monologue can be defeated but the the challenge we're facing is that the tech is generally much faster than what the policymakers are and a lot of the policy makers also don't have a tech background so it's you know we really need to work hard to educate them on on how on what's taking place here so so we're getting the situation where the first kind of non so you know I Define artificial intelligence just as non-biological intelligence all right and by that definition a company a corporation is also an artificial intelligence because the corporation isn't it's humans it's the system if a CEO decides the CEO of a tobacco company decides one morning that she or he doesn't want to sell cigarettes anymore they'll just put another CEO in there it's not enough to align the incentives of individual people or in align individual computers incentives to their owners which is what technically AI Safety Research is about you also have to align the incentives of Corporations with a greater good and some corporations have gotten so big and so powerful very quickly and that in many cases they're lobbyists instead align The Regulators to what they want rather than the other way around the classic regulatory capture right is is the thing that the Slowdown hopes to achieve is give enough time to the regulars to catch up or enough time to the companies themselves to breathe and understand how to do AI safety correctly I think both and but I think that the vision the path to success I see is first you give a breather actually to to the people in these companies their leadership who wants to do the right thing and they all have safety teams and so on other companies give them a chance to get together with the other companies and the outside pressure can also help catalyze that right and and work out what is it that's what are the reasonable uh safety requirements one should put on future systems before they get rolled out there are a lot of people also in Academia and elsewhere outside of these companies who can be brought into this and have a lot of very good ideas and then um I think it's very realistic that within six months you can get these people coming up so here's a white paper here's where we all think it's reasonable um you know you didn't just because cars killed a lot of people they didn't ban cars but they got together a bunch of people and decided you know in order to be allowed to sell a car it has to have a seat belt in them