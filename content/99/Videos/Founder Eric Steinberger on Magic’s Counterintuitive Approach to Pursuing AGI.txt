thing that remains to be solved is uh General domain uh long Horizon reliability and I think you need in France time comput test I'm confused for that when you try to prove a new theorem in math or when you're writing a large um software program or when you're writing an essay of reasonable complexity you usually wouldn't write a token by token uh you you'd want to think quite hard about some of those tokens and um finding ways to spend not 1X or 2X or 10x but a million x the resources on that token uh in a productive way I think is really important that is probably the last big problem [Music] hi and welcome to training data I'm delighted to share today's episode with Eric Steinberger founder and CEO of magic Eric has an epic backstory as a researcher having caught the attention of noan brown and becoming one of his research collaborators while still a student in high school Eric is known for his Exquisite research taste as well as his big ambition to build an AI software engineer we're excited to ask Eric about what it takes to build a fullstack company in AI his Ambitions for magic and what separates a good AI researcher from a legendary [Music] one H Eric welcome to the show thank you so much for joining us thank you for having me Sonia okay so let's start with who's Eric you're a Vienna born vrand uh whose early passion for math turned into a I think what you described as a full-fledged obsession with AI by age 14 take us back to age 14 Eric like what were you up to how did you become so obsessed with AI uh thank you Sonia I I I think I just had my midlife crisis when I was 14 and um I I just was just looking for something meaningful to do spent about a year looking at physics math bio medicine just anything really that seemed valuable to the world and um at some point bumped into just simply the idea of AI it hadn't sort of occur to me until then uh and if you could just build a system a computer system that could do all this other stuff for me like great like I don't have to decide so uh it felt like my decision paralysis was uh sort of resolved and I it was this weird moment where I could just see the next 30 years of my life unfold in front of me and I was like okay this is clearly what's going to happen like I have to I have to do this and uh it was it was quite it was quite nice um I like predictability so uh it was great to like know what the world will look like and you started loving math like why why AI then I think I'm naturally attracted to math it's just what my brain sort of gravitates to uh AI just seems useful I the thing that's most important to me is just what is useful for Humanity in the world and uh math is nice but not useful at some point like kind of you know 17 dimensional spheres are are probably not going to be the best career choice uh if you want to be useful so I it seemed like something that I could get good at uh but also just the most important thing ever uh so it was a very clear choice AI just is like as it was clear 10 years ago it's just it wasn't close and now it's close and clear can you tell the story of how you got aair I think it is such an epic story sure I I I mean so when I started with at 14 I had I didn't really know how to program I I didn't get into programming out of curiosity about computers I just wanted to uh solve AI basically um so after a couple years of just warming up on my own uh I reached out to uh one of David Silver's uh PhD students uh who who the alpago um Deep Mind co-founder uh and um the the this this PhD student I guess at that point he was a graduate and worked that deep mind um I asked him if he could like spend a year with me uh just every two weeks bashing my work uh sort of trying to do so sort of like super speed up uh uh mini kind of PhD like experience where I could just learn how to do research and uh I sent him this like giant email you could print it out I don't know how many pages it would be would it be a lot of pages I was basically just saying like I want to build this algorithm you made in your PhD sorry I want to beat this algorithm you made in your PhD here like here's a list of of 10 ideas I don't know if they're going to work and I think I need your help to figure that out um and then over a year we eventually got there um and he was like his name is Johannes Johannes was kind enough to just bash me every two weeks uh roughly and um yeah I it was it was brutal dude um like was just like cuz he I was like he hold me to the standard you know and I was like like don't don't be nice just cuz I'm you were in high school yeah I was in high school uh and and then when we were done uh I just graduated high school when when I finished so this this when I when I finished um the project uh that I was trying to get to with with with this uh and then noan Brown who is obviously one of the best RL researchers in the world um reached out because he had worked on something similar turns out and and we sort of uh uh had like some ideas that were very similar and some ideas that were a little different and so so we just both published this and um uh he reached out and then I got to work with no Brown for two years which was great and then that continued and so I got pass for another attention you were a high schooler he was no one brown um well I mean he published a paper called Deep counterfactual regret minimization and I published a paper called single deep counterfactual regret minimization and mine beat his by a little bit and uh so you want to know and brown as a high schooler uh I think I just graduated and I also it took him like three months to write this paper and it took me a couple years but uh it it uh yeah I mean slightly I'm sure he like would have come up with this the next day but the like the the the sort of the the gap between the two things but um it was it was just uh yeah yeah it was like obsession is the right word I just uh I do things like 100% And and yeah so so that that that was that was a lot of fun um kept working in our all with noan brown for a while and uh yeah so that's that's how I got to Fair noan Brown worked at fair at the time and uh he he reached out I was actually I was at University then and um basically just worked part-time as a researcher at Fair while studying and anyway so that was that was it that's awesome um it was it was a lot of fun no was great like the the brainstorm ping pong sessions with no Brown dude um there's like nothing like this where you just like there's like this problem and it's sort of like you know maybe you would like start a six month research no Noom and I would get on a call and it would just like we just discuss it and it's done that was so great I love that I love that what makes him so great as a researcher uh I think it's a number of things um as a researcher generally from more from a meta level he is fantastic at picking the right problems and uh spending a long time just grinding to make it better and better and better and better so he's very good at the whole like compounding thing um in research uh also making bets that aren't obviously uh the right bets when he makes them he makes them earlier I suppose and and making them def so he's generally very good at picking problems and then attacking them consistently um he's also just very smart I guess that helps he works really hard he used to do 100 hour weeks during his PhD I don't know if he still does them uh uh but uh he used to he used to work really really hard during his PhD I imagine he still is um okay so Nome arranged for you to become a researcher at fairwell you were still University student um if correct and you were jug my first semester I think or something so you were juggling that you were juggling being a collaborator to Noah at fair and then you became obsessed with yet another problem climate change and and actually started an NGO that is incredibly popular uh climate science um so you just didn't have enough on your plate uh was actually too crazy I that's when I dropped out I was like this is crazy this is too much I can do two things I cannot do three was like my conclusion after after doing like uh I did three months of that uh that was terrible that was that was awful doing like all three things cuz it just like you just can't do well at three things I mean Elon can but maybe I'll learn it in 10 years but the the I I I couldn't at the time uh so I dropped out at the time but yeah so I started an NGO I generally I just think like Cherry stuff is awesome and hugely appreciated like it's it's sort of like super high status to start a startup uh but I think it should be like equally cool to start a charity you're like helping the world in other ways um and so uh yeah I mean we we started it as a it's a nonprofit but we started at like a startup people were working insanely hard uh we had clear objectives it was you know a software product effectively uh it's it it was much more similar to a startup with the exception that there was no money in no money out um effectively which just very weird but um the yeah was mostly volunteered D or I guess is I just no longer run it uh but uh yeah that that that was an interesting experience you'd think I would like learn transfer a lot from running a quote unquote company to running a quote unquote company now but they is so different that I could like there was like no transfer at all between climate science and Magic like a th volunteers 20 hardcore Engineers no money at all I can't tell you how much we rais cuz it's not a yet but the you know Giant uh it's it's like completely different in every imaginable way totally so but yeah it's a lot fun so Eric climate science became an incredibly successful uh nonprofit and it wasn't just any nonprofit uh what made you decide to kind of hand over the rins and hand over the torch on that and and go start ACC companying AI I just thought AGI was further away when we started it at all uh I wouldn't ever have started anything else uh if I thought AI was so close uh and once I realized it is uh there was just like no other I I was I mean like I my initial thing was always AI That's what I did as a kid yeah uh I care about various issues in the world but uh it's n none of them are my like unique calling in any way I just you know I hopefully be in a position to donate a bunch of money and whatever but uh uh the thing I care about fundamentally is Agi and uh it was like oh damn it this is not 20 years away so I have been running around with the this AGI to-do list which is somewhat of a meme uh internally because we just like going through it then we're trying like to fix all these problems you have seen it yes we showed it to you um and I've been running around with a version of this there's actually like a 2017 or so like I was still in high school I got I don't know why but some conference invited me to present my AGI to the list it was wrong at the time I was also I was also sure it was wrong but um at some point so that was one thing I just couldn't at all figure out and I don't like blue sky research in the sense of like just staring at a wall and trying to like figure out what the right question is um I I I really like to have the question and then look for the right answer uh when starting an intense project uh because you need to know which direction you run in to really plan for it uh and the many things seemed clear but it seemed completely unclear how to make these models reason in the general domain uh and uh that became more clear with language models uh especially code models uh and and so uh yeah when when I saw just some of these early some of the early results in in the space like I was like okay I know all this stuff from the RL World um I have a bunch of other thoughts this seems great like we should just take LMS and make them do the RL stuff um so very simple kind of uh uh proposal but I think that's sort of where uh I mean it makes a lot of sense RL has been doing this for 10 years it works in in restricted domains if you can make something work in 20 restricted domains uh and you have something else that works in a general domain if you can combine them maybe you get both the X and the Y AIS and then you know you have your beautiful top right corner uh of the Matrix and uh yeah so it seemed like it seemed pursuable and if something when something becomes when something as important as AGI becomes a an actually executable to doist obviously there are still like things to figure out like you know details of the algorithms how do you make it efficient etc etc like it's not like we knew everything at all um many many things to figure out but the direction was clear and yeah so seemed like the right moment okay we're gonna Circle back to your AGI to-do list later because I'm I'm I'm curious about it sure um I want to brag about you for minutes because it might be wrong still I don't know until we have AGI it isn't is a hypothetical AGI to-do list but we're trying it's it's a I think the research field is tracking pretty closely to your to-do list um I want to brag about you for a minute I think you've been incredibly humble humble about your background um but you know as a high school student you did catch gnome Brown's Eye and and um as you know as one of his colleagues at fair you became one of his top collaborators not even just one of one of many because they're such talented people that work there but you're one of his top collaborators um and you know when I speak to folks that know you they just say extraordinary things about your capabilities as a researcher your creativity uh your work ethic as far as I can tell you work non-stop think you texted me at 2 am in preparation for this podcast um so I think it's safe to say no no uh thank you silent mod um anyways I think it's safe to say that you are one of the brightest minds of the current research generation already and will certainly be one of the legends that people talk about um for the next decade and so with that in mind I'd love to um ask you some questions of advice for for aspiring researchers and so maybe first off you did it all from a very untraditional background um how did you do it and like uh do you think that like what what advice would you give to others in your shoes I can only really speak for the sort of profile of goals and person I am I think I was lucky in the sense that I knew very very early with 14 as as we said exactly what I wanted to do with my life I had no doubt at all um and and and uncertainty can be paralyzing to a lot of people uh I also had a very clear sense that I did not at all have a plan B like there was no other path in life that I would have been even like remotely above the neutral line on like it it had to be build AI everything else is completely irrelevant so you know I understand so for many people like you know paying job at Google is is a great uh great achievement I mean I would if if it's on AI it's fine but it you get what I mean like I I just knew that there was nothing else I could do and like be fulfilled in life and look back when I'm 90 and be happy so in a way like burning the boats very very early gives you the opportunity to just be be get like do things that You' otherwise do 10 years later which again even like I I sucked at the beginning it took me two months to understand the first p paper I triy to understand um like I was terrible at programming for a long time but when you're a teenager you're like a decent researcher you don't have to be great like you know you that gets you that gets you uh things like a great mentor who then bashes you for a year uh which you know was was um very very helpful uh and and you know then you get better and you're still young so you s of your brain shapes more easily maybe I don't know so I feel like I benefited a lot from being early but within that um I'd say just like go for the end goal immediately doing anything sort of like oh I'm going to do a PhD because I need a PhD to get a that's all uh like you don't uh it's just completely uh the other thing is like writing five-page uh emails to people actually works um writing like I get a lot of these like two paragraph me things now and grateful I get emails but though I understand now why people think this stuff doesn't work it certainly does when you're like here is how I'm going to beat your algorithm please help me uh five pages at least in my experience every single time anyone I I I want help from in this way uh was very helpful so I suppose be proactive in seeking like the best people in the world to in a time efficient manner just distill their brain into yours and be show them that you can make use of that if you if you if you tell someone who's very good effectively hey I'm going to make good use of this if you want to coach someone I would love to be that person uh they'll they'll usually do it they won't do it for 10 people but if they do it for one or two that's enough you just have to to to win that seat I guess um so that that's been really helpful in my experience also just not shying away from learning new things um like I again I didn't get into programming because I'm curious about computers I'm not very curious about computers uh I I just like Ai and the computers are the thing that are necessary to so it's fun I enjoy programming now it's it's great but I wouldn't have gotten into it I think if if it wasn't for AI but still like you get into it so so like don't be shy like we interview a lot of people who who don't know um you know how how you'd Implement an llm and it's it's kind of crazy to me uh if you're a researcher and and you couldn't like Implement Charing or whatever like it's it's just insane um so so really understanding the whole stack going down to uh but sort of not bottom up really top down like here's the thing I care about this is the problem I want to solve okay like what do I need what do I need what do I need uh and and then like all the way down um and um and they're like much more confident people at colel programming at Hardware design or whatever than I could ever ever dream up to be but I understand enough of it to to do better work at the top of the stack than I could if I didn't um so um I think fundamentally you need to understand the domain you work in um it's also really good to just read everything um like I used to read I don't know I don't have a precise number but just every paper I could every paper I would see basically and eventually you get so fast at it that you can like that's feasible and you like build a database in your head of like oh this is similar to this thing this sort of like like but this was sort of my eye opening moment where Bill Gates has this intervie like oh yeah if you learned enough things they're all like similar to each other so it's not linear it gets easier and at that point I was like I should read every paper and uh so thanks for the advice Bill uh obviously was like through a video I never met him but um the uh so I just started reading every paper and that's really really helpful because a lot of the best ideas that we had that work really well now at at Magic um were enabled by random things that are like like oh this it would never work without this random thing that I would have to have come up with in tandem uh but because I have this database in my head I can go like oh yeah like this uh and and then so often like one good idea is enabled by three other ideas that others have come up with and and so so it's it's always just like this composition of stuff so so having a large database is really helpful um yeah and then just never stop uh like never never stop uh it it can it takes like ages to do good stuff to do good work and at any point there was actually one moment um with johanes the the the the Deep Mind research scientist who who mentored me for a year in high school um where uh we had a version of the algorithm that wasn't very good uh it just it was all right and and uh we were thinking like ah should we publish this like we were both not really happy about it and he was like close to giving up on me um it was like well you know like maybe this is just not going to work like I wouldn't want to publish this and so I was like dude you I'm just going to get this done and then we got it done like a month or two later uh and and so I think like I remember going on a walk after this um and uh just being like can I do this I don't know if I can do this but there is no no other option so I just better get it done and then I went back home and I started programming again it was still like sad that day but the next day was fine again it just keep going so I think you have to I think that was a pretty formative experience cuz I actually wasn't sure if I could do it and then we just did it like super soon after and so I really like haven't felt that insane level of like doubt and pressure since then which has sort of enabl I think it's actually beneficial you have to be realistic but you don't want to you you if you stop you yeah I mean so anyway so I think those would be the main things uh also be like really  honest about what you suck at um uh to yourself because otherwise you're never going to get good at it um like you need to search for the bad things um and uh uh uh instead of like trying actually yeah I think like as a researcher betting on your strengths is good only to the extent that you don't have uh necessary conditions that are completely missing like you you can't bet on your strengths if they're not enabled again back to the engineering thing for example so yeah I don't know I'm rambling but like that that's great that is such a fascinating glimps into like the inner mind of what it takes to be a great researcher and you know behind all the glamour of of training large large models and so like thank you for providing that that uh Peak and I'm really glad that you mentioned kind of reading every paper voraciously and having this database in your head because one thing I've heard from your collaborators is that your superpower is understanding and absorbing uh new research and so I'm curious do you agree like do you think that is your superpower as a researcher or what what kind of traits do you think have made you such an exceptional researcher so I think initially in the RL work I did it was synthesis where I would read every paper and I would go like this thing plus this thing plus that thing with this modification um I think that's what they would mean um that yes uh was definitely very helpful uh I think is a good way to do research generally there's enough work to for synthesis to be a successful strategy I guess to an extent still that I tried very hard after this is actually bring this up I realized this and I tried very hard to get better at leaps um like coming up with totally alien crap that just there's no reference for it at all uh and um because cuz ultimately like so if you take like the transformer for example right like attention existed um the idea of stacking a bunch of lstm blocks existed and you just had to remove the idea of recurrence really like then like a bunch a couple other things that that were't necessary right residual streams like the the residual update and Transformers exist from existed from reset so it's like it's synthesis um but there is an amount of leap in there uh to to to make it all work like it's it's a it's a little more complex than just taking components and putting them together you need to come up with new things too um like you know the normalization and the the the the the head square square the head which is actually incorrect but anyway everyone now knows this the the but roughly like you should do so there are some new ideas in there that like really help make it work um but but it's still a large amount of synthesis so so I suppose like most good ideas are synthesis but there are always some like in the best ideas there's some leaps uh and and um I'm trying to get better at those uh but still it's mostly I guess like take five things and throw it away the stuff that doesn't work uh in the make things work and configure but yeah I think I think some some stuff needs sleep but but yeah I guess like no that's a recipe like take LMS make them super efficient long contact giant throw our L on it make it all work together it's still mostly synthesis I guess you're right uh who do you admire most in the research world and like what do you think those folks superpowers are uh she here uh no there uh yes um he uh what is his superpower uh uh I guess to an extent synthesis um he is um I mean he's he's just the best at synthesis uh he's also great at everything in the stack uh he can uh like he he has no weakness really like he could implement the whole thing uh on his own if he had to uh run it uh he sees the future I think in in a way like it's very unconstrained and and that you know I think everyone sort of crediting uh you know a number of the labs for scaling laws this guy made a presentation where he was zipping through uh uh essays or completion or whatever written by like models of various scale I was like this is a 100 million parameter model this is a 300 million paramet model this is a billion parameter model this is a 5 billion parameter mod this is on YouTube Summer it's hilarious and you like what what if we make this bigger he's sort of presenting it this hilarious way um and then I everyone else like super scientific about it uh I think gnome is generally just uh if I had to put it he's very very intuitive um I I think there like a lot of labs and and and researchers are sort of and and I think this Al this is not a bad thing it's very good uh are very evil driven very mechanical right like s very empirical in a way like no no sort of just knows he's like God this this would work and then it works um so um I think that's a superpower that uh just extremely great synthesis he has the larger he has a larger database um because he's been around for so long he just he literally knows everything I mean he invented half of the stuff that everyone's doing now uh the the uh there's there's no one who who compar um I I'd say um there there are a number of other people I guess just you you you shouldn't fail out of all the people who are sort of the ogs um of deep learning I think you could of Hinton there deserves by far the most credit just cuz he like went through all the bashing when uh when when it was like God this will never work and they're like training like tiny tiny tiny tiny tiny things they're like this will never work and he's almost stuck with it I think that's that level of grit and and belief in something that is now obviously working um deserves a huge amount of credit uh whether capsul n work or not whatever yeah he he he like you know it's it's incredible to come to something like the the the conclusions that that the world is at now and if you look at some of the older papers a lot of the ideas that are important now were in there already so so that's important um and I think he just deserves a ton of credit uman noan Brown had um uh the army of nooms Noom Brown uh I should name myid I should name my kid Noom is what I'm it's a very good strategy yeah the um it's a great strategy actually I think 100% of nooms that are like somewh popular and well known in the research Community are great yeah no he's he's he's also amazing I mean a number of labs were working on what he was working on during his PhD and he basically soloed the thing uh and and was like way better and way faster than Labs that put 10 people including some really famous names uh on it and if you just look at the paper track track record like was like look here so the rest of the field and then no 100 X's efficiency and then here is the rest of the field then Noom life does it again and it's just consistent uh I think the consistency with which he has just bashed um out uh these 100x multipliers in in RL uh data efficiency and and computer efficiency is is crazy yeah so so yeah no Noom uh the Noom Army is pretty good I want to go back to this concept of you know leaps are still needed in research and that you still have this AGI to-do list like yes what what do you think are the most interesting unsolved problems in AI right now well so a lot of it is solved now I think and uh the thing that remains to be solved is uh General uh domain uh long Horizon reliability and I think you need inference time compute test time compute for that so You' want um when you try to prove a new theorem in math or when you're writing a large um software program or when you're writing an essay of reasonable complexity you usually wouldn't write a token by token uh you you'd want to think quite hard about some of those tokens and um finding ways to spend not 1X or 2X or 10x but a million x the resources on that token uh in a productive way I think is really important that is probably the last big problem fasinating the last one okay I hope so I think it's reasonable to think that is the last big unsold I mean look over the last few years all of this other stuff got sold like oh can we do multimodal things can we do long contexts can we do all this gone reasonably smart models you know they're they're quite efficient now in terms of cost that I mean it have to be a reality denier to like not see what's coming I mean this is just a this is like a realization to a lot of people in the LM space but but like RL has been doing this for like ages so so it's just like so clear that you need to do that um or I mean maybe you don't need to maybe you can get away without doing it which be insane but if you don't need to it will still help you a lot like it's just it's just like do I want to spend a billion doll on my pre-training run and then like a little bit more money on inference or do I need to spend billion on my preing on IID for you know like 10 billion would be great but I'm going to be I'm going to be I'm going to prefer spending one um and and is bringing is bringing like the llm and RL worlds together is that like a research problem like there's still like fundamental like unsolved science problems or is that like a you know we have the recipe we just need to do it and and have the comput and the data I think uh there is no public uccessful recipe right now um there are good ideas like okay even if you take best of n make n large enough it's sort of you know it's not terrible yeah um the so there are ideas um I don't know that the final idea exists I think there's just a lot of room up from what is currently known but but there are ideas see I I I think it's very unlikely that even if you stop progress in research we would not at some point hit something that everyone would agree as AGI is just it's just that I think we can do better and maybe it couldn't REM right maybe it couldn't do all these like super hard things but it'd be pretty good and now like I'm just curious like okay like what's the actual like if we did all the things uh how good will it get uh so so um I think there is research uh left to be done and uh there are a lot of ideas floating in the world now everyone's sort of working on this but um I don't even I don't know that the current set of ideas is even final like it it'll be it'll keep moving I think let's transition to talking about magic um maybe just what what is Magic you you've been very mysterious to date so maybe just share a little bit about what you're building yeah uh I mean we're trying to automate software engineering uh the it took us a while to figure out how to train super giant models um it's a pretty interesting engineering challenge I mean fundamentally we're trying to automate software engineering from uh the product side uh and and and like a subset of that is a model that can build AGI because if it's if it's like if it's a great software engineer then you should be able to do everyone's job at Magic like if you can do everyone else's job like that that would be a upset so um the idea is that you could use this to um recursively uh improve alignment as well as uh models themselves in in a way that isn't bottleneck by by human uh resources and you know there aren't that many Noom shers in the world uh if if I had a no shazir in my computer I could spin up a million of them and maybe alignment would just be solved uh I'm was like simplifying Aton and very idealistic in in the statement I'm happy to turn this whole thing into a skillable oversight uh podcast if you'd like but um the um the core idea is is like okay like if I could just clone what we are doing into a computer and then press uh yes on the money button uh to run a cluster uh to to do the work we would be doing next week uh that that that would be phenomenal uh so so I think we sort of we're pursuing these two things in tandem where we want to ship something that's a good AI software engineer for people to use it's it's like I think one of going to be one of the first domains to to see higher levels of Automation and I I I don't like talking around I don't think the whole assistant pitch is going to last very long once these models are good enough to automate like there's just no way the economy is not going to do that uh and I think everyone knows this and they're just like they just don't like talking about it it's it's totally fine the world we used to all be Farmers we're not Farmers we're fine everything prefer everyone prefers this I think we'll figure our figure our way out in the economy if it produces the same or more stuff with less inputs like we should be able to figure that out that's not a hard problem in like from like economic principles you just have to figure out distribution anyway um but that's what we're trying to do we're trying to automate software engineering and as a part of that automate ourselves uh in doing the work we want to do and so the reason they go after software engineering then is that is the kind of lever that allows you to to admit everything else it's like the MVP of AGI right like the the the minimum viable AGI yeah cuz then it creates everything else like yeah we we we wouldn't train something like Sora Sora is great you know fantastic generate videos awesome uh it's just not interesting uh from an AGI uh perspective if you believe that models can cope themselves soon totally and so out of all the companies that are trying to build an AI software engineer you are probably the only one uh that is really taking a uh vertically inrad approach and training your own models and that is either insanely Brave or insanely crazy and pro probably a combination of both um I'm I'm curious like why I know you love training models and so I know that's part of it but like why do you think you need to own the model to get this right and like how do you motivate yourself um in kind of the David versus Goliath of like knowing that open AI exists and has great people and cares about coding and um is great at building models obviously like how do you think about that entire Dynamic I think you need well to build the best model you need to build the model uh and we want to solve these fundamental problems you can't rely on an like if the API guys solded it then what the hell are you you know we might as well start the company 3 years later it goes to the point when we started right we we started working on this stuff um two years ago so we we have you know it took us some time to learn how to train these large models like it was really I think it took open AI two years to get from gbd3 to gbd4 uh as as well and I thought we could be like much faster and this is going to be great is it's a pain so it's definitely an engineering challenge uh but it's necessary like it's not like it's not think we're doing it just because it's fun or because I like training models it's it's a massive Financial investment that uh people trust us with uh that and it's it's not like it's one of those like one to one Roi investment it's like if it's work if it works it's fantastic and if it doesn't work the GPU is ran and the money is gone uh so like you're you're getting a lot of people's trust uh doing that it's certainly not something you should do just because it's fun and you enjoy it um fundamentally I think the value will ACR at both at the at the AGI and at the hardware level and never at the application Level there's no incentive at all to offer an API if the API creates a hundred billion doll company you will just build that company internally uh it is and and if if open AI doesn't someone else will like it's it's it's it's just incredibly unimaginable to me that that would be how you would build these companies in the first place so from a business perspective I don't think that's necessarily the right way maybe there's some partnership potentials you could like oh we'll get the expens access or whatever and then different from like cloud computing right like there's there's been many1 billion 100 it's much much much harder to build Netflix and Airbnb and Uber than it is to build a chat interface like fundamentally magic is an application you press download on that we have couple guys working on and it's just there like it's not you know you can build this with like YC preed money the modes in I guess I to make the API twice as expensive for the next model and then launch my own product and then undercut every it's it's really  to not own the model um in in in in this domain and in any domain that's going to generate a ton of revenue for a single company um in the case where it's distributed maybe it's fine but I don't think this will be um so so it's necessary both for the market which is good for us because the market is incentivized to fund folks like us um uh which which it isn't in other domains like have have fun writing like an email assistant you're not going to get that funded anymore uh so so so that's that's helpful but um fundamentally the reason we train our own models is because it's necessary for our mission and um I just wouldn't be interested in building like a nice little sass rapper it's just not like that's not every that's going to happen anyway and and I think though about competing against the 800 pound gorilla is like you've raised a lot of money but some people have raised boatloads of money they raised a lot more money too oh and well some people have a have 100 million plus in Revenue a year that they can spend so so it goes beyond even who could raise yeah absolutely and so how do you like how do you motivate yourself to compete in that in that uh you know reality the question is how much does it cost to build AGI and not how much money can you raise uh cuz if you can build AGI for however much you can raise uh and you're having more might help you but it won't get you there substantially sooner right like if you have all the right ideas and you get you can build it with a certain amount of Hardware like by definition like okay if someone had like 100 times more Hardware would it be like Computing that much faster or whatever but uh it it doesn't seem like a material advantage if your estimate for how much compute you need to build AGI is not as high as the revenue these companies can generate or the funding they raise is in fact much lower so Y and and I think that is the case uh so it's not by any means accessible it's very damn hard to get that much money but it's not 100 billion it's it's it and if I'm wrong I'm wrong and it'll be 100 billion and we will not have 100 billion and that's it but if we can get to that point where we have AGI and a couple others of AGI and then like the the the the sort of the benefit of additional computers there and you show an Roi it's it's like a reasonably even playing field in in terms of um additional Revenue you're just you're going to bring AI to the market you're going to raise more on it it's it's so the the starting conditions of of like have this Hardware is like you need sufficient Hardware but you don't need more than sufficient uh and and if so that's a bet that's not a you don't know but I think it's a bet with the high enough um probability of being right that it is reasonable to compete in the space and I think it is actually it is reasonable to think that um like the ROI of a of having quote unquote sufficient funding might be better than the ROI of having like infinite funding um early on um is there like an ideal for investors that is not not for me for investors is is there an ideal like team size for researchers is there a certain point at which you reach kind of like diminishing marginal returns of of adding on the extra researcher so one of my biggest weaknesses especially early on at Magic was just scaling the team effectively like we were very single-threaded on a very small number of people doing basically all the work uh in I and um I think we're getting better at that now uh it's also you just need a certain level of maturity of your code base and of your research ideas and everything to to properly segment them um so early on I would have said five uh for that time now I would say closer to 20 and I'm not including like folks working on other stuff I'm including folks working on like the models and everything i' Say closer to 20 uh I could imagine that in a few months I'll say at a slightly larger number especially when you get into large scale deployment you really want to have uh very very good uh uh processes uh around just uh having um High reliability availability of services that are detached from each other etc etc so then you can segment even more uh which which obviously stuff we're working on now um but um it sort of grows over time I I don't see it ever exceeding like the tens of people and right now it's in the Low T very low T but I don't know maybe it's it's a skill to be able to utilize if you're able to utilize 200 people you're just a better CEO than I am uh the the no seriously if if if you can it's it's a good skill uh and I think part of why I say a smaller number for us is that there is a ton of stuff we just don't do like we if we if we built a video model that would just be a separate team they built a video model and like you know that's that's more scaling so so to an extent we're more focused and that's why we're smaller but uh also if if we could double the team and be twice as fast that's that mean I would do it any day um back in ear was it late 2022 when I first met you um at the time like it was marketing assistance and email assistant were all the rage and you were the first pitch that I heard that was AI that feels like a colleague and I just remember that really sticking in my brain so in some sense you've been thinking about kind of like agents uh to use a buzz word longer than anyone else um maybe share your vision for that and like what what you think it takes to build a great agent fundamentally there are two tiers here I guess three one is useless the next is assistant that you have to micromanage and then the the next is the thing that manages you basically where you're it's sort of more like a colleague you could I think the layer where it's exactly even doesn't really exist cuz it's sort of this like little thin Point once the model is more competent than you are um you are there to give it guidance on what you want to be accomplished and um answer clarification questions but you'll never have to tell it like here's a bug uh I'm not saying that this is V1 of everything I'm not saying this is to be one of our product but F fundamentally that has to be the goal like the way I feel when I talk to my best engineer that's how I want to feel when I talk to um where we have a discussion he's almost always right and then he just writes the code and then he someone else reviews it and then it works like that experience where my job is exclusively saying like here's kind of what I want uh and then they help clarify even right like I just want here specifically that like that you you it should feel like that um and everything else doesn't matter to the user uh like what tools the Asian uses how it works does it run locally in the cloud does it need a VM does it have a browser I don't care doesn't matter our problem not your problem you care about your problems getting solved so fundamentally that's what I think matters to customers and everything else is dependent on exact product shape exact domain except exact everything and like I'm stubborn as I just don't want to launch anything that isn't that uh we will probably have to uh but the I I just really want to get that thing like I want to talk to my computer go and have lunch and come back and it built AGI like that's the that's that's the end goal right and uh there'll be there'll be checkpoints but but that yeah I don't think anything else matters uh the how how you accomplish that is uh is is up to individual company yeah how far away do you think we are from from that or I guess maybe maybe break it down into a little bit more we met in 2022 you learned how to extrapolate Eric's timelines um so uh maybe yeah one and a half or double everything I say but uh I think very soon like very small number of years I don't want to give a number now but very small number less than 10 oh definitely less than 10 I mean way less wow okay because I'm seeing some of the like the S agent uh stuff that just came out they're like 14% on sweet bench which feels like I mean 14% I just don't care about 14% like I I'm I'm I mean we we like I don't know if 80 or 90 is good enough like I like I I I think you need 99 like even 96 I don't trust my computer like I don't want to review the code if I have to like the tier of product where I have to review the code is fundamentally different from the tier of product where I don't have to review and understand the code and like you're not talking about 95 when you when you don't want to review you're talking about 99 something you're talking about whatever my developers accomplish plus some same as with self-driving cards like so the the difference with self-driving cars is like you die if the thing crashes and here you just have to review codes so it's launchable before but but fundamentally you need way way way more and like usually the last few right like the nines are hard to get um so yeah but but no I think you can I I don't know I I don't people have um I mean models have surpassed all these benchmarks I mean just recently the math benchmark right like way faster than even like for prediction markets assumed then like I I don't see that stopping um there's just too much like if if everyone was stuck and I I realized there some perception in the public that oh gp4 is like only like not getting much better get no um okay we're gonna close out with a lightning round um one more answers uh one what's your favorite AI app not magic probably all the invisible ones still like my spam filter and all this stuff uh just the things that keep life working I think are still at the moment more useful than the sort of AGI like apps cuz if you took them away like life would just be awful um like recommendation algorithms uh for whatever uh I think that's really useful uh um um other than that U yeah I think whichever uh you saying other than uh the let's say the other than the programming World um other than magic I I actually don't yeah but I'd say whichever model is currently like best would it's a very boring answer but I actually picked the SP filters Etc the recommendation Services first uh what paper has been most influential to you I don't think this paper is relevant at all in the world anymore but it was the first paper I ever tried to deeply understand like or spent months on it and reimplemented it and everything um and so it was most influential to me as a person not so much to my current work um and uh the the paper is called Deep stack it's one of those uh neural networks plus u imperfect information game solving papers it's reasonably complex for time it um uh yeah so it's per folks are interested it's it's like nowhere near s now but the uh it's s of just an irrelevant type of Al but the the at the current time at sorry right now back then it was useful um so that was very inal for me because it was just my first touch point with research uh really I I had no idea how to do research at all and then I sort of just was like I'm going to dig into this the way people like people like hyper rolling spam on Wikipedia where you like Revit hole I did that with this paper so I love it okay that's going to be my weekend reading uh last question um what are you most excited about in AI in the next one five and 10 years um just what it's gonna what's how Society is going to integrate with it um I think that's we're getting to the point now where it's really going to impact uh over the next one to five years it's really going to impact um how Society does stuff and Beyond just you know another tab in your browser that speeds you up by some percentage on some fast I think it'll get much more significant in that time frame and um ultimately you should like the only I I am not one of the intrinsic curiosity type of people I I know most researchers are I really am not I I just care about the outcome and uh that is the outcome so I'm most excited for the outcome Eric thank you for joining us again uh last time we recorded podcast we weren't actually able to talk about the thing that got us so excited about magic uh which was you had shared with us um your long context eval um and our own kind of AI uh researchers had gotten really excited by what You' accomplished on that and that was actually what Led Led to us investing in magic in the first place uh so you just made some exciting new announcements around the eval I was hoping you could share it with our audience yeah for sure thank you so much um yeah I mean we've been running around with this uh like hashes eval for a while um basically just being frustrated by uh need his eval and uh you know everyone keeps complaining about it and now that we we've decided to announce our uh where we're currently at and in terms of uh our context work um instead of just like you know blah blah talking about like oh we have so so many tokens um of context um it felt reasonable to to share the eval as well I mean we we've used it in our fundraising obviously and thanks thanks for for for backing us um and and generally just used it to guide our um our architecture development and our research so uh yeah Fel felt right to open source it and let others compare their architectures and their results with ours uh and then you know we yeah so it's exciting to share and thank you for for having back on to talk about it uh y thank you can you say a word on what's broken about needle and Haack and and what your eal does differently yeah for sure uh you know with with needle and Haack basically what you're testing is like find this weird thing the needle in in this giant pool of not weird stuff uh the he stack and so really all you need to be able to do to do this um is to sort of take like a little backpack and walk from the start of the context to the end of the context and like find the weird thing put it in your backpack and return it um you if you have to like sort of you have to sort of implicit prior that there is this thing is weird so you're more likely to remember it which sort of means that you you actually don't need to remember the whole uh the whole context window you don't you don't need to know all of it um and so so that allows you know some models I would say uh to to sort of look like they're doing this uh doing long context really well when really it's not working um as well so we decided to just go the complete opposite um super hardcore mode and just replace everything with random noise uh there's no semantic information at all because it's just randomly generated uh uh letters right basically just hashes um and uh if if you did something like needle and heack in a pool of hashes uh you really have to know the whole thing uh but then what we what we do is we also do a hop um so it's not just you find this one thing but you find this one thing and then you find another thing as obviously you know you can keep that going but that um that those two Dimensions I think really are the important quantitative components of context there are other things you can measure uh much better in in more domain specific evals of course we care a lot about code and so so we look a lot at that too uh internally but I think you know from a general purpose context evaluation uh perspective and the reason we chose to open source this eval and only this eval is just that you know I think this quantifies exactly what you want to measure when you think about long context that everything else is sort of domain specific um but yeah you you want to be you don't you want to be forced to remember the whole context window when you're talking about the context window otherwise is it really that big like yeah totally I remember our own researchers were just blown away by the the purity of the of the eval and um how well done it was and so thank you for what you're doing um and thank you for open sourcing it especially in an age where long context is becoming more and more important congratulations you back y cheers of course thanks Eric [Music] w [Music]