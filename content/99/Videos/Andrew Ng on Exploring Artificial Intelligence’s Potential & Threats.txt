to AI systems actually understand the world or the scientists calling stochastic parents I think AI systems do understand the world and they're also kind of getting better at explaining what they understand what they don't understand in fact you know this is term stochastic para this is just parroting words mimicking intelligence um but I but but there was actually one study that really influenced my thinking called Othello GPT in which a model was trained to predict the next move on a game of Othello when we think about existential risks I think there are existential risk to humanity I think high on the list would be you know maybe the next pandemic fingers crossed or I think that uh global climate change is a risk to certainly a large fraction of humanity what an asteroid did to the dinosaurs there was many tens of millions of years ago so it's less original it's probably not going to happen in our lifetimes but who knows a very likely have in the lifetime setting but to me we look at the actual things that could be the extinction of the humanity I think AI would be part of the solution hi I'm Craig Smith and this is ionai in this episode I'm going to talk to Andrew a well-known researcher and Pioneer in machine learning Andrew has taught courses at Stanford and trained many of the AI luminaries working today for a time he was the chief scientist at Baidu China's AI Giant and he co-founded Coursera the online education company currently he has an ml Ops company called Landing AI which has a suite of tools to make it easy for businesses to build deploy and manage machine learning models I wanted to talk to Andrew because he's on the Optimus side of the so-called threat debate arguing that AI does does not pose an imminent threat to humanity and that there's plenty of time to work out safety protocols guard rails and international agreements to prevent catastrophe now here is Andrew to begin with do you believe that AI poses an excess existential threat even in the long term uh no I don't I'm trying to keep an open mind but I'm having a really hard time seeing how AIG is a I know Jeff Hinton and Joshua banjo have both spoken about the extinction risk to humanity from AI I spoke with both Yasha and Jeff and what have the deepest respect for them I'm trying to follow the reasoning I'm struggling myself to to see how AI was a fantastic technology making Society much better off I struggle to see how that creates any meaningful Extinction risks of humanity yeah uh and and just for people that that haven't been following the debate but see the headlines there's no evidence no scientific evidence to support the notion that AI poses an existential threat uh right it's it's it's it's it's Theory it's uh speculation yeah so you know I feel like um the two arguments about AI potentially causing an existential relative Humanities the two arguments I heard is one is um what if AI is so powerful you're not gpd4 but gvt 25 or something um uh allows some really angry person uh or maybe someone that you know to create a bio weapon um that then causes Humanity to go extinct I think the rest of that seems small um because it's actually pretty difficult to wipe out Humanity no matter how angry one person may be um uh I do think that there's a risk of you know meaningful harm someone could create a weapon maybe but Extinction is a scale of risk that that seems very unlikely very implausible to me um yeah and and the second argument that heard is uh sometimes it's been called the pay-per-clip argument not the diminishing with that technology but you know whether someone mispecifies an AI objective like build a profitable company but it figures out the way to make a lot of money accidentally wise out Humanity I think of an AI as smart enough to do that it will probably be smart enough to understand our intentions uh and you know so many people work on AI safety so AI is smart enough to accidentally wipe us out we'll probably be smart enough to know if we said make a lot of paper clips we did not mean make a lot of paper clips and along the way respond to Wi-Fi Humanity so that seems you know unlikely to me as well yeah is is there a way that lay people looking at this debate can differentiate between real risks and speculative fears so I don't know it's a good question it's challenging so AI just technology it does have short-term harms today they've been documented cases of bias unfairness um you know we've seen that poorly program self-driving Health Systems can lead to car accidents these kinetic events that lead to human death right now so if you like there are those homes and AI researchers aren't working as an address one nice thing about large language models uh like chai GPT Bots various models is I do see many researchers working to make them safer so they're getting safer every month right now so if you good about that um you know I sometimes think about the aviation industry with the rise of Aviation airplanes were really dangerous they crashed they killed people completely tragic no no excuse for really airplane crashes having said that Humanity we learned from the airplane crashes and over time aircraft got much safer today I think the sphere about some aspects of AI because people say you can never control a large language model and you know what else you can't control you can't control an airplane either you can't perfectly control when airplane points because winds will blow around and sadly even today even you know in society today there are occasional airplane crashes which are very tragic and these are really catastrophic loss of human life having said that I think Society seems much better off to me with airplanes uh than than not and even though we can't perfectly control an airplane we can control them pretty well so when I got in the airplane just a few days ago I felt fine you know working on my laptop and not really worrying about the plane crash um and I think that we're on that trajectory as well that large language models even the last six months have gotten much safer much harder even for someone malicious to make them do something bad although I think it is still possible for some malicious and determined but I think that over time um the rest of either accidental or malicious harm it seems to be going down rapidly and I don't think we'll ever fully control them but we can't fully control airplanes either and I feel okay getting in one and adjusting my life to one yeah a couple of questions one this um concern about AI senders really on intelligence how intelligent AI systems are becoming uh and it and and there's the debate that well you won't know when when AI reaches super intelligence because it won't necessarily tell you can we objectively measure the understanding of AI systems do you think so this is debates about you know do AI systems actually understand the world or are they um sometimes calling stochastic parents I think AI systems do understand the world and they're also kind of getting better at explaining what they understand what they don't understand um uh in fact you know this is this is term stochastic para this is just parroting whereas mimicking intelligence um but I but but there was actually one study that really influenced my thinking called Othello GPT in which a model was trained to predict the next move on the game of Othello the game of reversio Othello and the authors of this study which is published in the iClear conference I think demonstrated that um the way to predict the next move in this game is to actually build a world model and specifically the office down that if you probe the state of the neural network of the being fed you know a set of moves it seems to be learning an underlying representation of the status of the board so it's not just mimicking surface level parroting out what's the next move is actually figured out what the game of Othello is so they're from Melissa moves it figures out what support status the board and therefore whether the possible next move so to me that was a fascinating study you know small scale is just the game of Othello but that really convinced me that I think today's large language models they are building a model of the world and um to me I believe they do understand the world um and also if even large language models says something and you say no you know that isn't right or you added that math wrong step five the fact they can say you know what I apologize my error I did make a miscalculation in step three and now but let me fix step three and this is my new math result for some math puzzle um I think that analogies between machines and humans are always dangerous you know because but but I feel like I don't know that that's very different than how a child learning to solve math work problems for the first time May interpret it where so I feel like the language models are getting better at explaining to us you know how they're seeing the worlds and just like when um when my daughter explains to me how she's thinking about the math problem I believe her you know I think she's telling me the truth so I think when the large language model was telling us how's visiting about the world for the most part I know it doesn't always tell me the truth but I think it tells says something close enough to the truth it feels okay to believe it at least some of the time when it says that's how I was thinking about the problems yeah uh so on the threat uh you know like your your conversation with Jeff sort of the the takeaway was that the research Community needs to come to some consensus about the level of the threat and how to uh counter the threat uh because right now with the uh with the Divergent opinions or the split in the community The public's confused and certainly uh policy makers Regulators uh are confused so how can the research Community Reach a consensus on the thread yeah more conversations I feel like I'm continue to have conversations on with with very different views including those actively read about Extinction to those were about other risks also many people are just busy building valuable applications um but not just me I think of everyone in the community communication you know polite constructive discussion um I think that we can maybe slowly probably be slower than any of us wants um gradually you come to come to a narrower range of views you know I remember six maybe 70 years ago um with a rise of deep learning kind of the wave of deep learning was started maybe 10 years ago a few individuals including most the Elon Musk still gains um warned of some of the rest of AI and I think there was a spirit to worry at that time that that then candidly died out I think we heard I heard much less about that after a while um I think Elon Musk said something like with AI we may be summoning the demon I I may be misquoting him but I would respectfully submit that in the last decade was summoned a lot more Angels than demons with AI um I mean not not to dismiss the harms there have been homs but net AI has been a massive contributor to society um and then and so I think that waiver where is frankly died down this new wave of worries with um buy-in from prominent scientists with you know Jeff and Joshua talk about Extinction risk that was a surprise to me but I think it'd be it'd be it'd be worthwhile to keep having conversations to see where we end up with this as well I'm really trying to keep an open mind even though I I think I said I just don't get it I don't see how AI could lead to human extension yeah yeah uh the the the lack of that consensus uh does does that is that a danger in it in itself that uh that either Regulators listen to the the people who are precious pressing the existential threat narrative and over regulate or though or they listen to those who who say look those threats are are far far in the future if they exist at all and under regulate yeah so one of the things Jefferson and I said in that video that I posted on on social media or Twitter and Linkedin is um one of the reasons why climate scientists have been an effective force is because they are aligned right so there are economic interests to ignore climate signs and you know let's have lots of and just keep on generating carbon emissions but the fact that climate scientists are more or less you know unified um on the signs of climate change that's made it much harder for economic interests they would find it more convenient to just you know not be regulated to to Lobby Regulators to ignore climate science so I think while AI while the AI Community is splintered it actually makes it unfortunately much easier for you know anyone with an agenda to Lobby Regulators to whichever argument is more convenient for the business um so the air conditioning unified then I think like climate scientists have we collectively do a much better job um helping Regulators unleash AI to treat all the value it can while also mitigating against realistic risks and and just be clear when we think about existential risks I think there are existential risks to humanity I think high on the list would be you know maybe the next pandemic fingers crossed um um or I think that uh global climate change is a risk to certainly a large fraction of humanity um and and you know what the asteroids did what an asteroid did to the dinosaurs there was many tens of millions of years ago so it's less urgent ever it's probably not going to happen in our lifetimes but who knows but very unlikely having their lifetimes I think but to me we look at the actual things that could be an extinction of the humanity I think AI would be part of the solution so um AI I I don't think the world responded that well to the last pandemic but I think AI enabled drug Discovery and um monitoring of disease conditions that seems important to me um as climate change becomes worse I think AI enabled solutions to mitigation into the smart grid to accelerate the electrification of society or candidly I often think about climate geoengineering um you know do we need Solutions like using high altitude aerosol sprays to slow down cooling of the planet or if not doing it now because it's a dangerous technology certainly to advance the science of climate zero engineering with AI enabled modeling the climate so we better understand if this is even an option we should seriously consider so if we look at um the real Extinction risk the humankind um and at least the one cycle foresee more clearly AI seems like an important piece of the solution so I would say if you want Humanity to survive and thrive for the next thousand years I would rather make ai go faster rather than slower I want to give a shout out to this episode's sponsor Masterworks an art investing platform that buys contemporary Masters outright works by Picasso and bankski and Warhol and others then qualify it with the SEC to offer it as an investment net proceeds from the sale are distributed to its investors last year most investors lost money even with a diversified stock portfolio and that's why some of the biggest money managers in the US have been looking outside the stock market for assets with low correlation to traditional Investments things like fine art the opportunity was exclusive to professional investors until now Masterwork makes it available to ordinary investors like me since the Inception they've sold over 45 million dollars worth of artwork and so far all of Masterworks exits have delivered positive net returns for their investors of course historical returns are not a guarantee for future returns I'm not a financial advisor so do your own due diligence there's always a risk of loss Masterworks has over 750 000 users and their art offerings usually sell out within hours which is why they've had to create a wait list but ionai listeners can skip the line and get Priority Access right now by signing up at www.masterworks.art backslash ionai e-y-e-o-n-a-i all run together take a look and see what you think yeah yeah I agree I mean that's that's uh an argument I've given around the dinner table that uh the real existential threat is or the confirmed existential threat is climate change and AI can do a lot to help else adopt or mitigate that the uh in fact in fact you know a few years ago I think Joshua Benja and I were both authors on this but David rolnick um another really nice survey uh paper um on you know uh uh all the ways that on many of the ways um that AI can play a role in climate change so that that paper which which I I I'm still really others you know David rolink and others did all the work but she's quite proud of having participated um in that work to Think Through how AI yeah what plan would change yeah that was those foundational paper for climate change AI I remember that yeah uh the uh there's a lot of concern on the threat side uh and not only the existential threat but immediate harm about uh open source AI systems uh and the that allow people to build uh beyond the purview of of uh Regulators or or uh um you know corporate management and that sort of thing I was surprised to find recently I mean I know you were it was quite a while ago but you you were at Baidu I I was surprised to find that there's a very robust open source ecosystem growing up around um large language models are large models in China uh do you think that open source uh is is a danger and specifically on China have you used any of the open source stuff they've uh they've put on GitHub yeah I think the open source committee is a global one um there's a lot of great work in the United States does a lot of great work in Europe and there's also a lot of great work in China so what I'm seeing is that um open source work is a a fantastic force that is giving access to a lot of people around the world to launch language models um I remember when stable diffusion released their uh you know image generation model right the train model open source um in late 2022 I think uh you know they were justifiably reasonable fears of wow what if this is used for harm or this Open Source One anyone could generate images now whether that goes really poorly and yes indeed it has to be acknowledged there was some problematic use cases uh um but I would say compared to the harm from a handful of problematic use cases to the massive amounts of innovation with people incorporating the models into all sorts of creative you know video and image editing software new uis I think the benefits vastly outweigh the harms I'm not dismissing the harms at all I think that you know the models do exhibit bias you also the generate people of certain professions that only generates pictures of one gender or narrower range of ethnicities those are real problems that we need to work to solve I mean there's certainly negative harmful use cases of you know deep fake imagery um having said that what we've seen so far is that releasing open source seems to create much more benefit when when weight against the homes so I'm nervous about um proposals to require licensing of models open source models it seems like an absolutely terrible idea of those stifle Innovation and lead to regular Vision capture where it's much easier for big tech companies to satisfy regulatory requirements thus concentrating power in large tech companies and disadvantaging academic research groups and and smaller businesses that don't have time or resources that deal with already onerous regular requirements that really are not in my opinion effective at really protecting people yeah you know and and I don't want to get off on a dog like on China but immediately after uh gbt three came out there was a lot of talk in the Press about how China is going to be left behind because their speech uh laws uh their laws uh the controls uh Speech restrict political speech uh will limit the the efficacy of large language models and I argued against that to a lot of people because our you know open AI or or Microsoft or or uh Google's large language models also have restrictions on speech so I thought that was a spacious argument nonetheless I was surprised to see open source thriving in China does that surprise you at all just from what you know of China gosh I don't know I I I I don't I constantly have an expert on that um but it has been fantastic to see open source models thriving all around the world um and it's been interesting how Global the research Community is a few weeks ago I was in Canada um for cvpr uh where you know speaking about Landing you guys visual prompting technology um but it was nice to see researchers from all around the world come together and just share ideas freely and collectively right work hard to advance the signs of AI a computer vision at that conference but everybody AI more broadly yeah well actually and I'm sorry I I've left this till the end but can you tell us about uh the visual prompting uh developments that that you've been pursuing at Landing AI yeah so I think the text prompting Revolution uh which are which I've already seen through child and Bard and so on is coming to Vision um and so Landing AI has been developing visual prompting technology uh to make it easy for anyone to build and deploy computer vision applications so maybe yeah I'm gonna flash my nerd license and get technical for a second but in um the text prompting Revolution was really enabled by uh text Transformers right the team I started in once left Google brain published the text Transformer paper in 2017 and since then um there was a wave of innovation by many many research groups uh on you know scaling up text Transformers and that led to gpd2 gbd3 you know I know Megatron uh sorry many models along the way until we got instruct GPU and then chat GPT um and bad and Bing chat and so on not many people know but the vision Transformer paper came out about three years later in 2020 and if you go to computer vision conferences um I think since 2020 there's been this wave of innovation in scaling up and exploration of how to get Vision Transformers to understand images and the underlying trends for both text and vision the vision coming a bit later is these are models trained on very large amounts of data text or images um the training is increasingly on unlabeled data so this you know lets you have access a lot more data or unable or technically self-supervision um and what was already seen in text is with pre-training on neural network on tons of unable text Data you can feed the very simple text prompt and have it make inferences what we're starting to see in computer vision which I think is like maybe a couple years one and a half years two years behind tax is when you create a very large Vision Transformer on a lot of images on the internet um then you can give it a simple visual prompt and then have it start to make inferences in just seconds so that AI will release our take on visual prompting where anyone can go and use it you know go use it for free um to label it prompt it with a few you know label a few pixels and have it then automatically figure out what to do after that as a developer to this is exciting because just as we've seen with text prompting applications that used to take me you know six months to build now anyone can build in maybe a day uh their applications used to take me six months to build in computer vision that you know with our tools is now getting to be possible to build and maybe a day or a few days uh so the Innovation is exciting not just from my team learning AI but for many groups I'm working on computer vision yeah yeah that's fascinating and the the just on visual prompting uh large image models if that's what they are they're they're vectorizing the uh an image of by converting each line of pixels to a vector is that right just yeah patches the image rather than patches yeah but in in they tokenize that in the same way that for a sentence uh the the you you you convert that to an embedding and then you're you're you're trying to predict the next token right yep yes and Jessica yes so I think in uh text based transform is you know the core task sometimes called the pretext task is um to predict the next word or technically predict the next token um so because text has that linear order but they think the next word the next token you know this is a nice way to use unlabeled data um one of the things one of the reasons why there's so much buzz and exploration division is the process for taking an image and converting that to a sequence of tokens there are a few different options for that so you know do you convert to the patches do you hide or mask some patches along the way but but so different researchers are exploring different ways to do that um but there's multiple ways of seem to be working and that scaling up of vision Transformers we're already seeing very exciting results right from let me AIO and then met a Sam segment anything model was another exciting breakthrough I'm just seeing actually when I was at cvpr um you know earlier this year in 2023 um I felt that Vision Transformers have become a solid alternative to convolutional neural networks and the buzz in Innovation I I remember a couple years before chat GPT in the NLP on the text processing Community everyone knew something was in the air about Transformers no one knew exactly what's going to happen but everyone knew something with well people knew something was up and today at cvpr I feel like something's in the air people know something is up even though the exact application is the exact ways this will get used is still being worked out no and and and your visual prompting uh with the landing AI tool is specifically for uh I mean it's primary use cases for uh labeling images is that right oh no um visual fronting is for uh building compute Vision applications so for example we've used this using it um for cell counting quite a lot of Life Sciences users but you know given a picture of cells in the pikri dish in seconds you can build an application to detect the cells and then post-process it to count the number of cells um or oh no I've used it to handle some satellite imagery Russia a lot of geospatial error imagery applications as well easy might be you know Finding tree cover or you can now do that in seconds and then of course a lot of Landing ai's users happen in manufacturing Industrial Automation and so um for many of you manufacturing defect detection tasks especially ones based on texture rather than shape our visual prompting is like people are built and deploy systems in seconds but I've been surprised also even though I mentioned some of you know what we are seeing as our most common use cases industrial manufacturing um life sciences and geospatial aerial imagery I'm seeing a very long tail of applications as well where many people where many of our users are coming with um all sorts of applications computer vision that would not have imagined and now able to build and deploy them for example there was one group that was um doing cosmology uh uh you know and I I since I'm not an astronomer I would never have thought of doing that with a computer vision visual prompting application facilities the creativity once people have this tool is bewildering just like I think when people had access to chat GPT you know the creativity a few things people did with it was incredible and we're definitely not yet there at computer vision but I think collectively the field is getting closer and closer you know at Landing AI where how where do you uh you personally where are you uh on the spectrum between peer research and and building applications uh Landing AI focuses on applications I mean are you where are you in that Spectrum I think we're a product company but the product uh the two for building so let me AI provide software that makes computer vision easy so the product Landing lens makes that possible but the product is backed by Deep Tech within doing our own internal research on visual prompting for like I don't know a year and a half maybe not quite two years but so I think the the way we approach the product is viral deep Tech so even today I spend a lot of my time um worrying about the tech how do we improve visual prompting and improve the algorithms uh as well as on the product how to make it easier to use that's it for this week's episode I want to thank Andrew for his time if you want to read a transcript of today's conversation you can find one on our website ionai that's e-y-e hyphen o n dot a i in the meantime remember the singularity may not be near but a i is about to change your world so pay attention foreign