foreign first first things first I know it's been a super long day and there have been like uh very cognitively intensive talks which I have loved but everyone should just stand up for a second because it's just like been a lot of time sitting and just like do a little Shake uh you're gonna feel a lot better and I'm and I'm less likely to put you to sleep that way is what I figure great thank you thank you very much for doing that I'm sure you feel better right okay stay hydrated too it's gonna be it's gonna be a long talk no I promise I won't go for the full hour okay okay uh so yes so this is uh the expanding Dark Forest and generative AI uh this was an essay I wrote um about oh and back in January so like five years ago in like Ai and AI time um and I've kind of expanded it into a little more comprehensive understanding of uh what we're about to face down with generator AI so uh this is mostly going to be about writing on the web uh trust and and human relationship so you know like really small topics uh and sadly also AI I apologize um a small footnote is that this talk is up to date as of about two weeks ago um so that means almost everything that I'm gonna say is perhaps completely irrelevant by this point I have essentially gathered some thoughts that relate to a moment that has like just whooshed past us so uh that's inevitable in this industry first a little bit of context is um I am obviously Maggie and I want to lay out all my biases up front I am a designer and an AI research lab called ought we make tools that use language models to augment and expand human reasoning in practice this means we mostly make research tools for academics and for large organizations oh like ngos I just skipped to the wrong slide sorry we're back I'm not going to touch that again to help them understand the scientific literature and make decisions second is that I am what we call very online this means I live on Twitter I know this is a mastodon crowd but sadly I'm one of the bad people on Twitter I write a lot online I hang out with other people who do the same and we all kind of like write blog posts and essays to each other like we're like 18th Century men of letters and this has led to lots of like friends and collaborators and wonderful jobs like I have had an overwhelmingly positive experience of being a sincere human on the web and I really want other people to have that experience and lastly um before I joined Tech I studied cultural anthropology and I think this sometimes can give me a useful perspective a set of Frameworks and tools for me to think about how culture and Society behaves on the web a little bit of like social behavior uh this is a logistical note this QR code if you scan it with your phone will uh take you to all my like slides and notes and links for this presentation so like you don't have to worry about like taking photos or like writing down paper names as I'm going I'm going to reference a lot of stuff um there's also a roughly accurate transcript on there although it like falls apart on the second half because I didn't have time to like make it nice right before I came up here but it will be nicer later and I'll show the skin at the end and it's also on this URL Maggie appleton.com forestalk okay so here's what I'm going to talk about first I'm going to explain what Dark Forest theory of the web is and then then going to talk about the state of generative AI you know as of two weeks ago I'm going to then ask like uh is this actually a problem I'm going to lay out some like hypothetical problems and then we can question if they were valid or not and then finally I want to talk about possible Futures and how we might deal with these hypothetical problems so first to explain the dog Forest theory of the web I first have to explain the Dark Forest theory of the universe so this Theory tries to explain why we haven't found intelligent life in the universe yet so here we are right with the pale blue dot uh and we are out here thinking that we're the only intelligent life that we found uh and we've been beaming out messages trying to find other intelligent life for over 60 years at this point and we haven't heard anything back so the big question is like why where is everyone else so doc Forest Theory says that the universe is like a dark Forest uh it's a place that seems through eerily quiet and lifeless um but the reason for that is that if you make a lot of noise in the universe the Predators come eat you so if you draw attention to yourself you're going to be attacked and destroyed so it stands to reason uh that all the other intelligent civilizations either died out or learn to shut up and we don't know which of those we are yet so the web version builds off this concept it's a theory that was proposed by Yancy strickler in 2019 uh he wrote this article and he described some of the trends and shifts of what it feels like to be in public spaces on the web so Yancey pointed out that we have two main Vibes that are going on the first is that being in public spaces on the web at the moment can often feel quite lifeless and automated and devoid of humans um so here we are a little individual on the web and we naively start to write a bunch of very sincere and authentic accounts of our lives and thoughts of experiences and we're trying to find other intelligent people who share our beliefs and share our interests um but it when we look around it feels like we're surrounded by content that doesn't feel very authentic and human it feels like a bunch of bots and marketing automations and growth hackers are just pumping out this kind of generic click bait content and they have ulterior motives to us we have all seen this stuff this is like low quality listicles like productivity rubbish like growth hacking advice banal motivational quotes like dramatic click bait it's stuff that feels like it may as well be automated and it's rarely trying to communicate kind of sincere original thoughts and ideas to other humans right it's just trying to get you to click and rack up views so this kind of overwhelming flood of low quality content has made a lot of us Retreat away from public spaces on the web because it's just like very costly to spend time and energy wading through this stuff so the second Vibe of the Dark Forest is that there is a lot of unnecessarily antagonistic Behavior at a very large scale so when we're putting out signals right trying to connect with other authentic humans we risk becoming a Target specifically like the Twitter mob might come eat us so there's a term on Twitter called getting main characters just people know what they said this is yeah um so every day uh there is one main character on Twitter and your goal is to not be that character so they usually get piled on for saying the wrong thing or for not considering how their words going to be taken out of context I've actually had some close friends get your main character for like frankly very banal like boring things and it's really quite quite harmful to their mental health um so a good example was I don't know if people remember Garden lady from October uh this is just last year this woman tweeted this really lovely thing about like how she and her husband sit in the garden every morning and just chat over coffee for hours and she like she loves him so much like how nice how nice is this right what do you think Twitter did uh so in the in the comments we got that's cool I wake up every morning and fight my way through traffic for an hour in Miami to get to work must be nice um I wake up at 6am shower and go to work for a shift that is a minimum of 10 hours long this is an unattainable goal for most people oh this one kind of goes on for a bit and then just goes it must be nice to be a trust fund baby with not a care in the world so as usual people on Twitter take things in the best possible light um and there's some this Tick Tock sounded like well is I don't really care if something could happen to you it should have happened to me instead so this is like really a dumb example but it's very indicative of the energy flows uh of specifically Twitter but also broadly of a lot of our media environments at this point right publishing to the open web could make you a target for criticism but it's very rarely the constructive kind so things that you say will very often be taken in bad faith they will be taken out of context and they can be Amplified to very unintended audiences right like this is how we get canceling and pylons uh John Ronson wrote an entire book on this uh it's called you've been publicly shamed and he points to a lot of very um real examples of people who've kind of had their lives destroyed by being canceled or piled on by social media obviously sometimes it's very Justified they say something that is like very um unacceptable that like none of us really want them to to be speaking in public anymore um but it ends up having yeah very material consequences people lose jobs they're alienated from their communities they suffer a lot of emotional trauma and so this makes the public web a sincerely dangerous place to publish your true thoughts right and most of us choose not to engage but then this makes it hard to find people right who are being sincere who are seeking coherence who are trying to build Collective knowledge in public I know this is not what everyone wants to do with the web like some people just want to watch funny Tech talk Dance videos or like unboxing stuff on YouTube and that's completely fine um I'm just interested in at least some parts of the web enabling this kind of productive discourse and Community Building I'm expecting a lot of people here feel the same so rather than it being this like threatening inhuman place where nothing is taken in good faith we want to try to find an alternative so how do we cope with this right we're all like wandering around the dog for our stuff like Facebook and Linkedin and Twitter and most of us realize we need to go somewhere that's a little bit safer so what we end up doing is we Retreat um primarily to What's called the Cozy web so this was a term coined by venkatesh Rao in direct response to the dark web Theory and then can't point out that we've all started to go underground as it were we moved to semi-private spaces like newsletters and personal websites where we're less at risk of attack but even these things personal websites and newsletters are sometimes a little bit too public you can still get Amplified in a way you didn't intend to so we Retreat even further into gate-kept public chats like slack Discord WhatsApp and this is where we spend most of our time right we are trying to just have like real human relationships and express our ideas and these are much safer spaces everything we say can kind of be taken in good faith that we can actually engage in discussions and help have our minds changed on things that we might be wrong about um the problem is obviously none of this is indexed or searchable right we are like hiding our Collective knowledge in these private databases that we don't own or control uh and like good luck searching for anything on Discord foreign so sadly my current theory is that this Dark Forest part of the web is about to expand quite a lot because generative AI um yeah so generative AI is a phrase that refers to essentially machine learning models that can generate content that before this point in history only humans can make uh this is primarily text images video and audio so here are some of the very popular models that I'm sure you've heard of for each media type right like gpt4 and Claude for text mid-journey and stable diffusion for images most people haven't really heard of like the audio stuff as much but it's out there this is obviously chat gbt like we have all seen a thousand screenshots of this at this point right so this is a large language model that can generate huge volumes of text in seconds human-like text and I'm going to assume a fair amount of knowledge about language models In This Crowd mostly because like previous speakers handily did it for me but the key points for us to remember are that they output text that is generally indistinguishable from Human Aid text we kind of usually say they write it like a high school essay level I will definitely get into the flaws of like language model text later but we should acknowledge that these outputs are like astonishingly good most of the time um they are trained on huge volumes of text that were primarily scraped from the English-speaking web I'll talk about that more later and all they really do is try to predict the next word in a sequence right given these 2000 characters like what do you think comes next um and that sounds simple but then it leads to all kinds of complex and potentially useful Behavior we can also now generate images right these are ones from a journey which is kind of the more aesthetic of all the of all the image generators and this is a video I'm gonna see if this plays we're gonna find out hello causal Islands I'm a pretty creepy fake person but pretty soon it'll be hard to distinguish me from a real person yeah creepy hey uh little uncanny valley still at this point um I'm not actually going to focus a lot on video and image in this talk um I'm just going to focus mostly on language models and text deep fakes are definitely a problem I'm just like all fill up in problems so like someone else will need to do that talk all right so by now language models have turned uh into lots of very easy to use products right you don't really need any technical skills to use them so these are a bunch of like very popular copywriting apps that are out there in the world like Jasper copy AI Moonbeam um they're mostly directed at marketers um here's kind of how they work so this is like an article generator you type in what you want to write about so I've said here right like why carbon credits are ineffective like I know absolutely nothing about carbon credits I have no idea if they're actually effective or not so I'm just gonna have this model like write the thing for me so it turns out 700 words on it right and they're actually kind of okay they're a bit generic but it's ready for me to publish right and it does argue that these carbon credits are ineffective um and if I'm someone lobbying against carbon credits this is like quite handy you know I can like generate 100 of these and then like optimize them for certain Google Keyword Search terms and like shove them on the web right like hard days advocacy done um Quality and truthfulness the of this is like clearly very questionable but we'll get into that in a minute um but the point is that this is incredibly easy to do at this point with no technical skills obviously it's not just limited to blog posts and articles any text that can be generated will so here it gives you an array of convenient formats like um presenting yourself on a dating site or writing your wedding vows or uh sharing tips and knowledge which clearly are not going to be based off anything that you've actually learned um and there's every manifestation of this right we have tweet generators we have LinkedIn post generators you can turn YouTube videos into tweets and vice versa right anything any kind of content is quite reusable obviously this is all like a marketer's dream and so most of the examples and tools I've shown are actually have quite a simple architecture they are made by feeding a single input or what we call a prompt into this big black mystery box of a language model I've drawn it as a black box here because we actually don't know much about how they reason or produce their answers like even the creators that we really don't understand how they work um so yeah big big Mystery Box um but anyway we get a single output right and that's like an image or some text or an article or whatever we asked for and we can scale it up to many outputs right most of the companies who make language models have an API we can hit so you can make you know a thousand or a hundred thousand articles but we're still quite Limited in how sophisticated we can get with this kind of like single input single output architecture but we've recently started to see much more sophisticated ways of prompting language models show up so one of the most promising is called prompt uh prompt chaining or composition ought has been doing research on this for a couple years but there's a new library called Lang chain out that's made this very popular and very easy to do and this approach ends up solving a lot of flaws or like weaknesses in language models so usually right they lack a lot of knowledge about recent events they aren't always accurate right you'll hear they hallucinate they don't do maths well they like lack long-term memory they can't interact with the rest of our digital worlds um but prompt training solves quite a lot of these um so the way that this works is you get a language model call and you set it up to act in a loop with a bunch of external tools so you give it a go which is like your input prompt and then you tell it like I want you to observe and reflect on what you know at each stage and like reflect on your goal so it uh you know it thinks a bit uh and then it decides on a course of action that things will help move it towards uh it's a its final goal and it picks from a set of available tools some of these might be searching the web it can write and run code you can get it to query a database you can use a calculator you can hit an API you can connect it to zapier or IFTTT and after each time it does one of these action steps it then reflects on what it's learned and it picks another action and like on and on it goes until it reaches what it thinks is an acceptable output and so doing this makes allows us to get much more sophisticated answers out of a single language model call it's like much more accurate it's able to do much more complex tasks you'll also notice that this mimics a very basic version of how humans reason right this is a little bit like an ooda Loop Orient observe Orient decide and act um it's it's a very simple version of that so some people have taken this further um this is a paper that came out just over two weeks ago on this New Concept called generative agents um so what they did here was they made a Sim game you know the Sims where the people are like playing in houses um except for each Sim they um backed them by a language model architecture that was very similar to what we saw with with the prompt chaining um except it looked a little bit like this um they added some extra things it has a long-term memory database that they can read and write to the little sins can like reflect on their experience and like log what they're doing every day they can plan on what to do next and they can of course like interact with other Sims in the game so they let this run for two days and they saw a lot of interesting stuff uh It produced kind of very compelling and believable human behaviors these little agents would go about their day like cooking breakfast and if it was burning they would like take it off the stove they would chat on one another they would form opinions they would reflect on their life and then they also showed a lot more like emergent social behavior so they told the The Sims or one of them like okay you're gonna plan a Valentine's Day party and then that same like told all the other invited them all and then they all like showed up on time and one of the other Sims like asked another Sim out on a date to the Valentine's Day party like they really had quite uh quite incredible stuff um so this is crazy like a bit of a little bit terrifying um and it's also because there's a new kind of like this agent-driven architecture that's becoming quite popular there's a new library called agent gbt that just came out a few weeks ago again this has all just happened in the last like five seconds um and it now makes it quite easy to spin up agents very similar to this but then they can also perform actions on the web they are very much a part of our existing informational ecosystems but have a lot of agency on their own uh distressing um so I think we're about to enter a stage of sharing the web with a lot of non-human agents um they're going to be very different to what we currently consider Bots they're going to have a lot more data on how to act like a realistic human and I think they're rapidly going to get more and more capable and soon we're not going to be able to tell the difference between one of these agents in a human like very very soon um I'm going to say sharing sharing the web with these agents I don't think it's going to be inherently bad right they could have lots of good use cases like they could be automated moderators they could be search assistants but uh suffice to say it's going to be complicated um so now now we get to talk about why this is a problem okay um so I'm only going to focus on how this is going to affect um human relationships and information on the web um anything else like how we might all end up unemployed or like dead very soon it's like far beyond my pay grade so I'm gonna leave that out okay so um the thing that's changed is the cost of creating and Publishing content to the web just dropped to almost zero like humans we are really quite expensive and slow at making content right we need time to research and think and then we like clumsily string together words and then we want to take a break because we want to sleep and we want to eat we want to shower and then we demand people pay us like extortionate hourly rates for our time like we're very inconvenient as content creators um whereas generative models they are way faster they don't need time off they don't get bored um chat GPT um which is like one of the more popular and accessible models um it costs a fraction of a cent to generate a thousand tokens like zero zero point zero zeros to two um uh which means that like making 100 articles that are each a thousand words will cost you two cents that's a that's a pretty cheap content creator obviously if you use more sophisticated prompt chaining tactics the ones I use that would be more expensive but it's still still within reasonable bounds um and given that these creations are cheap and easy to use and fast and that you can produce a near infinite amount of content I think we are about to drown in a sea of informational garbage like I think we're going to be absolutely swamped by masses of mediocre content I think every marketer and SEO Optimizer and uh strategist bro is just going to have a field day filling Twitter and Facebook and Linkedin and Google search results with just keyword stuffed optimize generated crap uh this explosion of noise is going to make it very difficult to find good quality content and to adhere the signal through this noise obviously we do already have tools that deal with Spam and they filter for low quality content right like we're not going into this with nothing in our tool belt um but I think that there are much more sophisticated type of content that we haven't seen before and I think it's all going to leak through I expect within a couple years we'll like level up our content moderation our filtering our defense systems and we'll find ways to deal with this then we're going to be in a strange in between phase for the next year or two um as a meta note this image is made in my journey and it's the only AI generated image I'm using in this talk but I just wanted to show that AI can do hands now so like clearly we've made progress okay um you can tell that this is already happening because spammers and scammers are lazy as like this is a recent Verge article pointing out that the phrase as an AI language model is showing up all over the place so if you don't know if you ask chat GPT things it often says has an AI language model I do not have a political opinion um and now if you search this it's like it's in Amazon reviews it's in Yelp reviews it's in tweets it's in LinkedIn posts it shows people just like copying and pasting chat GPT straight into stuff which means they couldn't even be bothered to like remove this obvious giveaway and I think this indicates like how much care and detail they're going to put into all their future work um so let's look at some hypothetical scenarios of how this might look so this is Nigel and he's written a book called why why nepotism is great um let's let's give them the benefit of the doubt but like he really wrote this book he didn't generate it okay he wants to be a book fluencer so he spins up an agent and he says to the agent like promote this you know not unlike you would to a traditional book agent and then he gives it access to like all his social media accounts via apis or zapier um and so the agent thinks for a bit and it goes okay well I'm going to generate and schedule like a steady stream of tweets based on your book content and then I'm going to turn that into like optimize for LinkedIn and Facebook versions of that and then let's write and schedule a newsletter that'll go out like every week for six months and then we can turn that into like media articles which is great and then I'll make some like really addictive Tick Tock videos based on your content right and I'll make like a 24 part series on YouTube of like many essays um and then I'm gonna make a bunch of podcast episodes and use your voice that's like actually very easy to do at this stage um and then I'm gonna find other people who write about nepotism I'm going to comment on their stuff and like you know engage with the community um and you know it's a grand success like Nigel's book gets a lot of attention um and the thing is that like none of this is very different to what Nigel could do um and the agent doesn't like make tons of content right it doesn't want to set off like content moderation Flags we don't know where the screen went there we go um you know he doesn't want to like set off any content moderation or filtering stuff so it tries to like look the same way that Nigel would be making this stuff um and like without an agent um 99 of people like Nigel wouldn't have the time and energy and motivation to do this like even though they could even if they've written a book and they certainly couldn't do it with this like volume and consistency of output so now instead of like one percent of people having the time and energy to be prolific self-promotives like these people exist we see them everywhere right now like 99 of people have the capacity to be that kind of person um obviously like we already as mentioned we have a lot of spam on the web and we're usually able to filter it out ignore it but I think the scale and quality of this new um stuff that's going to be coming is something we're not prepared for I think and I also think like Nigel's agent I expect to actually be quite good at writing the content it writes I actually think it might be better than Nigel was so like there's no way they're going to be able to distinguish it by it being worse um now let's imagine how this plays out um with a political group who has like a very specific agenda to push so this is genetic audience they are a bunch of lobbyists who strongly believe in gene editing and they want to spread the good word and they understand scale in a way that Nigel doesn't so they spin up a thousand agents and they tell them like globally influences like we want you to go um look like you are real consistent people and I want you to you know make accounts on most of the major social media platforms and like they can have their own websites and Twitter accounts and they're going to behave just like any other human on the web right we're not gonna be able to tell the difference but each influence is like this one person like social media machine right making engaging educational content about Gene editing right they like publish books and they're like making mini documentaries on YouTube and like they have each other on their podcasts like they for all intents and purposes look like they're just some like influencer you know content ring going on um but again they don't really set off moderation content Flags because they don't look any different to the way normal humans would publish on the web um and the gene genetic Guardians right they just like get a ton of really great promotional content out of this um this is all fairly doable right now it would be quite expensive to spin up something like this um but we should expect cost to drop uh and we also know there are like a lot of really well-funded political lobbying groups out there I wouldn't be surprised if this is already happening okay I do have some good news so let's take a breath right yeah good okay it's a little bit dark uh it'll get a little bit darker but then I promise uh only a bit I'll leave it okay the good news is okay this might not be a problem like this this is possible this is only going to be a problem if we want to use the web for very particular purposes okay so if we want the web to like facilitate genuine human connections and relationships or like to pursue Collective sense making and knowledge building or to like ground our knowledge and reality so if you don't care about any of these things like don't worry generative AI is going to be fine like you don't have anything to work about um yeah we're just gonna have like much more engaging content like tick tock's gonna be like a lot better um so the thing is I'm quite keen on some of these outcomes uh like I write on the web a lot I'm a big proponent of other people publishing their personal knowledge to the web I encourage everyone to do it I kind of like bang on about this thing called digital gardening where you like have your own personal Wiki on the web and you're like put out lots of unfinished stuff um and the whole point of that is right is to like make the spit web a space for Collective understanding and knowledge building right this is something a ton of the other speakers have touched on but that requires us to be able to like find and share and curate really high quality reliable insightful information so I'm really quite worried that generative agents threaten a lot of that at least in the short term until we can like build up our defenses against them so when I talk to my to people about my worries I always get this question right they're like well why does it matter that like a generative model made something rather than a human right like in most cases language models um when they write things it's actually they're more accurate and they're more knowledgeable than most humans like we have benchmarks that show this um at least when it comes to referencing things that are quite well-documented facts out on the web already like they're frankly better writers than a lot of us um so surely right like having more generated content on the web would actually make it a more reliable and valuable place for everyone right and like I'm sympathetic to this point like in theory but there are a few key differences between content generated by humans and generated by models um the first is its connection to reality the second is its social context and finally it's their potential for Human Relationships so I'm gonna I'm gonna go into each of these in detail so first generated content is different because it has a very different relationship to reality than we do okay so we are like embodied humans in this like shared reality of like Rich embodied sensory information and we read other people's accounts of this reality right and we like compare it against ourselves and we're like well do we believe that have I experienced that and then we write up our own accounts and like this is all like a really beautiful system uh where we're like trying to make sense of everything together in this like exchange of information right this is like the core of all Art and Science and literature and like beautiful knowledge building in the world right we're just trying to understand things together um and what we've now done is take that um like whole base of writing and feed it into a large language model which has encoded a bunch of patents in its Network and then form some kind of like representation of the written record of humanity uh in its memory and that model can now generate text that's very predictably similar to everything it's seen before and now here's the tricky bit that we're trying to figure out is like how much does that generated text relate to that reality and in some sense like it is fully unhinged like this model cannot check its claims against reality because it can't access reality it is like a bunch of neural Nets like in a computer it does not have a body like it does not have some channel for it to access and check things um but it's a bit like a fuzzy memory of reality which is where this gets complicated it is based of what on what we've written about the world but it can't validate its claims and we politely call this hallucination which is like when language models say things that like we know not to be true about the world um and in a way it's like a terribly smart person on some kind of mild drugs like it's confused about who it is or like where it is but it's actually really still quite competent and this disconnect between it's seemingly super human intelligence and its incompetence is one of the hardest things for us to understand and resolve uh and a big part of this limitation is that these language models only deal in language right and language is only one small part of how a human understands and processes the world like we perceive uh and reason and interact with the world in ways like spatial reasoning and embodiment and a sense of time and planning and vision and space um and Consciousness and like all of these are pre-linguistic things that like exist in completely separate parts of the brain to language like when you look at MRI scans like when the language bit of your brain lights up like it's like genuinely a separate section and it's not that language isn't important but it's absolutely not the whole of how a human interprets and interacts interacts with the world so generating text strings is not this like end all bill of what it means to be an intelligent human or to understand an intelligent human's world um and so yeah a second bit um language models are also different uh in their social context in that they have a very strange relationship to our social world so everything you and I say is situated in a social context right like I'm assuming everyone here has like a very unusually high technical literacy and so I'm going to talk to you in a way that I wouldn't talk to like my writer friends or my aunt like you just have a very different set of shared contacts with me um and it the same thing as if I meet someone who's from another culture or from another discipline I know I don't have as much shared context with them so we're always adjusting the way that we communicate to the people um what we know about the person we're talking to and how much shared context we think we have so like if I met someone from like Shakespeare in England we could communicate but we'd have trouble on some things and not just because we're speaking like a different dialect of English it's like we don't have the same assumed morals and values we don't have the same assumptions about like how Society works or how science works like there's a lot of stuff that we would have to build up together um so the point is that there is like no truth or knowledge outside of a social context everything we say is in a context is contextual and rests on shared context um but a language model is not a person with a fixed identity right like they know nothing about your social context when you're talking to them um and that they take on different characters depending on how you prompt them and they don't hold fixed opinions and they are not speaking from one stable social position this actually makes some people claim that they're like objective or like more reliable than people who have all these like strange social biases um but the thing is is they definitely do represent a particular way of seeing the world right like we train these models primarily on text scrape from the web like they do include like books and Wikipedia but it's honestly a very small percentage compared to Common cruel which is like this huge scrape of the web um and it's also like 95 English language uh scrape um so they kind of represent this like generalized view of this like majority English-speaking westernized population who have written a lot of stuff on Reddit and like lived between about the year 1900 and 2023 is like most of the opinion being promoted by these models which like in the grand scheme of all of history and geography is like this like incredibly narrow slice of humanity just like the smallest amount uh it obviously does not represent all human cultures and languages and ways of being um and we're taking this like already dominant way of seeing the world at least in our historical moment and then just like generating a ton of content that reinforces that same dominance and we just like don't have enough data from people who have lived far in the past or who are from Minority cultures where they don't have a lot of written written language to them we don't really have enough data to train models on them at least like not right now we maybe don't have the right techniques like we would hope this would improve with time but it's kind of hard to do without the data um and if I put my Anthropologist hat on here and then like look at this problem it just feels like exceptionally tragic it's like our entire discipline of anthropology is all about trying to expand the collective understanding of how diverse human cultures can be and help people realize like both how unified we are as a species but also how flexible and adaptable human culture makes us uh it's like far we order a more wonderful than we can imagine like every ethnography that you read you're like oh my God I can't believe humans could possibly live like that like we're so strange um so this is a quote from Tim Engel who's a really fantastic Anthropologist he's very famous and he says every way of life represents a communal experiment in living the world itself is never settles in its structure and composition it is continually coming into being um so yes so generating a massive content from a very particular single like monoculture way of seeing the world is funneling us down back into that model culture um which feels like shutting down a ton of cultural possibilities and diversity for all the ways that we might live in the future uh you know not to mention all the existing cultures and languages that we might lose by doing this okay lastly um generated content lacks the potential for Human Relationships that human content has so when you read someone else's writing it's a little bit like an invitation to connect with them right if it's someone you're reading on the web you can reply to their work you can DM them you guys can meet for coffee ideally you know become friends or intellectual sparring partners like I've had this happen with so many people um there's always someone on the other side of the work who you can actually have a relationship with and like a lot of us I think would argue this is the whole point of writing on the web like otherwise you're just writing alone in your room and it's like you know that fun uh so this is a still from the film her which is like now this canonical reference point for like parasocial relationships with AI um so this is Joaquin Phoenix and he's like having this wonderful relationship with his personal AI who lives in his earpiece in his ear and he grows like in these increasingly distant from all the humans in his life and he like falls in love with his Ai and the AI like grows Board of him and leaves and he's heartbroken so this is like clearly a lesson saying that like we um trying to have emotional relationships AI leaves leads to unfulfilling consequences right like people are already trying to use agents um to set up like girlfriend chat Bots like this is a very popular thing um right they're trying to use them to fill an emotional void that usually a human would fill um and they obviously cannot fulfill all the needs like the humans have for each other right they cannot hug you they cannot come to your birthday party they cannot get a drink with you they cannot truly empathize right they cannot like tell you about their experiences grounded in reality um so generated content can't facilitate any kind of real fulfilling human relationship on the other end okay so that all sounds quite bad again like the deep breath Break um I now do want to talk about possible features these will not all be dark um this is I'm gonna say roughly over the next five years I definitely don't want to speculate beyond that I could also obviously be writing about all of these I'm just kind of doing a little bit of like extrapolation from what we're currently seeing um this is going to be a non-comprehensive list it's going to be not mutually exclusive um these are just kind of themes and trends that I expect to happen in parallel okay so first is I think we're going to spend a lot of time thinking about how to pass the reverse Turing test my original essay like mostly focused on this it's this question of how we might prove we're human on this web filled with the least generative agents so right we all know the original Turing test right you have uh two humans and a computer in rooms and there's wolves between them and it can only text and pass text messages back and forth um and if a computer can convince one of the humans that it's actually a human it passes the test um on the new web we are the ones under scrutiny right we have to prove that we are actually human and that we are not computers um I think this is going to be quite challenging given how sophisticated these agents are getting um in the short term we can employ a bunch of Tricks um like we can use unusual jargon and kind of Insider terminology that the language models haven't been trained on yet we can write in non-dominant languages that the models aren't as good at writing in things like well she'll Catalan if you speak them writing in those languages is going to give you a big leg up um being multimodal uh so that means like writing in text or video and audio all at the same time I think honestly we have like a six to 12 month like advantage on that before they catch up but for the moment we can still use that and then honestly just doing higher quality writing that is like clearly grounded in research and critical thinking they aren't they aren't as good as us at that at the moment again they might catch up we're gonna see um another possible feature that's related to this is I think we're going to have much higher standards for humans as models take over more mundane tasks so we're going to demand more of human writers because great automated writing writing will be cheap and prolific uh this raises both the floor and the ceiling for the quality of writing um so at the moment right here's like some equal distribution of like exceptional and terrible writers on the web right and most of us are in this like mediocre range so first I think the language models are going to raise the floor because they're clearly useful for people who struggle to write right now right people who struggle because of their education level or because they're writing in a second language uh these people's work will actually get lifted up to be a little bit better I think there's also going to be some dual action with the mediocre and exceptional people so I think some people will actually become even more mediocre I think these are the people who are going to try to use language models to replace their critical thinking right they're going to try to like Outsource too much cognitive work to the model and they're going to end up publishing quite like boring predictable work because by definition that's what language models produce um but I think some people are going to realize that they shouldn't be letting language models like literally write the words for them they're going to realize they can strategically use them as part of that process so these are people who might use them to like develop initial ideas to use them as research helpers is to use them as debate Partners as Socratic reasoners and I think these people will actually get much better um but they will also be pushed to do more original creative work because the world will be flooded with this kind of like higher higher level of content okay uh this one I apologize already for the for the phrase um but it really perfectly captures this point uh I also like polls people whether I should use it in 50 50 so I went for it um we're about to enter a phrase of Human Centipede epistemology uh and I'm not going to explain that but you can Google it later um the point is that um if content from these models becomes our source of truth then the way we know things is simply that a language model once said them and then they're like forever captured in this like cycle of generated information so instead of this being our current model right where like the training data was at least based on some real world experience we're now going to start using text generated by these models to train new models and then that like tenuous link with the real world just like becomes completely divorced from it um this is kind of already happening in the fact that like models are still being trained on text um scraped from the web and we are already publishing lots of generated text to the web so like we are in this cycle um and I think like our shared truth is already on Shaky Ground so uh yeah it's extra concerning um one real risk here is the development of what we might call scientific paper mills so this is people using generative models to write scientific papers that claim to find things that haven't actually been tested in the world um this is usually going to be findings that like benefit particular commercial or political interests um so there's a study done this past December to get a sense of how possible this was so all they did was they took blinded human reviewers and they were given a mix of real paper abstracts and then abstracts generated by chat TBT which is like chat um GPT 3.5 is the model which is like a little bit worse than like some of the newer models we have at this point anyway they um they were like okay these abstracts are going to be submitted to like the five highest impact medical papers that was that was the frame these human reviews were given and they managed to spot uh the GB chat gbt generated abstracts like 68 of the time which is like not too bad but it means they couldn't Spot the Difference for 32 of them and they also incorrectly identified 14 of the real abstract as being AIA generated um so the stats are like still in our favor but given that this used an older model that wasn't sophisticated and didn't use any like prompt chaining and techniques or any of our kind of newer more sophisticated stuff I expect these numbers to change quite drastically um and this kind of takes the replication crisis to a whole new level like we already weren't able to reproduce science and like prove things that are published in journals and now it's plausible that people could write papers that just have no bearing in reality and get them published um right you kind of learn the harsh reality like just because words are published in a scientific journal does not make them true which has always been true but now now a bit more dramatically okay next we have the meat space premium um so I think we're going to begin to prefer and preference offline first interactions or as I like to call it you know meet space um so we're going to start to doubt all people online and we're uh the only way that we're going to be able to confirm humanity is to like meet the muffler and we're going to get a coffee with them or beer and like validate you are a human as well I won't TG you can then confirm Humanity of everyone else that you've met in real life right so like two people who know both of you can then assume Humanity because you have this trust Network going on um there's obviously going to be knock-on effects to this like I expect people to move back to cities and like densely populated spaces I expect much more in-person events um I expect that like being in Meet Space versus cyberspace is going to become a privilege and a premium um because like we shouldn't forget this obviously disadvantages people who can't move to dense urban areas or for other reasons cannot regularly get out of the house to meet people right this is like people with disabilities people who have young children people who are caretakers um or simply people without the financial material means to move to expensive cities um I think it sadly has a risk of like undoing a lot of the connective equalizing power that the original web did um so a natural follow-on to this is to you know put it on the blockchain right uh creating on-chain authenticity checks for human generated content uh on the web is something that I have heard a lot about from people um so this means something like some third party verifies that you're human in real life and that gives you some cryptographic key and then you like sign all your published content with it and that's all linked back to your identity um I'm not like an Unchained person so like I don't know the details of like what this would involve but I know other people here are interested in this stuff so like take care of it right for us that would be great um but this is like a real world thing uh this is World coin and this is like a scary orb that scans your eyeballs and confirms your identity and then like gives you this cryptographic key and then you can like sign all your content with it um ironically or perhaps appropriately this project was um co-founded by Sam Altman who runs openai which like makes most of the large language models that people use he's now just like on the board versus being a co-founder but um he clearly sees like the problem coming that he partially created um I'm also expecting any day now that elon's going to announce this like new purple check on Twitter that confirms your Humanity it's only going to cost like 30 a month you don't actually need verification you just like check this box it's like I am a human so okay those were all like a little bit negative um so let's do something a little bit helpful I think we are going to be able to fight um fire with fire I think it's reasonable to assume that we're all going to have our own personal language models helping us filter and manage information on the web and find good quality stuff so I definitely expect these to be like baked into browsers kind of are or maybe even just like on OS level um and these specialized language models will be able to do things like maybe identify generated content I think that's still up in the air but they can like debunk claims they can flag misinformation they can hunt down sources for us they can curate and suggest high quality content for us like they can solve the search and Discovery problems that like a web filled with crap would cause um we're obviously going to have to design these like very carefully because it gives a whole new meaning to the filter bubble if like everything is filtered through this language model um I think we're also going to find it absurd that anyone browse like the rural web without their personal language model in the middle in the same way I think the very few of us would voluntarily like log on to the dark web and just like click around and see what's there like I think we know what's there we don't really want to look at it um so the filtered web I think is actually gonna become the default okay we are we are almost done um the question that I want uh everyone to kind of think about or leave here with is um which of these possible Futures would you like to make happen or not make happen uh we have a lot of people um who are kind of sprinting to build uh frankly very shallow interfaces on top of chat TPT uh like all the big companies right are trying to like figure out their AI play and like their employees like DM me panicked being like what should I build uh I think it's good to point out here at this point that like generative AI is not necessarily the destructive force here uh the way we're choosing to deploy in the world is and the project decisions that we make will expand the Dark forestness of the web um or hopefully solve some of it um obviously I'm gonna say now if you are working on a tool that enables people to churn out large values of text without fact checking and critical thinking and then like publish it to every platform in parallel like please stop that is like very obviously bad and like not helping the situation but if you're not doing that you'll probably you're probably fine um okay so like let's talk about what we should be building okay I tried to come up with like three Snappy principles for building products with language models um I expect these to evolve over time but this is kind of my fast password it um the first is going to be to protect human agency the second is going to be to treat models as Tiny reasoning engines and not sources of Truth and the third is going to be to augment cognitive abilities and not replace them okay so first um protecting human agency um the generative model system um always starts with this human prompt like we're like hey you should do some stuff and in the agent model we hand that off to an autonomous agent right and then they like they go do a whole bunch of stuff and the locus of agency here is definitely with the agent right herein lies the path to self-destruction right this is what most AI safety researchers are very concerned about right we wholesale hand off these complex tasks to these enormous language models and then they just like go off the rails and kill us it's like somehow The Narrative um the more ideal form of this is that the human and the AI agent are collaborative Partners so this is sometimes called human and loop systems um so they are doing things uh together they are not like you know they are like one symbiotic system and the locus of agency is still sitting within the human but they're these very short feedback loops between the agent and the human there's a lot of close supervision of inputs and outputs and we're giving very limited power to the Asian um this is nice in theory but obviously who holds the agency in a system like this is actually kind of a spectrum and it's quite opaque it's very difficult to understand like who who is the agent at what point um so I think this is going to involve like quite a lot of difficult design thinking and difficult design work um actually Jeffrey and I were like talking yesterday about how there's a bunch of research done in the 90s on like agency and interfaces that apparently we all need to read and he promised to send me the link later and I can add it to the to the talk slides um this ties into principle number two which is to treat models as Tiny reasoning engines and not sources of Truth so at the moment the most uh the way that most of us use language models is kind of as like oracles right we like ask them questions and then like we take things they write like wholesale turn them into essays um and then this is where we get issues like hallucination and like Detachment from reality like that all becomes a big problem but I think they're much more interesting to think of them as these very small reasoning engines trained for very specific predictable tasks um so one alternate approach we could do is to start with our own curated data sets that we actually trust so this could be scientific papers that we know are valid this could be our own personal notes database this could be public databases like Wikipedia and then run many small specialized language models over them that do particular tasks right like they they summarize they extract data they could find contradictions for us they can compare and contrast right they could group things by certain variables they could stage a debate um and some of these will have to pull on like their generalized training data but there's much less risk of hallucination uh when you put it into the scope setting um and we will always kind of have these very small observable inputs and outputs with this kind of model you can always check exactly what the model is doing at every step um and then we also like don't treat treat the outputs as the final publishable stuff they are much more like interim outputs that we are using for our own critical thinking until like we finally write the thing that we want to share um also with smaller models we could like run these locally versus having to rely on something like open AI for all our language model stuff um so language model is actually getting quite good at these very specific reasoning tasks like we use them a lot in a lot of odds products but this is a paper that came out of Microsoft research a month ago um where they explore how gpd4 has a much better reasoning capacities than previous models um so to quote them gpt4 can solve novel and difficult tasks that span mathematics coding Vision medicine law psychology and more without needing any special prompting um they do caveat caveat this by saying like it still makes mistakes right there's a lot that's claiming this is like proto-agi um but it can do things that seem like it would need some kind of primitive reasoning skills um I don't think we should take this to mean like it is reasoning I think that's a very tricky and loaded word and I think we should all still be very skeptical of this and like you know more research needed but it also shows we should maybe rethink what we think these models are capable of yeah okay lastly is to augment cognitive abilities don't replace them so language models are very good at some things that humans are not good at like search and Discovery through huge sets of data doing role play and being able to change identities and characters quite quickly being able to rapidly organize and synthesize like huge amounts of data and then turning fuzzy natural language inputs into very like structured computational outputs right these are its strengths uh and then humans are good at tons of things that like language models are absolutely terrible at like checking claims against physical reality right um they have no long-term memory coherence right embodied knowledge they have no understanding of what it is to dance or run or like do anything sophisticated with a body um they have no social context they have no emotional intelligence right um so we should be using models to do the things that we can't do uh not things that already that we are already quite good at and quite enjoy doing right we should Leverage The Best of both of these like kinds of Minds um saying that language models are like an alien mind that we've just discovered is a very popular metaphor in the community we hear it quite a lot um it's a little bit like we've just discovered them we don't quite understand how to use them when we say aliens I like think of this which is like maybe appropriate for like AI risk like doomerism um but I do at least like the metaphor of it being a new species we have to figure out how to relate to so um Kate darling wrote this really great book called The New Breed and it argues she's talking about robots here she's a robotic robot assistant MIT and she's talking about we should think about robots uh as if they're animals as if they're some kind of companion species who complement our skills right and we work with them we have a lot of um established social cultural like legal structures for how we work with animals and how they fit into our lives and she's saying we should apply that to robots I think that extends quite naturally to AI um so we should just expand and augment our cognitive capacities by respecting their unique strengths and all their unique strengths okay um oh this is a pretty good article but it's like very much on that approach of blending human AI capabilities so this was posted to less wrong in February like I don't love lesserong as a community but they occasionally have some good AI thinking stuff on there um okay good thank you that was a lot thank you all for listening again if you want to see the slides of this talk or links to anything I referenced it's on this QR code or that URL my gearpool.com forestalk um I'm on Twitter at mapletons I'm sure there are lots of people who think I've said at least like one utterly sacrilegious or like misguided thing in this talk um so you can still try the main character be on Twitter like while that's still online yeah questions I was waiting for it I'm out of good questions for today so here's a silly one um do you think there's going to be some kind of equivalent of radiocarbon dating but for large language models like gpt4 being the last good one because all the other ones are trained on themselves [Music] the idea though someone should do that any others so I feel like an artifact of being extremely online and being connected to some of these tools means that we as tool users and Tool creators are accelerating away from the less online um what do you think about that divide um and as you said this was for us and we're like great a Mapleton summary that we can put in our brains what do you think the message is for the less online um that's oh that's really interesting um yeah like I agree a lot of the points I'm gonna do definitely most relevant to an audience who gets most of their truth and information from the internet and I yeah I know a lot of people do not right or just like are not on Twitter all day like that's like a most of the population um um I don't know if the message for them would be I like don't want to jump to like they should have to learn everything about language models like I don't like the idea that we always have to burden non-technologist people with like all business and like make them understand programming and make them understand models and I don't also don't want to frame it as like we have to protect them as if like we have all the power like us the world Savers like that's like the AI safety's like favorite thing to jump on to it's like we will save you all from this problem we invented ourselves um I don't know if I have good answers to that I want to think about it thank you so much for your talk it was so fascinating um I'm a marketer so I'm triggered right now I'm sorry sorry um but in a really good way in a really interesting way because yeah I've definitely seen you know like Jasper like showing up on my my Twitter like marketing to me to use that and um it makes me think so you you have that example of you have these different agents and they're creating they're basically doing content marketing social media marketing email marketing and they they have to do this in a way because that's the marketing cycle like that's the funnel that's like how we're trained to do marketing um and what has been effective so I'm wondering what your thoughts are on in these possible Futures do you I know that's kind of a big question but like what do you think would be like the future of marketing in that sense um it's a good question uh and I think a lot of Industries are going to have to like grapple with this of like what's our role uh I think it ends up I want to like say manager because that sounds like a little bit depressing but a little bit of like orchestration um you know if this all goes really well like you know not something like the dog Futures I painted right where we have these short feedback loops and like we are very much like the agencies with the human and we have these like wonderful tools that can help us do our jobs but it's not like replacing us or like taking over too much agency and kind of like running a Mark um then like as a marketer it's like you would have a whole bunch of tools that just like let you do less busy work and that you can just kind of like spin up a whole bunch of maybe marketing content and then you can review it and you're like the quality control barrier in this so I hopefully it would just like make your job a lot easier but it would be more one of like orchestrating many agents who do lots of micro tasks for you and then you're like validating their work and like then feeding it through or approving it over here hi yeah so jpt4 can kind of already deal with images and we've had like Natasha Jake and the other researchers working on this social aspect of AI of how AI can understand emotions and even try to replicate them and we have folks who work and stuff like him body of the eye both of those researchers has been doing that even before we had tragic PT and once you know everything like that gets connected watch last for us okay [Laughter] um I think I'm a little bit skeptical of I know there is work happening on trying to make like AI systems more embodied um I'm like quite skeptical of them achieving maybe what we would think of as a human human level intelligence I think they could achieve other levels of intelligence that is not human intelligence but I also think when we go through like okay we'll just like cell grow it in a lab I'm like at that point just make a baby like it's much easier like it's much cheaper like why spend just billions of dollars like making a fake human to like achieve AGI when like we are really good and we're actually quite easy to make if anyone's like noticed like it's not that hard to make it okay it's kind of hard to make a baby but it's not that hard um yeah that's like my current take on it I don't know what's left for us if we do manage to make the creepy robot baby over here so you were saying that you could train on like specific Trader sets so theoretically you could make customized spam and customize phishing emails that yes uh I was gonna mention somewhere in this talk that like someone should really do the information security version of this talk because it is dark and awful and like I didn't really want to go too much into it but like deep fakes or Eminem like you can like fake someone's voice very easily like targeted fishing and spam attacks I think are definitely like a risk that are about to come up like yeah I would say infosec is hiring right now it's like what I would imagine hi Maggie I'm Jasmine I'm working on Trellis um considering working on something after trellis which is like a worker Co-op proof of humanity org and I'm wondering you mentioned World coin um I'm curious if there are other proof of humanity like researchers or organizations or like any other Alternatives that you think highly of or anything that you wish would exist um I actually don't know of any like when I wrote the original essay um I don't know I've had a lot of you know great comments on Hacker News um and some of them were pointing out uh this thing of like oh but we'll just like solve this with like on chain Humanity but no one pointed me to any companies or people doing it I only found World coin so it doesn't mean they don't exist but I actually haven't come across me any other questions oh one of the things you spoke about that I really liked was the use of autonomous agents is small like Blobs of reasoning for doing things like taking unstructured data and so on and earlier when you and I were speaking you mentioned doing a lot of research on knowledge graphs and so on so I guess I was curious whether any of your research has involved using llms alongside Data Logger knowledge graphs or anything like that and if you could speak to that a little bit sure I guess at all um so like the product we make is yeah for researchers they can like type in a topic and then we give them essentially structured data that's extracted from scientific papers um and one thing we keep trying to figure out if we can do and we can't quite get gpd4 to do it yet or at least to the high enough quality that we want is but is to figure out okay can we just like make a knowledge graph of like I don't know every like claim made across like all these scientific papers or like every piece of evidence and like connect them all up and it's like it's like a citation graph but with the actual content of the papers um we haven't found the outputs a high enough quality yet it might just be like we haven't found what we call the right recipe which is that like chain of many small language models and other tools all interconnected um but it's definitely something you want to explore and I know there are other people working on this like trying to create big knowledge graphs using LMS it's like the structured database yeah it's probably a good startup idea if anyone really wants to cool thank you Aggie thank you so much thank you [Applause] foreign [Music]