[Music] foreign [Music] two opinions or three like uh why do you don't trust an AI here in this role oh over there in what oh you don't trust people okay that's one point another one uh-huh okay one more foreign ER Bryson here next to me and she uh couldn't be the better here on stage for this topic because she is Professor of ethics and Technology this is your stage okay thank you all right yeah I'm Joanna Bryson and I have way too many slides so I'll just go fast if you don't understand me you can raise your hand and tell me to slow down all right so what even is trust I think that's one of the questions we have to answer before you can answer whether you trust Ai and um there's a something called the trust game that economists and psychologists have worked out and so they have two people one person's given money and then they're saying there's another person you're never going to meet them would you like to give them money and if you do then I'm going to give them twice as much money as I gave you and then they're going to be allowed to give any amount back to you okay so think would you trust that other person okay so it turns out that many people will trust an unknown partner they'll believe that they're going to get more money back all right maybe three times more instead of two times more sorry it's that wrong right but they'll believe that someone over whom they have no control and they've never met will give them more money on the other hand if you tell them oh they'll give you uh They're Gonna Keep like 1.8 times more money that I gave you and they're only going to give you 1.2 times back even though they would make more money people reject that offer they say no I don't want to trade with someone who isn't fair even if it would benefit me I reject that they don't get that money that's my money somehow right we have this feeling so this is what trust really is trust is relationship it's it's building up a community of people that you have expectations about that are probably not necessarily going to do the right thing that's what trust is okay and so my entire point of this talk is basically why that's not what we should be trying to do with AI okay and just really quickly uh if you think well that's crazy why would you trust it this is something where we simulated a version of that and the blue line there is Trust so the trust it and what the what's going on here is the different people in the Society of people that's in a society are copying the most successful ones and so once people start giving a high return value more than fair return value that it makes sense to trust everyone right and then if those other people start defecting and not giving the return value which they can do and they can make a lot of money in that brief period of defecting then trust plummets the game breaks down and then it builds up again so that's the kind of dynamics that we see in humans all right and we we just simulated a version of that that's what the paper's about but now that we have a model that we can say what what does it take to get trust and so what's going on on the bottom of this graph here this is how many people you could choose between and what's going on on the the y-axis there is how much do How likely is it that you know how much to give back to you okay and what you see is that if you have too much information you don't need trust okay you don't need to trust you could just pick whoever's going to give you the highest return value so trust doesn't grow in that Society because you have perfect information similarly if you don't have any choice then people don't become trustworthy all right there's no reason to become the kind of person that gives a good return right this is the other side this is people that are being trusted and notice that if they are if you have lots of choice and you have um lots of information they basically have to give you all the money back right so that's actually a no trust situation it drives me crazy when people say why is it that now we trust everyone we just jump in the cards of strangers no if you have Uber you have you know that you're getting mapped where you're going right you have way more personal security than jumping into a taxi you you know that you're they know they're going to be paid something like one-tenth of Taxi rights do not get paid right but you've got two credit cards signed up that's not trust that's knowledge that's certain knowledge that almost certainly this this transaction is going to work right so that's the difference this is a different question sorry in the cartoons I am British you can tell by my accent right okay so um why do we tolerate hierarchy I don't usually talk about people I like to talk about monkeys it's easier okay so um there's a big question why do all these monkeys hanging around have to act subservient to the to the big monkeys right well the reason is because even if they get treated a little worse maybe they don't get us have as much sex as they'd like to at least they're with the others they know where the food is there's some access right and in fact this whole turn this this question that anthropologists used to have eventually got turned on its head they're like well wait a minute why are why are the big monkeys allowing these these little monkeys to stay around and get some of the food and the sex and stuff well they don't have time to chase all the other guys away all right it just isn't worth it so this is a relationship even if you say well these guys aren't equals they're near equals this is the kind of context where you can build up a society and this is what we do all social species you know chickens and stuff they all figure out how are we going to get together and we work on it because we're sort of peers even Elon okay kind of kind of appear all right robots are not our peers all right they're designed and they're owned you know I I was horrified the first time I heard this is not how we used to think about consent in the 70s when I was in school but now they say you cannot consent to have sex with your owner if you're a slave so all the children born out of whatever relationship that people may have felt like there was love or whatever there's that is not considered a statutory rape to have had sex with somebody you owned right so in the current thinking ethical thinking this means that it's impossible to have a consensual relationship you are not building a society was something that you've designed or something you've owned that doesn't make sense and um the other thing is robots aren't our peers they just aren't they're Nothing Like Us right so yeah the right way to think about robots actually and this is my main concern I can talk about the ethics if you want is that there are parts of corporations that we've stuck into our houses right they're not they're not people so um there's no way that we as individuals can treat an entire Corporation as a peer but we can build other structures such that they can more or less interact as peers that's what we've done with the EU right we made it so that all of us can sort of be peers with the US and China and India right um so similarly we build governments to try to keep the company the companies around us more or less in line with each other right so I've just talked about trust I hope that wasn't too long now I'm going to do intelligence all right first I'm going to start with computation a lot of people I don't think people in this room so I can go fast on this forget the computations the physical process it takes time space and energy it's not magic you don't just suddenly know something right that's why you have to plug in your computer it's not just for the light okay the omniscence is impossible no one is ever going to perfectly know things I have been in the rooms with American generals who thought that first of all they thought deep learning was the algorithm and we were now going to have all the knowledge and then they realized we didn't and they thought oh no what does the Chinese find the the the the algorithm before we do and it was just like literally it was one of the most terrifying rooms I've ever been in okay so so no you you won't get a perfect understanding of the universe we don't want that we actually want what what we as intelligent organisms usually want is a subset of that so intelligence is a subset of computation first of all so of all the kinds of computation there are it's the kind that generates action now this is one of those things that drives some people crazy because that's why I think the AI act has very bad by the applicability because I'm saying everything yes I don't care if it's an Excel Street sheet if it's taking an action that determines where your kid goes to school or what Healthcare you get then let's call it Ai and let's make sure that we can check who wrote it okay which is basically all the AI act does it's like a little bit of like meta information about who wrote the code when all right so intelligence agents only perceive a subside the universe and then they represent a little bit of it to make enough of a prediction that they can do the next thing we're all limited right and that includes with AI yeah this thing about infrastructure again this has already been said enough I can go super fast through this just don't forget it's not just the data it's not just the algorithms it's also the infrastructure Google and I'm not sure they're the only ones I just know more about them they have optic fiber optic networks around the world their own right they have chip Fab they use their own chips right they found out that their own national government was hacking them when Snowden did his leaks and they were really angry because they were already cooperating with that same government more than they wanted to and they still got hacked right so yeah AI is much more than data or algorithms and the tech Giants are I would argue significant transnational assets and I don't mean in intelligence the other kind of intelligence layer although a bit right I mean that this is infrastructure okay so going back to the definitions again artificial intelligence is really easy to Define if you accepted that previous definition it's just all the intelligence stuff that somebody built okay and then agents A lot of people think I don't mean that I mean some kind of agency there's a lot of definitions of agency these are not the only definitions that's why there's this caveat at the top but if you think about like for example a chemical reaction the things that change the world are typically called agents the things we actually care about are the moral agents who is it that's responsible for doing something and the other thing we care about is the moral patience which don't have to be intelligent for example the the ecosystem is something we now think we have to take care of right and basically you need to realize that we don't have agreement about who our moral agents we don't all agree about how old you have to be to be an adult how old you have to be to consent to sex how old you have to be to fight in a war these are things that that societies come up with and so this stuff is all stuff you could look up in the dictionary this stuff was really controversial for a while while but some people are taking it for granted now the idea is that ethics itself is basically composed of who do you think is the moral agent so who do you think the moral patients are and it is also Society specific now why people hate that is because they want to say but we're more ethical than we used to be that's fine you just have to say on what metrics so like we're more ethical because more people can work now or we have lower infant mortality or we you know we have better health care or something you can still say it you just can't just assume there's a single set of Ethics you have to choose one so I would argue that responsibility is the fundamental it's almost the definitional property of the moral agents right it's what we assign to each other to keep our societies together right that's what we're doing when we build a society and again this goes back to why I showed you the monkeys besides what they're cute all right this is what we have to do to build a society so trust is as I mentioned the relationship between peers where we're basically realizing we can't micromanage you but we're going to let you go and do things right accountability is your ability to re to trace responsibilities so if something goes wrong who did it and transparency is just how we Implement accountability it's not an end to itself okay open sourcing all your code neither necessary nor sufficient what will you need to know and this is all we want again from like the AI Act is can we tell who it is that was responsible as something went horribly wrong okay so uh yeah I already talked about that so I can skip that um again you can't make the robots responsible I should check my own watch I just realized I can't see time there's no time oh yeah I have 13 minutes okay great easy I want to leave you some time for questions though anyway you aren't going to build something that cares about being stuck in jail all right you just aren't and if you do you could unbuild it all right so just we're not going to throw the robots in jail all right that's a smart law people that helped write that paper right uh do you care about how the robots feel who cares anyone care about how the robots feel anyway don't worry that if worry about the cows first and the Rats because the rats and the cows experience much more like our feelings you know separation when you pull the calf off the cow so that you can have milk and stuff that's much more like what a woman being separate from her child is like then anything that's ever going to happen to a robot okay so we just aren't going to build those things the Arthur and Architects the experience of AI even if we could make it suffer that would probably be immoral given that we're going to own it right so why are people even talking about that uh some people say well we have to feel obliged to AI because we because we identify with it and they go back to Kant okay so Kant was saying oh like you know I don't know how God feels about the moral status of dogs but I noticed that people who treat dogs badly treat people badly so we can't we we shouldn't we shouldn't treat dogs badly okay I'm down with that I'm down with feeding dogs well but that doesn't make sense in AI if you think that's true of AI you've forgotten that it's uh that it's a artifact the A is for artifact right that I think it's wrong to believe that we have to do this because first of all a lot of super intelligent things as was just mentioned on the previous panel people don't even identify with right they don't identify with their phones they don't identify with Google search but secondly um yeah we could just fix it right if we know that then we can and that's one of the things the AI Act is doing as was correctly identified in the first keynote this morning you have to say if something is an artifact right you have to make it clear so people know they're not talking to a person they're talking to a thing which is actually a huge challenge to most natural language processing stuff that's going on right now because actually there's like usually one person running like 20 sock sock you know sock puppets whatever AI Bots they're sort of talking to you right but anyway I had no idea that that was going to be a challenge but then I did the zero European chat Bots super interesting anyway so Ai and law are both authored cultural artifacts so it's not a scientific matter about like is AI a moral patient or not right this is something we pick we pick both when we Define what our moral patients are and by how we design the AI system and I would argue like let's build it so that we don't have to complicate our law any more than necessary right so all we can do is science is predict what the outcomes of policy is and philosophy can sometimes discover logical fallacies but basically normative stuff that's what we hire politicians for and that's what we work as communities to determine okay EU regulations remember I said this thing about that keeping corporations to a pure like scale was like what antitrust law competition law is about this is all the rules this is one of my uh colleagues collaborators Helena malikova director General competition put the slide together and I didn't even know about all these things these are all the ones that she knows about being in the in the director General competition that our AI intensive legislation and look the dma the DSA and the gdpr are already done I almost feel like the AI Act is like this trial balloon for like letting Google and Microsoft shoe that because again there's so little in it I can't believe how much fuss there's been all right like other things I think about like valid consent um whether or not you can correct if there's an error the right to know what how a decision was made about you that's actually in the gdpr already all right what's the sorry about that if you can get the slides just email me or Twitter me or something I'll send you the slides okay aim to benefit the EU oh yeah the Digital Services Act is trying to make again all this legislation is about growing our digital economy that's the whole point right so we want a safe predictable trusted online environment by making it easier to defend users rights online and so the three things that really focuses on is profiling recommendation systems and targeted advertisements so I just mentioned also the gdpr sort of the profiling you're making sure that that information about you is accurate recommendation systems um are you know I would argue that Facebook and Twitter were both better when when we actually worked to follow people that didn't talk too much but talked about stuff that was interesting and weren't rude then getting recommendations I think that's actually worse it's it's made the experience worse and it's also given people in fact Jack wrote A Blog about this and that Elon bought the blog site and took it down so you couldn't read it anymore but Jack said the big mistake we made at Twitter was two years ago we had an activist person on the board and we started building more tools for other people to control our user experience when what we should have been doing was letting the users control their own experience and helping them understand but literally they apparently hired some guys from Facebook who said if you're asking the users questions you're losing you should just learn this stuff and that's just wrong okay anyway recommender systems um yeah and you know on the other hand there's nothing you can do but recommend with web search that's what web search is and and I kind of do get that it's kind of convenient to have some of the you know the trending topics stuff that is recommended Target advertising again some people claim it's not giving sales benefit yet look at this all the money that used to go to newspapers is now going to Google and Facebook right so I don't know what's going on there if it's the companies believe they need the information or if other people are encouraging this information to be gathered I don't know um yeah the AI regulation itself it does this categorization about what we don't want to be which is basically China right um so we're supposedly not going to do any biometric tracking or social credit scoring although in the US we already do but of course the US is not part of the EU um but but we don't have only one social credit score we have multiple um credit scores but anyway the high risk is the stuff that affects human outcomes so we don't want to have the kind of thing that happened in the UK with their post office Scandal we don't want to have that kind of thing happen in the Netherlands with their benefit scandals there ought to be ways to appeal if there's a really bad decisions being routinely taken if you can give evidence to that so you basically just need to document what you did this is basic devops this is you know if trust me it was a big deal and we started innovating devops in the 1980s development and operations keeping revision control knowing who had changed the code when and like maybe if we were lucky they put a note about why is basically all the AI Act is asking you to do and I recommend even if you don't have a high risk system that's really a good idea we figured that out in software engineering in the 80s why AI companies don't do that I don't know all right and it actually isn't that expensive um you do have to go and catalog where you do this or whatever and most people as I mentioned only have to identify as as was mentioned by the bot in the first keynote so um I think yeah I would I would encourage people who aren't yet doing high risk AI to voluntarily comply with some of the documentation it will just help you prove limit your liability so this is the big deal the AI action the DSA both say we ought to be able to audit and it's funny because some guy from Eli said to me that I was working on some space project with Anyway said you you say that they have all this information but you know they don't I want to be clear about this AI is easily auditable if you choose to do the right thing if you do keep those records it is also easily impossible to track what what what's done if somebody throws that information away right and that is negligent okay in any other sector you would be liable like you people keep that information to prove that they followed best practice and so they don't have to be liable right and if and for those of you who work with people that have you know you know real products you know they're already governed sectors you know that right they're they're like oh yeah we spend a bunch of time doing those kinds of things so yeah ordinary product law assumes that you can prove you've done due diligence what is due diligence it's what your sector says it is you don't have to keep writing the law that keeps up with AI you just have to have trade magazines that say most of us know that you know for example you you have a duty of care for the the information you scrape from your users right and that you shouldn't just sell that right maybe you use it for advertising but you don't just sell it right and that's the kind of thing that was used in these prosecutions again I love the previous panel um that were done uh uh in the EU in Allison Canada but not in the U.S yeah so Financial audits are the consultancies main Revenue sources and so they're actually kind of nervous about getting involved in this and they can't do it for people that they're already financially auditing and so they're trying to say oh we don't want to call it audits we're going to call it Assurance um but and they're talking about doing it on top of risk assessment I think that's wrong I think we should be starting from our cyber security audits because it's much you know first of all if the system isn't cyber secure then how can you possibly say that you're responsible for it you need to know that you're the one who actually wrote the code or that your owner operator actually used the code that is the normal problem you have like with a car right you either you negligently built it or the driver negligently drove it if it smashes into a tree right or there was an act of God or something ice I don't know okay so I'm going to skip this I'm running out of time and I want to be able to ask questions but I I just want to say there were so many people worried about uh like you know like bad words in their in their data models look what we've known I I was one of the people in 2017 which we've known for at least six years now is that if you learn about the world you find out what it's like and and a lot of those things are bad biases right like the stuff about uh women being more likely to be uh uh doing the laundry or something right it's gonna replicate lived experience and that's okay I don't think we need to throw that out we need to make something that's easily auditable the reason that that corporations don't like having four steps like this is because uh it's a little slower right but but they're there I was just at some within with World economic Forum people are starting to say maybe it's worth paying a little bit of time penalty maybe taking one or two hops to have something that's clearly auditable and so that we can tell for example um you know what what was done in the in the language model and what's being done at the app level just making that a little clearer not selling gluing those pieces together all right so anyway the whole thing is the translator don't have a moral Panic about what's in the language model do other things to do whatever you've decided fare was all right okay so yeah I already said this everything in the digital system is actually easily transparent you just have to keep track and transparent to the level that you need for accountability you just need to document all the stuff about where you got your data where you got your software libraries you may say well that's a pain it's a pain we haven't done before but solar winds happened Two Chains back in the software Library if you want to be responsible if you're doing if you're playing games fine I don't care except if your user data is bleeding out to the internet or to China or something but if you're if you're writing a medical application spend a little extra money buying buying your software libraries okay being sure or doing an open source one that you're really really you know it's been very carefully validated right so all of this stuff is not only helpful for if you ever get audited there's a question if there's capacity but also it will benefit you when you go back and try to check what you were doing right I can't believe c-suites aren't demanding to be able to know what their systems were architected to do so that's all I had to say I just and this is my point AI isn't something somebody tells you to trust AI is something you audit okay thank you [Applause] I'm so I'm really sorry for tired I'm really sorry for tired people I thought I had a half hour and then they told me I had 20 minutes are there any questions yes over there so um I uh have a big fear as many other people have which is that if we regulate AI in the way that it's currently designed to be regulated that Europe will fall back a lot in not only AI but also will fall back in industry and in any sector so um when we take the example of the translation I I agree that this is off obviously a biased translation so we just take common practice from the past um from old books old texts where these these roles of the role models were were like that which are not now um but does it mean that you would say rather than having the the the risk that this translation is biased like it is forbidding all translation systems that could possibly bias are not forbidding but having the document and and fix this first and ordered it first before using anything that could work like that okay translation is just an example okay which you gave right so so the um the answer to that question first of all we programmers tend to think like things have to be in these weird absolutes so I remember the trolley remember the trolley problem lawyers lawyers are like oh that happens every time we put up a stop sign that you know there's some people that are going to be killed that are different than the ones who are going to be killed before we just have to deal with that right it's not it's not the end of the world so similarly about about um again I was just at this this thing about uh governing uh generative AI the um first of all everybody is trying to vet and at least document what the biases in their system are and where it comes from and I think people are getting a better understanding of the fact that there will be biases and then you then once you certify as somebody who's selling a large language model or a solely access language large language model is how much vetting you did how much you you fixed it whatever and then the application developers make sure that people understand that too so it is about not necessarily about having this perfect piece of software but better but more about as I said building up a standard of good practice and communication and on this particular thing on bias we're getting there I think people are really starting to get that I got to tell you guys the story everyone says what about Amazon because you know they were hiring only male programmers no Amazon released that news story to show that how good it was that they checked and they noticed that their program said this and they didn't use it okay that was actually an AI ethics win it wasn't an AIS six lose and Ms sun is just bad at PR it's just really weird but but these things happen in social media I hope that I covered most of that question how can we how can we fight bias in this field oh uh how do you flag bias what people do is they like I said they establish practice about what they look for it oh how do we flag it if we see it that depends on the product so some products are allowing you to report but mostly people are just saying uh yeah that that that's it's something that should be checked either at the application level or as I said the model level and then when you're an app builder you choose whether you want that responsibility you can pass it on to your users and say you guys know we didn't do bias on this right or you can pass it on be back to you and say we only want an llm that has the current state of the art bias you know erasing and we don't care it's a little slower or whatever or you take care of it yourself you just add a little layer in there that looks for like you know gender stuff or whatever and you have a little bit of extra work and you slow down your app a little tiny bit so it's like this what we've heard before not the machine learning but then the machine teaching kind of thing it's the machine being used to measure I still don't like to ever talk about when you say the machine is doing something yeah you're giving an agency so it's what we do with the machines and what we can do is actually measure and improve our society yeah and I mean in the machine learning process we also teach the system right with the full spec thing okay but we need to continue uh thank you so much sure you're welcome