# AGI
## The age of spiritual machines.

* Should we start designing for a post-AGI society?
* What happens when our lives change because of AGI?
* Are we already there?

---

Artificial General Intelligence. Should we start designing for post-AGI? What happens when our lives change because of AGI? Are we already there?

The big takeaway is this: we don't have a chart for AGI. There's no clear map between here and there. It's extremely open-ended what we even mean by it and how it's different from our current levels of AI.

What we can be certain of is that AGI will likely be a combination of AI modalities. It won't just be language models or image generation or predictive AI - it will be all of these and more, working together with agency.

OpenAI defines AGI as "highly autonomous systems that outperform humans at most economically valuable work." But other thinkers, like Joscha Bach, see it as a system that reaches human level or beyond across all capability dimensions.

These capability dimensions are crucial. We're not just talking about narrow skills, but a broad spectrum including perception, reasoning, learning, representation, self-knowledge, language, and collaboration. For an AI to be truly "general", it needs to be capable across all these areas.

Prediction markets currently suggest we'll have AGI around 2032. But this entirely depends on how we define AGI and how we'll even know when we've achieved it. Some argue we've already seen "sparks of AGI" in models like GPT-4.

This chapter will explore various perspectives on AGI, its potential implications, and the ethical considerations we need to grapple with. We'll look at the current state of research, the challenges ahead, and what it might mean for humanity if and when we achieve AGI.

Remember, as Edsger W. Dijkstra said, "The question of whether machines can think is about as relevant as the question of whether submarines can swim." Perhaps we need to reframe how we think about intelligence altogether.


Slide-74.webp


image153-337.webp