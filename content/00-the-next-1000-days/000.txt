# The Next 1.000 Days
## Your guide for navigating the transition toward AGI. 

I am convinced that in the next few years, we will all be experiencing the effects of Artificial General Intelligence. 

AI is having a moment. Decades of fundamental discoveries and years of quiet revolutions are giving rise to a sudden explosion of applications in unexpected places.

Unlike other hype-heavy technologies of recent years, AI is already useful. While it’s acceleration might taper off, the genie isn’t going back into the bottle. This leaves us with an infinitude of questions to grapple with, by people of all levels of technical literacy, which will impact generations to come. That is why this newsletter exists: to inform the curious and help more people understand the underlying principles and possible outcomes of our collective transition towards artificial general intelligence.

You don’t have time to learn everything but want to keep up to speed. 

Every week you will find a selection of links with interviews and explainers by players in the AI space, with personal commentary from somebody dedicated to exploring the intersection of human and machine intelligence. The AI revolution might very well eclipse the technological advancements of the last century, or it could go nowhere. This will help you navigate whatever happens next.



--

How do you talk about something without hyping it? How do you avoid misrepresenting your observations while maintaining a level of excitement about something that is clearly going to affect a lot of people?

I try maintaining an equanimous view of technology – it is neither utopian, dystopian or protopian to me. Technology is an extension of our humanity, and how we utilize it says a lot about our values. Yet it is impossible to judge such hyperobjects in any meaningful way. That doesn’t mean we should abandon morals, but rather not try to classify technology as being something or the other. The only thing that matters is how we use it.

I am not sure whether such equanimity extends to AI. You could argue that all technology is out of our control, and that the technium is a form of superstructure with emergent characteristics and therefore it was never ours to control. But there is something inherently different with autonomous technology. It acts uncannily and messes with our expectations of how technology should behave. AI will only grow in size and relevance, and how it shapes our perception of the world should be strongly considered in how we act, plan and legislate moving forward.

Nobody is individually capable of shaping the development of AI. It will manifest as a combination of multiple areas of research combined with nearly infinite different applications. Somewhere at the intersection of computer science, statistics, ethics and linguistics sits AI, almost as a culmination of our capabilities. The sum total of what we know. There is no panic button for something like this. Much like how the internet was designed to withstand nuclear war, AI cannot be unplugged. It will keep developing and extending in vectors we can barely fathom. 

Where it goes from here depends only on us, and our ability to seize the moment, inform ourselves, and make better collective decisions. The alternative is having this inflection point seized by those with deepest pockets, who will inevitably shape the outcome towards greater personal benefit. 

As a collective technology, AI needs to be belong to everyone.





The purpose of this newsletter is to help more people think about the long term implications of AI while learning about how to actually work with these tools, as we might or might not progress towards forms of artificial general intelligence. A regular dose of interviews and articles works for me and how I make sense of the world. Maybe something else works for you. Help me shape this publication by replying with feedback or sharing it on your socials – shouting into the void can be its own reward, but knowing where you’re at is always welcome.

---


