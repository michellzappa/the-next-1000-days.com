---
title: "Training Data"
summary: "Dataset used to teach a ML model how to make predictions or perform tasks."
---
Training data is a crucial component in the field of machine learning, where it is used to build models capable of making predictions or decisions without being explicitly programmed to do so. This data consists of examples or observations that include input data along with the correct output, the latter often labeled by humans. The quality and quantity of training data can significantly impact the performance of machine learning models, influencing their ability to generalize well to new, unseen data. Training data must be representative of the real-world scenarios the model will encounter to avoid issues like overfitting (where the model performs well on the training data but poorly on new data) and underfitting (where the model is too simple to capture the underlying pattern).

The concept of training data has been integral to machine learning since its inception, gaining prominence as computational capacities expanded in the 1990s and 2000s, enabling more complex models to be trained on larger datasets.

While it's challenging to pinpoint specific contributors to the concept of training data, this concept has evolved with contributions from many fields including statistics, computer science, and various application domains that generate large datasets. Key figures in early machine learning and neural networks, such as Arthur Samuel and Frank Rosenblatt, indirectly contributed to how training data is used in AI systems.

