---
title: Decidability
summary: Whether a problem can be algorithmically solved, meaning there exists a clear procedure (algorithm) that will determine a yes-or-no answer for any given input within a finite amount of time.
---
**2. Detailed explanation:** In computational theory, a problem is decidable if there exists an algorithm that can always provide a solution for any input from a given set of instances, and do so within finite time. This concept is crucial in distinguishing between problems that can be completely solved using algorithms (decidable problems) and those that cannot (undecidable problems). Decidability is fundamental to understanding the limits of computation. For instance, the Halting Problem—determining whether a computer program will finish running or continue indefinitely—is a classic example of an undecidable problem. Decidability is central in fields like formal logic, where it helps in understanding which logical systems can be fully automated, and in computer science, particularly in the areas of algorithm design, complexity theory, and formal verification.

**3. Historical overview:** The concept of decidability dates back to the early 20th century, with roots in mathematical logic. It gained prominence in 1936 when Alan Turing introduced the concept of Turing machines, which formalized the idea of computation. His work, along with contemporaries like Alonzo Church, laid the foundation for understanding decidability and undecidability in computational theory.

**4. Key contributors:** Key figures in the development of decidability include Alan Turing, who formalized the notion of algorithmic computation, and Alonzo Church, who developed the lambda calculus. Both played pivotal roles in the formulation of the Church-Turing thesis, which asserts that any function that can be computed algorithmically can be computed by a Turing machine, thus linking it to the notion of decidability.